apiVersion: v1
items:
- apiVersion: v1
  data:
    process_anomaly_detector.py: "#!/usr/bin/env python3\n\"\"\"\nAdvanced Process
      Anomaly Detection System\n\nDetects anomalies in:\n- CPU usage patterns per
      process group\n- Memory consumption patterns\n- Process spawn behavior\n- New/unknown
      processes\n- Resource consumption changes\n\"\"\"\n\nimport requests\nimport
      numpy as np\nimport time\nimport logging\nimport json\nimport os\nfrom datetime
      import datetime, timedelta\nfrom typing import Dict, List, Tuple, Optional\nfrom
      collections import defaultdict, deque\nfrom prometheus_client import start_http_server,
      Gauge, Counter, Histogram, Info\nfrom sklearn.ensemble import IsolationForest\nfrom
      sklearn.preprocessing import StandardScaler\nimport joblib\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#
      Configure logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s
      - %(levelname)s - %(message)s')\nlogger = logging.getLogger('process-anomaly-detector')\n\n#
      Configuration\nPROMETHEUS_URL = os.getenv('PROMETHEUS_URL', 'http://prometheus:9090')\nDETECTION_INTERVAL
      = int(os.getenv('DETECTION_INTERVAL', '60'))  # seconds\nHISTORY_RETENTION_HOURS
      = int(os.getenv('HISTORY_RETENTION_HOURS', '24'))\nMODEL_RETRAIN_HOURS = int(os.getenv('MODEL_RETRAIN_HOURS',
      '6'))\nANOMALY_THRESHOLD = float(os.getenv('ANOMALY_THRESHOLD', '0.1'))  # Lower
      = more sensitive\n\n# Storage paths\nMODEL_DIR = '/tmp/process_models'\nHISTORY_DIR
      = '/tmp/process_history'\n\n# Prometheus metrics\nprocess_cpu_anomaly_score
      = Gauge('process_cpu_anomaly_score', 'Process CPU usage anomaly score', ['groupname',
      'instance'])\nprocess_memory_anomaly_score = Gauge('process_memory_anomaly_score',
      'Process memory usage anomaly score', ['groupname', 'instance'])\nprocess_count_anomaly_score
      = Gauge('process_count_anomaly_score', 'Process count anomaly score', ['groupname',
      'instance'])\nprocess_new_process_detected = Counter('process_new_process_detected_total',
      'New processes detected', ['groupname', 'instance'])\nprocess_anomaly_alerts
      = Counter('process_anomaly_alerts_total', 'Process anomaly alerts triggered',
      ['type', 'groupname', 'instance'])\n\n# Model info\nmodel_info = Info('process_anomaly_model_info',
      'Process anomaly detection model information')\nmodel_last_trained = Gauge('process_anomaly_model_last_trained_timestamp',
      'Last model training timestamp')\n\n# Detection statistics\ndetection_duration
      = Histogram('process_anomaly_detection_duration_seconds', 'Time spent on anomaly
      detection')\nprocesses_analyzed = Gauge('process_anomaly_processes_analyzed_total',
      'Number of processes analyzed')\n\nclass ProcessAnomalyDetector:\n    def __init__(self):\n
      \       self.models = {}\n        self.scalers = {}\n        self.process_history
      = defaultdict(lambda: deque(maxlen=1000))\n        self.known_processes = set()\n
      \       self.baseline_stats = {}\n        self.last_model_train = 0\n        \n
      \       # Create directories\n        os.makedirs(MODEL_DIR, exist_ok=True)\n
      \       os.makedirs(HISTORY_DIR, exist_ok=True)\n        \n        # Load existing
      models and history\n        self.load_models()\n        self.load_history()\n
      \       \n    def prometheus_query(self, query: str, start_time: Optional[str]
      = None) -> List[Dict]:\n        \"\"\"Execute Prometheus query\"\"\"\n        try:\n
      \           if start_time:\n                url = f\"{PROMETHEUS_URL}/api/v1/query_range\"\n
      \               params = {\n                    'query': query,\n                    'start':
      start_time,\n                    'end': str(int(time.time())),\n                    'step':
      '60s'\n                }\n            else:\n                url = f\"{PROMETHEUS_URL}/api/v1/query\"\n
      \               params = {'query': query}\n            \n            response
      = requests.get(url, params=params, timeout=30)\n            response.raise_for_status()\n
      \           data = response.json()\n            \n            if data['status']
      == 'success':\n                return data['data']['result']\n            else:\n
      \               logger.error(f\"Prometheus query failed: {data}\")\n                return
      []\n        except Exception as e:\n            logger.error(f\"Prometheus query
      error: {e}\")\n            return []\n    \n    def collect_process_metrics(self)
      -> Dict:\n        \"\"\"Collect current process metrics\"\"\"\n        metrics
      = {\n            'cpu_usage': {},\n            'memory_usage': {},\n            'process_counts':
      {},\n            'timestamp': time.time()\n        }\n        \n        # CPU
      usage rate (per second)\n        cpu_query = 'rate(namedprocess_namegroup_cpu_seconds_total[5m])
      * 100'\n        cpu_results = self.prometheus_query(cpu_query)\n        \n        for
      result in cpu_results:\n            groupname = result['metric'].get('groupname',
      'unknown')\n            instance = result['metric'].get('instance', 'localhost')\n
      \           value = float(result['value'][1])\n            metrics['cpu_usage'][f\"{groupname}@{instance}\"]
      = value\n        \n        # Memory usage (MB)\n        memory_query = 'namedprocess_namegroup_memory_bytes
      / 1024 / 1024'\n        memory_results = self.prometheus_query(memory_query)\n
      \       \n        for result in memory_results:\n            groupname = result['metric'].get('groupname',
      'unknown')\n            instance = result['metric'].get('instance', 'localhost')\n
      \           value = float(result['value'][1])\n            metrics['memory_usage'][f\"{groupname}@{instance}\"]
      = value\n        \n        # Process counts\n        count_query = 'namedprocess_namegroup_num_procs'\n
      \       count_results = self.prometheus_query(count_query)\n        \n        for
      result in count_results:\n            groupname = result['metric'].get('groupname',
      'unknown')\n            instance = result['metric'].get('instance', 'localhost')\n
      \           value = float(result['value'][1])\n            metrics['process_counts'][f\"{groupname}@{instance}\"]
      = value\n        \n        return metrics\n    \n    def collect_historical_data(self,
      hours: int = 24) -> Dict:\n        \"\"\"Collect historical process data for
      training\"\"\"\n        end_time = int(time.time())\n        start_time = end_time
      - (hours * 3600)\n        \n        logger.info(f\"Collecting {hours}h of historical
      data for model training...\")\n        \n        historical_data = defaultdict(list)\n
      \       \n        # Collect historical CPU data\n        cpu_query = 'rate(namedprocess_namegroup_cpu_seconds_total[5m])
      * 100'\n        cpu_results = self.prometheus_query(cpu_query, str(start_time))\n
      \       \n        for result in cpu_results:\n            groupname = result['metric'].get('groupname',
      'unknown')\n            instance = result['metric'].get('instance', 'localhost')\n
      \           process_key = f\"{groupname}@{instance}\"\n            \n            for
      timestamp, value in result['values']:\n                historical_data[process_key].append({\n
      \                   'timestamp': float(timestamp),\n                    'cpu_usage':
      float(value),\n                    'memory_usage': 0,  # Will be filled later\n
      \                   'process_count': 0\n                })\n        \n        #
      Collect historical memory data\n        memory_query = 'namedprocess_namegroup_memory_bytes
      / 1024 / 1024'\n        memory_results = self.prometheus_query(memory_query,
      str(start_time))\n        \n        for result in memory_results:\n            groupname
      = result['metric'].get('groupname', 'unknown')\n            instance = result['metric'].get('instance',
      'localhost')\n            process_key = f\"{groupname}@{instance}\"\n            \n
      \           for timestamp, value in result['values']:\n                # Find
      matching timestamp in historical_data\n                for entry in historical_data[process_key]:\n
      \                   if abs(entry['timestamp'] - float(timestamp)) < 30:  # 30
      second tolerance\n                        entry['memory_usage'] = float(value)\n
      \                       break\n        \n        # Collect historical process
      count data\n        count_query = 'namedprocess_namegroup_num_procs'\n        count_results
      = self.prometheus_query(count_query, str(start_time))\n        \n        for
      result in count_results:\n            groupname = result['metric'].get('groupname',
      'unknown')\n            instance = result['metric'].get('instance', 'localhost')\n
      \           process_key = f\"{groupname}@{instance}\"\n            \n            for
      timestamp, value in result['values']:\n                # Find matching timestamp
      in historical_data\n                for entry in historical_data[process_key]:\n
      \                   if abs(entry['timestamp'] - float(timestamp)) < 30:  # 30
      second tolerance\n                        entry['process_count'] = float(value)\n
      \                       break\n        \n        return dict(historical_data)\n
      \   \n    def train_models(self):\n        \"\"\"Train anomaly detection models
      for each process\"\"\"\n        logger.info(\"Starting model training...\")\n
      \       \n        # Collect training data\n        historical_data = self.collect_historical_data(HISTORY_RETENTION_HOURS)\n
      \       \n        trained_count = 0\n        for process_key, data_points in
      historical_data.items():\n            if len(data_points) < 50:  # Need minimum
      data points\n                continue\n            \n            # Prepare features\n
      \           features = []\n            for point in data_points:\n                features.append([\n
      \                   point['cpu_usage'],\n                    point['memory_usage'],\n
      \                   point['process_count']\n                ])\n            \n
      \           features = np.array(features)\n            \n            # Remove
      invalid data points\n            valid_mask = ~np.isnan(features).any(axis=1)
      & ~np.isinf(features).any(axis=1)\n            features = features[valid_mask]\n
      \           \n            if len(features) < 20:\n                continue\n
      \           \n            try:\n                # Scale features\n                scaler
      = StandardScaler()\n                features_scaled = scaler.fit_transform(features)\n
      \               \n                # Train Isolation Forest\n                model
      = IsolationForest(\n                    contamination=ANOMALY_THRESHOLD,\n                    random_state=42,\n
      \                   n_estimators=100\n                )\n                model.fit(features_scaled)\n
      \               \n                # Store model and scaler\n                self.models[process_key]
      = model\n                self.scalers[process_key] = scaler\n                \n
      \               # Calculate baseline statistics\n                self.baseline_stats[process_key]
      = {\n                    'cpu_mean': float(np.mean(features[:, 0])),\n                    'cpu_std':
      float(np.std(features[:, 0])),\n                    'memory_mean': float(np.mean(features[:,
      1])),\n                    'memory_std': float(np.std(features[:, 1])),\n                    'count_mean':
      float(np.mean(features[:, 2])),\n                    'count_std': float(np.std(features[:,
      2]))\n                }\n                \n                trained_count +=
      1\n                \n            except Exception as e:\n                logger.error(f\"Failed
      to train model for {process_key}: {e}\")\n        \n        self.last_model_train
      = time.time()\n        logger.info(f\"Trained {trained_count} models\")\n        \n
      \       # Save models\n        self.save_models()\n        \n        # Update
      metrics\n        model_last_trained.set(self.last_model_train)\n        model_info.info({\n
      \           'models_trained': str(trained_count),\n            'last_training':
      datetime.fromtimestamp(self.last_model_train).isoformat(),\n            'contamination_threshold':
      str(ANOMALY_THRESHOLD)\n        })\n    \n    def detect_anomalies(self, current_metrics:
      Dict) -> Dict:\n        \"\"\"Detect anomalies in current metrics\"\"\"\n        anomalies
      = {\n            'cpu_anomalies': {},\n            'memory_anomalies': {},\n
      \           'count_anomalies': {},\n            'new_processes': []\n        }\n
      \       \n        # Check for new processes\n        current_processes = set()\n
      \       for metric_type in ['cpu_usage', 'memory_usage', 'process_counts']:\n
      \           current_processes.update(current_metrics[metric_type].keys())\n
      \       \n        new_processes = current_processes - self.known_processes\n
      \       if new_processes:\n            for process in new_processes:\n                anomalies['new_processes'].append(process)\n
      \               groupname, instance = process.split('@', 1)\n                process_new_process_detected.labels(groupname=groupname,
      instance=instance).inc()\n                process_anomaly_alerts.labels(type='new_process',
      groupname=groupname, instance=instance).inc()\n                logger.warning(f\"New
      process detected: {process}\")\n            \n            self.known_processes.update(new_processes)\n
      \       \n        # Analyze each process for anomalies\n        for process_key
      in current_processes:\n            if process_key not in self.models:\n                continue\n
      \           \n            try:\n                # Prepare current features\n
      \               cpu_usage = current_metrics['cpu_usage'].get(process_key, 0)\n
      \               memory_usage = current_metrics['memory_usage'].get(process_key,
      0)\n                process_count = current_metrics['process_counts'].get(process_key,
      0)\n                \n                features = np.array([[cpu_usage, memory_usage,
      process_count]])\n                \n                # Scale features\n                scaler
      = self.scalers[process_key]\n                features_scaled = scaler.transform(features)\n
      \               \n                # Get anomaly score\n                model
      = self.models[process_key]\n                anomaly_score = model.decision_function(features_scaled)[0]\n
      \               is_anomaly = model.predict(features_scaled)[0] == -1\n                \n
      \               # Normalize score to 0-1 range (lower = more anomalous)\n                normalized_score
      = max(0, min(1, (anomaly_score + 1) / 2))\n                \n                groupname,
      instance = process_key.split('@', 1)\n                \n                # Update
      metrics\n                process_cpu_anomaly_score.labels(groupname=groupname,
      instance=instance).set(normalized_score)\n                \n                #
      Specific anomaly detection\n                baseline = self.baseline_stats.get(process_key,
      {})\n                \n                # CPU anomaly detection\n                cpu_threshold
      = baseline.get('cpu_mean', 0) + 3 * baseline.get('cpu_std', 1)\n                if
      cpu_usage > cpu_threshold or (is_anomaly and cpu_usage > baseline.get('cpu_mean',
      0)):\n                    anomalies['cpu_anomalies'][process_key] = {\n                        'current':
      cpu_usage,\n                        'threshold': cpu_threshold,\n                        'score':
      normalized_score\n                    }\n                    process_anomaly_alerts.labels(type='cpu_anomaly',
      groupname=groupname, instance=instance).inc()\n                \n                #
      Memory anomaly detection\n                memory_threshold = baseline.get('memory_mean',
      0) + 3 * baseline.get('memory_std', 1)\n                if memory_usage > memory_threshold
      or (is_anomaly and memory_usage > baseline.get('memory_mean', 0)):\n                    anomalies['memory_anomalies'][process_key]
      = {\n                        'current': memory_usage,\n                        'threshold':
      memory_threshold,\n                        'score': normalized_score\n                    }\n
      \                   process_memory_anomaly_score.labels(groupname=groupname,
      instance=instance).set(normalized_score)\n                    process_anomaly_alerts.labels(type='memory_anomaly',
      groupname=groupname, instance=instance).inc()\n                \n                #
      Process count anomaly detection\n                count_threshold = baseline.get('count_mean',
      0) + 2 * baseline.get('count_std', 1)\n                if process_count > count_threshold
      or (is_anomaly and process_count > baseline.get('count_mean', 0)):\n                    anomalies['count_anomalies'][process_key]
      = {\n                        'current': process_count,\n                        'threshold':
      count_threshold,\n                        'score': normalized_score\n                    }\n
      \                   process_count_anomaly_score.labels(groupname=groupname,
      instance=instance).set(normalized_score)\n                    process_anomaly_alerts.labels(type='count_anomaly',
      groupname=groupname, instance=instance).inc()\n                \n            except
      Exception as e:\n                logger.error(f\"Anomaly detection failed for
      {process_key}: {e}\")\n        \n        return anomalies\n    \n    def save_models(self):\n
      \       \"\"\"Save trained models to disk\"\"\"\n        try:\n            model_data
      = {\n                'models': {},\n                'scalers': {},\n                'baseline_stats':
      self.baseline_stats,\n                'known_processes': list(self.known_processes),\n
      \               'last_trained': self.last_model_train\n            }\n            \n
      \           # Save models using joblib\n            for process_key, model in
      self.models.items():\n                model_file = f\"{MODEL_DIR}/model_{process_key.replace('@',
      '_').replace('/', '_')}.joblib\"\n                joblib.dump(model, model_file)\n
      \               model_data['models'][process_key] = model_file\n            \n
      \           for process_key, scaler in self.scalers.items():\n                scaler_file
      = f\"{MODEL_DIR}/scaler_{process_key.replace('@', '_').replace('/', '_')}.joblib\"\n
      \               joblib.dump(scaler, scaler_file)\n                model_data['scalers'][process_key]
      = scaler_file\n            \n            # Save metadata\n            with open(f\"{MODEL_DIR}/metadata.json\",
      'w') as f:\n                json.dump(model_data, f, indent=2)\n            \n
      \           logger.info(f\"Saved {len(self.models)} models to {MODEL_DIR}\")\n
      \       except Exception as e:\n            logger.error(f\"Failed to save models:
      {e}\")\n    \n    def load_models(self):\n        \"\"\"Load trained models
      from disk\"\"\"\n        try:\n            metadata_file = f\"{MODEL_DIR}/metadata.json\"\n
      \           if not os.path.exists(metadata_file):\n                logger.info(\"No
      existing models found\")\n                return\n            \n            with
      open(metadata_file, 'r') as f:\n                model_data = json.load(f)\n
      \           \n            # Load models\n            for process_key, model_file
      in model_data.get('models', {}).items():\n                if os.path.exists(model_file):\n
      \                   self.models[process_key] = joblib.load(model_file)\n            \n
      \           # Load scalers\n            for process_key, scaler_file in model_data.get('scalers',
      {}).items():\n                if os.path.exists(scaler_file):\n                    self.scalers[process_key]
      = joblib.load(scaler_file)\n            \n            # Load other data\n            self.baseline_stats
      = model_data.get('baseline_stats', {})\n            self.known_processes = set(model_data.get('known_processes',
      []))\n            self.last_model_train = model_data.get('last_trained', 0)\n
      \           \n            logger.info(f\"Loaded {len(self.models)} models from
      {MODEL_DIR}\")\n            \n            # Update metrics\n            if self.last_model_train
      > 0:\n                model_last_trained.set(self.last_model_train)\n                model_info.info({\n
      \                   'models_loaded': str(len(self.models)),\n                    'last_training':
      datetime.fromtimestamp(self.last_model_train).isoformat(),\n                    'contamination_threshold':
      str(ANOMALY_THRESHOLD)\n                })\n            \n        except Exception
      as e:\n            logger.error(f\"Failed to load models: {e}\")\n    \n    def
      load_history(self):\n        \"\"\"Load process history from disk\"\"\"\n        try:\n
      \           history_file = f\"{HISTORY_DIR}/process_history.json\"\n            if
      os.path.exists(history_file):\n                with open(history_file, 'r')
      as f:\n                    history_data = json.load(f)\n                \n                for
      process_key, data_points in history_data.items():\n                    self.process_history[process_key]
      = deque(data_points, maxlen=1000)\n                \n                logger.info(f\"Loaded
      history for {len(history_data)} processes\")\n        except Exception as e:\n
      \           logger.error(f\"Failed to load history: {e}\")\n    \n    def save_history(self):\n
      \       \"\"\"Save process history to disk\"\"\"\n        try:\n            history_data
      = {}\n            for process_key, data_points in self.process_history.items():\n
      \               history_data[process_key] = list(data_points)\n            \n
      \           with open(f\"{HISTORY_DIR}/process_history.json\", 'w') as f:\n
      \               json.dump(history_data, f, indent=2)\n            \n        except
      Exception as e:\n            logger.error(f\"Failed to save history: {e}\")\n
      \   \n    def run_detection_cycle(self):\n        \"\"\"Run one complete detection
      cycle\"\"\"\n        start_time = time.time()\n        \n        try:\n            #
      Collect current metrics\n            current_metrics = self.collect_process_metrics()\n
      \           \n            # Update process count metric\n            total_processes
      = len(set().union(\n                current_metrics['cpu_usage'].keys(),\n                current_metrics['memory_usage'].keys(),\n
      \               current_metrics['process_counts'].keys()\n            ))\n            processes_analyzed.set(total_processes)\n
      \           \n            # Store in history\n            for process_key in
      current_metrics['cpu_usage'].keys():\n                data_point = {\n                    'timestamp':
      current_metrics['timestamp'],\n                    'cpu_usage': current_metrics['cpu_usage'].get(process_key,
      0),\n                    'memory_usage': current_metrics['memory_usage'].get(process_key,
      0),\n                    'process_count': current_metrics['process_counts'].get(process_key,
      0)\n                }\n                self.process_history[process_key].append(data_point)\n
      \           \n            # Detect anomalies if models are available\n            if
      self.models:\n                anomalies = self.detect_anomalies(current_metrics)\n
      \               \n                # Log significant anomalies\n                for
      anomaly_type, anomaly_data in anomalies.items():\n                    if isinstance(anomaly_data,
      dict) and anomaly_data:\n                        logger.warning(f\"Detected
      {anomaly_type}: {list(anomaly_data.keys())}\")\n                    elif isinstance(anomaly_data,
      list) and anomaly_data:\n                        logger.warning(f\"Detected
      {anomaly_type}: {anomaly_data}\")\n            \n            # Check if we need
      to retrain models\n            time_since_training = time.time() - self.last_model_train\n
      \           if time_since_training > (MODEL_RETRAIN_HOURS * 3600):\n                logger.info(\"Retraining
      models...\")\n                self.train_models()\n            \n            #
      Save history periodically\n            if int(time.time()) % 300 == 0:  # Every
      5 minutes\n                self.save_history()\n            \n        except
      Exception as e:\n            logger.error(f\"Detection cycle error: {e}\")\n
      \       \n        finally:\n            duration = time.time() - start_time\n
      \           detection_duration.observe(duration)\n\ndef main():\n    logger.info(\"Starting
      Advanced Process Anomaly Detection System\")\n    \n    # Start Prometheus metrics
      server\n    start_http_server(9409)\n    logger.info(\"Metrics server started
      on port 9409\")\n    \n    # Initialize detector\n    detector = ProcessAnomalyDetector()\n
      \   \n    # Initial model training if no models exist\n    if not detector.models:\n
      \       logger.info(\"No existing models found, training initial models...\")\n
      \       detector.train_models()\n    \n    # Main detection loop\n    logger.info(f\"Starting
      detection loop (interval: {DETECTION_INTERVAL}s)\")\n    \n    while True:\n
      \       try:\n            detector.run_detection_cycle()\n            time.sleep(DETECTION_INTERVAL)\n
      \           \n        except KeyboardInterrupt:\n            logger.info(\"Shutdown
      requested\")\n            detector.save_models()\n            detector.save_history()\n
      \           break\n        except Exception as e:\n            logger.error(f\"Main
      loop error: {e}\")\n            time.sleep(60)  # Wait before retrying\n\nif
      __name__ == '__main__':\n    main()\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"process_anomaly_detector.py":"#!/usr/bin/env python3\n\"\"\"\nAdvanced Process Anomaly Detection System\n\nDetects anomalies in:\n- CPU usage patterns per process group\n- Memory consumption patterns\n- Process spawn behavior\n- New/unknown processes\n- Resource consumption changes\n\"\"\"\n\nimport requests\nimport numpy as np\nimport time\nimport logging\nimport json\nimport os\nfrom datetime import datetime, timedelta\nfrom typing import Dict, List, Tuple, Optional\nfrom collections import defaultdict, deque\nfrom prometheus_client import start_http_server, Gauge, Counter, Histogram, Info\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.preprocessing import StandardScaler\nimport joblib\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger('process-anomaly-detector')\n\n# Configuration\nPROMETHEUS_URL = os.getenv('PROMETHEUS_URL', 'http://prometheus:9090')\nDETECTION_INTERVAL = int(os.getenv('DETECTION_INTERVAL', '60'))  # seconds\nHISTORY_RETENTION_HOURS = int(os.getenv('HISTORY_RETENTION_HOURS', '24'))\nMODEL_RETRAIN_HOURS = int(os.getenv('MODEL_RETRAIN_HOURS', '6'))\nANOMALY_THRESHOLD = float(os.getenv('ANOMALY_THRESHOLD', '0.1'))  # Lower = more sensitive\n\n# Storage paths\nMODEL_DIR = '/tmp/process_models'\nHISTORY_DIR = '/tmp/process_history'\n\n# Prometheus metrics\nprocess_cpu_anomaly_score = Gauge('process_cpu_anomaly_score', 'Process CPU usage anomaly score', ['groupname', 'instance'])\nprocess_memory_anomaly_score = Gauge('process_memory_anomaly_score', 'Process memory usage anomaly score', ['groupname', 'instance'])\nprocess_count_anomaly_score = Gauge('process_count_anomaly_score', 'Process count anomaly score', ['groupname', 'instance'])\nprocess_new_process_detected = Counter('process_new_process_detected_total', 'New processes detected', ['groupname', 'instance'])\nprocess_anomaly_alerts = Counter('process_anomaly_alerts_total', 'Process anomaly alerts triggered', ['type', 'groupname', 'instance'])\n\n# Model info\nmodel_info = Info('process_anomaly_model_info', 'Process anomaly detection model information')\nmodel_last_trained = Gauge('process_anomaly_model_last_trained_timestamp', 'Last model training timestamp')\n\n# Detection statistics\ndetection_duration = Histogram('process_anomaly_detection_duration_seconds', 'Time spent on anomaly detection')\nprocesses_analyzed = Gauge('process_anomaly_processes_analyzed_total', 'Number of processes analyzed')\n\nclass ProcessAnomalyDetector:\n    def __init__(self):\n        self.models = {}\n        self.scalers = {}\n        self.process_history = defaultdict(lambda: deque(maxlen=1000))\n        self.known_processes = set()\n        self.baseline_stats = {}\n        self.last_model_train = 0\n        \n        # Create directories\n        os.makedirs(MODEL_DIR, exist_ok=True)\n        os.makedirs(HISTORY_DIR, exist_ok=True)\n        \n        # Load existing models and history\n        self.load_models()\n        self.load_history()\n        \n    def prometheus_query(self, query: str, start_time: Optional[str] = None) -\u003e List[Dict]:\n        \"\"\"Execute Prometheus query\"\"\"\n        try:\n            if start_time:\n                url = f\"{PROMETHEUS_URL}/api/v1/query_range\"\n                params = {\n                    'query': query,\n                    'start': start_time,\n                    'end': str(int(time.time())),\n                    'step': '60s'\n                }\n            else:\n                url = f\"{PROMETHEUS_URL}/api/v1/query\"\n                params = {'query': query}\n            \n            response = requests.get(url, params=params, timeout=30)\n            response.raise_for_status()\n            data = response.json()\n            \n            if data['status'] == 'success':\n                return data['data']['result']\n            else:\n                logger.error(f\"Prometheus query failed: {data}\")\n                return []\n        except Exception as e:\n            logger.error(f\"Prometheus query error: {e}\")\n            return []\n    \n    def collect_process_metrics(self) -\u003e Dict:\n        \"\"\"Collect current process metrics\"\"\"\n        metrics = {\n            'cpu_usage': {},\n            'memory_usage': {},\n            'process_counts': {},\n            'timestamp': time.time()\n        }\n        \n        # CPU usage rate (per second)\n        cpu_query = 'rate(namedprocess_namegroup_cpu_seconds_total[5m]) * 100'\n        cpu_results = self.prometheus_query(cpu_query)\n        \n        for result in cpu_results:\n            groupname = result['metric'].get('groupname', 'unknown')\n            instance = result['metric'].get('instance', 'localhost')\n            value = float(result['value'][1])\n            metrics['cpu_usage'][f\"{groupname}@{instance}\"] = value\n        \n        # Memory usage (MB)\n        memory_query = 'namedprocess_namegroup_memory_bytes / 1024 / 1024'\n        memory_results = self.prometheus_query(memory_query)\n        \n        for result in memory_results:\n            groupname = result['metric'].get('groupname', 'unknown')\n            instance = result['metric'].get('instance', 'localhost')\n            value = float(result['value'][1])\n            metrics['memory_usage'][f\"{groupname}@{instance}\"] = value\n        \n        # Process counts\n        count_query = 'namedprocess_namegroup_num_procs'\n        count_results = self.prometheus_query(count_query)\n        \n        for result in count_results:\n            groupname = result['metric'].get('groupname', 'unknown')\n            instance = result['metric'].get('instance', 'localhost')\n            value = float(result['value'][1])\n            metrics['process_counts'][f\"{groupname}@{instance}\"] = value\n        \n        return metrics\n    \n    def collect_historical_data(self, hours: int = 24) -\u003e Dict:\n        \"\"\"Collect historical process data for training\"\"\"\n        end_time = int(time.time())\n        start_time = end_time - (hours * 3600)\n        \n        logger.info(f\"Collecting {hours}h of historical data for model training...\")\n        \n        historical_data = defaultdict(list)\n        \n        # Collect historical CPU data\n        cpu_query = 'rate(namedprocess_namegroup_cpu_seconds_total[5m]) * 100'\n        cpu_results = self.prometheus_query(cpu_query, str(start_time))\n        \n        for result in cpu_results:\n            groupname = result['metric'].get('groupname', 'unknown')\n            instance = result['metric'].get('instance', 'localhost')\n            process_key = f\"{groupname}@{instance}\"\n            \n            for timestamp, value in result['values']:\n                historical_data[process_key].append({\n                    'timestamp': float(timestamp),\n                    'cpu_usage': float(value),\n                    'memory_usage': 0,  # Will be filled later\n                    'process_count': 0\n                })\n        \n        # Collect historical memory data\n        memory_query = 'namedprocess_namegroup_memory_bytes / 1024 / 1024'\n        memory_results = self.prometheus_query(memory_query, str(start_time))\n        \n        for result in memory_results:\n            groupname = result['metric'].get('groupname', 'unknown')\n            instance = result['metric'].get('instance', 'localhost')\n            process_key = f\"{groupname}@{instance}\"\n            \n            for timestamp, value in result['values']:\n                # Find matching timestamp in historical_data\n                for entry in historical_data[process_key]:\n                    if abs(entry['timestamp'] - float(timestamp)) \u003c 30:  # 30 second tolerance\n                        entry['memory_usage'] = float(value)\n                        break\n        \n        # Collect historical process count data\n        count_query = 'namedprocess_namegroup_num_procs'\n        count_results = self.prometheus_query(count_query, str(start_time))\n        \n        for result in count_results:\n            groupname = result['metric'].get('groupname', 'unknown')\n            instance = result['metric'].get('instance', 'localhost')\n            process_key = f\"{groupname}@{instance}\"\n            \n            for timestamp, value in result['values']:\n                # Find matching timestamp in historical_data\n                for entry in historical_data[process_key]:\n                    if abs(entry['timestamp'] - float(timestamp)) \u003c 30:  # 30 second tolerance\n                        entry['process_count'] = float(value)\n                        break\n        \n        return dict(historical_data)\n    \n    def train_models(self):\n        \"\"\"Train anomaly detection models for each process\"\"\"\n        logger.info(\"Starting model training...\")\n        \n        # Collect training data\n        historical_data = self.collect_historical_data(HISTORY_RETENTION_HOURS)\n        \n        trained_count = 0\n        for process_key, data_points in historical_data.items():\n            if len(data_points) \u003c 50:  # Need minimum data points\n                continue\n            \n            # Prepare features\n            features = []\n            for point in data_points:\n                features.append([\n                    point['cpu_usage'],\n                    point['memory_usage'],\n                    point['process_count']\n                ])\n            \n            features = np.array(features)\n            \n            # Remove invalid data points\n            valid_mask = ~np.isnan(features).any(axis=1) \u0026 ~np.isinf(features).any(axis=1)\n            features = features[valid_mask]\n            \n            if len(features) \u003c 20:\n                continue\n            \n            try:\n                # Scale features\n                scaler = StandardScaler()\n                features_scaled = scaler.fit_transform(features)\n                \n                # Train Isolation Forest\n                model = IsolationForest(\n                    contamination=ANOMALY_THRESHOLD,\n                    random_state=42,\n                    n_estimators=100\n                )\n                model.fit(features_scaled)\n                \n                # Store model and scaler\n                self.models[process_key] = model\n                self.scalers[process_key] = scaler\n                \n                # Calculate baseline statistics\n                self.baseline_stats[process_key] = {\n                    'cpu_mean': float(np.mean(features[:, 0])),\n                    'cpu_std': float(np.std(features[:, 0])),\n                    'memory_mean': float(np.mean(features[:, 1])),\n                    'memory_std': float(np.std(features[:, 1])),\n                    'count_mean': float(np.mean(features[:, 2])),\n                    'count_std': float(np.std(features[:, 2]))\n                }\n                \n                trained_count += 1\n                \n            except Exception as e:\n                logger.error(f\"Failed to train model for {process_key}: {e}\")\n        \n        self.last_model_train = time.time()\n        logger.info(f\"Trained {trained_count} models\")\n        \n        # Save models\n        self.save_models()\n        \n        # Update metrics\n        model_last_trained.set(self.last_model_train)\n        model_info.info({\n            'models_trained': str(trained_count),\n            'last_training': datetime.fromtimestamp(self.last_model_train).isoformat(),\n            'contamination_threshold': str(ANOMALY_THRESHOLD)\n        })\n    \n    def detect_anomalies(self, current_metrics: Dict) -\u003e Dict:\n        \"\"\"Detect anomalies in current metrics\"\"\"\n        anomalies = {\n            'cpu_anomalies': {},\n            'memory_anomalies': {},\n            'count_anomalies': {},\n            'new_processes': []\n        }\n        \n        # Check for new processes\n        current_processes = set()\n        for metric_type in ['cpu_usage', 'memory_usage', 'process_counts']:\n            current_processes.update(current_metrics[metric_type].keys())\n        \n        new_processes = current_processes - self.known_processes\n        if new_processes:\n            for process in new_processes:\n                anomalies['new_processes'].append(process)\n                groupname, instance = process.split('@', 1)\n                process_new_process_detected.labels(groupname=groupname, instance=instance).inc()\n                process_anomaly_alerts.labels(type='new_process', groupname=groupname, instance=instance).inc()\n                logger.warning(f\"New process detected: {process}\")\n            \n            self.known_processes.update(new_processes)\n        \n        # Analyze each process for anomalies\n        for process_key in current_processes:\n            if process_key not in self.models:\n                continue\n            \n            try:\n                # Prepare current features\n                cpu_usage = current_metrics['cpu_usage'].get(process_key, 0)\n                memory_usage = current_metrics['memory_usage'].get(process_key, 0)\n                process_count = current_metrics['process_counts'].get(process_key, 0)\n                \n                features = np.array([[cpu_usage, memory_usage, process_count]])\n                \n                # Scale features\n                scaler = self.scalers[process_key]\n                features_scaled = scaler.transform(features)\n                \n                # Get anomaly score\n                model = self.models[process_key]\n                anomaly_score = model.decision_function(features_scaled)[0]\n                is_anomaly = model.predict(features_scaled)[0] == -1\n                \n                # Normalize score to 0-1 range (lower = more anomalous)\n                normalized_score = max(0, min(1, (anomaly_score + 1) / 2))\n                \n                groupname, instance = process_key.split('@', 1)\n                \n                # Update metrics\n                process_cpu_anomaly_score.labels(groupname=groupname, instance=instance).set(normalized_score)\n                \n                # Specific anomaly detection\n                baseline = self.baseline_stats.get(process_key, {})\n                \n                # CPU anomaly detection\n                cpu_threshold = baseline.get('cpu_mean', 0) + 3 * baseline.get('cpu_std', 1)\n                if cpu_usage \u003e cpu_threshold or (is_anomaly and cpu_usage \u003e baseline.get('cpu_mean', 0)):\n                    anomalies['cpu_anomalies'][process_key] = {\n                        'current': cpu_usage,\n                        'threshold': cpu_threshold,\n                        'score': normalized_score\n                    }\n                    process_anomaly_alerts.labels(type='cpu_anomaly', groupname=groupname, instance=instance).inc()\n                \n                # Memory anomaly detection\n                memory_threshold = baseline.get('memory_mean', 0) + 3 * baseline.get('memory_std', 1)\n                if memory_usage \u003e memory_threshold or (is_anomaly and memory_usage \u003e baseline.get('memory_mean', 0)):\n                    anomalies['memory_anomalies'][process_key] = {\n                        'current': memory_usage,\n                        'threshold': memory_threshold,\n                        'score': normalized_score\n                    }\n                    process_memory_anomaly_score.labels(groupname=groupname, instance=instance).set(normalized_score)\n                    process_anomaly_alerts.labels(type='memory_anomaly', groupname=groupname, instance=instance).inc()\n                \n                # Process count anomaly detection\n                count_threshold = baseline.get('count_mean', 0) + 2 * baseline.get('count_std', 1)\n                if process_count \u003e count_threshold or (is_anomaly and process_count \u003e baseline.get('count_mean', 0)):\n                    anomalies['count_anomalies'][process_key] = {\n                        'current': process_count,\n                        'threshold': count_threshold,\n                        'score': normalized_score\n                    }\n                    process_count_anomaly_score.labels(groupname=groupname, instance=instance).set(normalized_score)\n                    process_anomaly_alerts.labels(type='count_anomaly', groupname=groupname, instance=instance).inc()\n                \n            except Exception as e:\n                logger.error(f\"Anomaly detection failed for {process_key}: {e}\")\n        \n        return anomalies\n    \n    def save_models(self):\n        \"\"\"Save trained models to disk\"\"\"\n        try:\n            model_data = {\n                'models': {},\n                'scalers': {},\n                'baseline_stats': self.baseline_stats,\n                'known_processes': list(self.known_processes),\n                'last_trained': self.last_model_train\n            }\n            \n            # Save models using joblib\n            for process_key, model in self.models.items():\n                model_file = f\"{MODEL_DIR}/model_{process_key.replace('@', '_').replace('/', '_')}.joblib\"\n                joblib.dump(model, model_file)\n                model_data['models'][process_key] = model_file\n            \n            for process_key, scaler in self.scalers.items():\n                scaler_file = f\"{MODEL_DIR}/scaler_{process_key.replace('@', '_').replace('/', '_')}.joblib\"\n                joblib.dump(scaler, scaler_file)\n                model_data['scalers'][process_key] = scaler_file\n            \n            # Save metadata\n            with open(f\"{MODEL_DIR}/metadata.json\", 'w') as f:\n                json.dump(model_data, f, indent=2)\n            \n            logger.info(f\"Saved {len(self.models)} models to {MODEL_DIR}\")\n        except Exception as e:\n            logger.error(f\"Failed to save models: {e}\")\n    \n    def load_models(self):\n        \"\"\"Load trained models from disk\"\"\"\n        try:\n            metadata_file = f\"{MODEL_DIR}/metadata.json\"\n            if not os.path.exists(metadata_file):\n                logger.info(\"No existing models found\")\n                return\n            \n            with open(metadata_file, 'r') as f:\n                model_data = json.load(f)\n            \n            # Load models\n            for process_key, model_file in model_data.get('models', {}).items():\n                if os.path.exists(model_file):\n                    self.models[process_key] = joblib.load(model_file)\n            \n            # Load scalers\n            for process_key, scaler_file in model_data.get('scalers', {}).items():\n                if os.path.exists(scaler_file):\n                    self.scalers[process_key] = joblib.load(scaler_file)\n            \n            # Load other data\n            self.baseline_stats = model_data.get('baseline_stats', {})\n            self.known_processes = set(model_data.get('known_processes', []))\n            self.last_model_train = model_data.get('last_trained', 0)\n            \n            logger.info(f\"Loaded {len(self.models)} models from {MODEL_DIR}\")\n            \n            # Update metrics\n            if self.last_model_train \u003e 0:\n                model_last_trained.set(self.last_model_train)\n                model_info.info({\n                    'models_loaded': str(len(self.models)),\n                    'last_training': datetime.fromtimestamp(self.last_model_train).isoformat(),\n                    'contamination_threshold': str(ANOMALY_THRESHOLD)\n                })\n            \n        except Exception as e:\n            logger.error(f\"Failed to load models: {e}\")\n    \n    def load_history(self):\n        \"\"\"Load process history from disk\"\"\"\n        try:\n            history_file = f\"{HISTORY_DIR}/process_history.json\"\n            if os.path.exists(history_file):\n                with open(history_file, 'r') as f:\n                    history_data = json.load(f)\n                \n                for process_key, data_points in history_data.items():\n                    self.process_history[process_key] = deque(data_points, maxlen=1000)\n                \n                logger.info(f\"Loaded history for {len(history_data)} processes\")\n        except Exception as e:\n            logger.error(f\"Failed to load history: {e}\")\n    \n    def save_history(self):\n        \"\"\"Save process history to disk\"\"\"\n        try:\n            history_data = {}\n            for process_key, data_points in self.process_history.items():\n                history_data[process_key] = list(data_points)\n            \n            with open(f\"{HISTORY_DIR}/process_history.json\", 'w') as f:\n                json.dump(history_data, f, indent=2)\n            \n        except Exception as e:\n            logger.error(f\"Failed to save history: {e}\")\n    \n    def run_detection_cycle(self):\n        \"\"\"Run one complete detection cycle\"\"\"\n        start_time = time.time()\n        \n        try:\n            # Collect current metrics\n            current_metrics = self.collect_process_metrics()\n            \n            # Update process count metric\n            total_processes = len(set().union(\n                current_metrics['cpu_usage'].keys(),\n                current_metrics['memory_usage'].keys(),\n                current_metrics['process_counts'].keys()\n            ))\n            processes_analyzed.set(total_processes)\n            \n            # Store in history\n            for process_key in current_metrics['cpu_usage'].keys():\n                data_point = {\n                    'timestamp': current_metrics['timestamp'],\n                    'cpu_usage': current_metrics['cpu_usage'].get(process_key, 0),\n                    'memory_usage': current_metrics['memory_usage'].get(process_key, 0),\n                    'process_count': current_metrics['process_counts'].get(process_key, 0)\n                }\n                self.process_history[process_key].append(data_point)\n            \n            # Detect anomalies if models are available\n            if self.models:\n                anomalies = self.detect_anomalies(current_metrics)\n                \n                # Log significant anomalies\n                for anomaly_type, anomaly_data in anomalies.items():\n                    if isinstance(anomaly_data, dict) and anomaly_data:\n                        logger.warning(f\"Detected {anomaly_type}: {list(anomaly_data.keys())}\")\n                    elif isinstance(anomaly_data, list) and anomaly_data:\n                        logger.warning(f\"Detected {anomaly_type}: {anomaly_data}\")\n            \n            # Check if we need to retrain models\n            time_since_training = time.time() - self.last_model_train\n            if time_since_training \u003e (MODEL_RETRAIN_HOURS * 3600):\n                logger.info(\"Retraining models...\")\n                self.train_models()\n            \n            # Save history periodically\n            if int(time.time()) % 300 == 0:  # Every 5 minutes\n                self.save_history()\n            \n        except Exception as e:\n            logger.error(f\"Detection cycle error: {e}\")\n        \n        finally:\n            duration = time.time() - start_time\n            detection_duration.observe(duration)\n\ndef main():\n    logger.info(\"Starting Advanced Process Anomaly Detection System\")\n    \n    # Start Prometheus metrics server\n    start_http_server(9409)\n    logger.info(\"Metrics server started on port 9409\")\n    \n    # Initialize detector\n    detector = ProcessAnomalyDetector()\n    \n    # Initial model training if no models exist\n    if not detector.models:\n        logger.info(\"No existing models found, training initial models...\")\n        detector.train_models()\n    \n    # Main detection loop\n    logger.info(f\"Starting detection loop (interval: {DETECTION_INTERVAL}s)\")\n    \n    while True:\n        try:\n            detector.run_detection_cycle()\n            time.sleep(DETECTION_INTERVAL)\n            \n        except KeyboardInterrupt:\n            logger.info(\"Shutdown requested\")\n            detector.save_models()\n            detector.save_history()\n            break\n        except Exception as e:\n            logger.error(f\"Main loop error: {e}\")\n            time.sleep(60)  # Wait before retrying\n\nif __name__ == '__main__':\n    main()\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"advanced-process-anomaly-detector-script","namespace":"monitoring"}}
    creationTimestamp: "2025-06-02T19:05:44Z"
    name: advanced-process-anomaly-detector-script
    namespace: monitoring
    resourceVersion: "1885986"
    uid: df065271-b77a-4a3f-a86a-c0fe08c73a65
- apiVersion: v1
  data:
    alertmanager.yml: |
      global:
        smtp_smarthost: 'localhost:587'
        smtp_from: 'odin-alerts@localhost'
        resolve_timeout: 5m

      templates:
      - '/etc/alertmanager/templates/*.tmpl'

      route:
        group_by: ['alertname', 'cluster', 'service']
        group_wait: 10s
        group_interval: 10s
        repeat_interval: 12h
        receiver: 'default'
        routes:
        - match:
            severity: critical
          receiver: 'critical-alerts'
          continue: false
        - match:
            severity: warning
          receiver: 'warning-alerts'
          continue: false
        - match:
            alertname: GPUHighTemperature
          receiver: 'gpu-alerts'
          continue: false

      receivers:
      - name: 'default'
        webhook_configs:
        - url: 'http://direct-alert-bridge.odin-prime.svc.cluster.local:8080/webhook'
          send_resolved: true

      - name: 'critical-alerts'
        webhook_configs:
        - url: 'http://direct-alert-bridge.odin-prime.svc.cluster.local:8080/webhook'
          send_resolved: true

      - name: 'warning-alerts'
        webhook_configs:
        - url: 'http://direct-alert-bridge.odin-prime.svc.cluster.local:8080/webhook'
          send_resolved: true

      - name: 'gpu-alerts'
        webhook_configs:
        - url: 'http://direct-alert-bridge.odin-prime.svc.cluster.local:8080/webhook'
          send_resolved: true

      inhibit_rules:
      - source_match:
          severity: 'critical'
        target_match:
          severity: 'warning'
        equal: ['alertname', 'instance']
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"alertmanager.yml":"global:\n  smtp_smarthost: 'localhost:587'\n  smtp_from: 'odin-alerts@localhost'\n  resolve_timeout: 5m\n\ntemplates:\n- '/etc/alertmanager/templates/*.tmpl'\n\nroute:\n  group_by: ['alertname', 'cluster', 'service']\n  group_wait: 10s\n  group_interval: 10s\n  repeat_interval: 12h\n  receiver: 'default'\n  routes:\n  - match:\n      severity: critical\n    receiver: 'critical-alerts'\n    continue: false\n  - match:\n      severity: warning\n    receiver: 'warning-alerts'\n    continue: false\n  - match:\n      alertname: GPUHighTemperature\n    receiver: 'gpu-alerts'\n    continue: false\n\nreceivers:\n- name: 'default'\n  webhook_configs:\n  - url: 'http://direct-alert-bridge.odin-prime.svc.cluster.local:8080/webhook'\n    send_resolved: true\n\n- name: 'critical-alerts'\n  webhook_configs:\n  - url: 'http://direct-alert-bridge.odin-prime.svc.cluster.local:8080/webhook'\n    send_resolved: true\n\n- name: 'warning-alerts'\n  webhook_configs:\n  - url: 'http://direct-alert-bridge.odin-prime.svc.cluster.local:8080/webhook'\n    send_resolved: true\n\n- name: 'gpu-alerts'\n  webhook_configs:\n  - url: 'http://direct-alert-bridge.odin-prime.svc.cluster.local:8080/webhook'\n    send_resolved: true\n\ninhibit_rules:\n- source_match:\n    severity: 'critical'\n  target_match:\n    severity: 'warning'\n  equal: ['alertname', 'instance']\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"alertmanager-config","namespace":"monitoring"}}
    creationTimestamp: "2025-05-27T22:21:43Z"
    name: alertmanager-config
    namespace: monitoring
    resourceVersion: "5299405"
    uid: 7fd1799e-7406-4bcc-8014-1e743388bd20
- apiVersion: v1
  data:
    deadman-receiver.yaml: "# Add this to your AlertManager config\nreceivers:\n-
      name: 'dead-mans-switch'\n  webhook_configs:\n  - url: 'https://nosnch.in/YOUR_SNITCH_ID'
      \ # Replace with your Dead Man's Snitch URL\n    send_resolved: false\n    max_alerts:
      1\n\n# Route for dead man's switch\nroute:\n  routes:\n  - match:\n      alertname:
      ODINPrimeHeartbeat\n    receiver: dead-mans-switch\n    group_wait: 0s\n    group_interval:
      30s\n    repeat_interval: 30s\n  \n  - match:\n      notification: external\n
      \   receiver: critical-external  # Your external notification service\n    continue:
      true\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"deadman-receiver.yaml":"# Add this to your AlertManager config\nreceivers:\n- name: 'dead-mans-switch'\n  webhook_configs:\n  - url: 'https://nosnch.in/YOUR_SNITCH_ID'  # Replace with your Dead Man's Snitch URL\n    send_resolved: false\n    max_alerts: 1\n\n# Route for dead man's switch\nroute:\n  routes:\n  - match:\n      alertname: ODINPrimeHeartbeat\n    receiver: dead-mans-switch\n    group_wait: 0s\n    group_interval: 30s\n    repeat_interval: 30s\n  \n  - match:\n      notification: external\n    receiver: critical-external  # Your external notification service\n    continue: true\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"alertmanager-deadman-config","namespace":"monitoring"}}
    creationTimestamp: "2025-06-08T01:21:17Z"
    name: alertmanager-deadman-config
    namespace: monitoring
    resourceVersion: "5213602"
    uid: 84a5b7fd-3ba2-4c71-8fba-efe54dfd2f0d
- apiVersion: v1
  data:
    alertmanager.yml: "global:\n  resolve_timeout: 5m\n  smtp_smarthost: 'smtp.gmail.com:587'\n
      \ smtp_from: 'odin-alerts@gmail.com'\n  smtp_auth_username: 'jason.holt@andominia.com'\n
      \ smtp_auth_password: 'DA!Amar01'\n  smtp_require_tls: true\n  \nroute:\n  receiver:
      'default-receiver'\n  group_by: ['alertname', 'cluster', 'service', 'component']\n
      \ group_wait: 10s\n  group_interval: 10s\n  repeat_interval: 15m\n  \n  routes:\n
      \ # Critical alerts - immediate email\n  - match:\n      severity: critical\n
      \   receiver: 'critical-email-receiver'\n    group_wait: 0s\n    repeat_interval:
      5m\n    \n  # Monitoring stack issues - immediate email\n  - match:\n      component:
      monitoring-stack\n    receiver: 'monitoring-email-receiver'\n    group_wait:
      30s\n    repeat_interval: 10m\n    \n  # Pod crashes and OOM - immediate email
      \ \n  - match_re:\n      alertname: '.*OOM.*|.*Crash.*|.*Restart.*'\n    receiver:
      'pod-issues-email-receiver'\n    group_wait: 0s\n    repeat_interval: 5m\n    \n
      \ # GPU and thermal issues\n  - match_re:\n      alertname: '.*GPU.*|.*Thermal.*|.*Temperature.*'\n
      \   receiver: 'gpu-email-receiver'\n    group_wait: 30s\n    repeat_interval:
      10m\n    \n  # ML anomaly detection issues\n  - match_re:\n      alertname:
      '.*Anomaly.*|.*ML.*|.*Model.*'\n    receiver: 'ml-email-receiver'\n    group_wait:
      60s\n    repeat_interval: 15m\n    \n  # Claude Code monitoring\n  - match:\n
      \     component: claude-code\n    receiver: 'claude-email-receiver'\n    repeat_interval:
      24h\n    \n  # Default webhook fallback\n  - receiver: 'webhook-receiver'\n
      \   \nreceivers:\n# Email receivers for different alert types\n- name: 'critical-email-receiver'\n
      \ email_configs:\n  - to: 'jason.holt@andominia.com'\n    subject: '\U0001F6A8
      ODIN CRITICAL: {{ .GroupLabels.alertname }}'\n    html: |\n      <h2>\U0001F6A8
      Critical Alert: {{ .GroupLabels.alertname }}</h2>\n      <p><strong>Cluster:</strong>
      ODIN Monitoring</p>\n      <p><strong>Time:</strong> {{ .CommonAnnotations.timestamp
      }}</p>\n      \n      {{ range .Alerts }}\n      <h3>{{ .Annotations.summary
      }}</h3>\n      <p><strong>Description:</strong> {{ .Annotations.description
      }}</p>\n      <p><strong>Pod/Service:</strong> {{ .Labels.pod }}{{ .Labels.service
      }}</p>\n      <p><strong>Namespace:</strong> {{ .Labels.namespace }}</p>\n      <p><strong>Severity:</strong>
      {{ .Labels.severity }}</p>\n      <hr>\n      {{ end }}\n      \n      <p><a
      href=\"http://localhost:31494\">\U0001F517 View Grafana Dashboards</a></p>\n
      \ webhook_configs:\n  - url: 'http://webhook-logger:8080/critical'\n    send_resolved:
      true\n    \n- name: 'monitoring-email-receiver'\n  email_configs:\n  - to: 'jason.holt@andominia.com'\n
      \   subject: '\U0001F4CA ODIN Monitoring Issue: {{ .GroupLabels.alertname }}'\n
      \   html: |\n      <h2>\U0001F4CA Monitoring Stack Alert: {{ .GroupLabels.alertname
      }}</h2>\n      \n      {{ range .Alerts }}\n      <h3>{{ .Annotations.summary
      }}</h3>\n      <p><strong>Description:</strong> {{ .Annotations.description
      }}</p>\n      <p><strong>Component:</strong> {{ .Labels.component }}</p>\n      <p><strong>Service:</strong>
      {{ .Labels.service }}</p>\n      <p><strong>Instance:</strong> {{ .Labels.instance
      }}</p>\n      <hr>\n      {{ end }}\n      \n      <p><a href=\"http://localhost:31494/d/odin-system-overview\">\U0001F517
      System Overview Dashboard</a></p>\n  webhook_configs:\n  - url: 'http://webhook-logger:8080/monitoring'\n
      \   send_resolved: true\n    \n- name: 'pod-issues-email-receiver'\n  email_configs:\n
      \ - to: 'jason.holt@andominia.com'\n    subject: '\U0001F504 ODIN Pod Issue:
      {{ .GroupLabels.alertname }}'\n    html: |\n      <h2>\U0001F504 Pod Management
      Alert: {{ .GroupLabels.alertname }}</h2>\n      \n      {{ range .Alerts }}\n
      \     <h3>{{ .Annotations.summary }}</h3>\n      <p><strong>Description:</strong>
      {{ .Annotations.description }}</p>\n      <p><strong>Pod:</strong> {{ .Labels.pod
      }}</p>\n      <p><strong>Namespace:</strong> {{ .Labels.namespace }}</p>\n      <p><strong>Container:</strong>
      {{ .Labels.container }}</p>\n      <p><strong>Restart Count:</strong> {{ .Labels.restart_count
      }}</p>\n      \n      <h4>\U0001F4CB Troubleshooting Steps:</h4>\n      <pre>\n
      \     # Check pod status\n      kubectl describe pod {{ .Labels.pod }} -n {{
      .Labels.namespace }}\n      \n      # Check logs\n      kubectl logs {{ .Labels.pod
      }} -n {{ .Labels.namespace }} --previous\n      \n      # Check resource usage\n
      \     kubectl top pod {{ .Labels.pod }} -n {{ .Labels.namespace }}\n      </pre>\n
      \     <hr>\n      {{ end }}\n      \n      <p><a href=\"http://localhost:31494/d/k8s-pods\">\U0001F517
      Pod Monitoring Dashboard</a></p>\n  webhook_configs:\n  - url: 'http://webhook-logger:8080/pods'\n
      \   send_resolved: true\n    \n- name: 'gpu-email-receiver'\n  email_configs:\n
      \ - to: 'jason.holt@andominia.com'\n    subject: '\U0001F3AE ODIN GPU Alert:
      {{ .GroupLabels.alertname }}'\n    html: |\n      <h2>\U0001F3AE GPU Hardware
      Alert: {{ .GroupLabels.alertname }}</h2>\n      \n      {{ range .Alerts }}\n
      \     <h3>{{ .Annotations.summary }}</h3>\n      <p><strong>Description:</strong>
      {{ .Annotations.description }}</p>\n      <p><strong>GPU:</strong> {{ .Labels.gpu
      }}</p>\n      <p><strong>Temperature:</strong> {{ .Labels.temperature }}°C</p>\n
      \     <p><strong>Power:</strong> {{ .Labels.power }}W</p>\n      <hr>\n      {{
      end }}\n      \n      <p><a href=\"http://localhost:31494/d/gpu-monitoring\">\U0001F517
      GPU Dashboard</a></p>\n  webhook_configs:\n  - url: 'http://webhook-logger:8080/gpu'\n
      \   send_resolved: true\n    \n- name: 'ml-email-receiver'\n  email_configs:\n
      \ - to: 'jason.holt@andominia.com'\n    subject: '\U0001F9E0 ODIN ML Alert:
      {{ .GroupLabels.alertname }}'\n    html: |\n      <h2>\U0001F9E0 Machine Learning
      Alert: {{ .GroupLabels.alertname }}</h2>\n      \n      {{ range .Alerts }}\n
      \     <h3>{{ .Annotations.summary }}</h3>\n      <p><strong>Description:</strong>
      {{ .Annotations.description }}</p>\n      <p><strong>Detector:</strong> {{ .Labels.detector
      }}</p>\n      <p><strong>Algorithm:</strong> {{ .Labels.algorithm }}</p>\n      <p><strong>Score:</strong>
      {{ .Labels.score }}</p>\n      <hr>\n      {{ end }}\n      \n      <p><a href=\"http://localhost:31494/d/ml-anomaly-detection\">\U0001F517
      ML Dashboard</a></p>\n  webhook_configs:\n  - url: 'http://webhook-logger:8080/ml'\n
      \   send_resolved: true\n    \n- name: 'claude-email-receiver'\n  email_configs:\n
      \ - to: 'jason.holt@andominia.com'\n    subject: '\U0001F916 ODIN Claude Code
      Alert: {{ .GroupLabels.alertname }}'\n    html: |\n      <h2>\U0001F916 Claude
      Code Alert: {{ .GroupLabels.alertname }}</h2>\n      \n      {{ range .Alerts
      }}\n      <h3>{{ .Annotations.summary }}</h3>\n      <p><strong>Description:</strong>
      {{ .Annotations.description }}</p>\n      <p><strong>API Usage:</strong> {{
      .Labels.api_usage }}</p>\n      <p><strong>Cost:</strong> ${{ .Labels.cost }}</p>\n
      \     <hr>\n      {{ end }}\n      \n      <p><a href=\"http://localhost:31494/d/claude-monitoring\">\U0001F517
      Claude Dashboard</a></p>\n  webhook_configs:\n  - url: 'http://webhook-logger:8080/claude'\n
      \   send_resolved: true\n    \n# Default receivers  \n- name: 'default-receiver'\n
      \ email_configs:\n  - to: 'jason.holt@andominia.com'\n    subject: '\U0001F4E2
      ODIN Alert: {{ .GroupLabels.alertname }}'\n    html: |\n      <h2>\U0001F4E2
      ODIN Alert: {{ .GroupLabels.alertname }}</h2>\n      \n      {{ range .Alerts
      }}\n      <h3>{{ .Annotations.summary }}</h3>\n      <p><strong>Description:</strong>
      {{ .Annotations.description }}</p>\n      <hr>\n      {{ end }}\n      \n- name:
      'webhook-receiver'\n  webhook_configs:\n  - url: 'http://webhook-logger:8080/webhook'\n
      \   send_resolved: true\n    http_config:\n      basic_auth:\n        username:
      'odin'\n        password: 'monitoring'\n        \ninhibit_rules:\n# Don't send
      pod alerts if node is down\n- source_match:\n    alertname: 'NodeNotReady'\n
      \ target_match_re:\n    alertname: 'Pod.*|Container.*'\n  equal: ['node']\n
      \ \n# Don't send target down if Prometheus is down\n- source_match:\n    alertname:
      'PrometheusDown'\n  target_match:\n    alertname: 'PrometheusTargetDown'\n  equal:
      ['instance']\n  \n# Don't send individual monitoring alerts if whole stack is
      critical\n- source_match:\n    alertname: 'MonitoringStackCritical'\n  target_match:\n
      \   component: 'monitoring-stack'\n    severity: 'warning'\n    \n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: "{\"apiVersion\":\"v1\",\"data\":{\"alertmanager.yml\":\"global:\\n
        \ resolve_timeout: 5m\\n  smtp_smarthost: 'smtp.gmail.com:587'\\n  smtp_from:
        'odin-alerts@gmail.com'\\n  smtp_auth_username: 'jason.holt@andominia.com'\\n
        \ smtp_auth_password: 'DA!Amar01'\\n  smtp_require_tls: true\\n  \\nroute:\\n
        \ receiver: 'default-receiver'\\n  group_by: ['alertname', 'cluster', 'service',
        'component']\\n  group_wait: 10s\\n  group_interval: 10s\\n  repeat_interval:
        15m\\n  \\n  routes:\\n  # Critical alerts - immediate email\\n  - match:\\n
        \     severity: critical\\n    receiver: 'critical-email-receiver'\\n    group_wait:
        0s\\n    repeat_interval: 5m\\n    \\n  # Monitoring stack issues - immediate
        email\\n  - match:\\n      component: monitoring-stack\\n    receiver: 'monitoring-email-receiver'\\n
        \   group_wait: 30s\\n    repeat_interval: 10m\\n    \\n  # Pod crashes and
        OOM - immediate email  \\n  - match_re:\\n      alertname: '.*OOM.*|.*Crash.*|.*Restart.*'\\n
        \   receiver: 'pod-issues-email-receiver'\\n    group_wait: 0s\\n    repeat_interval:
        5m\\n    \\n  # GPU and thermal issues\\n  - match_re:\\n      alertname:
        '.*GPU.*|.*Thermal.*|.*Temperature.*'\\n    receiver: 'gpu-email-receiver'\\n
        \   group_wait: 30s\\n    repeat_interval: 10m\\n    \\n  # ML anomaly detection
        issues\\n  - match_re:\\n      alertname: '.*Anomaly.*|.*ML.*|.*Model.*'\\n
        \   receiver: 'ml-email-receiver'\\n    group_wait: 60s\\n    repeat_interval:
        15m\\n    \\n  # Claude Code monitoring\\n  - match:\\n      component: claude-code\\n
        \   receiver: 'claude-email-receiver'\\n    repeat_interval: 24h\\n    \\n
        \ # Default webhook fallback\\n  - receiver: 'webhook-receiver'\\n    \\nreceivers:\\n#
        Email receivers for different alert types\\n- name: 'critical-email-receiver'\\n
        \ email_configs:\\n  - to: 'jason.holt@andominia.com'\\n    subject: '\U0001F6A8
        ODIN CRITICAL: {{ .GroupLabels.alertname }}'\\n    html: |\\n      \\u003ch2\\u003e\U0001F6A8
        Critical Alert: {{ .GroupLabels.alertname }}\\u003c/h2\\u003e\\n      \\u003cp\\u003e\\u003cstrong\\u003eCluster:\\u003c/strong\\u003e
        ODIN Monitoring\\u003c/p\\u003e\\n      \\u003cp\\u003e\\u003cstrong\\u003eTime:\\u003c/strong\\u003e
        {{ .CommonAnnotations.timestamp }}\\u003c/p\\u003e\\n      \\n      {{ range
        .Alerts }}\\n      \\u003ch3\\u003e{{ .Annotations.summary }}\\u003c/h3\\u003e\\n
        \     \\u003cp\\u003e\\u003cstrong\\u003eDescription:\\u003c/strong\\u003e
        {{ .Annotations.description }}\\u003c/p\\u003e\\n      \\u003cp\\u003e\\u003cstrong\\u003ePod/Service:\\u003c/strong\\u003e
        {{ .Labels.pod }}{{ .Labels.service }}\\u003c/p\\u003e\\n      \\u003cp\\u003e\\u003cstrong\\u003eNamespace:\\u003c/strong\\u003e
        {{ .Labels.namespace }}\\u003c/p\\u003e\\n      \\u003cp\\u003e\\u003cstrong\\u003eSeverity:\\u003c/strong\\u003e
        {{ .Labels.severity }}\\u003c/p\\u003e\\n      \\u003chr\\u003e\\n      {{
        end }}\\n      \\n      \\u003cp\\u003e\\u003ca href=\\\"http://localhost:31494\\\"\\u003e\U0001F517
        View Grafana Dashboards\\u003c/a\\u003e\\u003c/p\\u003e\\n  webhook_configs:\\n
        \ - url: 'http://webhook-logger:8080/critical'\\n    send_resolved: true\\n
        \   \\n- name: 'monitoring-email-receiver'\\n  email_configs:\\n  - to: 'jason.holt@andominia.com'\\n
        \   subject: '\U0001F4CA ODIN Monitoring Issue: {{ .GroupLabels.alertname
        }}'\\n    html: |\\n      \\u003ch2\\u003e\U0001F4CA Monitoring Stack Alert:
        {{ .GroupLabels.alertname }}\\u003c/h2\\u003e\\n      \\n      {{ range .Alerts
        }}\\n      \\u003ch3\\u003e{{ .Annotations.summary }}\\u003c/h3\\u003e\\n
        \     \\u003cp\\u003e\\u003cstrong\\u003eDescription:\\u003c/strong\\u003e
        {{ .Annotations.description }}\\u003c/p\\u003e\\n      \\u003cp\\u003e\\u003cstrong\\u003eComponent:\\u003c/strong\\u003e
        {{ .Labels.component }}\\u003c/p\\u003e\\n      \\u003cp\\u003e\\u003cstrong\\u003eService:\\u003c/strong\\u003e
        {{ .Labels.service }}\\u003c/p\\u003e\\n      \\u003cp\\u003e\\u003cstrong\\u003eInstance:\\u003c/strong\\u003e
        {{ .Labels.instance }}\\u003c/p\\u003e\\n      \\u003chr\\u003e\\n      {{
        end }}\\n      \\n      \\u003cp\\u003e\\u003ca href=\\\"http://localhost:31494/d/odin-system-overview\\\"\\u003e\U0001F517
        System Overview Dashboard\\u003c/a\\u003e\\u003c/p\\u003e\\n  webhook_configs:\\n
        \ - url: 'http://webhook-logger:8080/monitoring'\\n    send_resolved: true\\n
        \   \\n- name: 'pod-issues-email-receiver'\\n  email_configs:\\n  - to: 'jason.holt@andominia.com'\\n
        \   subject: '\U0001F504 ODIN Pod Issue: {{ .GroupLabels.alertname }}'\\n
        \   html: |\\n      \\u003ch2\\u003e\U0001F504 Pod Management Alert: {{ .GroupLabels.alertname
        }}\\u003c/h2\\u003e\\n      \\n      {{ range .Alerts }}\\n      \\u003ch3\\u003e{{
        .Annotations.summary }}\\u003c/h3\\u003e\\n      \\u003cp\\u003e\\u003cstrong\\u003eDescription:\\u003c/strong\\u003e
        {{ .Annotations.description }}\\u003c/p\\u003e\\n      \\u003cp\\u003e\\u003cstrong\\u003ePod:\\u003c/strong\\u003e
        {{ .Labels.pod }}\\u003c/p\\u003e\\n      \\u003cp\\u003e\\u003cstrong\\u003eNamespace:\\u003c/strong\\u003e
        {{ .Labels.namespace }}\\u003c/p\\u003e\\n      \\u003cp\\u003e\\u003cstrong\\u003eContainer:\\u003c/strong\\u003e
        {{ .Labels.container }}\\u003c/p\\u003e\\n      \\u003cp\\u003e\\u003cstrong\\u003eRestart
        Count:\\u003c/strong\\u003e {{ .Labels.restart_count }}\\u003c/p\\u003e\\n
        \     \\n      \\u003ch4\\u003e\U0001F4CB Troubleshooting Steps:\\u003c/h4\\u003e\\n
        \     \\u003cpre\\u003e\\n      # Check pod status\\n      kubectl describe
        pod {{ .Labels.pod }} -n {{ .Labels.namespace }}\\n      \\n      # Check
        logs\\n      kubectl logs {{ .Labels.pod }} -n {{ .Labels.namespace }} --previous\\n
        \     \\n      # Check resource usage\\n      kubectl top pod {{ .Labels.pod
        }} -n {{ .Labels.namespace }}\\n      \\u003c/pre\\u003e\\n      \\u003chr\\u003e\\n
        \     {{ end }}\\n      \\n      \\u003cp\\u003e\\u003ca href=\\\"http://localhost:31494/d/k8s-pods\\\"\\u003e\U0001F517
        Pod Monitoring Dashboard\\u003c/a\\u003e\\u003c/p\\u003e\\n  webhook_configs:\\n
        \ - url: 'http://webhook-logger:8080/pods'\\n    send_resolved: true\\n    \\n-
        name: 'gpu-email-receiver'\\n  email_configs:\\n  - to: 'jason.holt@andominia.com'\\n
        \   subject: '\U0001F3AE ODIN GPU Alert: {{ .GroupLabels.alertname }}'\\n
        \   html: |\\n      \\u003ch2\\u003e\U0001F3AE GPU Hardware Alert: {{ .GroupLabels.alertname
        }}\\u003c/h2\\u003e\\n      \\n      {{ range .Alerts }}\\n      \\u003ch3\\u003e{{
        .Annotations.summary }}\\u003c/h3\\u003e\\n      \\u003cp\\u003e\\u003cstrong\\u003eDescription:\\u003c/strong\\u003e
        {{ .Annotations.description }}\\u003c/p\\u003e\\n      \\u003cp\\u003e\\u003cstrong\\u003eGPU:\\u003c/strong\\u003e
        {{ .Labels.gpu }}\\u003c/p\\u003e\\n      \\u003cp\\u003e\\u003cstrong\\u003eTemperature:\\u003c/strong\\u003e
        {{ .Labels.temperature }}°C\\u003c/p\\u003e\\n      \\u003cp\\u003e\\u003cstrong\\u003ePower:\\u003c/strong\\u003e
        {{ .Labels.power }}W\\u003c/p\\u003e\\n      \\u003chr\\u003e\\n      {{ end
        }}\\n      \\n      \\u003cp\\u003e\\u003ca href=\\\"http://localhost:31494/d/gpu-monitoring\\\"\\u003e\U0001F517
        GPU Dashboard\\u003c/a\\u003e\\u003c/p\\u003e\\n  webhook_configs:\\n  - url:
        'http://webhook-logger:8080/gpu'\\n    send_resolved: true\\n    \\n- name:
        'ml-email-receiver'\\n  email_configs:\\n  - to: 'jason.holt@andominia.com'\\n
        \   subject: '\U0001F9E0 ODIN ML Alert: {{ .GroupLabels.alertname }}'\\n    html:
        |\\n      \\u003ch2\\u003e\U0001F9E0 Machine Learning Alert: {{ .GroupLabels.alertname
        }}\\u003c/h2\\u003e\\n      \\n      {{ range .Alerts }}\\n      \\u003ch3\\u003e{{
        .Annotations.summary }}\\u003c/h3\\u003e\\n      \\u003cp\\u003e\\u003cstrong\\u003eDescription:\\u003c/strong\\u003e
        {{ .Annotations.description }}\\u003c/p\\u003e\\n      \\u003cp\\u003e\\u003cstrong\\u003eDetector:\\u003c/strong\\u003e
        {{ .Labels.detector }}\\u003c/p\\u003e\\n      \\u003cp\\u003e\\u003cstrong\\u003eAlgorithm:\\u003c/strong\\u003e
        {{ .Labels.algorithm }}\\u003c/p\\u003e\\n      \\u003cp\\u003e\\u003cstrong\\u003eScore:\\u003c/strong\\u003e
        {{ .Labels.score }}\\u003c/p\\u003e\\n      \\u003chr\\u003e\\n      {{ end
        }}\\n      \\n      \\u003cp\\u003e\\u003ca href=\\\"http://localhost:31494/d/ml-anomaly-detection\\\"\\u003e\U0001F517
        ML Dashboard\\u003c/a\\u003e\\u003c/p\\u003e\\n  webhook_configs:\\n  - url:
        'http://webhook-logger:8080/ml'\\n    send_resolved: true\\n    \\n- name:
        'claude-email-receiver'\\n  email_configs:\\n  - to: 'jason.holt@andominia.com'\\n
        \   subject: '\U0001F916 ODIN Claude Code Alert: {{ .GroupLabels.alertname
        }}'\\n    html: |\\n      \\u003ch2\\u003e\U0001F916 Claude Code Alert: {{
        .GroupLabels.alertname }}\\u003c/h2\\u003e\\n      \\n      {{ range .Alerts
        }}\\n      \\u003ch3\\u003e{{ .Annotations.summary }}\\u003c/h3\\u003e\\n
        \     \\u003cp\\u003e\\u003cstrong\\u003eDescription:\\u003c/strong\\u003e
        {{ .Annotations.description }}\\u003c/p\\u003e\\n      \\u003cp\\u003e\\u003cstrong\\u003eAPI
        Usage:\\u003c/strong\\u003e {{ .Labels.api_usage }}\\u003c/p\\u003e\\n      \\u003cp\\u003e\\u003cstrong\\u003eCost:\\u003c/strong\\u003e
        ${{ .Labels.cost }}\\u003c/p\\u003e\\n      \\u003chr\\u003e\\n      {{ end
        }}\\n      \\n      \\u003cp\\u003e\\u003ca href=\\\"http://localhost:31494/d/claude-monitoring\\\"\\u003e\U0001F517
        Claude Dashboard\\u003c/a\\u003e\\u003c/p\\u003e\\n  webhook_configs:\\n  -
        url: 'http://webhook-logger:8080/claude'\\n    send_resolved: true\\n    \\n#
        Default receivers  \\n- name: 'default-receiver'\\n  email_configs:\\n  -
        to: 'jason.holt@andominia.com'\\n    subject: '\U0001F4E2 ODIN Alert: {{ .GroupLabels.alertname
        }}'\\n    html: |\\n      \\u003ch2\\u003e\U0001F4E2 ODIN Alert: {{ .GroupLabels.alertname
        }}\\u003c/h2\\u003e\\n      \\n      {{ range .Alerts }}\\n      \\u003ch3\\u003e{{
        .Annotations.summary }}\\u003c/h3\\u003e\\n      \\u003cp\\u003e\\u003cstrong\\u003eDescription:\\u003c/strong\\u003e
        {{ .Annotations.description }}\\u003c/p\\u003e\\n      \\u003chr\\u003e\\n
        \     {{ end }}\\n      \\n- name: 'webhook-receiver'\\n  webhook_configs:\\n
        \ - url: 'http://webhook-logger:8080/webhook'\\n    send_resolved: true\\n
        \   http_config:\\n      basic_auth:\\n        username: 'odin'\\n        password:
        'monitoring'\\n        \\ninhibit_rules:\\n# Don't send pod alerts if node
        is down\\n- source_match:\\n    alertname: 'NodeNotReady'\\n  target_match_re:\\n
        \   alertname: 'Pod.*|Container.*'\\n  equal: ['node']\\n  \\n# Don't send
        target down if Prometheus is down\\n- source_match:\\n    alertname: 'PrometheusDown'\\n
        \ target_match:\\n    alertname: 'PrometheusTargetDown'\\n  equal: ['instance']\\n
        \ \\n# Don't send individual monitoring alerts if whole stack is critical\\n-
        source_match:\\n    alertname: 'MonitoringStackCritical'\\n  target_match:\\n
        \   component: 'monitoring-stack'\\n    severity: 'warning'\\n    \\n\"},\"kind\":\"ConfigMap\",\"metadata\":{\"annotations\":{},\"name\":\"alertmanager-email-config\",\"namespace\":\"monitoring\"}}\n"
    creationTimestamp: "2025-06-01T04:36:26Z"
    name: alertmanager-email-config
    namespace: monitoring
    resourceVersion: "879750"
    uid: 31bad1b3-6592-4236-a448-1d4024834032
- apiVersion: v1
  data:
    alertmanager.yml: "global:\n  resolve_timeout: 5m\n  smtp_smarthost: 'smtp.gmail.com:587'\n
      \ smtp_from: 'odin-alerts@gmail.com'\n  smtp_auth_username: 'jason.holt@andominia.com'\n
      \ smtp_auth_password: 'DA!Amar01'\n  smtp_require_tls: true\n  \nroute:\n  receiver:
      'default-receiver'\n  group_by: ['alertname', 'cluster', 'service', 'component']\n
      \ group_wait: 10s\n  group_interval: 10s\n  repeat_interval: 15m\n  \n  routes:\n
      \ # Critical alerts - immediate email\n  - match:\n      severity: critical\n
      \   receiver: 'critical-email-receiver'\n    group_wait: 0s\n    repeat_interval:
      5m\n    \n  # Monitoring stack issues - immediate email\n  - match:\n      component:
      monitoring-stack\n    receiver: 'monitoring-email-receiver'\n    group_wait:
      30s\n    repeat_interval: 10m\n    \n  # Pod crashes and OOM - immediate email
      \ \n  - match_re:\n      alertname: '.*OOM.*|.*Crash.*|.*Restart.*'\n    receiver:
      'pod-issues-email-receiver'\n    group_wait: 0s\n    repeat_interval: 5m\n    \n
      \ # GPU and thermal issues\n  - match_re:\n      alertname: '.*GPU.*|.*Thermal.*|.*Temperature.*'\n
      \   receiver: 'gpu-email-receiver'\n    group_wait: 30s\n    repeat_interval:
      10m\n    \n  # Default webhook fallback\n  - receiver: 'webhook-receiver'\n
      \   \nreceivers:\n# Email receivers for different alert types\n- name: 'critical-email-receiver'\n
      \ email_configs:\n  - to: 'jason.holt@andominia.com'\n    subject: '\U0001F6A8
      ODIN CRITICAL: {{ .GroupLabels.alertname }}'\n    body: |\n      \U0001F6A8
      Critical Alert: {{ .GroupLabels.alertname }}\n      \n      Cluster: ODIN Monitoring\n
      \     Time: {{ .CommonAnnotations.timestamp }}\n      \n      {{ range .Alerts
      }}\n      Alert: {{ .Annotations.summary }}\n      Description: {{ .Annotations.description
      }}\n      Pod/Service: {{ .Labels.pod }}{{ .Labels.service }}\n      Namespace:
      {{ .Labels.namespace }}\n      Severity: {{ .Labels.severity }}\n      {{ end
      }}\n      \n      View Grafana: http://localhost:31494\n  webhook_configs:\n
      \ - url: 'http://webhook-logger:8080/critical'\n    send_resolved: true\n    \n-
      name: 'monitoring-email-receiver'\n  email_configs:\n  - to: 'jason.holt@andominia.com'\n
      \   subject: '\U0001F4CA ODIN Monitoring Issue: {{ .GroupLabels.alertname }}'\n
      \   body: |\n      \U0001F4CA Monitoring Stack Alert: {{ .GroupLabels.alertname
      }}\n      \n      {{ range .Alerts }}\n      Alert: {{ .Annotations.summary
      }}\n      Description: {{ .Annotations.description }}\n      Component: {{ .Labels.component
      }}\n      Service: {{ .Labels.service }}\n      Instance: {{ .Labels.instance
      }}\n      {{ end }}\n      \n      System Overview: http://localhost:31494/d/odin-system-overview\n
      \ webhook_configs:\n  - url: 'http://webhook-logger:8080/monitoring'\n    send_resolved:
      true\n    \n- name: 'pod-issues-email-receiver'\n  email_configs:\n  - to: 'jason.holt@andominia.com'\n
      \   subject: '\U0001F504 ODIN Pod Issue: {{ .GroupLabels.alertname }}'\n    body:
      |\n      \U0001F504 Pod Management Alert: {{ .GroupLabels.alertname }}\n      \n
      \     {{ range .Alerts }}\n      Alert: {{ .Annotations.summary }}\n      Description:
      {{ .Annotations.description }}\n      Pod: {{ .Labels.pod }}\n      Namespace:
      {{ .Labels.namespace }}\n      Container: {{ .Labels.container }}\n      \n
      \     Troubleshooting:\n      kubectl describe pod {{ .Labels.pod }} -n {{ .Labels.namespace
      }}\n      kubectl logs {{ .Labels.pod }} -n {{ .Labels.namespace }} --previous\n
      \     {{ end }}\n      \n      Pod Dashboard: http://localhost:31494/d/k8s-pods\n
      \ webhook_configs:\n  - url: 'http://webhook-logger:8080/pods'\n    send_resolved:
      true\n    \n- name: 'gpu-email-receiver'\n  email_configs:\n  - to: 'jason.holt@andominia.com'\n
      \   subject: '\U0001F3AE ODIN GPU Alert: {{ .GroupLabels.alertname }}'\n    body:
      |\n      \U0001F3AE GPU Hardware Alert: {{ .GroupLabels.alertname }}\n      \n
      \     {{ range .Alerts }}\n      Alert: {{ .Annotations.summary }}\n      Description:
      {{ .Annotations.description }}\n      GPU: {{ .Labels.gpu }}\n      Temperature:
      {{ .Labels.temperature }}°C\n      Power: {{ .Labels.power }}W\n      {{ end
      }}\n      \n      GPU Dashboard: http://localhost:31494/d/gpu-monitoring\n  webhook_configs:\n
      \ - url: 'http://webhook-logger:8080/gpu'\n    send_resolved: true\n    \n#
      Default receivers  \n- name: 'default-receiver'\n  email_configs:\n  - to: 'jason.holt@andominia.com'\n
      \   subject: '\U0001F4E2 ODIN Alert: {{ .GroupLabels.alertname }}'\n    body:
      |\n      \U0001F4E2 ODIN Alert: {{ .GroupLabels.alertname }}\n      \n      {{
      range .Alerts }}\n      Alert: {{ .Annotations.summary }}\n      Description:
      {{ .Annotations.description }}\n      {{ end }}\n      \n- name: 'webhook-receiver'\n
      \ webhook_configs:\n  - url: 'http://webhook-logger:8080/webhook'\n    send_resolved:
      true\n    http_config:\n      basic_auth:\n        username: 'odin'\n        password:
      'monitoring'\n        \ninhibit_rules:\n# Don't send pod alerts if node is down\n-
      source_match:\n    alertname: 'NodeNotReady'\n  target_match_re:\n    alertname:
      'Pod.*|Container.*'\n  equal: ['node']\n  \n# Don't send target down if Prometheus
      is down\n- source_match:\n    alertname: 'PrometheusDown'\n  target_match:\n
      \   alertname: 'PrometheusTargetDown'\n  equal: ['instance']\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: "{\"apiVersion\":\"v1\",\"data\":{\"alertmanager.yml\":\"global:\\n
        \ resolve_timeout: 5m\\n  smtp_smarthost: 'smtp.gmail.com:587'\\n  smtp_from:
        'odin-alerts@gmail.com'\\n  smtp_auth_username: 'jason.holt@andominia.com'\\n
        \ smtp_auth_password: 'DA!Amar01'\\n  smtp_require_tls: true\\n  \\nroute:\\n
        \ receiver: 'default-receiver'\\n  group_by: ['alertname', 'cluster', 'service',
        'component']\\n  group_wait: 10s\\n  group_interval: 10s\\n  repeat_interval:
        15m\\n  \\n  routes:\\n  # Critical alerts - immediate email\\n  - match:\\n
        \     severity: critical\\n    receiver: 'critical-email-receiver'\\n    group_wait:
        0s\\n    repeat_interval: 5m\\n    \\n  # Monitoring stack issues - immediate
        email\\n  - match:\\n      component: monitoring-stack\\n    receiver: 'monitoring-email-receiver'\\n
        \   group_wait: 30s\\n    repeat_interval: 10m\\n    \\n  # Pod crashes and
        OOM - immediate email  \\n  - match_re:\\n      alertname: '.*OOM.*|.*Crash.*|.*Restart.*'\\n
        \   receiver: 'pod-issues-email-receiver'\\n    group_wait: 0s\\n    repeat_interval:
        5m\\n    \\n  # GPU and thermal issues\\n  - match_re:\\n      alertname:
        '.*GPU.*|.*Thermal.*|.*Temperature.*'\\n    receiver: 'gpu-email-receiver'\\n
        \   group_wait: 30s\\n    repeat_interval: 10m\\n    \\n  # Default webhook
        fallback\\n  - receiver: 'webhook-receiver'\\n    \\nreceivers:\\n# Email
        receivers for different alert types\\n- name: 'critical-email-receiver'\\n
        \ email_configs:\\n  - to: 'jason.holt@andominia.com'\\n    subject: '\U0001F6A8
        ODIN CRITICAL: {{ .GroupLabels.alertname }}'\\n    body: |\\n      \U0001F6A8
        Critical Alert: {{ .GroupLabels.alertname }}\\n      \\n      Cluster: ODIN
        Monitoring\\n      Time: {{ .CommonAnnotations.timestamp }}\\n      \\n      {{
        range .Alerts }}\\n      Alert: {{ .Annotations.summary }}\\n      Description:
        {{ .Annotations.description }}\\n      Pod/Service: {{ .Labels.pod }}{{ .Labels.service
        }}\\n      Namespace: {{ .Labels.namespace }}\\n      Severity: {{ .Labels.severity
        }}\\n      {{ end }}\\n      \\n      View Grafana: http://localhost:31494\\n
        \ webhook_configs:\\n  - url: 'http://webhook-logger:8080/critical'\\n    send_resolved:
        true\\n    \\n- name: 'monitoring-email-receiver'\\n  email_configs:\\n  -
        to: 'jason.holt@andominia.com'\\n    subject: '\U0001F4CA ODIN Monitoring
        Issue: {{ .GroupLabels.alertname }}'\\n    body: |\\n      \U0001F4CA Monitoring
        Stack Alert: {{ .GroupLabels.alertname }}\\n      \\n      {{ range .Alerts
        }}\\n      Alert: {{ .Annotations.summary }}\\n      Description: {{ .Annotations.description
        }}\\n      Component: {{ .Labels.component }}\\n      Service: {{ .Labels.service
        }}\\n      Instance: {{ .Labels.instance }}\\n      {{ end }}\\n      \\n
        \     System Overview: http://localhost:31494/d/odin-system-overview\\n  webhook_configs:\\n
        \ - url: 'http://webhook-logger:8080/monitoring'\\n    send_resolved: true\\n
        \   \\n- name: 'pod-issues-email-receiver'\\n  email_configs:\\n  - to: 'jason.holt@andominia.com'\\n
        \   subject: '\U0001F504 ODIN Pod Issue: {{ .GroupLabels.alertname }}'\\n
        \   body: |\\n      \U0001F504 Pod Management Alert: {{ .GroupLabels.alertname
        }}\\n      \\n      {{ range .Alerts }}\\n      Alert: {{ .Annotations.summary
        }}\\n      Description: {{ .Annotations.description }}\\n      Pod: {{ .Labels.pod
        }}\\n      Namespace: {{ .Labels.namespace }}\\n      Container: {{ .Labels.container
        }}\\n      \\n      Troubleshooting:\\n      kubectl describe pod {{ .Labels.pod
        }} -n {{ .Labels.namespace }}\\n      kubectl logs {{ .Labels.pod }} -n {{
        .Labels.namespace }} --previous\\n      {{ end }}\\n      \\n      Pod Dashboard:
        http://localhost:31494/d/k8s-pods\\n  webhook_configs:\\n  - url: 'http://webhook-logger:8080/pods'\\n
        \   send_resolved: true\\n    \\n- name: 'gpu-email-receiver'\\n  email_configs:\\n
        \ - to: 'jason.holt@andominia.com'\\n    subject: '\U0001F3AE ODIN GPU Alert:
        {{ .GroupLabels.alertname }}'\\n    body: |\\n      \U0001F3AE GPU Hardware
        Alert: {{ .GroupLabels.alertname }}\\n      \\n      {{ range .Alerts }}\\n
        \     Alert: {{ .Annotations.summary }}\\n      Description: {{ .Annotations.description
        }}\\n      GPU: {{ .Labels.gpu }}\\n      Temperature: {{ .Labels.temperature
        }}°C\\n      Power: {{ .Labels.power }}W\\n      {{ end }}\\n      \\n      GPU
        Dashboard: http://localhost:31494/d/gpu-monitoring\\n  webhook_configs:\\n
        \ - url: 'http://webhook-logger:8080/gpu'\\n    send_resolved: true\\n    \\n#
        Default receivers  \\n- name: 'default-receiver'\\n  email_configs:\\n  -
        to: 'jason.holt@andominia.com'\\n    subject: '\U0001F4E2 ODIN Alert: {{ .GroupLabels.alertname
        }}'\\n    body: |\\n      \U0001F4E2 ODIN Alert: {{ .GroupLabels.alertname
        }}\\n      \\n      {{ range .Alerts }}\\n      Alert: {{ .Annotations.summary
        }}\\n      Description: {{ .Annotations.description }}\\n      {{ end }}\\n
        \     \\n- name: 'webhook-receiver'\\n  webhook_configs:\\n  - url: 'http://webhook-logger:8080/webhook'\\n
        \   send_resolved: true\\n    http_config:\\n      basic_auth:\\n        username:
        'odin'\\n        password: 'monitoring'\\n        \\ninhibit_rules:\\n# Don't
        send pod alerts if node is down\\n- source_match:\\n    alertname: 'NodeNotReady'\\n
        \ target_match_re:\\n    alertname: 'Pod.*|Container.*'\\n  equal: ['node']\\n
        \ \\n# Don't send target down if Prometheus is down\\n- source_match:\\n    alertname:
        'PrometheusDown'\\n  target_match:\\n    alertname: 'PrometheusTargetDown'\\n
        \ equal: ['instance']\\n\"},\"kind\":\"ConfigMap\",\"metadata\":{\"annotations\":{},\"name\":\"alertmanager-email-config-fixed\",\"namespace\":\"monitoring\"}}\n"
    creationTimestamp: "2025-06-01T04:38:32Z"
    name: alertmanager-email-config-fixed
    namespace: monitoring
    resourceVersion: "880764"
    uid: e56e135e-2b2e-4e58-96ff-d1591c5e9974
- apiVersion: v1
  data:
    default.tmpl: |
      {{ define "odin.default.subject" }}
      [{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ .GroupLabels.SortedPairs.Values | join " " }} {{ if gt (len .CommonLabels) (len .GroupLabels) }}({{ with .CommonLabels.Remove .GroupLabels.Names }}{{ .Values | join " " }}{{ end }}){{ end }}
      {{ end }}

      {{ define "odin.default.text" }}
      {{ range .Alerts }}
      *Alert:* {{ .Annotations.summary }}{{ if .Labels.severity }} - `{{ .Labels.severity }}`{{ end }}
      *Description:* {{ .Annotations.description }}
      *Details:*
      {{ range .Labels.SortedPairs }} • *{{ .Name }}:* `{{ .Value }}`
      {{ end }}
      *Source:* {{ .GeneratorURL }}
      {{ end }}
      {{ end }}
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"default.tmpl":"{{ define \"odin.default.subject\" }}\n[{{ .Status | toUpper }}{{ if eq .Status \"firing\" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ .GroupLabels.SortedPairs.Values | join \" \" }} {{ if gt (len .CommonLabels) (len .GroupLabels) }}({{ with .CommonLabels.Remove .GroupLabels.Names }}{{ .Values | join \" \" }}{{ end }}){{ end }}\n{{ end }}\n\n{{ define \"odin.default.text\" }}\n{{ range .Alerts }}\n*Alert:* {{ .Annotations.summary }}{{ if .Labels.severity }} - `{{ .Labels.severity }}`{{ end }}\n*Description:* {{ .Annotations.description }}\n*Details:*\n{{ range .Labels.SortedPairs }} • *{{ .Name }}:* `{{ .Value }}`\n{{ end }}\n*Source:* {{ .GeneratorURL }}\n{{ end }}\n{{ end }}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"alertmanager-templates","namespace":"monitoring"}}
    creationTimestamp: "2025-05-29T23:07:31Z"
    name: alertmanager-templates
    namespace: monitoring
    resourceVersion: "85795"
    uid: 3cd36fdb-8b6a-42ba-a95a-3a0007ce6676
- apiVersion: v1
  data:
    anomaly-alerts.yaml: "groups:\n- name: anomaly_detection_alerts\n  interval: 30s\n
      \ rules:\n  # High anomaly scores - TUNED to reduce noise\n  - alert: HighAnomalyScore\n
      \   expr: |\n      anomaly_score{metric_name!~\"cpu_usage_percent|memory_usage_percent\"}
      > 85\n      and anomaly_score{metric_name!~\"cpu_usage_percent|memory_usage_percent\"}
      < 100\n    for: 10m  # Increased from 5m to reduce flapping\n    labels:\n      severity:
      warning\n      component: anomaly-detection\n    annotations:\n      summary:
      \"High anomaly score detected\"\n      description: \"{{ $labels.metric_name
      }} has anomaly score of {{ $value }} (algorithm: {{ $labels.algorithm }})\"\n
      \     \n  - alert: CriticalAnomalyScore\n    expr: |\n      anomaly_score{metric_name!~\"cpu_usage_percent|memory_usage_percent\"}
      > 95\n    for: 5m  # Increased from 2m\n    labels:\n      severity: critical\n
      \     component: anomaly-detection\n    annotations:\n      summary: \"Critical
      anomaly detected\"\n      description: \"{{ $labels.metric_name }} has critical
      anomaly score of {{ $value }} - immediate investigation required\"\n  \n  #
      CPU/Memory specific anomalies with context\n  - alert: SystemResourceAnomaly\n
      \   expr: |\n      (anomaly_score{metric_name=\"cpu_usage_percent\"} > 90 and
      node_cpu_seconds_total > 90)\n      or\n      (anomaly_score{metric_name=\"memory_usage_percent\"}
      > 90 and (1 - node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) >
      0.85)\n    for: 15m\n    labels:\n      severity: warning\n      component:
      system\n      anomaly: true\n    annotations:\n      summary: \"System resource
      anomaly with high usage\"\n      description: \"{{ $labels.metric_name }} showing
      anomaly score {{ $value }} with actual high resource usage\"\n      \n  # GPU-specific
      anomalies\n  - alert: GPUTemperatureAnomaly\n    expr: anomaly_score{metric_name=\"nvidia_gpu_temperature_celsius\"}
      > 75 and nvidia_gpu_temperature_celsius > 75\n    for: 5m\n    labels:\n      severity:
      warning\n      component: gpu\n      anomaly: true\n    annotations:\n      summary:
      \"GPU temperature anomaly detected\"\n      description: \"GPU temperature is
      {{ $labels.nvidia_gpu_temperature_celsius }}°C with anomaly score {{ $value
      }}\"\n      \n  - alert: GPUPowerAnomaly\n    expr: anomaly_score{metric_name=\"nvidia_gpu_power_draw_watts\"}
      > 75 and nvidia_gpu_power_draw_watts > 200\n    for: 10m\n    labels:\n      severity:
      warning\n      component: gpu\n      anomaly: true\n    annotations:\n      summary:
      \"GPU power draw anomaly detected\"\n      description: \"GPU power consumption
      showing unusual pattern (score: {{ $value }}, power: {{ $labels.nvidia_gpu_power_draw_watts
      }}W)\"\n      \n  # Network anomalies - only alert on significant deviations\n
      \ - alert: NetworkTrafficAnomaly\n    expr: |\n      anomaly_score{metric_name=\"rate(node_network_receive_bytes_total[5m])\"}
      > 85\n      and rate(node_network_receive_bytes_total[5m]) > 100000000  # 100MB/s\n
      \   for: 10m\n    labels:\n      severity: warning\n      component: network\n
      \     anomaly: true\n    annotations:\n      summary: \"Network traffic anomaly
      detected\"\n      description: \"Network receive traffic showing unusual pattern
      (score: {{ $value }})\"\n      \n  # Memory anomalies - only when actually low\n
      \ - alert: MemoryUsageAnomaly\n    expr: |\n      anomaly_score{metric_name=\"node_memory_MemAvailable_bytes\"}
      > 80\n      and node_memory_MemAvailable_bytes < 2147483648  # Less than 2GB\n
      \   for: 10m\n    labels:\n      severity: warning\n      component: system\n
      \     anomaly: true\n    annotations:\n      summary: \"Memory usage anomaly
      detected\"\n      description: \"Memory availability showing unusual pattern
      with low available memory (score: {{ $value }})\"\n      \n  # Claude API anomalies\n
      \ - alert: ClaudeAPIUsageAnomaly\n    expr: |\n      anomaly_score{metric_name=\"claude_code_api_requests_total\"}
      > 85\n      and rate(claude_code_api_requests_total[5m]) > 0.5  # More than
      30 requests/minute\n    for: 15m\n    labels:\n      severity: warning\n      component:
      claude-code\n      anomaly: true\n    annotations:\n      summary: \"Claude
      API usage anomaly detected\"\n      description: \"Claude API request pattern
      is unusual (score: {{ $value }})\"\n      \n  # Anomaly detector health - Updated
      to check actual running detectors\n  - alert: GPUAnomalyDetectorDown\n    expr:
      up{job=\"gpu-anomaly-detector\"} == 0\n    for: 5m\n    labels:\n      severity:
      warning\n      component: anomaly-detection\n      detector: gpu\n    annotations:\n
      \     summary: \"GPU anomaly detector is down\"\n      description: \"GPU anomaly
      detection service is not responding\"\n      \n  - alert: K8sPodAnomalyDetectorDown\n
      \   expr: up{job=\"k8s-pod-anomaly-detector\"} == 0\n    for: 5m\n    labels:\n
      \     severity: warning\n      component: anomaly-detection\n      detector:
      k8s-pod\n    annotations:\n      summary: \"K8s pod anomaly detector is down\"\n
      \     description: \"Kubernetes pod anomaly detection service is not responding\"\n
      \     \n  - alert: DiskAnomalyDetectorDown\n    expr: up{job=\"disk-anomaly-detector\"}
      == 0\n    for: 5m\n    labels:\n      severity: warning\n      component: anomaly-detection\n
      \     detector: disk\n    annotations:\n      summary: \"Disk anomaly detector
      is down\"\n      description: \"Disk anomaly detection service is not responding\"\n
      \     \n  - alert: AnomalyDetectionErrors\n    expr: rate(anomaly_detection_errors_total[5m])
      > 0.1\n    for: 5m\n    labels:\n      severity: warning\n      component: anomaly-detection\n
      \   annotations:\n      summary: \"Anomaly detection errors\"\n      description:
      \"Anomaly detector is experiencing {{ $value }} errors per second for {{ $labels.metric_name
      }}\"\n      \n  # Correlation alerts - increased thresholds\n  - alert: MultipleAnomaliesDetected\n
      \   expr: |\n      count(anomaly_score{metric_name!~\"cpu_usage_percent|memory_usage_percent\"}
      > 85) > 5\n    for: 10m\n    labels:\n      severity: critical\n      component:
      anomaly-detection\n    annotations:\n      summary: \"Multiple anomalies detected
      simultaneously\"\n      description: \"{{ $value }} metrics are showing anomalous
      behavior - possible system-wide issue\"\n      \n  - alert: GPUAndPowerAnomaly\n
      \   expr: |\n      (anomaly_score{metric_name=\"nvidia_gpu_temperature_celsius\"}
      > 70) \n      and \n      (anomaly_score{metric_name=\"nvidia_gpu_power_draw_watts\"}
      > 70)\n      and\n      (nvidia_gpu_temperature_celsius > 75 or nvidia_gpu_power_draw_watts
      > 200)\n    for: 10m\n    labels:\n      severity: critical\n      component:
      gpu\n      anomaly: true\n    annotations:\n      summary: \"Correlated GPU
      anomalies detected\"\n      description: \"Both GPU temperature and power draw
      are showing anomalous patterns - possible hardware issue\"\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"anomaly-alerts.yaml":"groups:\n- name: anomaly_detection_alerts\n  interval: 30s\n  rules:\n  # High anomaly scores - TUNED to reduce noise\n  - alert: HighAnomalyScore\n    expr: |\n      anomaly_score{metric_name!~\"cpu_usage_percent|memory_usage_percent\"} \u003e 85\n      and anomaly_score{metric_name!~\"cpu_usage_percent|memory_usage_percent\"} \u003c 100\n    for: 10m  # Increased from 5m to reduce flapping\n    labels:\n      severity: warning\n      component: anomaly-detection\n    annotations:\n      summary: \"High anomaly score detected\"\n      description: \"{{ $labels.metric_name }} has anomaly score of {{ $value }} (algorithm: {{ $labels.algorithm }})\"\n      \n  - alert: CriticalAnomalyScore\n    expr: |\n      anomaly_score{metric_name!~\"cpu_usage_percent|memory_usage_percent\"} \u003e 95\n    for: 5m  # Increased from 2m\n    labels:\n      severity: critical\n      component: anomaly-detection\n    annotations:\n      summary: \"Critical anomaly detected\"\n      description: \"{{ $labels.metric_name }} has critical anomaly score of {{ $value }} - immediate investigation required\"\n  \n  # CPU/Memory specific anomalies with context\n  - alert: SystemResourceAnomaly\n    expr: |\n      (anomaly_score{metric_name=\"cpu_usage_percent\"} \u003e 90 and node_cpu_seconds_total \u003e 90)\n      or\n      (anomaly_score{metric_name=\"memory_usage_percent\"} \u003e 90 and (1 - node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) \u003e 0.85)\n    for: 15m\n    labels:\n      severity: warning\n      component: system\n      anomaly: true\n    annotations:\n      summary: \"System resource anomaly with high usage\"\n      description: \"{{ $labels.metric_name }} showing anomaly score {{ $value }} with actual high resource usage\"\n      \n  # GPU-specific anomalies\n  - alert: GPUTemperatureAnomaly\n    expr: anomaly_score{metric_name=\"nvidia_gpu_temperature_celsius\"} \u003e 75 and nvidia_gpu_temperature_celsius \u003e 75\n    for: 5m\n    labels:\n      severity: warning\n      component: gpu\n      anomaly: true\n    annotations:\n      summary: \"GPU temperature anomaly detected\"\n      description: \"GPU temperature is {{ $labels.nvidia_gpu_temperature_celsius }}°C with anomaly score {{ $value }}\"\n      \n  - alert: GPUPowerAnomaly\n    expr: anomaly_score{metric_name=\"nvidia_gpu_power_draw_watts\"} \u003e 75 and nvidia_gpu_power_draw_watts \u003e 200\n    for: 10m\n    labels:\n      severity: warning\n      component: gpu\n      anomaly: true\n    annotations:\n      summary: \"GPU power draw anomaly detected\"\n      description: \"GPU power consumption showing unusual pattern (score: {{ $value }}, power: {{ $labels.nvidia_gpu_power_draw_watts }}W)\"\n      \n  # Network anomalies - only alert on significant deviations\n  - alert: NetworkTrafficAnomaly\n    expr: |\n      anomaly_score{metric_name=\"rate(node_network_receive_bytes_total[5m])\"} \u003e 85\n      and rate(node_network_receive_bytes_total[5m]) \u003e 100000000  # 100MB/s\n    for: 10m\n    labels:\n      severity: warning\n      component: network\n      anomaly: true\n    annotations:\n      summary: \"Network traffic anomaly detected\"\n      description: \"Network receive traffic showing unusual pattern (score: {{ $value }})\"\n      \n  # Memory anomalies - only when actually low\n  - alert: MemoryUsageAnomaly\n    expr: |\n      anomaly_score{metric_name=\"node_memory_MemAvailable_bytes\"} \u003e 80\n      and node_memory_MemAvailable_bytes \u003c 2147483648  # Less than 2GB\n    for: 10m\n    labels:\n      severity: warning\n      component: system\n      anomaly: true\n    annotations:\n      summary: \"Memory usage anomaly detected\"\n      description: \"Memory availability showing unusual pattern with low available memory (score: {{ $value }})\"\n      \n  # Claude API anomalies\n  - alert: ClaudeAPIUsageAnomaly\n    expr: |\n      anomaly_score{metric_name=\"claude_code_api_requests_total\"} \u003e 85\n      and rate(claude_code_api_requests_total[5m]) \u003e 0.5  # More than 30 requests/minute\n    for: 15m\n    labels:\n      severity: warning\n      component: claude-code\n      anomaly: true\n    annotations:\n      summary: \"Claude API usage anomaly detected\"\n      description: \"Claude API request pattern is unusual (score: {{ $value }})\"\n      \n  # Anomaly detector health - Updated to check actual running detectors\n  - alert: GPUAnomalyDetectorDown\n    expr: up{job=\"gpu-anomaly-detector\"} == 0\n    for: 5m\n    labels:\n      severity: warning\n      component: anomaly-detection\n      detector: gpu\n    annotations:\n      summary: \"GPU anomaly detector is down\"\n      description: \"GPU anomaly detection service is not responding\"\n      \n  - alert: K8sPodAnomalyDetectorDown\n    expr: up{job=\"k8s-pod-anomaly-detector\"} == 0\n    for: 5m\n    labels:\n      severity: warning\n      component: anomaly-detection\n      detector: k8s-pod\n    annotations:\n      summary: \"K8s pod anomaly detector is down\"\n      description: \"Kubernetes pod anomaly detection service is not responding\"\n      \n  - alert: DiskAnomalyDetectorDown\n    expr: up{job=\"disk-anomaly-detector\"} == 0\n    for: 5m\n    labels:\n      severity: warning\n      component: anomaly-detection\n      detector: disk\n    annotations:\n      summary: \"Disk anomaly detector is down\"\n      description: \"Disk anomaly detection service is not responding\"\n      \n  - alert: AnomalyDetectionErrors\n    expr: rate(anomaly_detection_errors_total[5m]) \u003e 0.1\n    for: 5m\n    labels:\n      severity: warning\n      component: anomaly-detection\n    annotations:\n      summary: \"Anomaly detection errors\"\n      description: \"Anomaly detector is experiencing {{ $value }} errors per second for {{ $labels.metric_name }}\"\n      \n  # Correlation alerts - increased thresholds\n  - alert: MultipleAnomaliesDetected\n    expr: |\n      count(anomaly_score{metric_name!~\"cpu_usage_percent|memory_usage_percent\"} \u003e 85) \u003e 5\n    for: 10m\n    labels:\n      severity: critical\n      component: anomaly-detection\n    annotations:\n      summary: \"Multiple anomalies detected simultaneously\"\n      description: \"{{ $value }} metrics are showing anomalous behavior - possible system-wide issue\"\n      \n  - alert: GPUAndPowerAnomaly\n    expr: |\n      (anomaly_score{metric_name=\"nvidia_gpu_temperature_celsius\"} \u003e 70) \n      and \n      (anomaly_score{metric_name=\"nvidia_gpu_power_draw_watts\"} \u003e 70)\n      and\n      (nvidia_gpu_temperature_celsius \u003e 75 or nvidia_gpu_power_draw_watts \u003e 200)\n    for: 10m\n    labels:\n      severity: critical\n      component: gpu\n      anomaly: true\n    annotations:\n      summary: \"Correlated GPU anomalies detected\"\n      description: \"Both GPU temperature and power draw are showing anomalous patterns - possible hardware issue\"\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"anomaly-alert-rules","namespace":"monitoring"}}
    creationTimestamp: "2025-05-29T23:50:47Z"
    name: anomaly-alert-rules
    namespace: monitoring
    resourceVersion: "5306129"
    uid: 123dae89-32fc-4683-9a2f-7188798fbd9a
- apiVersion: v1
  data:
    ml-anomaly-detection.json: |
      {
        "uid": "ml-anomaly-detection",
        "title": "ODIN ML Anomaly Detection",
        "tags": ["odin", "ml", "anomaly-detection"],
        "timezone": "America/Los_Angeles",
        "refresh": "30s",
        "panels": [
          {
            "gridPos": {"h": 1, "w": 24, "x": 0, "y": 0},
            "id": 1,
            "type": "row",
            "title": "Anomaly Detector Status",
            "collapsed": false
          },
          {
            "gridPos": {"h": 4, "w": 6, "x": 0, "y": 1},
            "id": 2,
            "type": "stat",
            "title": "GPU Anomaly Detector",
            "targets": [
              {
                "expr": "up{job=\"gpu-anomaly-detector\"}",
                "refId": "A"
              }
            ],
            "options": {
              "graphMode": "none",
              "colorMode": "background",
              "reduceOptions": {
                "values": false,
                "calcs": ["lastNotNull"]
              }
            },
            "fieldConfig": {
              "defaults": {
                "mappings": [
                  {"type": "value", "value": 1, "text": "UP", "color": "green"},
                  {"type": "value", "value": 0, "text": "DOWN", "color": "red"}
                ],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"value": 0, "color": "red"},
                    {"value": 1, "color": "green"}
                  ]
                }
              }
            }
          },
          {
            "gridPos": {"h": 4, "w": 6, "x": 6, "y": 1},
            "id": 3,
            "type": "stat",
            "title": "Process Anomaly Detector",
            "targets": [
              {
                "expr": "up{job=\"process-anomaly-detector\"}",
                "refId": "A"
              }
            ],
            "options": {
              "graphMode": "none",
              "colorMode": "background",
              "reduceOptions": {
                "values": false,
                "calcs": ["lastNotNull"]
              }
            },
            "fieldConfig": {
              "defaults": {
                "mappings": [
                  {"type": "value", "value": 1, "text": "UP", "color": "green"},
                  {"type": "value", "value": 0, "text": "DOWN", "color": "red"}
                ],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"value": 0, "color": "red"},
                    {"value": 1, "color": "green"}
                  ]
                }
              }
            }
          },
          {
            "gridPos": {"h": 4, "w": 6, "x": 12, "y": 1},
            "id": 4,
            "type": "stat",
            "title": "K8s Pod Anomaly Detector",
            "targets": [
              {
                "expr": "up{job=\"k8s-pod-anomaly-detector\"}",
                "refId": "A"
              }
            ],
            "options": {
              "graphMode": "none",
              "colorMode": "background",
              "reduceOptions": {
                "values": false,
                "calcs": ["lastNotNull"]
              }
            },
            "fieldConfig": {
              "defaults": {
                "mappings": [
                  {"type": "value", "value": 1, "text": "UP", "color": "green"},
                  {"type": "value", "value": 0, "text": "DOWN", "color": "red"}
                ],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"value": 0, "color": "red"},
                    {"value": 1, "color": "green"}
                  ]
                }
              }
            }
          },
          {
            "gridPos": {"h": 4, "w": 6, "x": 18, "y": 1},
            "id": 5,
            "type": "stat",
            "title": "Disk Anomaly Detector",
            "targets": [
              {
                "expr": "up{job=\"disk-anomaly-detector\"}",
                "refId": "A"
              }
            ],
            "options": {
              "graphMode": "none",
              "colorMode": "background",
              "reduceOptions": {
                "values": false,
                "calcs": ["lastNotNull"]
              }
            },
            "fieldConfig": {
              "defaults": {
                "mappings": [
                  {"type": "value", "value": 1, "text": "UP", "color": "green"},
                  {"type": "value", "value": 0, "text": "DOWN", "color": "red"}
                ],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"value": 0, "color": "red"},
                    {"value": 1, "color": "green"}
                  ]
                }
              }
            }
          },
          {
            "gridPos": {"h": 1, "w": 24, "x": 0, "y": 5},
            "id": 6,
            "type": "row",
            "title": "GPU Anomaly Scores",
            "collapsed": false
          },
          {
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 6},
            "id": 7,
            "type": "timeseries",
            "title": "GPU Temperature Anomaly Score",
            "targets": [
              {
                "expr": "gpu_anomaly_score{metric_name=\"nvidia_gpu_temperature_celsius\"}",
                "legendFormat": "GPU {{gpu}} Temperature",
                "refId": "A"
              }
            ],
            "options": {
              "tooltip": {"mode": "multi"},
              "legend": {"displayMode": "list", "placement": "bottom"}
            },
            "fieldConfig": {
              "defaults": {
                "unit": "percent",
                "min": 0,
                "max": 100,
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"value": 0, "color": "green"},
                    {"value": 50, "color": "yellow"},
                    {"value": 80, "color": "red"}
                  ]
                }
              }
            }
          },
          {
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 6},
            "id": 8,
            "type": "timeseries",
            "title": "GPU Power Anomaly Score",
            "targets": [
              {
                "expr": "gpu_anomaly_score{metric_name=\"node_gpu_power_watts\"}",
                "legendFormat": "GPU {{gpu}} Power",
                "refId": "A"
              }
            ],
            "options": {
              "tooltip": {"mode": "multi"},
              "legend": {"displayMode": "list", "placement": "bottom"}
            },
            "fieldConfig": {
              "defaults": {
                "unit": "percent",
                "min": 0,
                "max": 100,
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"value": 0, "color": "green"},
                    {"value": 50, "color": "yellow"},
                    {"value": 80, "color": "red"}
                  ]
                }
              }
            }
          },
          {
            "gridPos": {"h": 1, "w": 24, "x": 0, "y": 14},
            "id": 9,
            "type": "row",
            "title": "Process Anomaly Scores",
            "collapsed": false
          },
          {
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 15},
            "id": 10,
            "type": "timeseries",
            "title": "Process Anomaly Scores",
            "targets": [
              {
                "expr": "topk(10, process_anomaly_score)",
                "legendFormat": "{{process_name}} - {{metric_type}}",
                "refId": "A"
              }
            ],
            "options": {
              "tooltip": {"mode": "multi"},
              "legend": {"displayMode": "table", "placement": "right"}
            },
            "fieldConfig": {
              "defaults": {
                "unit": "percent",
                "min": 0,
                "max": 100,
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"value": 0, "color": "green"},
                    {"value": 50, "color": "yellow"},
                    {"value": 80, "color": "red"}
                  ]
                }
              }
            }
          },
          {
            "gridPos": {"h": 1, "w": 24, "x": 0, "y": 23},
            "id": 11,
            "type": "row",
            "title": "Disk Anomaly Scores",
            "collapsed": false
          },
          {
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 24},
            "id": 12,
            "type": "timeseries",
            "title": "Disk Space Anomaly Scores",
            "targets": [
              {
                "expr": "disk_anomaly_score",
                "legendFormat": "{{mountpoint}} - {{device}}",
                "refId": "A"
              }
            ],
            "options": {
              "tooltip": {"mode": "multi"},
              "legend": {"displayMode": "table", "placement": "right"}
            },
            "fieldConfig": {
              "defaults": {
                "unit": "percent",
                "min": 0,
                "max": 100,
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"value": 0, "color": "green"},
                    {"value": 50, "color": "yellow"},
                    {"value": 80, "color": "red"}
                  ]
                }
              }
            }
          },
          {
            "gridPos": {"h": 1, "w": 24, "x": 0, "y": 32},
            "id": 13,
            "type": "row",
            "title": "Pod Anomaly Scores",
            "collapsed": false
          },
          {
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 33},
            "id": 14,
            "type": "timeseries",
            "title": "K8s Pod Anomaly Scores",
            "targets": [
              {
                "expr": "topk(10, pod_anomaly_score)",
                "legendFormat": "{{namespace}}/{{pod}} - {{metric_type}}",
                "refId": "A"
              }
            ],
            "options": {
              "tooltip": {"mode": "multi"},
              "legend": {"displayMode": "table", "placement": "right"}
            },
            "fieldConfig": {
              "defaults": {
                "unit": "percent",
                "min": 0,
                "max": 100,
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"value": 0, "color": "green"},
                    {"value": 50, "color": "yellow"},
                    {"value": 80, "color": "red"}
                  ]
                }
              }
            }
          }
        ],
        "editable": true,
        "schemaVersion": 38,
        "version": 1
      }
    process-anomaly-detection.json: |
      {
        "id": null,
        "uid": "process-anomaly-detection",
        "title": "ODIN Process Anomaly Detection",
        "tags": ["anomaly", "process", "ml", "security", "odin"],
        "timezone": "America/Los_Angeles",
        "schemaVersion": 38,
        "version": 2,
        "refresh": "30s",
        "time": {
          "from": "now-3h",
          "to": "now"
        },
        "templating": {
          "list": [
            {
              "name": "groupname",
              "type": "query",
              "datasource": "Prometheus",
              "query": "label_values(process_cpu_anomaly_score, groupname)",
              "refresh": 1,
              "includeAll": true,
              "allValue": ".*",
              "multi": true
            },
            {
              "name": "instance",
              "type": "query",
              "datasource": "Prometheus",
              "query": "label_values(process_cpu_anomaly_score, instance)",
              "refresh": 1,
              "includeAll": true,
              "allValue": ".*",
              "multi": true
            },
            {
              "name": "top_n",
              "type": "custom",
              "current": {
                "text": "30",
                "value": "30"
              },
              "options": [
                {"text": "10", "value": "10"},
                {"text": "20", "value": "20"},
                {"text": "30", "value": "30"},
                {"text": "50", "value": "50"},
                {"text": "100", "value": "100"}
              ],
              "query": "10,20,30,50,100",
              "description": "Number of top anomalous processes to display"
            }
          ]
        },
        "panels": [
          {
            "gridPos": {"h": 6, "w": 24, "x": 0, "y": 0},
            "id": 1,
            "type": "text",
            "title": "Process Anomaly Detection Overview",
            "options": {
              "mode": "markdown",
              "content": "# ML-Based Process Anomaly Detection\\n\\nAdvanced process monitoring using **Isolation Forest** machine learning algorithms analyzing top CPU and memory consuming processes.\\n\\n## Detection Areas\\n- **CPU Usage Anomalies**: Unusual CPU consumption patterns\\n- **Memory Usage Anomalies**: Abnormal memory allocation behaviors\\n- **Process Count Anomalies**: Unexpected process scaling\\n- **New Process Detection**: Real-time alerts for unknown processes\\n- **Security Analysis**: Detection of suspicious process behaviors\\n\\n## Anomaly Scores\\n- **1.0** = Normal behavior (green)\\n- **0.5** = Moderate anomaly (yellow)\\n- **0.0** = Severe anomaly requiring investigation (red)\\n\\n## Tips\\n- Use the **top_n** variable to control how many processes to display\\n- Filter by specific process names using the **groupname** selector\\n- The improved dashboard at [Process Anomaly Detection (Improved)](/d/process-anomaly-improved) provides better visualization for large numbers of processes"
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 8, "w": 6, "x": 0, "y": 6},
            "id": 2,
            "type": "stat",
            "title": "Detection Status",
            "targets": [
              {
                "expr": "up{job=\"advanced-process-anomaly-detector\"}",
                "refId": "A"
              }
            ],
            "options": {
              "graphMode": "none",
              "colorMode": "background",
              "justifyMode": "center"
            },
            "fieldConfig": {
              "defaults": {
                "mappings": [
                  {"value": 1, "text": "ACTIVE", "color": "green"},
                  {"value": 0, "text": "DOWN", "color": "red"}
                ],
                "color": {"mode": "thresholds"},
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "green", "value": 1}
                  ]
                }
              }
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 8, "w": 6, "x": 6, "y": 6},
            "id": 3,
            "type": "stat",
            "title": "Processes Analyzed",
            "targets": [
              {
                "expr": "process_anomaly_processes_analyzed_total",
                "refId": "A"
              }
            ],
            "options": {
              "graphMode": "area",
              "colorMode": "value",
              "justifyMode": "center"
            },
            "fieldConfig": {
              "defaults": {
                "color": {"mode": "palette-classic"},
                "unit": "short"
              }
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 8, "w": 6, "x": 12, "y": 6},
            "id": 4,
            "type": "stat",
            "title": "Unique Processes",
            "targets": [
              {
                "expr": "count(count by (groupname) (process_cpu_anomaly_score))",
                "refId": "A"
              }
            ],
            "options": {
              "graphMode": "none",
              "colorMode": "value",
              "justifyMode": "center"
            },
            "fieldConfig": {
              "defaults": {
                "unit": "short",
                "color": {"mode": "palette-classic"}
              }
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 8, "w": 6, "x": 18, "y": 6},
            "id": 5,
            "type": "stat",
            "title": "Anomalous Processes",
            "targets": [
              {
                "expr": "count(process_cpu_anomaly_score < 0.7 or process_memory_anomaly_score < 0.7)",
                "refId": "A"
              }
            ],
            "options": {
              "graphMode": "none",
              "colorMode": "value",
              "justifyMode": "center"
            },
            "fieldConfig": {
              "defaults": {
                "unit": "short",
                "color": {"mode": "thresholds"},
                "thresholds": {
                  "steps": [
                    {"color": "green", "value": 0},
                    {"color": "yellow", "value": 10},
                    {"color": "red", "value": 50}
                  ]
                }
              }
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 12, "w": 24, "x": 0, "y": 14},
            "id": 6,
            "type": "barchart",
            "title": "Top $top_n Most Anomalous Processes (Lower = More Anomalous)",
            "targets": [
              {
                "expr": "bottomk($top_n, (process_cpu_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"} * 100)) and (process_cpu_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"} < 0.8)",
                "legendFormat": "CPU: {{groupname}}",
                "refId": "A"
              },
              {
                "expr": "bottomk($top_n, (process_memory_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"} * 100)) and (process_memory_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"} < 0.8)",
                "legendFormat": "Memory: {{groupname}}",
                "refId": "B"
              }
            ],
            "options": {
              "orientation": "horizontal",
              "displayMode": "gradient",
              "legend": {"displayMode": "table", "placement": "right", "calcs": ["lastNotNull"]},
              "tooltip": {"mode": "multi", "sort": "asc"}
            },
            "fieldConfig": {
              "defaults": {
                "color": {"mode": "continuous-GrYlRd"},
                "custom": {
                  "hideFrom": {"tooltip": false, "vis": false, "legend": false}
                },
                "unit": "percent",
                "min": 0,
                "max": 100,
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "yellow", "value": 30},
                    {"color": "green", "value": 70}
                  ]
                }
              }
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 10, "w": 12, "x": 0, "y": 26},
            "id": 7,
            "type": "timeseries",
            "title": "CPU Usage Anomaly Scores (Top $top_n Most Anomalous)",
            "targets": [
              {
                "expr": "bottomk($top_n, process_cpu_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"}) and (process_cpu_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"} < 0.8)",
                "legendFormat": "{{groupname}}",
                "refId": "A"
              }
            ],
            "options": {
              "legend": {"displayMode": "table", "placement": "right", "calcs": ["lastNotNull", "min"]},
              "tooltip": {"mode": "multi", "sort": "asc"}
            },
            "fieldConfig": {
              "defaults": {
                "color": {"mode": "palette-classic"},
                "custom": {
                  "drawStyle": "line",
                  "lineInterpolation": "smooth",
                  "lineWidth": 2,
                  "fillOpacity": 15,
                  "pointSize": 4
                },
                "unit": "percentunit",
                "min": 0,
                "max": 1,
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "yellow", "value": 0.3},
                    {"color": "green", "value": 0.7}
                  ]
                }
              }
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 10, "w": 12, "x": 12, "y": 26},
            "id": 8,
            "type": "timeseries",
            "title": "Memory Usage Anomaly Scores (Top $top_n Most Anomalous)",
            "targets": [
              {
                "expr": "bottomk($top_n, process_memory_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"}) and (process_memory_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"} < 0.8)",
                "legendFormat": "{{groupname}}",
                "refId": "A"
              }
            ],
            "options": {
              "legend": {"displayMode": "table", "placement": "right", "calcs": ["lastNotNull", "min"]},
              "tooltip": {"mode": "multi", "sort": "asc"}
            },
            "fieldConfig": {
              "defaults": {
                "color": {"mode": "palette-classic"},
                "custom": {
                  "drawStyle": "line",
                  "lineInterpolation": "smooth",
                  "lineWidth": 2,
                  "fillOpacity": 15,
                  "pointSize": 4
                },
                "unit": "percentunit",
                "min": 0,
                "max": 1,
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "yellow", "value": 0.3},
                    {"color": "green", "value": 0.7}
                  ]
                }
              }
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 10, "w": 24, "x": 0, "y": 36},
            "id": 9,
            "type": "state-timeline",
            "title": "Process Anomaly State Timeline (Top $top_n)",
            "targets": [
              {
                "expr": "bottomk($top_n, process_cpu_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"} < 0.8)",
                "format": "time_series",
                "refId": "A"
              }
            ],
            "options": {
              "legend": {
                "displayMode": "list",
                "placement": "bottom",
                "showLegend": true
              },
              "tooltip": {
                "mode": "single",
                "sort": "none"
              },
              "timezone": ["browser"],
              "rowHeight": 0.9
            },
            "fieldConfig": {
              "defaults": {
                "custom": {
                  "lineWidth": 0,
                  "fillOpacity": 70,
                  "spanNulls": false,
                  "insertNulls": false,
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  }
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "orange", "value": 0.3},
                    {"color": "yellow", "value": 0.5},
                    {"color": "green", "value": 0.7}
                  ]
                },
                "unit": "percentunit",
                "min": 0,
                "max": 1
              }
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 12, "w": 24, "x": 0, "y": 46},
            "id": 10,
            "type": "table",
            "title": "Detailed Anomalous Process Analysis (Top $top_n)",
            "targets": [
              {
                "expr": "bottomk($top_n, process_cpu_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"} < 0.8)",
                "format": "table",
                "instant": true,
                "refId": "A"
              },
              {
                "expr": "bottomk($top_n, process_memory_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"} < 0.8)",
                "format": "table",
                "instant": true,
                "refId": "B"
              },
              {
                "expr": "bottomk($top_n, process_count_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"} < 0.8)",
                "format": "table",
                "instant": true,
                "refId": "C"
              }
            ],
            "transformations": [
              {
                "id": "merge",
                "options": {}
              },
              {
                "id": "organize",
                "options": {
                  "excludeByName": {
                    "Time": true,
                    "__name__": true,
                    "job": true
                  },
                  "indexByName": {},
                  "renameByName": {
                    "Value #A": "CPU Anomaly Score",
                    "Value #B": "Memory Anomaly Score",
                    "Value #C": "Count Anomaly Score",
                    "groupname": "Process Group",
                    "instance": "Instance",
                    "type": "Alert Type"
                  }
                }
              }
            ],
            "fieldConfig": {
              "defaults": {
                "custom": {
                  "align": "center",
                  "filterable": true,
                  "sortBy": [{"desc": false, "displayName": "CPU Anomaly Score"}]
                },
                "unit": "percentunit",
                "min": 0,
                "max": 1,
                "color": {"mode": "thresholds"},
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "yellow", "value": 0.3},
                    {"color": "green", "value": 0.7}
                  ]
                }
              },
              "overrides": [
                {
                  "matcher": {"id": "byName", "options": "Alert Rate"},
                  "properties": [
                    {"id": "unit", "value": "reqps"},
                    {"id": "min", "value": 0},
                    {"id": "max"},
                    {"id": "color", "value": {"mode": "thresholds"}},
                    {
                      "id": "thresholds",
                      "value": {
                        "steps": [
                          {"color": "green", "value": 0},
                          {"color": "yellow", "value": 0.1},
                          {"color": "red", "value": 0.5}
                        ]
                      }
                    }
                  ]
                }
              ]
            },
            "options": {
              "showHeader": true,
              "sortBy": [{"desc": false, "displayName": "CPU Anomaly Score"}]
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 10, "w": 12, "x": 0, "y": 58},
            "id": 11,
            "type": "timeseries",
            "title": "New Process Detection Rate",
            "targets": [
              {
                "expr": "rate(process_new_process_detected_total{groupname=~\"$groupname\", instance=~\"$instance\"}[5m])",
                "legendFormat": "{{groupname}}",
                "refId": "A"
              }
            ],
            "options": {
              "legend": {"displayMode": "table", "placement": "right", "calcs": ["lastNotNull", "max"]},
              "tooltip": {"mode": "multi", "sort": "desc"}
            },
            "fieldConfig": {
              "defaults": {
                "color": {"mode": "palette-classic"},
                "custom": {
                  "drawStyle": "line",
                  "lineInterpolation": "smooth",
                  "lineWidth": 2,
                  "fillOpacity": 10,
                  "pointSize": 3
                },
                "unit": "reqps",
                "min": 0
              }
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 10, "w": 12, "x": 12, "y": 58},
            "id": 12,
            "type": "timeseries",
            "title": "Security Process Alerts (Suspicious Patterns)",
            "targets": [
              {
                "expr": "rate(process_anomaly_alerts_total{type=~\"cpu_anomaly|memory_anomaly\", groupname=~\".*crypto.*|.*miner.*|.*coin.*|.*hash.*|.*bash.*|.*sh.*|.*nc.*|.*netcat.*|.*wget.*|.*curl.*\"}[5m])",
                "legendFormat": "{{groupname}} - {{type}}",
                "refId": "A"
              }
            ],
            "options": {
              "legend": {"displayMode": "table", "placement": "right", "calcs": ["lastNotNull", "max"]},
              "tooltip": {"mode": "multi", "sort": "desc"}
            },
            "fieldConfig": {
              "defaults": {
                "color": {"mode": "palette-classic"},
                "custom": {
                  "drawStyle": "bars",
                  "lineInterpolation": "smooth",
                  "lineWidth": 2,
                  "fillOpacity": 50,
                  "pointSize": 5
                },
                "unit": "reqps",
                "min": 0
              }
            }
          }
        ]
      }
    process-anomaly-improved.json: |
      {
        "uid": "process-anomaly-improved",
        "title": "ODIN Process Anomaly Detection (Improved)",
        "tags": ["anomaly", "process", "ml", "security", "odin", "improved"],
        "timezone": "America/Los_Angeles",
        "schemaVersion": 38,
        "version": 1,
        "refresh": "30s",
        "editable": true,
        "time": {
          "from": "now-3h",
          "to": "now"
        },
        "templating": {
          "list": [
            {
              "name": "top_n",
              "type": "custom",
              "current": {
                "text": "30",
                "value": "30"
              },
              "options": [
                {"text": "10", "value": "10"},
                {"text": "20", "value": "20"},
                {"text": "30", "value": "30"},
                {"text": "50", "value": "50"},
                {"text": "100", "value": "100"}
              ],
              "query": "10,20,30,50,100",
              "description": "Number of top anomalous processes to show"
            }
          ]
        },
        "panels": [
          {
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 0},
            "id": 1,
            "type": "barchart",
            "title": "Top $top_n Most Anomalous Processes",
            "datasource": "Prometheus",
            "targets": [
              {
                "expr": "bottomk($top_n, min by (groupname) (process_cpu_anomaly_score < 0.8 or process_memory_anomaly_score < 0.8))",
                "legendFormat": "{{groupname}}",
                "refId": "A"
              }
            ],
            "options": {
              "orientation": "horizontal",
              "displayMode": "gradient",
              "showValue": "always",
              "legend": {
                "displayMode": "hidden"
              }
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "continuous-GrYlRd"
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "yellow", "value": 0.3},
                    {"color": "green", "value": 0.7}
                  ]
                },
                "unit": "percentunit",
                "min": 0,
                "max": 1
              }
            }
          },
          {
            "gridPos": {"h": 10, "w": 12, "x": 0, "y": 8},
            "id": 2,
            "type": "timeseries",
            "title": "CPU Anomaly Trends (Top $top_n)",
            "datasource": "Prometheus",
            "targets": [
              {
                "expr": "bottomk($top_n, process_cpu_anomaly_score < 0.8)",
                "legendFormat": "{{groupname}}",
                "refId": "A"
              }
            ],
            "options": {
              "tooltip": {"mode": "multi"},
              "legend": {"displayMode": "table", "placement": "right", "calcs": ["lastNotNull", "min"]}
            },
            "fieldConfig": {
              "defaults": {
                "color": {"mode": "palette-classic"},
                "custom": {
                  "drawStyle": "line",
                  "lineInterpolation": "smooth",
                  "lineWidth": 2,
                  "fillOpacity": 10,
                  "pointSize": 3
                },
                "unit": "percentunit",
                "min": 0,
                "max": 1,
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "yellow", "value": 0.3},
                    {"color": "green", "value": 0.7}
                  ]
                }
              }
            }
          },
          {
            "gridPos": {"h": 10, "w": 12, "x": 12, "y": 8},
            "id": 3,
            "type": "timeseries",
            "title": "Memory Anomaly Trends (Top $top_n)",
            "datasource": "Prometheus",
            "targets": [
              {
                "expr": "bottomk($top_n, process_memory_anomaly_score < 0.8)",
                "legendFormat": "{{groupname}}",
                "refId": "A"
              }
            ],
            "options": {
              "tooltip": {"mode": "multi"},
              "legend": {"displayMode": "table", "placement": "right", "calcs": ["lastNotNull", "min"]}
            },
            "fieldConfig": {
              "defaults": {
                "color": {"mode": "palette-classic"},
                "custom": {
                  "drawStyle": "line",
                  "lineInterpolation": "smooth",
                  "lineWidth": 2,
                  "fillOpacity": 10,
                  "pointSize": 3
                },
                "unit": "percentunit",
                "min": 0,
                "max": 1,
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "yellow", "value": 0.3},
                    {"color": "green", "value": 0.7}
                  ]
                }
              }
            }
          },
          {
            "gridPos": {"h": 10, "w": 24, "x": 0, "y": 18},
            "id": 4,
            "type": "state-timeline",
            "title": "Process Anomaly State Timeline (Top $top_n)",
            "datasource": "Prometheus",
            "targets": [
              {
                "expr": "bottomk($top_n, process_cpu_anomaly_score < 0.8)",
                "refId": "A"
              }
            ],
            "options": {
              "legend": {
                "displayMode": "list",
                "placement": "bottom",
                "showLegend": true
              },
              "tooltip": {
                "mode": "single"
              },
              "rowHeight": 0.9
            },
            "fieldConfig": {
              "defaults": {
                "custom": {
                  "lineWidth": 0,
                  "fillOpacity": 70,
                  "spanNulls": false
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "orange", "value": 0.3},
                    {"color": "yellow", "value": 0.5},
                    {"color": "green", "value": 0.7}
                  ]
                },
                "unit": "percentunit",
                "min": 0,
                "max": 1
              }
            }
          },
          {
            "gridPos": {"h": 10, "w": 24, "x": 0, "y": 28},
            "id": 5,
            "type": "table",
            "title": "Anomaly Score Details (Sortable)",
            "datasource": "Prometheus",
            "targets": [
              {
                "expr": "process_cpu_anomaly_score < 0.9",
                "format": "table",
                "instant": true,
                "refId": "A"
              },
              {
                "expr": "process_memory_anomaly_score < 0.9",
                "format": "table",
                "instant": true,
                "refId": "B"
              }
            ],
            "transformations": [
              {
                "id": "merge"
              },
              {
                "id": "organize",
                "options": {
                  "excludeByName": {
                    "Time": true,
                    "__name__": true,
                    "job": true
                  },
                  "renameByName": {
                    "Value #A": "CPU Score",
                    "Value #B": "Memory Score",
                    "groupname": "Process",
                    "instance": "Host"
                  }
                }
              }
            ],
            "options": {
              "showHeader": true,
              "sortBy": [{"desc": false, "displayName": "CPU Score"}]
            },
            "fieldConfig": {
              "defaults": {
                "custom": {
                  "align": "center",
                  "displayMode": "color-background-solid",
                  "filterable": true
                },
                "unit": "percentunit",
                "min": 0,
                "max": 1,
                "color": {"mode": "thresholds"},
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "yellow", "value": 0.3},
                    {"color": "green", "value": 0.7}
                  ]
                }
              }
            }
          }
        ]
      }
  kind: ConfigMap
  metadata:
    creationTimestamp: "2025-06-07T02:40:57Z"
    name: anomaly-detection-dashboard
    namespace: monitoring
    resourceVersion: "4610564"
    uid: ddecfee6-a940-4814-86c6-983403a45903
- apiVersion: v1
  data:
    anomaly-detection-dashboard.json: "{\n  \"dashboard\": {\n    \"id\": null,\n
      \   \"uid\": \"anomaly-detection\",\n    \"title\": \"ML Anomaly Detection\",\n
      \   \"tags\": [\"odin\", \"anomaly\", \"ml\", \"ai\"],\n    \"timezone\": \"browser\",\n
      \   \"schemaVersion\": 38,\n    \"version\": 1,\n    \"refresh\": \"30s\",\n
      \   \"time\": {\n      \"from\": \"now-3h\",\n      \"to\": \"now\"\n    },\n
      \   \"fiscalYearStartMonth\": 0,\n    \"graphTooltip\": 0,\n    \"links\": [],\n
      \   \"liveNow\": false,\n    \"panels\": [\n      {\n        \"datasource\":
      {\n          \"type\": \"prometheus\",\n          \"uid\": \"prometheus\"\n
      \       },\n        \"gridPos\": {\"h\": 4, \"w\": 24, \"x\": 0, \"y\": 0},\n
      \       \"id\": 1,\n        \"type\": \"text\",\n        \"title\": \"\",\n
      \       \"options\": {\n          \"mode\": \"markdown\",\n          \"code\":
      {\n            \"language\": \"plaintext\",\n            \"showLineNumbers\":
      false,\n            \"showMiniMap\": false\n          },\n          \"content\":
      \"# ML-Based Anomaly Detection\\n\\nThis dashboard shows anomaly scores for
      key metrics using machine learning algorithms:\\n- **Isolation Forest**: For
      complex patterns (GPU, network)\\n- **Statistical Methods**: For simpler metrics
      (CPU, memory)\\n\\n**Scoring**: 0 = Normal, 100 = Highly Anomalous\"\n        }\n
      \     },\n      {\n        \"datasource\": {\n          \"type\": \"prometheus\",
      \n          \"uid\": \"prometheus\"\n        },\n        \"fieldConfig\": {\n
      \         \"defaults\": {\n            \"color\": {\n              \"mode\":
      \"palette-classic\"\n            },\n            \"custom\": {\n              \"axisLabel\":
      \"\",\n              \"axisPlacement\": \"auto\",\n              \"barAlignment\":
      0,\n              \"drawStyle\": \"line\",\n              \"fillOpacity\": 10,\n
      \             \"gradientMode\": \"none\",\n              \"hideFrom\": {\n                \"tooltip\":
      false,\n                \"viz\": false,\n                \"legend\": false\n
      \             },\n              \"lineInterpolation\": \"linear\",\n              \"lineWidth\":
      2,\n              \"pointSize\": 5,\n              \"scaleDistribution\": {\n
      \               \"type\": \"linear\"\n              },\n              \"showPoints\":
      \"never\",\n              \"spanNulls\": false,\n              \"stacking\":
      {\n                \"group\": \"A\",\n                \"mode\": \"none\"\n              },\n
      \             \"thresholdsStyle\": {\n                \"mode\": \"line\"\n              }\n
      \           },\n            \"mappings\": [],\n            \"thresholds\": {\n
      \             \"mode\": \"absolute\",\n              \"steps\": [\n                {\n
      \                 \"color\": \"green\",\n                  \"value\": null\n
      \               },\n                {\n                  \"color\": \"yellow\",
      \n                  \"value\": 60\n                },\n                {\n                  \"color\":
      \"red\",\n                  \"value\": 80\n                }\n              ]\n
      \           },\n            \"unit\": \"percent\"\n          },\n          \"overrides\":
      []\n        },\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\":
      4},\n        \"id\": 2,\n        \"type\": \"timeseries\",\n        \"title\":
      \"GPU Temperature Anomaly Score\",\n        \"targets\": [\n          {\n            \"datasource\":
      {\n              \"type\": \"prometheus\",\n              \"uid\": \"prometheus\"\n
      \           },\n            \"expr\": \"anomaly_score{metric_name=\\\"nvidia_gpu_temperature_celsius\\\"}\",\n
      \           \"legendFormat\": \"Anomaly Score\",\n            \"refId\": \"A\"\n
      \         }\n        ],\n        \"options\": {\n          \"tooltip\": {\n
      \           \"mode\": \"single\",\n            \"sort\": \"none\"\n          },\n
      \         \"legend\": {\n            \"displayMode\": \"list\",\n            \"placement\":
      \"bottom\",\n            \"calcs\": []\n          }\n        }\n      },\n      {\n
      \       \"datasource\": {\n          \"type\": \"prometheus\",\n          \"uid\":
      \"prometheus\"\n        },\n        \"fieldConfig\": {\n          \"defaults\":
      {\n            \"color\": {\n              \"mode\": \"palette-classic\"\n            },\n
      \           \"custom\": {\n              \"axisLabel\": \"\",\n              \"axisPlacement\":
      \"auto\",\n              \"barAlignment\": 0,\n              \"drawStyle\":
      \"line\",\n              \"fillOpacity\": 10,\n              \"gradientMode\":
      \"none\",\n              \"hideFrom\": {\n                \"tooltip\": false,\n
      \               \"viz\": false,\n                \"legend\": false\n              },\n
      \             \"lineInterpolation\": \"linear\",\n              \"lineWidth\":
      2,\n              \"pointSize\": 5,\n              \"scaleDistribution\": {\n
      \               \"type\": \"linear\"\n              },\n              \"showPoints\":
      \"never\",\n              \"spanNulls\": false,\n              \"stacking\":
      {\n                \"group\": \"A\",\n                \"mode\": \"none\"\n              },\n
      \             \"thresholdsStyle\": {\n                \"mode\": \"line\"\n              }\n
      \           },\n            \"mappings\": [],\n            \"thresholds\": {\n
      \             \"mode\": \"absolute\",\n              \"steps\": [\n                {\n
      \                 \"color\": \"green\",\n                  \"value\": null\n
      \               },\n                {\n                  \"color\": \"yellow\",\n
      \                 \"value\": 60\n                },\n                {\n                  \"color\":
      \"red\",\n                  \"value\": 80\n                }\n              ]\n
      \           },\n            \"unit\": \"percent\"\n          },\n          \"overrides\":
      []\n        },\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\":
      4},\n        \"id\": 3,\n        \"type\": \"timeseries\",\n        \"title\":
      \"GPU Power Draw Anomaly Score\",\n        \"targets\": [\n          {\n            \"datasource\":
      {\n              \"type\": \"prometheus\",\n              \"uid\": \"prometheus\"\n
      \           },\n            \"expr\": \"anomaly_score{metric_name=\\\"node_gpu_power_watts\\\"}\",\n
      \           \"legendFormat\": \"Anomaly Score\",\n            \"refId\": \"A\"\n
      \         }\n        ],\n        \"options\": {\n          \"tooltip\": {\n
      \           \"mode\": \"single\",\n            \"sort\": \"none\"\n          },\n
      \         \"legend\": {\n            \"displayMode\": \"list\",\n            \"placement\":
      \"bottom\",\n            \"calcs\": []\n          }\n        }\n      },\n      {\n
      \       \"datasource\": {\n          \"type\": \"prometheus\",\n          \"uid\":
      \"prometheus\"\n        },\n        \"fieldConfig\": {\n          \"defaults\":
      {\n            \"color\": {\n              \"mode\": \"palette-classic\"\n            },\n
      \           \"custom\": {\n              \"axisLabel\": \"\",\n              \"axisPlacement\":
      \"auto\",\n              \"barAlignment\": 0,\n              \"drawStyle\":
      \"line\",\n              \"fillOpacity\": 10,\n              \"gradientMode\":
      \"none\",\n              \"hideFrom\": {\n                \"tooltip\": false,\n
      \               \"viz\": false,\n                \"legend\": false\n              },\n
      \             \"lineInterpolation\": \"linear\",\n              \"lineWidth\":
      2,\n              \"pointSize\": 5,\n              \"scaleDistribution\": {\n
      \               \"type\": \"linear\"\n              },\n              \"showPoints\":
      \"never\",\n              \"spanNulls\": false,\n              \"stacking\":
      {\n                \"group\": \"A\",\n                \"mode\": \"none\"\n              },\n
      \             \"thresholdsStyle\": {\n                \"mode\": \"line\"\n              }\n
      \           },\n            \"mappings\": [],\n            \"thresholds\": {\n
      \             \"mode\": \"absolute\",\n              \"steps\": [\n                {\n
      \                 \"color\": \"green\",\n                  \"value\": null\n
      \               },\n                {\n                  \"color\": \"yellow\",\n
      \                 \"value\": 60\n                },\n                {\n                  \"color\":
      \"red\",\n                  \"value\": 80\n                }\n              ]\n
      \           },\n            \"unit\": \"percent\"\n          },\n          \"overrides\":
      []\n        },\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\":
      12},\n        \"id\": 4,\n        \"type\": \"timeseries\",\n        \"title\":
      \"Memory Availability Anomaly Score\",\n        \"targets\": [\n          {\n
      \           \"datasource\": {\n              \"type\": \"prometheus\",\n              \"uid\":
      \"prometheus\"\n            },\n            \"expr\": \"anomaly_score{metric_name=\\\"node_memory_MemAvailable_bytes\\\"}\",\n
      \           \"legendFormat\": \"Anomaly Score\",\n            \"refId\": \"A\"\n
      \         }\n        ],\n        \"options\": {\n          \"tooltip\": {\n
      \           \"mode\": \"single\",\n            \"sort\": \"none\"\n          },\n
      \         \"legend\": {\n            \"displayMode\": \"list\",\n            \"placement\":
      \"bottom\",\n            \"calcs\": []\n          }\n        }\n      },\n      {\n
      \       \"datasource\": {\n          \"type\": \"prometheus\",\n          \"uid\":
      \"prometheus\"\n        },\n        \"fieldConfig\": {\n          \"defaults\":
      {\n            \"color\": {\n              \"mode\": \"palette-classic\"\n            },\n
      \           \"custom\": {\n              \"axisLabel\": \"\",\n              \"axisPlacement\":
      \"auto\",\n              \"barAlignment\": 0,\n              \"drawStyle\":
      \"line\",\n              \"fillOpacity\": 10,\n              \"gradientMode\":
      \"none\",\n              \"hideFrom\": {\n                \"tooltip\": false,\n
      \               \"viz\": false,\n                \"legend\": false\n              },\n
      \             \"lineInterpolation\": \"linear\",\n              \"lineWidth\":
      2,\n              \"pointSize\": 5,\n              \"scaleDistribution\": {\n
      \               \"type\": \"linear\"\n              },\n              \"showPoints\":
      \"never\",\n              \"spanNulls\": false,\n              \"stacking\":
      {\n                \"group\": \"A\",\n                \"mode\": \"none\"\n              },\n
      \             \"thresholdsStyle\": {\n                \"mode\": \"line\"\n              }\n
      \           },\n            \"mappings\": [],\n            \"thresholds\": {\n
      \             \"mode\": \"absolute\",\n              \"steps\": [\n                {\n
      \                 \"color\": \"green\",\n                  \"value\": null\n
      \               },\n                {\n                  \"color\": \"yellow\",\n
      \                 \"value\": 60\n                },\n                {\n                  \"color\":
      \"red\",\n                  \"value\": 80\n                }\n              ]\n
      \           },\n            \"unit\": \"percent\"\n          },\n          \"overrides\":
      []\n        },\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\":
      12},\n        \"id\": 5,\n        \"type\": \"timeseries\",\n        \"title\":
      \"Network Traffic Anomaly Score\",\n        \"targets\": [\n          {\n            \"datasource\":
      {\n              \"type\": \"prometheus\",\n              \"uid\": \"prometheus\"\n
      \           },\n            \"expr\": \"anomaly_score{metric_name=\\\"network_receive_rate\\\"}\",\n
      \           \"legendFormat\": \"Anomaly Score\",\n            \"refId\": \"A\"\n
      \         }\n        ],\n        \"options\": {\n          \"tooltip\": {\n
      \           \"mode\": \"single\",\n            \"sort\": \"none\"\n          },\n
      \         \"legend\": {\n            \"displayMode\": \"list\",\n            \"placement\":
      \"bottom\",\n            \"calcs\": []\n          }\n        }\n      },\n      {\n
      \       \"datasource\": {\n          \"type\": \"prometheus\",\n          \"uid\":
      \"prometheus\"\n        },\n        \"fieldConfig\": {\n          \"defaults\":
      {\n            \"color\": {\n              \"mode\": \"thresholds\"\n            },\n
      \           \"custom\": {\n              \"align\": \"center\",\n              \"displayMode\":
      \"color-background-solid\",\n              \"inspect\": false,\n              \"filterable\":
      false\n            },\n            \"mappings\": [],\n            \"thresholds\":
      {\n              \"mode\": \"absolute\",\n              \"steps\": [\n                {\n
      \                 \"color\": \"green\",\n                  \"value\": null\n
      \               },\n                {\n                  \"color\": \"yellow\",\n
      \                 \"value\": 60\n                },\n                {\n                  \"color\":
      \"red\",\n                  \"value\": 80\n                }\n              ]\n
      \           },\n            \"unit\": \"percent\"\n          },\n          \"overrides\":
      [\n            {\n              \"matcher\": {\n                \"id\": \"byName\",\n
      \               \"options\": \"Anomaly Score\"\n              },\n              \"properties\":
      [\n                {\n                  \"id\": \"custom.displayMode\",\n                  \"value\":
      \"gradient-gauge\"\n                },\n                {\n                  \"id\":
      \"custom.width\",\n                  \"value\": 200\n                },\n                {\n
      \                 \"id\": \"min\",\n                  \"value\": 0\n                },\n
      \               {\n                  \"id\": \"max\",\n                  \"value\":
      100\n                }\n              ]\n            }\n          ]\n        },\n
      \       \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 20},\n        \"id\":
      6,\n        \"type\": \"table\",\n        \"title\": \"Current Anomaly Status\",\n
      \       \"targets\": [\n          {\n            \"datasource\": {\n              \"type\":
      \"prometheus\",\n              \"uid\": \"prometheus\"\n            },\n            \"expr\":
      \"anomaly_score\",\n            \"format\": \"table\",\n            \"instant\":
      true,\n            \"refId\": \"A\"\n          }\n        ],\n        \"transformations\":
      [\n          {\n            \"id\": \"organize\",\n            \"options\":
      {\n              \"excludeByName\": {\n                \"Time\": true,\n                \"__name__\":
      true,\n                \"job\": true,\n                \"instance\": true\n
      \             },\n              \"renameByName\": {\n                \"metric_name\":
      \"Metric\",\n                \"algorithm\": \"Algorithm\",\n                \"Value\":
      \"Anomaly Score\"\n              }\n            }\n          }\n        ],\n
      \       \"options\": {\n          \"showHeader\": true,\n          \"footer\":
      {\n            \"show\": false,\n            \"reducer\": [\"sum\"],\n            \"fields\":
      \"\"\n          },\n          \"frameIndex\": 0\n        }\n      }\n    ],\n
      \   \"templating\": {\n      \"list\": []\n    },\n    \"annotations\": {\n
      \     \"list\": [\n        {\n          \"builtIn\": 1,\n          \"datasource\":
      {\n            \"type\": \"grafana\",\n            \"uid\": \"-- Grafana --\"\n
      \         },\n          \"enable\": true,\n          \"hide\": true,\n          \"iconColor\":
      \"rgba(0, 211, 255, 1)\",\n          \"name\": \"Annotations & Alerts\",\n          \"type\":
      \"dashboard\"\n        }\n      ]\n    }\n  },\n  \"folderUid\": \"\",\n  \"overwrite\":
      true\n}\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"anomaly-detection-dashboard.json":"{\n  \"dashboard\": {\n    \"id\": null,\n    \"uid\": \"anomaly-detection\",\n    \"title\": \"ML Anomaly Detection\",\n    \"tags\": [\"odin\", \"anomaly\", \"ml\", \"ai\"],\n    \"timezone\": \"browser\",\n    \"schemaVersion\": 38,\n    \"version\": 1,\n    \"refresh\": \"30s\",\n    \"time\": {\n      \"from\": \"now-3h\",\n      \"to\": \"now\"\n    },\n    \"fiscalYearStartMonth\": 0,\n    \"graphTooltip\": 0,\n    \"links\": [],\n    \"liveNow\": false,\n    \"panels\": [\n      {\n        \"datasource\": {\n          \"type\": \"prometheus\",\n          \"uid\": \"prometheus\"\n        },\n        \"gridPos\": {\"h\": 4, \"w\": 24, \"x\": 0, \"y\": 0},\n        \"id\": 1,\n        \"type\": \"text\",\n        \"title\": \"\",\n        \"options\": {\n          \"mode\": \"markdown\",\n          \"code\": {\n            \"language\": \"plaintext\",\n            \"showLineNumbers\": false,\n            \"showMiniMap\": false\n          },\n          \"content\": \"# ML-Based Anomaly Detection\\n\\nThis dashboard shows anomaly scores for key metrics using machine learning algorithms:\\n- **Isolation Forest**: For complex patterns (GPU, network)\\n- **Statistical Methods**: For simpler metrics (CPU, memory)\\n\\n**Scoring**: 0 = Normal, 100 = Highly Anomalous\"\n        }\n      },\n      {\n        \"datasource\": {\n          \"type\": \"prometheus\", \n          \"uid\": \"prometheus\"\n        },\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"color\": {\n              \"mode\": \"palette-classic\"\n            },\n            \"custom\": {\n              \"axisLabel\": \"\",\n              \"axisPlacement\": \"auto\",\n              \"barAlignment\": 0,\n              \"drawStyle\": \"line\",\n              \"fillOpacity\": 10,\n              \"gradientMode\": \"none\",\n              \"hideFrom\": {\n                \"tooltip\": false,\n                \"viz\": false,\n                \"legend\": false\n              },\n              \"lineInterpolation\": \"linear\",\n              \"lineWidth\": 2,\n              \"pointSize\": 5,\n              \"scaleDistribution\": {\n                \"type\": \"linear\"\n              },\n              \"showPoints\": \"never\",\n              \"spanNulls\": false,\n              \"stacking\": {\n                \"group\": \"A\",\n                \"mode\": \"none\"\n              },\n              \"thresholdsStyle\": {\n                \"mode\": \"line\"\n              }\n            },\n            \"mappings\": [],\n            \"thresholds\": {\n              \"mode\": \"absolute\",\n              \"steps\": [\n                {\n                  \"color\": \"green\",\n                  \"value\": null\n                },\n                {\n                  \"color\": \"yellow\", \n                  \"value\": 60\n                },\n                {\n                  \"color\": \"red\",\n                  \"value\": 80\n                }\n              ]\n            },\n            \"unit\": \"percent\"\n          },\n          \"overrides\": []\n        },\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 4},\n        \"id\": 2,\n        \"type\": \"timeseries\",\n        \"title\": \"GPU Temperature Anomaly Score\",\n        \"targets\": [\n          {\n            \"datasource\": {\n              \"type\": \"prometheus\",\n              \"uid\": \"prometheus\"\n            },\n            \"expr\": \"anomaly_score{metric_name=\\\"nvidia_gpu_temperature_celsius\\\"}\",\n            \"legendFormat\": \"Anomaly Score\",\n            \"refId\": \"A\"\n          }\n        ],\n        \"options\": {\n          \"tooltip\": {\n            \"mode\": \"single\",\n            \"sort\": \"none\"\n          },\n          \"legend\": {\n            \"displayMode\": \"list\",\n            \"placement\": \"bottom\",\n            \"calcs\": []\n          }\n        }\n      },\n      {\n        \"datasource\": {\n          \"type\": \"prometheus\",\n          \"uid\": \"prometheus\"\n        },\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"color\": {\n              \"mode\": \"palette-classic\"\n            },\n            \"custom\": {\n              \"axisLabel\": \"\",\n              \"axisPlacement\": \"auto\",\n              \"barAlignment\": 0,\n              \"drawStyle\": \"line\",\n              \"fillOpacity\": 10,\n              \"gradientMode\": \"none\",\n              \"hideFrom\": {\n                \"tooltip\": false,\n                \"viz\": false,\n                \"legend\": false\n              },\n              \"lineInterpolation\": \"linear\",\n              \"lineWidth\": 2,\n              \"pointSize\": 5,\n              \"scaleDistribution\": {\n                \"type\": \"linear\"\n              },\n              \"showPoints\": \"never\",\n              \"spanNulls\": false,\n              \"stacking\": {\n                \"group\": \"A\",\n                \"mode\": \"none\"\n              },\n              \"thresholdsStyle\": {\n                \"mode\": \"line\"\n              }\n            },\n            \"mappings\": [],\n            \"thresholds\": {\n              \"mode\": \"absolute\",\n              \"steps\": [\n                {\n                  \"color\": \"green\",\n                  \"value\": null\n                },\n                {\n                  \"color\": \"yellow\",\n                  \"value\": 60\n                },\n                {\n                  \"color\": \"red\",\n                  \"value\": 80\n                }\n              ]\n            },\n            \"unit\": \"percent\"\n          },\n          \"overrides\": []\n        },\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 4},\n        \"id\": 3,\n        \"type\": \"timeseries\",\n        \"title\": \"GPU Power Draw Anomaly Score\",\n        \"targets\": [\n          {\n            \"datasource\": {\n              \"type\": \"prometheus\",\n              \"uid\": \"prometheus\"\n            },\n            \"expr\": \"anomaly_score{metric_name=\\\"node_gpu_power_watts\\\"}\",\n            \"legendFormat\": \"Anomaly Score\",\n            \"refId\": \"A\"\n          }\n        ],\n        \"options\": {\n          \"tooltip\": {\n            \"mode\": \"single\",\n            \"sort\": \"none\"\n          },\n          \"legend\": {\n            \"displayMode\": \"list\",\n            \"placement\": \"bottom\",\n            \"calcs\": []\n          }\n        }\n      },\n      {\n        \"datasource\": {\n          \"type\": \"prometheus\",\n          \"uid\": \"prometheus\"\n        },\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"color\": {\n              \"mode\": \"palette-classic\"\n            },\n            \"custom\": {\n              \"axisLabel\": \"\",\n              \"axisPlacement\": \"auto\",\n              \"barAlignment\": 0,\n              \"drawStyle\": \"line\",\n              \"fillOpacity\": 10,\n              \"gradientMode\": \"none\",\n              \"hideFrom\": {\n                \"tooltip\": false,\n                \"viz\": false,\n                \"legend\": false\n              },\n              \"lineInterpolation\": \"linear\",\n              \"lineWidth\": 2,\n              \"pointSize\": 5,\n              \"scaleDistribution\": {\n                \"type\": \"linear\"\n              },\n              \"showPoints\": \"never\",\n              \"spanNulls\": false,\n              \"stacking\": {\n                \"group\": \"A\",\n                \"mode\": \"none\"\n              },\n              \"thresholdsStyle\": {\n                \"mode\": \"line\"\n              }\n            },\n            \"mappings\": [],\n            \"thresholds\": {\n              \"mode\": \"absolute\",\n              \"steps\": [\n                {\n                  \"color\": \"green\",\n                  \"value\": null\n                },\n                {\n                  \"color\": \"yellow\",\n                  \"value\": 60\n                },\n                {\n                  \"color\": \"red\",\n                  \"value\": 80\n                }\n              ]\n            },\n            \"unit\": \"percent\"\n          },\n          \"overrides\": []\n        },\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 12},\n        \"id\": 4,\n        \"type\": \"timeseries\",\n        \"title\": \"Memory Availability Anomaly Score\",\n        \"targets\": [\n          {\n            \"datasource\": {\n              \"type\": \"prometheus\",\n              \"uid\": \"prometheus\"\n            },\n            \"expr\": \"anomaly_score{metric_name=\\\"node_memory_MemAvailable_bytes\\\"}\",\n            \"legendFormat\": \"Anomaly Score\",\n            \"refId\": \"A\"\n          }\n        ],\n        \"options\": {\n          \"tooltip\": {\n            \"mode\": \"single\",\n            \"sort\": \"none\"\n          },\n          \"legend\": {\n            \"displayMode\": \"list\",\n            \"placement\": \"bottom\",\n            \"calcs\": []\n          }\n        }\n      },\n      {\n        \"datasource\": {\n          \"type\": \"prometheus\",\n          \"uid\": \"prometheus\"\n        },\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"color\": {\n              \"mode\": \"palette-classic\"\n            },\n            \"custom\": {\n              \"axisLabel\": \"\",\n              \"axisPlacement\": \"auto\",\n              \"barAlignment\": 0,\n              \"drawStyle\": \"line\",\n              \"fillOpacity\": 10,\n              \"gradientMode\": \"none\",\n              \"hideFrom\": {\n                \"tooltip\": false,\n                \"viz\": false,\n                \"legend\": false\n              },\n              \"lineInterpolation\": \"linear\",\n              \"lineWidth\": 2,\n              \"pointSize\": 5,\n              \"scaleDistribution\": {\n                \"type\": \"linear\"\n              },\n              \"showPoints\": \"never\",\n              \"spanNulls\": false,\n              \"stacking\": {\n                \"group\": \"A\",\n                \"mode\": \"none\"\n              },\n              \"thresholdsStyle\": {\n                \"mode\": \"line\"\n              }\n            },\n            \"mappings\": [],\n            \"thresholds\": {\n              \"mode\": \"absolute\",\n              \"steps\": [\n                {\n                  \"color\": \"green\",\n                  \"value\": null\n                },\n                {\n                  \"color\": \"yellow\",\n                  \"value\": 60\n                },\n                {\n                  \"color\": \"red\",\n                  \"value\": 80\n                }\n              ]\n            },\n            \"unit\": \"percent\"\n          },\n          \"overrides\": []\n        },\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 12},\n        \"id\": 5,\n        \"type\": \"timeseries\",\n        \"title\": \"Network Traffic Anomaly Score\",\n        \"targets\": [\n          {\n            \"datasource\": {\n              \"type\": \"prometheus\",\n              \"uid\": \"prometheus\"\n            },\n            \"expr\": \"anomaly_score{metric_name=\\\"network_receive_rate\\\"}\",\n            \"legendFormat\": \"Anomaly Score\",\n            \"refId\": \"A\"\n          }\n        ],\n        \"options\": {\n          \"tooltip\": {\n            \"mode\": \"single\",\n            \"sort\": \"none\"\n          },\n          \"legend\": {\n            \"displayMode\": \"list\",\n            \"placement\": \"bottom\",\n            \"calcs\": []\n          }\n        }\n      },\n      {\n        \"datasource\": {\n          \"type\": \"prometheus\",\n          \"uid\": \"prometheus\"\n        },\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"color\": {\n              \"mode\": \"thresholds\"\n            },\n            \"custom\": {\n              \"align\": \"center\",\n              \"displayMode\": \"color-background-solid\",\n              \"inspect\": false,\n              \"filterable\": false\n            },\n            \"mappings\": [],\n            \"thresholds\": {\n              \"mode\": \"absolute\",\n              \"steps\": [\n                {\n                  \"color\": \"green\",\n                  \"value\": null\n                },\n                {\n                  \"color\": \"yellow\",\n                  \"value\": 60\n                },\n                {\n                  \"color\": \"red\",\n                  \"value\": 80\n                }\n              ]\n            },\n            \"unit\": \"percent\"\n          },\n          \"overrides\": [\n            {\n              \"matcher\": {\n                \"id\": \"byName\",\n                \"options\": \"Anomaly Score\"\n              },\n              \"properties\": [\n                {\n                  \"id\": \"custom.displayMode\",\n                  \"value\": \"gradient-gauge\"\n                },\n                {\n                  \"id\": \"custom.width\",\n                  \"value\": 200\n                },\n                {\n                  \"id\": \"min\",\n                  \"value\": 0\n                },\n                {\n                  \"id\": \"max\",\n                  \"value\": 100\n                }\n              ]\n            }\n          ]\n        },\n        \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 20},\n        \"id\": 6,\n        \"type\": \"table\",\n        \"title\": \"Current Anomaly Status\",\n        \"targets\": [\n          {\n            \"datasource\": {\n              \"type\": \"prometheus\",\n              \"uid\": \"prometheus\"\n            },\n            \"expr\": \"anomaly_score\",\n            \"format\": \"table\",\n            \"instant\": true,\n            \"refId\": \"A\"\n          }\n        ],\n        \"transformations\": [\n          {\n            \"id\": \"organize\",\n            \"options\": {\n              \"excludeByName\": {\n                \"Time\": true,\n                \"__name__\": true,\n                \"job\": true,\n                \"instance\": true\n              },\n              \"renameByName\": {\n                \"metric_name\": \"Metric\",\n                \"algorithm\": \"Algorithm\",\n                \"Value\": \"Anomaly Score\"\n              }\n            }\n          }\n        ],\n        \"options\": {\n          \"showHeader\": true,\n          \"footer\": {\n            \"show\": false,\n            \"reducer\": [\"sum\"],\n            \"fields\": \"\"\n          },\n          \"frameIndex\": 0\n        }\n      }\n    ],\n    \"templating\": {\n      \"list\": []\n    },\n    \"annotations\": {\n      \"list\": [\n        {\n          \"builtIn\": 1,\n          \"datasource\": {\n            \"type\": \"grafana\",\n            \"uid\": \"-- Grafana --\"\n          },\n          \"enable\": true,\n          \"hide\": true,\n          \"iconColor\": \"rgba(0, 211, 255, 1)\",\n          \"name\": \"Annotations \u0026 Alerts\",\n          \"type\": \"dashboard\"\n        }\n      ]\n    }\n  },\n  \"folderUid\": \"\",\n  \"overwrite\": true\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"anomaly-detection-dashboard-fixed","namespace":"monitoring"}}
    creationTimestamp: "2025-05-30T02:00:08Z"
    name: anomaly-detection-dashboard-fixed
    namespace: monitoring
    resourceVersion: "91074"
    uid: 5cb1716d-6c43-42dc-90ec-c7dd0b55581f
- apiVersion: v1
  data:
    requirements.txt: |
      prometheus-client==0.19.0
      requests==2.31.0
      numpy==1.24.3
      pandas==2.0.3
      scikit-learn==1.3.0
      kubernetes==27.2.0
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"requirements.txt":"prometheus-client==0.19.0\nrequests==2.31.0\nnumpy==1.24.3\npandas==2.0.3\nscikit-learn==1.3.0\nkubernetes==27.2.0\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"anomaly-detector-requirements","namespace":"monitoring"}}
    creationTimestamp: "2025-05-29T23:49:35Z"
    name: anomaly-detector-requirements
    namespace: monitoring
    resourceVersion: "673650"
    uid: 90e13246-4825-4f5a-a0fd-0c5d4c1d3cbb
- apiVersion: v1
  data:
    anomaly_detector.py: "#!/usr/bin/env python3\nimport time\nimport numpy as np\nimport
      pandas as pd\nfrom datetime import datetime, timedelta\nimport requests\nimport
      logging\nimport json\nimport os\nimport pickle\nfrom prometheus_client import
      start_http_server, Gauge, Counter, Histogram\nfrom sklearn.ensemble import IsolationForest\nfrom
      sklearn.preprocessing import StandardScaler\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#
      Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s
      - %(name)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger('anomaly-detector')\n\n#
      Prometheus metrics\nanomaly_score = Gauge('anomaly_score', 'Anomaly score for
      metric', ['metric_name', 'algorithm'])\nanomaly_threshold = Gauge('anomaly_threshold',
      'Dynamic threshold for metric', ['metric_name', 'type'])\nmodel_training_duration
      = Histogram('anomaly_model_training_duration_seconds', 'Model training duration')\nmodel_updates
      = Counter('anomaly_model_updates_total', 'Total model updates', ['metric_name'])\ndetection_errors
      = Counter('anomaly_detection_errors_total', 'Total detection errors', ['metric_name'])\nhealth_status
      = Gauge('anomaly_detector_health', 'Health status of anomaly detector')\n\n#
      Configuration\nPROMETHEUS_URL = os.getenv('PROMETHEUS_URL', 'http://prometheus:9090')\nMODEL_PATH
      = '/models'\nUPDATE_INTERVAL = int(os.getenv('UPDATE_INTERVAL', '300'))  # 5
      minutes\nTRAINING_WINDOW = os.getenv('TRAINING_WINDOW', '7d')\n\n# Metrics configuration\nMONITORED_METRICS
      = [\n    {\n        'name': 'nvidia_gpu_temperature_celsius',\n        'algorithm':
      'isolation_forest',\n        'sensitivity': 0.05,  # Lower = more sensitive\n
      \       'min_samples': 100\n    },\n    {\n        'name': 'node_gpu_power_watts',\n
      \       'algorithm': 'isolation_forest',\n        'sensitivity': 0.05,\n        'min_samples':
      100\n    },\n    {\n        'name': 'node_memory_MemAvailable_bytes',\n        'algorithm':
      'statistical',\n        'z_threshold': 3,\n        'min_samples': 50\n    },\n
      \   {\n        'name': 'rate(node_cpu_seconds_total[5m])',\n        'query':
      'rate(node_cpu_seconds_total[5m])',\n        'algorithm': 'statistical',\n        'z_threshold':
      2.5,\n        'min_samples': 50\n    },\n    {\n        'name': 'rate(node_network_receive_bytes_total[5m])',\n
      \       'query': 'rate(node_network_receive_bytes_total{device=\"enp110s0\"}[5m])',\n
      \       'algorithm': 'isolation_forest',\n        'sensitivity': 0.1,\n        'min_samples':
      100\n    },\n    {\n        'name': 'claude_code_api_requests_total',\n        'algorithm':
      'statistical',\n        'z_threshold': 3,\n        'min_samples': 30\n    }\n]\n\nclass
      AnomalyDetector:\n    def __init__(self):\n        self.models = {}\n        self.scalers
      = {}\n        self.thresholds = {}\n        os.makedirs(MODEL_PATH, exist_ok=True)\n
      \       self.load_models()\n        \n    def load_models(self):\n        \"\"\"Load
      saved models from disk\"\"\"\n        for metric in MONITORED_METRICS:\n            model_file
      = os.path.join(MODEL_PATH, f\"{metric['name'].replace('/', '_')}.pkl\")\n            if
      os.path.exists(model_file):\n                try:\n                    with
      open(model_file, 'rb') as f:\n                        data = pickle.load(f)\n
      \                       self.models[metric['name']] = data['model']\n                        self.scalers[metric['name']]
      = data['scaler']\n                        self.thresholds[metric['name']] =
      data.get('thresholds', {})\n                        logger.info(f\"Loaded model
      for {metric['name']}\")\n                except Exception as e:\n                    logger.error(f\"Failed
      to load model for {metric['name']}: {e}\")\n                    \n    def save_model(self,
      metric_name):\n        \"\"\"Save model to disk\"\"\"\n        if metric_name
      in self.models:\n            model_file = os.path.join(MODEL_PATH, f\"{metric_name.replace('/',
      '_')}.pkl\")\n            try:\n                with open(model_file, 'wb')
      as f:\n                    pickle.dump({\n                        'model': self.models[metric_name],\n
      \                       'scaler': self.scalers.get(metric_name),\n                        'thresholds':
      self.thresholds.get(metric_name, {})\n                    }, f)\n                logger.info(f\"Saved
      model for {metric_name}\")\n            except Exception as e:\n                logger.error(f\"Failed
      to save model for {metric_name}: {e}\")\n                \n    def query_prometheus(self,
      query, start_time=None, end_time=None, step='60s'):\n        \"\"\"Query Prometheus
      for metric data\"\"\"\n        if not start_time:\n            end_time = datetime.now()\n
      \           start_time = end_time - timedelta(days=7)\n            \n        params
      = {\n            'query': query,\n            'start': start_time.timestamp(),\n
      \           'end': end_time.timestamp(),\n            'step': step\n        }\n
      \       \n        try:\n            response = requests.get(f\"{PROMETHEUS_URL}/api/v1/query_range\",
      params=params)\n            response.raise_for_status()\n            data =
      response.json()\n            \n            if data['status'] == 'success' and
      data['data']['result']:\n                # Extract time series data\n                result
      = data['data']['result'][0]\n                values = [(float(v[0]), float(v[1]))
      for v in result['values']]\n                return pd.DataFrame(values, columns=['timestamp',
      'value'])\n                \n        except Exception as e:\n            logger.error(f\"Failed
      to query Prometheus: {e}\")\n            detection_errors.labels(metric_name=query).inc()\n
      \           \n        return pd.DataFrame()\n        \n    def train_isolation_forest(self,
      metric_config, data):\n        \"\"\"Train Isolation Forest model\"\"\"\n        if
      len(data) < metric_config['min_samples']:\n            logger.warning(f\"Insufficient
      data for {metric_config['name']}: {len(data)} samples\")\n            return
      None, None\n            \n        # Prepare features\n        X = data[['value']].values\n
      \       \n        # Add time-based features\n        data['hour'] = pd.to_datetime(data['timestamp'],
      unit='s').dt.hour\n        data['dayofweek'] = pd.to_datetime(data['timestamp'],
      unit='s').dt.dayofweek\n        X = np.column_stack([X, data['hour'].values,
      data['dayofweek'].values])\n        \n        # Scale features\n        scaler
      = StandardScaler()\n        X_scaled = scaler.fit_transform(X)\n        \n        #
      Train model\n        model = IsolationForest(\n            contamination=metric_config['sensitivity'],\n
      \           random_state=42,\n            n_estimators=100\n        )\n        \n
      \       with model_training_duration.time():\n            model.fit(X_scaled)\n
      \           \n        model_updates.labels(metric_name=metric_config['name']).inc()\n
      \       \n        return model, scaler\n        \n    def train_statistical_model(self,
      metric_config, data):\n        \"\"\"Train statistical anomaly detection model\"\"\"\n
      \       if len(data) < metric_config['min_samples']:\n            logger.warning(f\"Insufficient
      data for {metric_config['name']}: {len(data)} samples\")\n            return
      None\n            \n        values = data['value'].values\n        \n        #
      Calculate statistics\n        mean = np.mean(values)\n        std = np.std(values)\n
      \       \n        # Calculate percentiles for dynamic thresholds\n        thresholds
      = {\n            'mean': mean,\n            'std': std,\n            'p99':
      np.percentile(values, 99),\n            'p95': np.percentile(values, 95),\n
      \           'p05': np.percentile(values, 5),\n            'p01': np.percentile(values,
      1)\n        }\n        \n        model_updates.labels(metric_name=metric_config['name']).inc()\n
      \       \n        return thresholds\n        \n    def detect_anomalies(self,
      metric_config):\n        \"\"\"Detect anomalies for a specific metric\"\"\"\n
      \       try:\n            # Query recent data for detection\n            query
      = metric_config.get('query', metric_config['name'])\n            recent_data
      = self.query_prometheus(\n                query,\n                start_time=datetime.now()
      - timedelta(minutes=10),\n                step='30s'\n            )\n            \n
      \           if recent_data.empty or len(recent_data) == 0:\n                return\n
      \               \n            current_value = recent_data['value'].iloc[-1]\n
      \           \n            if metric_config['algorithm'] == 'isolation_forest':\n
      \               if metric_config['name'] in self.models:\n                    model
      = self.models[metric_config['name']]\n                    scaler = self.scalers[metric_config['name']]\n
      \                   \n                    # Prepare features\n                    hour
      = pd.to_datetime(recent_data['timestamp'].iloc[-1], unit='s').hour\n                    dayofweek
      = pd.to_datetime(recent_data['timestamp'].iloc[-1], unit='s').dayofweek\n                    X
      = np.array([[current_value, hour, dayofweek]])\n                    X_scaled
      = scaler.transform(X)\n                    \n                    # Get anomaly
      score (-1 for anomaly, 1 for normal)\n                    score = model.decision_function(X_scaled)[0]\n
      \                   # Convert to 0-100 scale (lower score = more anomalous)\n
      \                   normalized_score = 50 + (score * 50)\n                    normalized_score
      = max(0, min(100, normalized_score))\n                    \n                    anomaly_score.labels(\n
      \                       metric_name=metric_config['name'],\n                        algorithm='isolation_forest'\n
      \                   ).set(100 - normalized_score)\n                    \n            elif
      metric_config['algorithm'] == 'statistical':\n                if metric_config['name']
      in self.thresholds:\n                    thresholds = self.thresholds[metric_config['name']]\n
      \                   \n                    # Calculate z-score\n                    z_score
      = abs((current_value - thresholds['mean']) / (thresholds['std'] + 1e-10))\n
      \                   \n                    # Convert to 0-100 scale\n                    score
      = min(100, (z_score / metric_config['z_threshold']) * 100)\n                    \n
      \                   anomaly_score.labels(\n                        metric_name=metric_config['name'],\n
      \                       algorithm='statistical'\n                    ).set(score)\n
      \                   \n                    # Set dynamic thresholds\n                    anomaly_threshold.labels(\n
      \                       metric_name=metric_config['name'],\n                        type='upper_bound'\n
      \                   ).set(thresholds['p99'])\n                    \n                    anomaly_threshold.labels(\n
      \                       metric_name=metric_config['name'],\n                        type='lower_bound'\n
      \                   ).set(thresholds['p01'])\n                    \n        except
      Exception as e:\n            logger.error(f\"Error detecting anomalies for {metric_config['name']}:
      {e}\")\n            detection_errors.labels(metric_name=metric_config['name']).inc()\n
      \           \n    def update_models(self):\n        \"\"\"Update all models
      with recent training data\"\"\"\n        logger.info(\"Updating anomaly detection
      models...\")\n        \n        for metric_config in MONITORED_METRICS:\n            try:\n
      \               # Query training data\n                query = metric_config.get('query',
      metric_config['name'])\n                training_data = self.query_prometheus(query)\n
      \               \n                if training_data.empty:\n                    logger.warning(f\"No
      training data for {metric_config['name']}\")\n                    continue\n
      \                   \n                if metric_config['algorithm'] == 'isolation_forest':\n
      \                   model, scaler = self.train_isolation_forest(metric_config,
      training_data)\n                    if model:\n                        self.models[metric_config['name']]
      = model\n                        self.scalers[metric_config['name']] = scaler\n
      \                       self.save_model(metric_config['name'])\n                        \n
      \               elif metric_config['algorithm'] == 'statistical':\n                    thresholds
      = self.train_statistical_model(metric_config, training_data)\n                    if
      thresholds:\n                        self.thresholds[metric_config['name']]
      = thresholds\n                        self.save_model(metric_config['name'])\n
      \                       \n                logger.info(f\"Updated model for {metric_config['name']}\")\n
      \               \n            except Exception as e:\n                logger.error(f\"Failed
      to update model for {metric_config['name']}: {e}\")\n                \n    def
      run(self):\n        \"\"\"Main detection loop\"\"\"\n        # Initial model
      training\n        self.update_models()\n        \n        last_model_update
      = time.time()\n        \n        while True:\n            try:\n                #
      Detect anomalies for all metrics\n                for metric_config in MONITORED_METRICS:\n
      \                   self.detect_anomalies(metric_config)\n                    \n
      \               # Update models periodically (every 6 hours)\n                if
      time.time() - last_model_update > 21600:\n                    self.update_models()\n
      \                   last_model_update = time.time()\n                    \n
      \               # Set health status\n                health_status.set(1)\n
      \               \n                time.sleep(UPDATE_INTERVAL)\n                \n
      \           except Exception as e:\n                logger.error(f\"Error in
      main loop: {e}\")\n                health_status.set(0)\n                time.sleep(60)\n\ndef
      main():\n    # Start Prometheus metrics server\n    start_http_server(9405)\n
      \   logger.info(\"Started metrics server on port 9405\")\n    \n    # Start
      anomaly detector\n    detector = AnomalyDetector()\n    detector.run()\n\nif
      __name__ == '__main__':\n    main()\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"anomaly_detector.py":"#!/usr/bin/env python3\nimport time\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta\nimport requests\nimport logging\nimport json\nimport os\nimport pickle\nfrom prometheus_client import start_http_server, Gauge, Counter, Histogram\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger('anomaly-detector')\n\n# Prometheus metrics\nanomaly_score = Gauge('anomaly_score', 'Anomaly score for metric', ['metric_name', 'algorithm'])\nanomaly_threshold = Gauge('anomaly_threshold', 'Dynamic threshold for metric', ['metric_name', 'type'])\nmodel_training_duration = Histogram('anomaly_model_training_duration_seconds', 'Model training duration')\nmodel_updates = Counter('anomaly_model_updates_total', 'Total model updates', ['metric_name'])\ndetection_errors = Counter('anomaly_detection_errors_total', 'Total detection errors', ['metric_name'])\nhealth_status = Gauge('anomaly_detector_health', 'Health status of anomaly detector')\n\n# Configuration\nPROMETHEUS_URL = os.getenv('PROMETHEUS_URL', 'http://prometheus:9090')\nMODEL_PATH = '/models'\nUPDATE_INTERVAL = int(os.getenv('UPDATE_INTERVAL', '300'))  # 5 minutes\nTRAINING_WINDOW = os.getenv('TRAINING_WINDOW', '7d')\n\n# Metrics configuration\nMONITORED_METRICS = [\n    {\n        'name': 'nvidia_gpu_temperature_celsius',\n        'algorithm': 'isolation_forest',\n        'sensitivity': 0.05,  # Lower = more sensitive\n        'min_samples': 100\n    },\n    {\n        'name': 'node_gpu_power_watts',\n        'algorithm': 'isolation_forest',\n        'sensitivity': 0.05,\n        'min_samples': 100\n    },\n    {\n        'name': 'node_memory_MemAvailable_bytes',\n        'algorithm': 'statistical',\n        'z_threshold': 3,\n        'min_samples': 50\n    },\n    {\n        'name': 'rate(node_cpu_seconds_total[5m])',\n        'query': 'rate(node_cpu_seconds_total[5m])',\n        'algorithm': 'statistical',\n        'z_threshold': 2.5,\n        'min_samples': 50\n    },\n    {\n        'name': 'rate(node_network_receive_bytes_total[5m])',\n        'query': 'rate(node_network_receive_bytes_total{device=\"enp110s0\"}[5m])',\n        'algorithm': 'isolation_forest',\n        'sensitivity': 0.1,\n        'min_samples': 100\n    },\n    {\n        'name': 'claude_code_api_requests_total',\n        'algorithm': 'statistical',\n        'z_threshold': 3,\n        'min_samples': 30\n    }\n]\n\nclass AnomalyDetector:\n    def __init__(self):\n        self.models = {}\n        self.scalers = {}\n        self.thresholds = {}\n        os.makedirs(MODEL_PATH, exist_ok=True)\n        self.load_models()\n        \n    def load_models(self):\n        \"\"\"Load saved models from disk\"\"\"\n        for metric in MONITORED_METRICS:\n            model_file = os.path.join(MODEL_PATH, f\"{metric['name'].replace('/', '_')}.pkl\")\n            if os.path.exists(model_file):\n                try:\n                    with open(model_file, 'rb') as f:\n                        data = pickle.load(f)\n                        self.models[metric['name']] = data['model']\n                        self.scalers[metric['name']] = data['scaler']\n                        self.thresholds[metric['name']] = data.get('thresholds', {})\n                        logger.info(f\"Loaded model for {metric['name']}\")\n                except Exception as e:\n                    logger.error(f\"Failed to load model for {metric['name']}: {e}\")\n                    \n    def save_model(self, metric_name):\n        \"\"\"Save model to disk\"\"\"\n        if metric_name in self.models:\n            model_file = os.path.join(MODEL_PATH, f\"{metric_name.replace('/', '_')}.pkl\")\n            try:\n                with open(model_file, 'wb') as f:\n                    pickle.dump({\n                        'model': self.models[metric_name],\n                        'scaler': self.scalers.get(metric_name),\n                        'thresholds': self.thresholds.get(metric_name, {})\n                    }, f)\n                logger.info(f\"Saved model for {metric_name}\")\n            except Exception as e:\n                logger.error(f\"Failed to save model for {metric_name}: {e}\")\n                \n    def query_prometheus(self, query, start_time=None, end_time=None, step='60s'):\n        \"\"\"Query Prometheus for metric data\"\"\"\n        if not start_time:\n            end_time = datetime.now()\n            start_time = end_time - timedelta(days=7)\n            \n        params = {\n            'query': query,\n            'start': start_time.timestamp(),\n            'end': end_time.timestamp(),\n            'step': step\n        }\n        \n        try:\n            response = requests.get(f\"{PROMETHEUS_URL}/api/v1/query_range\", params=params)\n            response.raise_for_status()\n            data = response.json()\n            \n            if data['status'] == 'success' and data['data']['result']:\n                # Extract time series data\n                result = data['data']['result'][0]\n                values = [(float(v[0]), float(v[1])) for v in result['values']]\n                return pd.DataFrame(values, columns=['timestamp', 'value'])\n                \n        except Exception as e:\n            logger.error(f\"Failed to query Prometheus: {e}\")\n            detection_errors.labels(metric_name=query).inc()\n            \n        return pd.DataFrame()\n        \n    def train_isolation_forest(self, metric_config, data):\n        \"\"\"Train Isolation Forest model\"\"\"\n        if len(data) \u003c metric_config['min_samples']:\n            logger.warning(f\"Insufficient data for {metric_config['name']}: {len(data)} samples\")\n            return None, None\n            \n        # Prepare features\n        X = data[['value']].values\n        \n        # Add time-based features\n        data['hour'] = pd.to_datetime(data['timestamp'], unit='s').dt.hour\n        data['dayofweek'] = pd.to_datetime(data['timestamp'], unit='s').dt.dayofweek\n        X = np.column_stack([X, data['hour'].values, data['dayofweek'].values])\n        \n        # Scale features\n        scaler = StandardScaler()\n        X_scaled = scaler.fit_transform(X)\n        \n        # Train model\n        model = IsolationForest(\n            contamination=metric_config['sensitivity'],\n            random_state=42,\n            n_estimators=100\n        )\n        \n        with model_training_duration.time():\n            model.fit(X_scaled)\n            \n        model_updates.labels(metric_name=metric_config['name']).inc()\n        \n        return model, scaler\n        \n    def train_statistical_model(self, metric_config, data):\n        \"\"\"Train statistical anomaly detection model\"\"\"\n        if len(data) \u003c metric_config['min_samples']:\n            logger.warning(f\"Insufficient data for {metric_config['name']}: {len(data)} samples\")\n            return None\n            \n        values = data['value'].values\n        \n        # Calculate statistics\n        mean = np.mean(values)\n        std = np.std(values)\n        \n        # Calculate percentiles for dynamic thresholds\n        thresholds = {\n            'mean': mean,\n            'std': std,\n            'p99': np.percentile(values, 99),\n            'p95': np.percentile(values, 95),\n            'p05': np.percentile(values, 5),\n            'p01': np.percentile(values, 1)\n        }\n        \n        model_updates.labels(metric_name=metric_config['name']).inc()\n        \n        return thresholds\n        \n    def detect_anomalies(self, metric_config):\n        \"\"\"Detect anomalies for a specific metric\"\"\"\n        try:\n            # Query recent data for detection\n            query = metric_config.get('query', metric_config['name'])\n            recent_data = self.query_prometheus(\n                query,\n                start_time=datetime.now() - timedelta(minutes=10),\n                step='30s'\n            )\n            \n            if recent_data.empty or len(recent_data) == 0:\n                return\n                \n            current_value = recent_data['value'].iloc[-1]\n            \n            if metric_config['algorithm'] == 'isolation_forest':\n                if metric_config['name'] in self.models:\n                    model = self.models[metric_config['name']]\n                    scaler = self.scalers[metric_config['name']]\n                    \n                    # Prepare features\n                    hour = pd.to_datetime(recent_data['timestamp'].iloc[-1], unit='s').hour\n                    dayofweek = pd.to_datetime(recent_data['timestamp'].iloc[-1], unit='s').dayofweek\n                    X = np.array([[current_value, hour, dayofweek]])\n                    X_scaled = scaler.transform(X)\n                    \n                    # Get anomaly score (-1 for anomaly, 1 for normal)\n                    score = model.decision_function(X_scaled)[0]\n                    # Convert to 0-100 scale (lower score = more anomalous)\n                    normalized_score = 50 + (score * 50)\n                    normalized_score = max(0, min(100, normalized_score))\n                    \n                    anomaly_score.labels(\n                        metric_name=metric_config['name'],\n                        algorithm='isolation_forest'\n                    ).set(100 - normalized_score)\n                    \n            elif metric_config['algorithm'] == 'statistical':\n                if metric_config['name'] in self.thresholds:\n                    thresholds = self.thresholds[metric_config['name']]\n                    \n                    # Calculate z-score\n                    z_score = abs((current_value - thresholds['mean']) / (thresholds['std'] + 1e-10))\n                    \n                    # Convert to 0-100 scale\n                    score = min(100, (z_score / metric_config['z_threshold']) * 100)\n                    \n                    anomaly_score.labels(\n                        metric_name=metric_config['name'],\n                        algorithm='statistical'\n                    ).set(score)\n                    \n                    # Set dynamic thresholds\n                    anomaly_threshold.labels(\n                        metric_name=metric_config['name'],\n                        type='upper_bound'\n                    ).set(thresholds['p99'])\n                    \n                    anomaly_threshold.labels(\n                        metric_name=metric_config['name'],\n                        type='lower_bound'\n                    ).set(thresholds['p01'])\n                    \n        except Exception as e:\n            logger.error(f\"Error detecting anomalies for {metric_config['name']}: {e}\")\n            detection_errors.labels(metric_name=metric_config['name']).inc()\n            \n    def update_models(self):\n        \"\"\"Update all models with recent training data\"\"\"\n        logger.info(\"Updating anomaly detection models...\")\n        \n        for metric_config in MONITORED_METRICS:\n            try:\n                # Query training data\n                query = metric_config.get('query', metric_config['name'])\n                training_data = self.query_prometheus(query)\n                \n                if training_data.empty:\n                    logger.warning(f\"No training data for {metric_config['name']}\")\n                    continue\n                    \n                if metric_config['algorithm'] == 'isolation_forest':\n                    model, scaler = self.train_isolation_forest(metric_config, training_data)\n                    if model:\n                        self.models[metric_config['name']] = model\n                        self.scalers[metric_config['name']] = scaler\n                        self.save_model(metric_config['name'])\n                        \n                elif metric_config['algorithm'] == 'statistical':\n                    thresholds = self.train_statistical_model(metric_config, training_data)\n                    if thresholds:\n                        self.thresholds[metric_config['name']] = thresholds\n                        self.save_model(metric_config['name'])\n                        \n                logger.info(f\"Updated model for {metric_config['name']}\")\n                \n            except Exception as e:\n                logger.error(f\"Failed to update model for {metric_config['name']}: {e}\")\n                \n    def run(self):\n        \"\"\"Main detection loop\"\"\"\n        # Initial model training\n        self.update_models()\n        \n        last_model_update = time.time()\n        \n        while True:\n            try:\n                # Detect anomalies for all metrics\n                for metric_config in MONITORED_METRICS:\n                    self.detect_anomalies(metric_config)\n                    \n                # Update models periodically (every 6 hours)\n                if time.time() - last_model_update \u003e 21600:\n                    self.update_models()\n                    last_model_update = time.time()\n                    \n                # Set health status\n                health_status.set(1)\n                \n                time.sleep(UPDATE_INTERVAL)\n                \n            except Exception as e:\n                logger.error(f\"Error in main loop: {e}\")\n                health_status.set(0)\n                time.sleep(60)\n\ndef main():\n    # Start Prometheus metrics server\n    start_http_server(9405)\n    logger.info(\"Started metrics server on port 9405\")\n    \n    # Start anomaly detector\n    detector = AnomalyDetector()\n    detector.run()\n\nif __name__ == '__main__':\n    main()\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"anomaly-detector-script","namespace":"monitoring"}}
    creationTimestamp: "2025-05-29T23:49:35Z"
    name: anomaly-detector-script
    namespace: monitoring
    resourceVersion: "87287"
    uid: 3ca57c72-63c7-4d27-96b1-333042912223
- apiVersion: v1
  data:
    anomaly_detector.py: "#!/usr/bin/env python3\nimport time\nimport numpy as np\nimport
      pandas as pd\nfrom datetime import datetime, timedelta\nimport requests\nimport
      logging\nimport json\nimport os\nimport pickle\nfrom prometheus_client import
      start_http_server, Gauge, Counter, Histogram\nfrom sklearn.ensemble import IsolationForest\nfrom
      sklearn.preprocessing import StandardScaler\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#
      Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s
      - %(name)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger('anomaly-detector')\n\n#
      Prometheus metrics\nanomaly_score = Gauge('anomaly_score', 'Anomaly score for
      metric', ['metric_name', 'algorithm'])\nanomaly_threshold = Gauge('anomaly_threshold',
      'Dynamic threshold for metric', ['metric_name', 'type'])\nmodel_training_duration
      = Histogram('anomaly_model_training_duration_seconds', 'Model training duration')\nmodel_updates
      = Counter('anomaly_model_updates_total', 'Total model updates', ['metric_name'])\ndetection_errors
      = Counter('anomaly_detection_errors_total', 'Total detection errors', ['metric_name'])\nhealth_status
      = Gauge('anomaly_detector_health', 'Health status of anomaly detector')\nmetrics_processed
      = Counter('anomaly_metrics_processed_total', 'Total metrics processed', ['metric_name'])\n\n#
      Configuration\nPROMETHEUS_URL = os.getenv('PROMETHEUS_URL', 'http://prometheus:9090')\nMODEL_PATH
      = '/models'\nUPDATE_INTERVAL = int(os.getenv('UPDATE_INTERVAL', '300'))  # 5
      minutes\nTRAINING_WINDOW = os.getenv('TRAINING_WINDOW', '7d')\n\n# Metrics configuration\nMONITORED_METRICS
      = [\n    {\n        'name': 'nvidia_gpu_temperature_celsius',\n        'algorithm':
      'isolation_forest',\n        'sensitivity': 0.05,\n        'min_samples': 100\n
      \   },\n    {\n        'name': 'node_gpu_power_watts',\n        'algorithm':
      'isolation_forest',\n        'sensitivity': 0.05,\n        'min_samples': 100\n
      \   },\n    {\n        'name': 'node_memory_MemAvailable_bytes',\n        'algorithm':
      'statistical',\n        'z_threshold': 3,\n        'min_samples': 50\n    },\n
      \   {\n        'name': 'cpu_usage_percent',\n        'query': '100 - (avg(rate(node_cpu_seconds_total{mode=\"idle\"}[5m]))
      * 100)',\n        'algorithm': 'statistical',\n        'z_threshold': 2.5,\n
      \       'min_samples': 50\n    },\n    {\n        'name': 'network_receive_rate',\n
      \       'query': 'rate(node_network_receive_bytes_total{device=\"enp110s0\"}[5m])',\n
      \       'algorithm': 'isolation_forest',\n        'sensitivity': 0.1,\n        'min_samples':
      100\n    }\n]\n\nclass AnomalyDetector:\n    def __init__(self):\n        self.models
      = {}\n        self.scalers = {}\n        self.thresholds = {}\n        os.makedirs(MODEL_PATH,
      exist_ok=True)\n        self.load_models()\n        \n    def load_models(self):\n
      \       \"\"\"Load saved models from disk\"\"\"\n        for metric in MONITORED_METRICS:\n
      \           model_file = os.path.join(MODEL_PATH, f\"{metric['name'].replace('/',
      '_')}.pkl\")\n            if os.path.exists(model_file):\n                try:\n
      \                   with open(model_file, 'rb') as f:\n                        data
      = pickle.load(f)\n                        self.models[metric['name']] = data['model']\n
      \                       self.scalers[metric['name']] = data['scaler']\n                        self.thresholds[metric['name']]
      = data.get('thresholds', {})\n                        logger.info(f\"Loaded
      model for {metric['name']}\")\n                except Exception as e:\n                    logger.error(f\"Failed
      to load model for {metric['name']}: {e}\")\n                    \n    def save_model(self,
      metric_name):\n        \"\"\"Save model to disk\"\"\"\n        if metric_name
      in self.models:\n            model_file = os.path.join(MODEL_PATH, f\"{metric_name.replace('/',
      '_')}.pkl\")\n            try:\n                with open(model_file, 'wb')
      as f:\n                    pickle.dump({\n                        'model': self.models[metric_name],\n
      \                       'scaler': self.scalers.get(metric_name),\n                        'thresholds':
      self.thresholds.get(metric_name, {})\n                    }, f)\n                logger.info(f\"Saved
      model for {metric_name}\")\n            except Exception as e:\n                logger.error(f\"Failed
      to save model for {metric_name}: {e}\")\n                \n    def query_prometheus(self,
      query, start_time=None, end_time=None, step='60s'):\n        \"\"\"Query Prometheus
      for metric data\"\"\"\n        if not start_time:\n            end_time = datetime.now()\n
      \           start_time = end_time - timedelta(days=7)\n            \n        params
      = {\n            'query': query,\n            'start': start_time.timestamp(),\n
      \           'end': end_time.timestamp(),\n            'step': step\n        }\n
      \       \n        try:\n            response = requests.get(f\"{PROMETHEUS_URL}/api/v1/query_range\",
      params=params)\n            response.raise_for_status()\n            data =
      response.json()\n            \n            if data['status'] == 'success' and
      data['data']['result']:\n                # Extract time series data\n                result
      = data['data']['result'][0]\n                values = [(float(v[0]), float(v[1]))
      for v in result['values']]\n                return pd.DataFrame(values, columns=['timestamp',
      'value'])\n                \n        except Exception as e:\n            logger.error(f\"Failed
      to query Prometheus: {e}\")\n            detection_errors.labels(metric_name=query).inc()\n
      \           \n        return pd.DataFrame()\n        \n    def query_instant(self,
      query):\n        \"\"\"Query Prometheus for instant value\"\"\"\n        try:\n
      \           response = requests.get(f\"{PROMETHEUS_URL}/api/v1/query\", params={'query':
      query})\n            response.raise_for_status()\n            data = response.json()\n
      \           \n            if data['status'] == 'success' and data['data']['result']:\n
      \               result = data['data']['result'][0]\n                return float(result['value'][1])\n
      \               \n        except Exception as e:\n            logger.error(f\"Failed
      to query instant value: {e}\")\n            \n        return None\n        \n
      \   def train_isolation_forest(self, metric_config, data):\n        \"\"\"Train
      Isolation Forest model\"\"\"\n        if len(data) < metric_config['min_samples']:\n
      \           logger.warning(f\"Insufficient data for {metric_config['name']}:
      {len(data)} samples\")\n            return None, None\n            \n        #
      Prepare features\n        X = data[['value']].values\n        \n        # Add
      time-based features\n        data['hour'] = pd.to_datetime(data['timestamp'],
      unit='s').dt.hour\n        data['dayofweek'] = pd.to_datetime(data['timestamp'],
      unit='s').dt.dayofweek\n        X = np.column_stack([X, data['hour'].values,
      data['dayofweek'].values])\n        \n        # Scale features\n        scaler
      = StandardScaler()\n        X_scaled = scaler.fit_transform(X)\n        \n        #
      Train model\n        model = IsolationForest(\n            contamination=metric_config['sensitivity'],\n
      \           random_state=42,\n            n_estimators=100\n        )\n        \n
      \       with model_training_duration.time():\n            model.fit(X_scaled)\n
      \           \n        model_updates.labels(metric_name=metric_config['name']).inc()\n
      \       \n        return model, scaler\n        \n    def train_statistical_model(self,
      metric_config, data):\n        \"\"\"Train statistical anomaly detection model\"\"\"\n
      \       if len(data) < metric_config['min_samples']:\n            logger.warning(f\"Insufficient
      data for {metric_config['name']}: {len(data)} samples\")\n            return
      None\n            \n        values = data['value'].values\n        \n        #
      Calculate statistics\n        mean = np.mean(values)\n        std = np.std(values)\n
      \       \n        # Calculate percentiles for dynamic thresholds\n        thresholds
      = {\n            'mean': mean,\n            'std': std,\n            'p99':
      np.percentile(values, 99),\n            'p95': np.percentile(values, 95),\n
      \           'p05': np.percentile(values, 5),\n            'p01': np.percentile(values,
      1)\n        }\n        \n        model_updates.labels(metric_name=metric_config['name']).inc()\n
      \       \n        return thresholds\n        \n    def detect_anomalies(self,
      metric_config):\n        \"\"\"Detect anomalies for a specific metric\"\"\"\n
      \       try:\n            # Query current value\n            query = metric_config.get('query',
      metric_config['name'])\n            current_value = self.query_instant(query)\n
      \           \n            if current_value is None:\n                logger.debug(f\"No
      data for {metric_config['name']}\")\n                return\n                \n
      \           metrics_processed.labels(metric_name=metric_config['name']).inc()\n
      \           \n            if metric_config['algorithm'] == 'isolation_forest':\n
      \               if metric_config['name'] in self.models:\n                    model
      = self.models[metric_config['name']]\n                    scaler = self.scalers[metric_config['name']]\n
      \                   \n                    # Prepare features\n                    now
      = datetime.now()\n                    hour = now.hour\n                    dayofweek
      = now.weekday()\n                    X = np.array([[current_value, hour, dayofweek]])\n
      \                   X_scaled = scaler.transform(X)\n                    \n                    #
      Get anomaly score (-1 for anomaly, 1 for normal)\n                    score
      = model.decision_function(X_scaled)[0]\n                    # Convert to 0-100
      scale (lower score = more anomalous)\n                    normalized_score =
      50 + (score * 50)\n                    normalized_score = max(0, min(100, normalized_score))\n
      \                   \n                    anomaly_score.labels(\n                        metric_name=metric_config['name'],\n
      \                       algorithm='isolation_forest'\n                    ).set(100
      - normalized_score)\n                    \n                    logger.debug(f\"{metric_config['name']}:
      value={current_value}, score={100-normalized_score}\")\n                    \n
      \           elif metric_config['algorithm'] == 'statistical':\n                if
      metric_config['name'] in self.thresholds:\n                    thresholds =
      self.thresholds[metric_config['name']]\n                    \n                    #
      Calculate z-score\n                    z_score = abs((current_value - thresholds['mean'])
      / (thresholds['std'] + 1e-10))\n                    \n                    #
      Convert to 0-100 scale\n                    score = min(100, (z_score / metric_config['z_threshold'])
      * 100)\n                    \n                    anomaly_score.labels(\n                        metric_name=metric_config['name'],\n
      \                       algorithm='statistical'\n                    ).set(score)\n
      \                   \n                    # Set dynamic thresholds\n                    anomaly_threshold.labels(\n
      \                       metric_name=metric_config['name'],\n                        type='upper_bound'\n
      \                   ).set(thresholds['p99'])\n                    \n                    anomaly_threshold.labels(\n
      \                       metric_name=metric_config['name'],\n                        type='lower_bound'\n
      \                   ).set(thresholds['p01'])\n                    \n                    logger.debug(f\"{metric_config['name']}:
      value={current_value}, z-score={z_score}, score={score}\")\n                    \n
      \       except Exception as e:\n            logger.error(f\"Error detecting
      anomalies for {metric_config['name']}: {e}\")\n            detection_errors.labels(metric_name=metric_config['name']).inc()\n
      \           \n    def update_models(self):\n        \"\"\"Update all models
      with recent training data\"\"\"\n        logger.info(\"Updating anomaly detection
      models...\")\n        \n        for metric_config in MONITORED_METRICS:\n            try:\n
      \               # Query training data\n                query = metric_config.get('query',
      metric_config['name'])\n                training_data = self.query_prometheus(query)\n
      \               \n                if training_data.empty:\n                    logger.warning(f\"No
      training data for {metric_config['name']}\")\n                    continue\n
      \                   \n                if metric_config['algorithm'] == 'isolation_forest':\n
      \                   model, scaler = self.train_isolation_forest(metric_config,
      training_data)\n                    if model:\n                        self.models[metric_config['name']]
      = model\n                        self.scalers[metric_config['name']] = scaler\n
      \                       self.save_model(metric_config['name'])\n                        \n
      \               elif metric_config['algorithm'] == 'statistical':\n                    thresholds
      = self.train_statistical_model(metric_config, training_data)\n                    if
      thresholds:\n                        self.thresholds[metric_config['name']]
      = thresholds\n                        self.save_model(metric_config['name'])\n
      \                       \n                logger.info(f\"Updated model for {metric_config['name']}\")\n
      \               \n            except Exception as e:\n                logger.error(f\"Failed
      to update model for {metric_config['name']}: {e}\")\n                \n    def
      run(self):\n        \"\"\"Main detection loop\"\"\"\n        # Initial model
      training\n        self.update_models()\n        \n        last_model_update
      = time.time()\n        \n        while True:\n            try:\n                #
      Detect anomalies for all metrics\n                for metric_config in MONITORED_METRICS:\n
      \                   self.detect_anomalies(metric_config)\n                    \n
      \               # Update models periodically (every 6 hours)\n                if
      time.time() - last_model_update > 21600:\n                    self.update_models()\n
      \                   last_model_update = time.time()\n                    \n
      \               # Set health status\n                health_status.set(1)\n
      \               \n                time.sleep(UPDATE_INTERVAL)\n                \n
      \           except Exception as e:\n                logger.error(f\"Error in
      main loop: {e}\")\n                health_status.set(0)\n                time.sleep(60)\n\ndef
      main():\n    # Start Prometheus metrics server\n    start_http_server(9405)\n
      \   logger.info(\"Started metrics server on port 9405\")\n    \n    # Start
      anomaly detector\n    detector = AnomalyDetector()\n    detector.run()\n\nif
      __name__ == '__main__':\n    main()\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"anomaly_detector.py":"#!/usr/bin/env python3\nimport time\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta\nimport requests\nimport logging\nimport json\nimport os\nimport pickle\nfrom prometheus_client import start_http_server, Gauge, Counter, Histogram\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger('anomaly-detector')\n\n# Prometheus metrics\nanomaly_score = Gauge('anomaly_score', 'Anomaly score for metric', ['metric_name', 'algorithm'])\nanomaly_threshold = Gauge('anomaly_threshold', 'Dynamic threshold for metric', ['metric_name', 'type'])\nmodel_training_duration = Histogram('anomaly_model_training_duration_seconds', 'Model training duration')\nmodel_updates = Counter('anomaly_model_updates_total', 'Total model updates', ['metric_name'])\ndetection_errors = Counter('anomaly_detection_errors_total', 'Total detection errors', ['metric_name'])\nhealth_status = Gauge('anomaly_detector_health', 'Health status of anomaly detector')\nmetrics_processed = Counter('anomaly_metrics_processed_total', 'Total metrics processed', ['metric_name'])\n\n# Configuration\nPROMETHEUS_URL = os.getenv('PROMETHEUS_URL', 'http://prometheus:9090')\nMODEL_PATH = '/models'\nUPDATE_INTERVAL = int(os.getenv('UPDATE_INTERVAL', '300'))  # 5 minutes\nTRAINING_WINDOW = os.getenv('TRAINING_WINDOW', '7d')\n\n# Metrics configuration\nMONITORED_METRICS = [\n    {\n        'name': 'nvidia_gpu_temperature_celsius',\n        'algorithm': 'isolation_forest',\n        'sensitivity': 0.05,\n        'min_samples': 100\n    },\n    {\n        'name': 'node_gpu_power_watts',\n        'algorithm': 'isolation_forest',\n        'sensitivity': 0.05,\n        'min_samples': 100\n    },\n    {\n        'name': 'node_memory_MemAvailable_bytes',\n        'algorithm': 'statistical',\n        'z_threshold': 3,\n        'min_samples': 50\n    },\n    {\n        'name': 'cpu_usage_percent',\n        'query': '100 - (avg(rate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)',\n        'algorithm': 'statistical',\n        'z_threshold': 2.5,\n        'min_samples': 50\n    },\n    {\n        'name': 'network_receive_rate',\n        'query': 'rate(node_network_receive_bytes_total{device=\"enp110s0\"}[5m])',\n        'algorithm': 'isolation_forest',\n        'sensitivity': 0.1,\n        'min_samples': 100\n    }\n]\n\nclass AnomalyDetector:\n    def __init__(self):\n        self.models = {}\n        self.scalers = {}\n        self.thresholds = {}\n        os.makedirs(MODEL_PATH, exist_ok=True)\n        self.load_models()\n        \n    def load_models(self):\n        \"\"\"Load saved models from disk\"\"\"\n        for metric in MONITORED_METRICS:\n            model_file = os.path.join(MODEL_PATH, f\"{metric['name'].replace('/', '_')}.pkl\")\n            if os.path.exists(model_file):\n                try:\n                    with open(model_file, 'rb') as f:\n                        data = pickle.load(f)\n                        self.models[metric['name']] = data['model']\n                        self.scalers[metric['name']] = data['scaler']\n                        self.thresholds[metric['name']] = data.get('thresholds', {})\n                        logger.info(f\"Loaded model for {metric['name']}\")\n                except Exception as e:\n                    logger.error(f\"Failed to load model for {metric['name']}: {e}\")\n                    \n    def save_model(self, metric_name):\n        \"\"\"Save model to disk\"\"\"\n        if metric_name in self.models:\n            model_file = os.path.join(MODEL_PATH, f\"{metric_name.replace('/', '_')}.pkl\")\n            try:\n                with open(model_file, 'wb') as f:\n                    pickle.dump({\n                        'model': self.models[metric_name],\n                        'scaler': self.scalers.get(metric_name),\n                        'thresholds': self.thresholds.get(metric_name, {})\n                    }, f)\n                logger.info(f\"Saved model for {metric_name}\")\n            except Exception as e:\n                logger.error(f\"Failed to save model for {metric_name}: {e}\")\n                \n    def query_prometheus(self, query, start_time=None, end_time=None, step='60s'):\n        \"\"\"Query Prometheus for metric data\"\"\"\n        if not start_time:\n            end_time = datetime.now()\n            start_time = end_time - timedelta(days=7)\n            \n        params = {\n            'query': query,\n            'start': start_time.timestamp(),\n            'end': end_time.timestamp(),\n            'step': step\n        }\n        \n        try:\n            response = requests.get(f\"{PROMETHEUS_URL}/api/v1/query_range\", params=params)\n            response.raise_for_status()\n            data = response.json()\n            \n            if data['status'] == 'success' and data['data']['result']:\n                # Extract time series data\n                result = data['data']['result'][0]\n                values = [(float(v[0]), float(v[1])) for v in result['values']]\n                return pd.DataFrame(values, columns=['timestamp', 'value'])\n                \n        except Exception as e:\n            logger.error(f\"Failed to query Prometheus: {e}\")\n            detection_errors.labels(metric_name=query).inc()\n            \n        return pd.DataFrame()\n        \n    def query_instant(self, query):\n        \"\"\"Query Prometheus for instant value\"\"\"\n        try:\n            response = requests.get(f\"{PROMETHEUS_URL}/api/v1/query\", params={'query': query})\n            response.raise_for_status()\n            data = response.json()\n            \n            if data['status'] == 'success' and data['data']['result']:\n                result = data['data']['result'][0]\n                return float(result['value'][1])\n                \n        except Exception as e:\n            logger.error(f\"Failed to query instant value: {e}\")\n            \n        return None\n        \n    def train_isolation_forest(self, metric_config, data):\n        \"\"\"Train Isolation Forest model\"\"\"\n        if len(data) \u003c metric_config['min_samples']:\n            logger.warning(f\"Insufficient data for {metric_config['name']}: {len(data)} samples\")\n            return None, None\n            \n        # Prepare features\n        X = data[['value']].values\n        \n        # Add time-based features\n        data['hour'] = pd.to_datetime(data['timestamp'], unit='s').dt.hour\n        data['dayofweek'] = pd.to_datetime(data['timestamp'], unit='s').dt.dayofweek\n        X = np.column_stack([X, data['hour'].values, data['dayofweek'].values])\n        \n        # Scale features\n        scaler = StandardScaler()\n        X_scaled = scaler.fit_transform(X)\n        \n        # Train model\n        model = IsolationForest(\n            contamination=metric_config['sensitivity'],\n            random_state=42,\n            n_estimators=100\n        )\n        \n        with model_training_duration.time():\n            model.fit(X_scaled)\n            \n        model_updates.labels(metric_name=metric_config['name']).inc()\n        \n        return model, scaler\n        \n    def train_statistical_model(self, metric_config, data):\n        \"\"\"Train statistical anomaly detection model\"\"\"\n        if len(data) \u003c metric_config['min_samples']:\n            logger.warning(f\"Insufficient data for {metric_config['name']}: {len(data)} samples\")\n            return None\n            \n        values = data['value'].values\n        \n        # Calculate statistics\n        mean = np.mean(values)\n        std = np.std(values)\n        \n        # Calculate percentiles for dynamic thresholds\n        thresholds = {\n            'mean': mean,\n            'std': std,\n            'p99': np.percentile(values, 99),\n            'p95': np.percentile(values, 95),\n            'p05': np.percentile(values, 5),\n            'p01': np.percentile(values, 1)\n        }\n        \n        model_updates.labels(metric_name=metric_config['name']).inc()\n        \n        return thresholds\n        \n    def detect_anomalies(self, metric_config):\n        \"\"\"Detect anomalies for a specific metric\"\"\"\n        try:\n            # Query current value\n            query = metric_config.get('query', metric_config['name'])\n            current_value = self.query_instant(query)\n            \n            if current_value is None:\n                logger.debug(f\"No data for {metric_config['name']}\")\n                return\n                \n            metrics_processed.labels(metric_name=metric_config['name']).inc()\n            \n            if metric_config['algorithm'] == 'isolation_forest':\n                if metric_config['name'] in self.models:\n                    model = self.models[metric_config['name']]\n                    scaler = self.scalers[metric_config['name']]\n                    \n                    # Prepare features\n                    now = datetime.now()\n                    hour = now.hour\n                    dayofweek = now.weekday()\n                    X = np.array([[current_value, hour, dayofweek]])\n                    X_scaled = scaler.transform(X)\n                    \n                    # Get anomaly score (-1 for anomaly, 1 for normal)\n                    score = model.decision_function(X_scaled)[0]\n                    # Convert to 0-100 scale (lower score = more anomalous)\n                    normalized_score = 50 + (score * 50)\n                    normalized_score = max(0, min(100, normalized_score))\n                    \n                    anomaly_score.labels(\n                        metric_name=metric_config['name'],\n                        algorithm='isolation_forest'\n                    ).set(100 - normalized_score)\n                    \n                    logger.debug(f\"{metric_config['name']}: value={current_value}, score={100-normalized_score}\")\n                    \n            elif metric_config['algorithm'] == 'statistical':\n                if metric_config['name'] in self.thresholds:\n                    thresholds = self.thresholds[metric_config['name']]\n                    \n                    # Calculate z-score\n                    z_score = abs((current_value - thresholds['mean']) / (thresholds['std'] + 1e-10))\n                    \n                    # Convert to 0-100 scale\n                    score = min(100, (z_score / metric_config['z_threshold']) * 100)\n                    \n                    anomaly_score.labels(\n                        metric_name=metric_config['name'],\n                        algorithm='statistical'\n                    ).set(score)\n                    \n                    # Set dynamic thresholds\n                    anomaly_threshold.labels(\n                        metric_name=metric_config['name'],\n                        type='upper_bound'\n                    ).set(thresholds['p99'])\n                    \n                    anomaly_threshold.labels(\n                        metric_name=metric_config['name'],\n                        type='lower_bound'\n                    ).set(thresholds['p01'])\n                    \n                    logger.debug(f\"{metric_config['name']}: value={current_value}, z-score={z_score}, score={score}\")\n                    \n        except Exception as e:\n            logger.error(f\"Error detecting anomalies for {metric_config['name']}: {e}\")\n            detection_errors.labels(metric_name=metric_config['name']).inc()\n            \n    def update_models(self):\n        \"\"\"Update all models with recent training data\"\"\"\n        logger.info(\"Updating anomaly detection models...\")\n        \n        for metric_config in MONITORED_METRICS:\n            try:\n                # Query training data\n                query = metric_config.get('query', metric_config['name'])\n                training_data = self.query_prometheus(query)\n                \n                if training_data.empty:\n                    logger.warning(f\"No training data for {metric_config['name']}\")\n                    continue\n                    \n                if metric_config['algorithm'] == 'isolation_forest':\n                    model, scaler = self.train_isolation_forest(metric_config, training_data)\n                    if model:\n                        self.models[metric_config['name']] = model\n                        self.scalers[metric_config['name']] = scaler\n                        self.save_model(metric_config['name'])\n                        \n                elif metric_config['algorithm'] == 'statistical':\n                    thresholds = self.train_statistical_model(metric_config, training_data)\n                    if thresholds:\n                        self.thresholds[metric_config['name']] = thresholds\n                        self.save_model(metric_config['name'])\n                        \n                logger.info(f\"Updated model for {metric_config['name']}\")\n                \n            except Exception as e:\n                logger.error(f\"Failed to update model for {metric_config['name']}: {e}\")\n                \n    def run(self):\n        \"\"\"Main detection loop\"\"\"\n        # Initial model training\n        self.update_models()\n        \n        last_model_update = time.time()\n        \n        while True:\n            try:\n                # Detect anomalies for all metrics\n                for metric_config in MONITORED_METRICS:\n                    self.detect_anomalies(metric_config)\n                    \n                # Update models periodically (every 6 hours)\n                if time.time() - last_model_update \u003e 21600:\n                    self.update_models()\n                    last_model_update = time.time()\n                    \n                # Set health status\n                health_status.set(1)\n                \n                time.sleep(UPDATE_INTERVAL)\n                \n            except Exception as e:\n                logger.error(f\"Error in main loop: {e}\")\n                health_status.set(0)\n                time.sleep(60)\n\ndef main():\n    # Start Prometheus metrics server\n    start_http_server(9405)\n    logger.info(\"Started metrics server on port 9405\")\n    \n    # Start anomaly detector\n    detector = AnomalyDetector()\n    detector.run()\n\nif __name__ == '__main__':\n    main()\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"anomaly-detector-script-v2","namespace":"monitoring"}}
    creationTimestamp: "2025-05-30T00:00:11Z"
    name: anomaly-detector-script-v2
    namespace: monitoring
    resourceVersion: "87564"
    uid: cc18efa3-557a-426c-9260-edf5bbd8b65d
- apiVersion: v1
  data:
    anomaly_detector.py: "#!/usr/bin/env python3\nimport time\nimport numpy as np\nimport
      pandas as pd\nfrom datetime import datetime, timedelta\nimport requests\nimport
      logging\nimport json\nimport os\nimport pickle\nfrom prometheus_client import
      start_http_server, Gauge, Counter, Histogram\nfrom sklearn.ensemble import IsolationForest\nfrom
      sklearn.preprocessing import StandardScaler\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#
      Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s
      - %(name)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger('anomaly-detector')\n\n#
      Prometheus metrics\nanomaly_score = Gauge('anomaly_score', 'Anomaly score for
      metric', ['metric_name', 'algorithm'])\nanomaly_threshold = Gauge('anomaly_threshold',
      'Dynamic threshold for metric', ['metric_name', 'type'])\nmodel_training_duration
      = Histogram('anomaly_model_training_duration_seconds', 'Model training duration')\nmodel_updates
      = Counter('anomaly_model_updates_total', 'Total model updates', ['metric_name'])\ndetection_errors
      = Counter('anomaly_detection_errors_total', 'Total detection errors', ['metric_name'])\nhealth_status
      = Gauge('anomaly_detector_health', 'Health status of anomaly detector')\nmetrics_processed
      = Counter('anomaly_metrics_processed_total', 'Total metrics processed', ['metric_name'])\n\n#
      Configuration\nPROMETHEUS_URL = os.getenv('PROMETHEUS_URL', 'http://prometheus:9090')\nMODEL_PATH
      = '/models'\nUPDATE_INTERVAL = int(os.getenv('UPDATE_INTERVAL', '300'))  # 5
      minutes\nTRAINING_WINDOW = os.getenv('TRAINING_WINDOW', '7d')\n\n# Metrics configuration
      - Now includes TCP metrics\nMONITORED_METRICS = [\n    {\n        'name': 'nvidia_gpu_temperature_celsius',\n
      \       'algorithm': 'isolation_forest',\n        'sensitivity': 0.05,\n        'min_samples':
      100\n    },\n    {\n        'name': 'node_gpu_power_watts',\n        'algorithm':
      'isolation_forest',\n        'sensitivity': 0.05,\n        'min_samples': 100\n
      \   },\n    {\n        'name': 'node_memory_MemAvailable_bytes',\n        'algorithm':
      'statistical',\n        'z_threshold': 3,\n        'min_samples': 50\n    },\n
      \   {\n        'name': 'cpu_usage_percent',\n        'query': '100 - (avg(rate(node_cpu_seconds_total{mode=\"idle\"}[5m]))
      * 100)',\n        'algorithm': 'statistical',\n        'z_threshold': 2.5,\n
      \       'min_samples': 50\n    },\n    {\n        'name': 'network_receive_rate',\n
      \       'query': 'rate(node_network_receive_bytes_total{device=\"enp110s0\"}[5m])',\n
      \       'algorithm': 'isolation_forest',\n        'sensitivity': 0.1,\n        'min_samples':
      100\n    },\n    # New TCP metrics\n    {\n        'name': 'tcp_reset_rate',\n
      \       'query': 'rate(node_netstat_Tcp_OutRsts[5m])',\n        'algorithm':
      'statistical',\n        'z_threshold': 2.5,\n        'min_samples': 50\n    },\n
      \   {\n        'name': 'tcp_reset_percentage',\n        'query': '(rate(node_netstat_Tcp_OutRsts[5m])
      / rate(node_netstat_Tcp_ActiveOpens[5m])) * 100',\n        'algorithm': 'statistical',\n
      \       'z_threshold': 2.0,\n        'min_samples': 50\n    },\n    {\n        'name':
      'tcp_retransmission_rate',\n        'query': '(rate(node_netstat_Tcp_RetransSegs[5m])
      / rate(node_netstat_Tcp_OutSegs[5m])) * 100',\n        'algorithm': 'statistical',\n
      \       'z_threshold': 3.0,\n        'min_samples': 50\n    },\n    {\n        'name':
      'tcp_connection_failures',\n        'query': 'rate(node_netstat_Tcp_AttemptFails[5m])',\n
      \       'algorithm': 'isolation_forest',\n        'sensitivity': 0.05,\n        'min_samples':
      100\n    }\n]\n\nclass AnomalyDetector:\n    def __init__(self):\n        self.models
      = {}\n        self.scalers = {}\n        self.thresholds = {}\n        os.makedirs(MODEL_PATH,
      exist_ok=True)\n        self.load_models()\n        \n    def load_models(self):\n
      \       \"\"\"Load saved models from disk\"\"\"\n        for metric in MONITORED_METRICS:\n
      \           model_file = os.path.join(MODEL_PATH, f\"{metric['name'].replace('/',
      '_')}.pkl\")\n            if os.path.exists(model_file):\n                try:\n
      \                   with open(model_file, 'rb') as f:\n                        data
      = pickle.load(f)\n                        self.models[metric['name']] = data['model']\n
      \                       self.scalers[metric['name']] = data['scaler']\n                        self.thresholds[metric['name']]
      = data.get('thresholds', {})\n                        logger.info(f\"Loaded
      model for {metric['name']}\")\n                except Exception as e:\n                    logger.error(f\"Failed
      to load model for {metric['name']}: {e}\")\n                    \n    def save_model(self,
      metric_name):\n        \"\"\"Save model to disk\"\"\"\n        if metric_name
      in self.models:\n            model_file = os.path.join(MODEL_PATH, f\"{metric_name.replace('/',
      '_')}.pkl\")\n            try:\n                with open(model_file, 'wb')
      as f:\n                    pickle.dump({\n                        'model': self.models[metric_name],\n
      \                       'scaler': self.scalers.get(metric_name),\n                        'thresholds':
      self.thresholds.get(metric_name, {})\n                    }, f)\n                logger.info(f\"Saved
      model for {metric_name}\")\n            except Exception as e:\n                logger.error(f\"Failed
      to save model for {metric_name}: {e}\")\n                \n    def query_prometheus(self,
      query, start_time=None, end_time=None, step='60s'):\n        \"\"\"Query Prometheus
      for metric data\"\"\"\n        if not start_time:\n            end_time = datetime.now()\n
      \           start_time = end_time - timedelta(days=7)\n            \n        params
      = {\n            'query': query,\n            'start': start_time.timestamp(),\n
      \           'end': end_time.timestamp(),\n            'step': step\n        }\n
      \       \n        try:\n            response = requests.get(f\"{PROMETHEUS_URL}/api/v1/query_range\",
      params=params)\n            response.raise_for_status()\n            data =
      response.json()\n            \n            if data['status'] == 'success' and
      data['data']['result']:\n                # Extract time series data\n                result
      = data['data']['result'][0]\n                values = [(float(v[0]), float(v[1]))
      for v in result['values']]\n                return pd.DataFrame(values, columns=['timestamp',
      'value'])\n                \n        except Exception as e:\n            logger.error(f\"Failed
      to query Prometheus: {e}\")\n            detection_errors.labels(metric_name=query).inc()\n
      \           \n        return pd.DataFrame()\n        \n    def query_instant(self,
      query):\n        \"\"\"Query Prometheus for instant value\"\"\"\n        try:\n
      \           response = requests.get(f\"{PROMETHEUS_URL}/api/v1/query\", params={'query':
      query})\n            response.raise_for_status()\n            data = response.json()\n
      \           \n            if data['status'] == 'success' and data['data']['result']:\n
      \               result = data['data']['result'][0]\n                return float(result['value'][1])\n
      \               \n        except Exception as e:\n            logger.error(f\"Failed
      to query instant value: {e}\")\n            \n        return None\n        \n
      \   def train_isolation_forest(self, metric_config, data):\n        \"\"\"Train
      Isolation Forest model\"\"\"\n        if len(data) < metric_config['min_samples']:\n
      \           logger.warning(f\"Insufficient data for {metric_config['name']}:
      {len(data)} samples\")\n            return None, None\n            \n        #
      Prepare features\n        X = data[['value']].values\n        \n        # Add
      time-based features\n        data['hour'] = pd.to_datetime(data['timestamp'],
      unit='s').dt.hour\n        data['dayofweek'] = pd.to_datetime(data['timestamp'],
      unit='s').dt.dayofweek\n        X = np.column_stack([X, data['hour'].values,
      data['dayofweek'].values])\n        \n        # Scale features\n        scaler
      = StandardScaler()\n        X_scaled = scaler.fit_transform(X)\n        \n        #
      Train model\n        model = IsolationForest(\n            contamination=metric_config['sensitivity'],\n
      \           random_state=42,\n            n_estimators=100\n        )\n        \n
      \       with model_training_duration.time():\n            model.fit(X_scaled)\n
      \           \n        model_updates.labels(metric_name=metric_config['name']).inc()\n
      \       \n        return model, scaler\n        \n    def train_statistical_model(self,
      metric_config, data):\n        \"\"\"Train statistical anomaly detection model\"\"\"\n
      \       if len(data) < metric_config['min_samples']:\n            logger.warning(f\"Insufficient
      data for {metric_config['name']}: {len(data)} samples\")\n            return
      None\n            \n        values = data['value'].values\n        \n        #
      Calculate statistics\n        mean = np.mean(values)\n        std = np.std(values)\n
      \       \n        # Calculate percentiles for dynamic thresholds\n        thresholds
      = {\n            'mean': mean,\n            'std': std,\n            'p99':
      np.percentile(values, 99),\n            'p95': np.percentile(values, 95),\n
      \           'p05': np.percentile(values, 5),\n            'p01': np.percentile(values,
      1)\n        }\n        \n        model_updates.labels(metric_name=metric_config['name']).inc()\n
      \       \n        return thresholds\n        \n    def detect_anomalies(self,
      metric_config):\n        \"\"\"Detect anomalies for a specific metric\"\"\"\n
      \       try:\n            # Query current value\n            query = metric_config.get('query',
      metric_config['name'])\n            current_value = self.query_instant(query)\n
      \           \n            if current_value is None:\n                logger.debug(f\"No
      data for {metric_config['name']}\")\n                return\n                \n
      \           metrics_processed.labels(metric_name=metric_config['name']).inc()\n
      \           \n            if metric_config['algorithm'] == 'isolation_forest':\n
      \               if metric_config['name'] in self.models:\n                    model
      = self.models[metric_config['name']]\n                    scaler = self.scalers[metric_config['name']]\n
      \                   \n                    # Prepare features\n                    now
      = datetime.now()\n                    hour = now.hour\n                    dayofweek
      = now.weekday()\n                    X = np.array([[current_value, hour, dayofweek]])\n
      \                   X_scaled = scaler.transform(X)\n                    \n                    #
      Get anomaly score (-1 for anomaly, 1 for normal)\n                    score
      = model.decision_function(X_scaled)[0]\n                    # Convert to 0-100
      scale (lower score = more anomalous)\n                    normalized_score =
      50 + (score * 50)\n                    normalized_score = max(0, min(100, normalized_score))\n
      \                   \n                    anomaly_score.labels(\n                        metric_name=metric_config['name'],\n
      \                       algorithm='isolation_forest'\n                    ).set(100
      - normalized_score)\n                    \n                    logger.debug(f\"{metric_config['name']}:
      value={current_value}, score={100-normalized_score}\")\n                    \n
      \           elif metric_config['algorithm'] == 'statistical':\n                if
      metric_config['name'] in self.thresholds:\n                    thresholds =
      self.thresholds[metric_config['name']]\n                    \n                    #
      Calculate z-score\n                    z_score = abs((current_value - thresholds['mean'])
      / (thresholds['std'] + 1e-10))\n                    \n                    #
      Convert to 0-100 scale\n                    score = min(100, (z_score / metric_config['z_threshold'])
      * 100)\n                    \n                    anomaly_score.labels(\n                        metric_name=metric_config['name'],\n
      \                       algorithm='statistical'\n                    ).set(score)\n
      \                   \n                    # Set dynamic thresholds\n                    anomaly_threshold.labels(\n
      \                       metric_name=metric_config['name'],\n                        type='upper_bound'\n
      \                   ).set(thresholds['p99'])\n                    \n                    anomaly_threshold.labels(\n
      \                       metric_name=metric_config['name'],\n                        type='lower_bound'\n
      \                   ).set(thresholds['p01'])\n                    \n                    logger.debug(f\"{metric_config['name']}:
      value={current_value}, z-score={z_score}, score={score}\")\n                    \n
      \       except Exception as e:\n            logger.error(f\"Error detecting
      anomalies for {metric_config['name']}: {e}\")\n            detection_errors.labels(metric_name=metric_config['name']).inc()\n
      \           \n    def update_models(self):\n        \"\"\"Update all models
      with recent training data\"\"\"\n        logger.info(\"Updating anomaly detection
      models...\")\n        \n        for metric_config in MONITORED_METRICS:\n            try:\n
      \               # Query training data\n                query = metric_config.get('query',
      metric_config['name'])\n                training_data = self.query_prometheus(query)\n
      \               \n                if training_data.empty:\n                    logger.warning(f\"No
      training data for {metric_config['name']}\")\n                    continue\n
      \                   \n                if metric_config['algorithm'] == 'isolation_forest':\n
      \                   model, scaler = self.train_isolation_forest(metric_config,
      training_data)\n                    if model:\n                        self.models[metric_config['name']]
      = model\n                        self.scalers[metric_config['name']] = scaler\n
      \                       self.save_model(metric_config['name'])\n                        \n
      \               elif metric_config['algorithm'] == 'statistical':\n                    thresholds
      = self.train_statistical_model(metric_config, training_data)\n                    if
      thresholds:\n                        self.thresholds[metric_config['name']]
      = thresholds\n                        self.save_model(metric_config['name'])\n
      \                       \n                logger.info(f\"Updated model for {metric_config['name']}\")\n
      \               \n            except Exception as e:\n                logger.error(f\"Failed
      to update model for {metric_config['name']}: {e}\")\n                \n    def
      run(self):\n        \"\"\"Main detection loop\"\"\"\n        # Initial model
      training\n        self.update_models()\n        \n        last_model_update
      = time.time()\n        \n        while True:\n            try:\n                #
      Detect anomalies for all metrics\n                for metric_config in MONITORED_METRICS:\n
      \                   self.detect_anomalies(metric_config)\n                    \n
      \               # Update models periodically (every 6 hours)\n                if
      time.time() - last_model_update > 21600:\n                    self.update_models()\n
      \                   last_model_update = time.time()\n                    \n
      \               # Set health status\n                health_status.set(1)\n
      \               \n                time.sleep(UPDATE_INTERVAL)\n                \n
      \           except Exception as e:\n                logger.error(f\"Error in
      main loop: {e}\")\n                health_status.set(0)\n                time.sleep(60)\n\ndef
      main():\n    # Start Prometheus metrics server\n    start_http_server(9405)\n
      \   logger.info(\"Started metrics server on port 9405\")\n    \n    # Start
      anomaly detector\n    detector = AnomalyDetector()\n    detector.run()\n\nif
      __name__ == '__main__':\n    main()\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"anomaly_detector.py":"#!/usr/bin/env python3\nimport time\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta\nimport requests\nimport logging\nimport json\nimport os\nimport pickle\nfrom prometheus_client import start_http_server, Gauge, Counter, Histogram\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger('anomaly-detector')\n\n# Prometheus metrics\nanomaly_score = Gauge('anomaly_score', 'Anomaly score for metric', ['metric_name', 'algorithm'])\nanomaly_threshold = Gauge('anomaly_threshold', 'Dynamic threshold for metric', ['metric_name', 'type'])\nmodel_training_duration = Histogram('anomaly_model_training_duration_seconds', 'Model training duration')\nmodel_updates = Counter('anomaly_model_updates_total', 'Total model updates', ['metric_name'])\ndetection_errors = Counter('anomaly_detection_errors_total', 'Total detection errors', ['metric_name'])\nhealth_status = Gauge('anomaly_detector_health', 'Health status of anomaly detector')\nmetrics_processed = Counter('anomaly_metrics_processed_total', 'Total metrics processed', ['metric_name'])\n\n# Configuration\nPROMETHEUS_URL = os.getenv('PROMETHEUS_URL', 'http://prometheus:9090')\nMODEL_PATH = '/models'\nUPDATE_INTERVAL = int(os.getenv('UPDATE_INTERVAL', '300'))  # 5 minutes\nTRAINING_WINDOW = os.getenv('TRAINING_WINDOW', '7d')\n\n# Metrics configuration - Now includes TCP metrics\nMONITORED_METRICS = [\n    {\n        'name': 'nvidia_gpu_temperature_celsius',\n        'algorithm': 'isolation_forest',\n        'sensitivity': 0.05,\n        'min_samples': 100\n    },\n    {\n        'name': 'node_gpu_power_watts',\n        'algorithm': 'isolation_forest',\n        'sensitivity': 0.05,\n        'min_samples': 100\n    },\n    {\n        'name': 'node_memory_MemAvailable_bytes',\n        'algorithm': 'statistical',\n        'z_threshold': 3,\n        'min_samples': 50\n    },\n    {\n        'name': 'cpu_usage_percent',\n        'query': '100 - (avg(rate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)',\n        'algorithm': 'statistical',\n        'z_threshold': 2.5,\n        'min_samples': 50\n    },\n    {\n        'name': 'network_receive_rate',\n        'query': 'rate(node_network_receive_bytes_total{device=\"enp110s0\"}[5m])',\n        'algorithm': 'isolation_forest',\n        'sensitivity': 0.1,\n        'min_samples': 100\n    },\n    # New TCP metrics\n    {\n        'name': 'tcp_reset_rate',\n        'query': 'rate(node_netstat_Tcp_OutRsts[5m])',\n        'algorithm': 'statistical',\n        'z_threshold': 2.5,\n        'min_samples': 50\n    },\n    {\n        'name': 'tcp_reset_percentage',\n        'query': '(rate(node_netstat_Tcp_OutRsts[5m]) / rate(node_netstat_Tcp_ActiveOpens[5m])) * 100',\n        'algorithm': 'statistical',\n        'z_threshold': 2.0,\n        'min_samples': 50\n    },\n    {\n        'name': 'tcp_retransmission_rate',\n        'query': '(rate(node_netstat_Tcp_RetransSegs[5m]) / rate(node_netstat_Tcp_OutSegs[5m])) * 100',\n        'algorithm': 'statistical',\n        'z_threshold': 3.0,\n        'min_samples': 50\n    },\n    {\n        'name': 'tcp_connection_failures',\n        'query': 'rate(node_netstat_Tcp_AttemptFails[5m])',\n        'algorithm': 'isolation_forest',\n        'sensitivity': 0.05,\n        'min_samples': 100\n    }\n]\n\nclass AnomalyDetector:\n    def __init__(self):\n        self.models = {}\n        self.scalers = {}\n        self.thresholds = {}\n        os.makedirs(MODEL_PATH, exist_ok=True)\n        self.load_models()\n        \n    def load_models(self):\n        \"\"\"Load saved models from disk\"\"\"\n        for metric in MONITORED_METRICS:\n            model_file = os.path.join(MODEL_PATH, f\"{metric['name'].replace('/', '_')}.pkl\")\n            if os.path.exists(model_file):\n                try:\n                    with open(model_file, 'rb') as f:\n                        data = pickle.load(f)\n                        self.models[metric['name']] = data['model']\n                        self.scalers[metric['name']] = data['scaler']\n                        self.thresholds[metric['name']] = data.get('thresholds', {})\n                        logger.info(f\"Loaded model for {metric['name']}\")\n                except Exception as e:\n                    logger.error(f\"Failed to load model for {metric['name']}: {e}\")\n                    \n    def save_model(self, metric_name):\n        \"\"\"Save model to disk\"\"\"\n        if metric_name in self.models:\n            model_file = os.path.join(MODEL_PATH, f\"{metric_name.replace('/', '_')}.pkl\")\n            try:\n                with open(model_file, 'wb') as f:\n                    pickle.dump({\n                        'model': self.models[metric_name],\n                        'scaler': self.scalers.get(metric_name),\n                        'thresholds': self.thresholds.get(metric_name, {})\n                    }, f)\n                logger.info(f\"Saved model for {metric_name}\")\n            except Exception as e:\n                logger.error(f\"Failed to save model for {metric_name}: {e}\")\n                \n    def query_prometheus(self, query, start_time=None, end_time=None, step='60s'):\n        \"\"\"Query Prometheus for metric data\"\"\"\n        if not start_time:\n            end_time = datetime.now()\n            start_time = end_time - timedelta(days=7)\n            \n        params = {\n            'query': query,\n            'start': start_time.timestamp(),\n            'end': end_time.timestamp(),\n            'step': step\n        }\n        \n        try:\n            response = requests.get(f\"{PROMETHEUS_URL}/api/v1/query_range\", params=params)\n            response.raise_for_status()\n            data = response.json()\n            \n            if data['status'] == 'success' and data['data']['result']:\n                # Extract time series data\n                result = data['data']['result'][0]\n                values = [(float(v[0]), float(v[1])) for v in result['values']]\n                return pd.DataFrame(values, columns=['timestamp', 'value'])\n                \n        except Exception as e:\n            logger.error(f\"Failed to query Prometheus: {e}\")\n            detection_errors.labels(metric_name=query).inc()\n            \n        return pd.DataFrame()\n        \n    def query_instant(self, query):\n        \"\"\"Query Prometheus for instant value\"\"\"\n        try:\n            response = requests.get(f\"{PROMETHEUS_URL}/api/v1/query\", params={'query': query})\n            response.raise_for_status()\n            data = response.json()\n            \n            if data['status'] == 'success' and data['data']['result']:\n                result = data['data']['result'][0]\n                return float(result['value'][1])\n                \n        except Exception as e:\n            logger.error(f\"Failed to query instant value: {e}\")\n            \n        return None\n        \n    def train_isolation_forest(self, metric_config, data):\n        \"\"\"Train Isolation Forest model\"\"\"\n        if len(data) \u003c metric_config['min_samples']:\n            logger.warning(f\"Insufficient data for {metric_config['name']}: {len(data)} samples\")\n            return None, None\n            \n        # Prepare features\n        X = data[['value']].values\n        \n        # Add time-based features\n        data['hour'] = pd.to_datetime(data['timestamp'], unit='s').dt.hour\n        data['dayofweek'] = pd.to_datetime(data['timestamp'], unit='s').dt.dayofweek\n        X = np.column_stack([X, data['hour'].values, data['dayofweek'].values])\n        \n        # Scale features\n        scaler = StandardScaler()\n        X_scaled = scaler.fit_transform(X)\n        \n        # Train model\n        model = IsolationForest(\n            contamination=metric_config['sensitivity'],\n            random_state=42,\n            n_estimators=100\n        )\n        \n        with model_training_duration.time():\n            model.fit(X_scaled)\n            \n        model_updates.labels(metric_name=metric_config['name']).inc()\n        \n        return model, scaler\n        \n    def train_statistical_model(self, metric_config, data):\n        \"\"\"Train statistical anomaly detection model\"\"\"\n        if len(data) \u003c metric_config['min_samples']:\n            logger.warning(f\"Insufficient data for {metric_config['name']}: {len(data)} samples\")\n            return None\n            \n        values = data['value'].values\n        \n        # Calculate statistics\n        mean = np.mean(values)\n        std = np.std(values)\n        \n        # Calculate percentiles for dynamic thresholds\n        thresholds = {\n            'mean': mean,\n            'std': std,\n            'p99': np.percentile(values, 99),\n            'p95': np.percentile(values, 95),\n            'p05': np.percentile(values, 5),\n            'p01': np.percentile(values, 1)\n        }\n        \n        model_updates.labels(metric_name=metric_config['name']).inc()\n        \n        return thresholds\n        \n    def detect_anomalies(self, metric_config):\n        \"\"\"Detect anomalies for a specific metric\"\"\"\n        try:\n            # Query current value\n            query = metric_config.get('query', metric_config['name'])\n            current_value = self.query_instant(query)\n            \n            if current_value is None:\n                logger.debug(f\"No data for {metric_config['name']}\")\n                return\n                \n            metrics_processed.labels(metric_name=metric_config['name']).inc()\n            \n            if metric_config['algorithm'] == 'isolation_forest':\n                if metric_config['name'] in self.models:\n                    model = self.models[metric_config['name']]\n                    scaler = self.scalers[metric_config['name']]\n                    \n                    # Prepare features\n                    now = datetime.now()\n                    hour = now.hour\n                    dayofweek = now.weekday()\n                    X = np.array([[current_value, hour, dayofweek]])\n                    X_scaled = scaler.transform(X)\n                    \n                    # Get anomaly score (-1 for anomaly, 1 for normal)\n                    score = model.decision_function(X_scaled)[0]\n                    # Convert to 0-100 scale (lower score = more anomalous)\n                    normalized_score = 50 + (score * 50)\n                    normalized_score = max(0, min(100, normalized_score))\n                    \n                    anomaly_score.labels(\n                        metric_name=metric_config['name'],\n                        algorithm='isolation_forest'\n                    ).set(100 - normalized_score)\n                    \n                    logger.debug(f\"{metric_config['name']}: value={current_value}, score={100-normalized_score}\")\n                    \n            elif metric_config['algorithm'] == 'statistical':\n                if metric_config['name'] in self.thresholds:\n                    thresholds = self.thresholds[metric_config['name']]\n                    \n                    # Calculate z-score\n                    z_score = abs((current_value - thresholds['mean']) / (thresholds['std'] + 1e-10))\n                    \n                    # Convert to 0-100 scale\n                    score = min(100, (z_score / metric_config['z_threshold']) * 100)\n                    \n                    anomaly_score.labels(\n                        metric_name=metric_config['name'],\n                        algorithm='statistical'\n                    ).set(score)\n                    \n                    # Set dynamic thresholds\n                    anomaly_threshold.labels(\n                        metric_name=metric_config['name'],\n                        type='upper_bound'\n                    ).set(thresholds['p99'])\n                    \n                    anomaly_threshold.labels(\n                        metric_name=metric_config['name'],\n                        type='lower_bound'\n                    ).set(thresholds['p01'])\n                    \n                    logger.debug(f\"{metric_config['name']}: value={current_value}, z-score={z_score}, score={score}\")\n                    \n        except Exception as e:\n            logger.error(f\"Error detecting anomalies for {metric_config['name']}: {e}\")\n            detection_errors.labels(metric_name=metric_config['name']).inc()\n            \n    def update_models(self):\n        \"\"\"Update all models with recent training data\"\"\"\n        logger.info(\"Updating anomaly detection models...\")\n        \n        for metric_config in MONITORED_METRICS:\n            try:\n                # Query training data\n                query = metric_config.get('query', metric_config['name'])\n                training_data = self.query_prometheus(query)\n                \n                if training_data.empty:\n                    logger.warning(f\"No training data for {metric_config['name']}\")\n                    continue\n                    \n                if metric_config['algorithm'] == 'isolation_forest':\n                    model, scaler = self.train_isolation_forest(metric_config, training_data)\n                    if model:\n                        self.models[metric_config['name']] = model\n                        self.scalers[metric_config['name']] = scaler\n                        self.save_model(metric_config['name'])\n                        \n                elif metric_config['algorithm'] == 'statistical':\n                    thresholds = self.train_statistical_model(metric_config, training_data)\n                    if thresholds:\n                        self.thresholds[metric_config['name']] = thresholds\n                        self.save_model(metric_config['name'])\n                        \n                logger.info(f\"Updated model for {metric_config['name']}\")\n                \n            except Exception as e:\n                logger.error(f\"Failed to update model for {metric_config['name']}: {e}\")\n                \n    def run(self):\n        \"\"\"Main detection loop\"\"\"\n        # Initial model training\n        self.update_models()\n        \n        last_model_update = time.time()\n        \n        while True:\n            try:\n                # Detect anomalies for all metrics\n                for metric_config in MONITORED_METRICS:\n                    self.detect_anomalies(metric_config)\n                    \n                # Update models periodically (every 6 hours)\n                if time.time() - last_model_update \u003e 21600:\n                    self.update_models()\n                    last_model_update = time.time()\n                    \n                # Set health status\n                health_status.set(1)\n                \n                time.sleep(UPDATE_INTERVAL)\n                \n            except Exception as e:\n                logger.error(f\"Error in main loop: {e}\")\n                health_status.set(0)\n                time.sleep(60)\n\ndef main():\n    # Start Prometheus metrics server\n    start_http_server(9405)\n    logger.info(\"Started metrics server on port 9405\")\n    \n    # Start anomaly detector\n    detector = AnomalyDetector()\n    detector.run()\n\nif __name__ == '__main__':\n    main()\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"anomaly-detector-script-v3","namespace":"monitoring"}}
    creationTimestamp: "2025-05-30T21:09:33Z"
    name: anomaly-detector-script-v3
    namespace: monitoring
    resourceVersion: "221171"
    uid: d1fbb4d3-2aef-4034-b779-9595d01cc2e8
- apiVersion: v1
  data:
    anomaly-recording-rules.yaml: "groups:\n- name: anomaly_metric_mapping\n  interval:
      15s\n  rules:\n  # Map GPU anomaly scores\n  - record: gpu_anomaly_score\n    expr:
      |\n      anomaly_score{metric_name=~\"nvidia_gpu_temperature_celsius|node_gpu_power_watts\"}\n
      \ \n  # Map process anomaly scores\n  - record: process_anomaly_score\n    expr:
      |\n      label_replace(\n        process_cpu_anomaly_score or\n        process_memory_anomaly_score
      or\n        process_count_anomaly_score,\n        \"metric_type\", \"$1\", \"__name__\",
      \"(.*)\"\n      )\n  \n  # Map disk anomaly scores\n  - record: disk_anomaly_score\n
      \   expr: |\n      disk_space_anomaly_score\n  \n  # Map pod anomaly scores
      (if needed)\n  - record: pod_anomaly_score\n    expr: |\n      k8s_pod_anomaly_score
      or\n      pod_restart_anomaly_score or\n      pod_cpu_anomaly_score or\n      pod_memory_anomaly_score\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"anomaly-recording-rules.yaml":"groups:\n- name: anomaly_metric_mapping\n  interval: 15s\n  rules:\n  # Map GPU anomaly scores\n  - record: gpu_anomaly_score\n    expr: |\n      anomaly_score{metric_name=~\"nvidia_gpu_temperature_celsius|node_gpu_power_watts\"}\n  \n  # Map process anomaly scores\n  - record: process_anomaly_score\n    expr: |\n      label_replace(\n        process_cpu_anomaly_score or\n        process_memory_anomaly_score or\n        process_count_anomaly_score,\n        \"metric_type\", \"$1\", \"__name__\", \"(.*)\"\n      )\n  \n  # Map disk anomaly scores\n  - record: disk_anomaly_score\n    expr: |\n      disk_space_anomaly_score\n  \n  # Map pod anomaly scores (if needed)\n  - record: pod_anomaly_score\n    expr: |\n      k8s_pod_anomaly_score or\n      pod_restart_anomaly_score or\n      pod_cpu_anomaly_score or\n      pod_memory_anomaly_score\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"anomaly-recording-rules","namespace":"monitoring"}}
    creationTimestamp: "2025-06-06T23:04:23Z"
    name: anomaly-recording-rules
    namespace: monitoring
    resourceVersion: "4517966"
    uid: 00123821-0c2a-49a6-b41f-c9211fb8b864
- apiVersion: v1
  data:
    application-network-dashboard.json: |
      {
        "uid": "app-network-analysis",
        "title": "Application Network Analysis",
        "description": "Per-process network connection analysis and trends",
        "tags": ["network", "process", "application"],
        "timezone": "browser",
        "schemaVersion": 27,
        "version": 1,
        "refresh": "30s",
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "panels": [
          {
            "id": 1,
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0},
            "type": "table",
            "title": "Top Processes by Connection Count",
            "targets": [
              {
                "expr": "topk(20, sum by (pid) (process_network_connections))",
                "format": "table",
                "instant": true
              }
            ],
            "transformations": [
              {
                "id": "organize",
                "options": {
                  "excludeByName": {
                    "Time": true,
                    "job": true,
                    "instance": true
                  },
                  "renameByName": {
                    "pid": "Process ID",
                    "Value": "Total Connections"
                  }
                }
              },
              {
                "id": "sortBy",
                "options": {
                  "fields": {},
                  "sort": [
                    {
                      "field": "Total Connections",
                      "desc": true
                    }
                  ]
                }
              }
            ],
            "fieldConfig": {
              "defaults": {
                "custom": {
                  "align": "auto",
                  "displayMode": "gradient-gauge"
                }
              },
              "overrides": [
                {
                  "matcher": {"id": "byName", "options": "Total Connections"},
                  "properties": [
                    {
                      "id": "color",
                      "value": {
                        "mode": "continuous-GrYlRd"
                      }
                    }
                  ]
                }
              ]
            }
          },
          {
            "id": 2,
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0},
            "type": "piechart",
            "title": "Connection States Distribution",
            "targets": [
              {
                "expr": "sum by (state) (process_network_connections{protocol=\"tcp\"})",
                "legendFormat": "{{state}}"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "short",
                "decimals": 0,
                "color": {"mode": "palette-classic"}
              }
            },
            "options": {
              "pieType": "donut",
              "displayLabels": ["name", "percent", "value"],
              "legendDisplayMode": "table",
              "legendValues": ["value", "percent"]
            }
          },
          {
            "id": 3,
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 8},
            "type": "table",
            "title": "Process Connection Details",
            "targets": [
              {
                "expr": "process_network_connections",
                "format": "table",
                "instant": true
              }
            ],
            "transformations": [
              {
                "id": "organize",
                "options": {
                  "excludeByName": {
                    "Time": true,
                    "job": true,
                    "instance": true,
                    "__name__": true
                  },
                  "renameByName": {
                    "pid": "Process ID",
                    "state": "State",
                    "protocol": "Protocol",
                    "Value": "Count"
                  }
                }
              },
              {
                "id": "groupBy",
                "options": {
                  "fields": {
                    "Process ID": {
                      "aggregations": [],
                      "operation": "groupby"
                    },
                    "State": {
                      "aggregations": [],
                      "operation": "groupby"
                    },
                    "Protocol": {
                      "aggregations": [],
                      "operation": "groupby"
                    },
                    "Count": {
                      "aggregations": ["sum"],
                      "operation": "aggregate"
                    }
                  }
                }
              },
              {
                "id": "sortBy",
                "options": {
                  "fields": {},
                  "sort": [
                    {
                      "field": "Count (sum)",
                      "desc": true
                    }
                  ]
                }
              }
            ],
            "fieldConfig": {
              "defaults": {
                "custom": {
                  "align": "auto",
                  "displayMode": "color-background",
                  "filterable": true
                }
              },
              "overrides": [
                {
                  "matcher": {"id": "byName", "options": "State"},
                  "properties": [
                    {
                      "id": "mappings",
                      "value": [
                        {"type": "value", "value": "LISTEN", "text": "LISTEN", "color": "blue"},
                        {"type": "value", "value": "ESTAB", "text": "ESTABLISHED", "color": "green"},
                        {"type": "value", "value": "TIME_WAIT", "text": "TIME_WAIT", "color": "yellow"},
                        {"type": "value", "value": "CLOSE_WAIT", "text": "CLOSE_WAIT", "color": "orange"},
                        {"type": "value", "value": "SYN_SENT", "text": "SYN_SENT", "color": "purple"}
                      ]
                    }
                  ]
                }
              ]
            }
          },
          {
            "id": 4,
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 16},
            "type": "timeseries",
            "title": "Connection Count Trends",
            "targets": [
              {
                "expr": "sum by (state) (process_network_connections{protocol=\"tcp\"})",
                "legendFormat": "{{state}}"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "short",
                "color": {"mode": "palette-classic"},
                "custom": {
                  "lineInterpolation": "smooth",
                  "lineWidth": 2,
                  "fillOpacity": 10,
                  "showPoints": "never",
                  "spanNulls": true,
                  "stacking": {
                    "mode": "normal",
                    "group": "A"
                  }
                }
              }
            }
          },
          {
            "id": 5,
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 16},
            "type": "stat",
            "title": "Protocol Distribution",
            "targets": [
              {
                "expr": "sum by (protocol) (process_network_connections)",
                "legendFormat": "{{protocol | upper}}"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "short",
                "color": {"mode": "palette-classic"}
              }
            },
            "options": {
              "graphMode": "area",
              "orientation": "horizontal",
              "textMode": "auto",
              "colorMode": "value",
              "justifyMode": "auto"
            }
          },
          {
            "id": 6,
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 24},
            "type": "timeseries",
            "title": "Top 10 Processes - Connection History",
            "targets": [
              {
                "expr": "topk(10, sum by (pid) (process_network_connections))",
                "legendFormat": "PID: {{pid}}"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "short",
                "color": {"mode": "palette-classic"},
                "custom": {
                  "lineInterpolation": "smooth",
                  "lineWidth": 2,
                  "fillOpacity": 10,
                  "showPoints": "never",
                  "spanNulls": true
                }
              }
            }
          },
          {
            "id": 7,
            "gridPos": {"h": 6, "w": 8, "x": 0, "y": 32},
            "type": "stat",
            "title": "Listening Services",
            "description": "Number of processes with listening sockets",
            "targets": [
              {
                "expr": "count(count by (pid) (process_network_connections{state=\"LISTEN\"}))",
                "legendFormat": "Services"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "short",
                "color": {"mode": "thresholds"},
                "thresholds": {
                  "steps": [
                    {"color": "green", "value": null},
                    {"color": "yellow", "value": 50},
                    {"color": "red", "value": 100}
                  ]
                }
              }
            }
          },
          {
            "id": 8,
            "gridPos": {"h": 6, "w": 8, "x": 8, "y": 32},
            "type": "stat",
            "title": "Active Connections",
            "description": "Total established connections",
            "targets": [
              {
                "expr": "sum(process_network_connections{state=\"ESTAB\"})",
                "legendFormat": "Established"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "short",
                "color": {"mode": "thresholds"},
                "thresholds": {
                  "steps": [
                    {"color": "green", "value": null},
                    {"color": "yellow", "value": 100},
                    {"color": "red", "value": 500}
                  ]
                }
              }
            }
          },
          {
            "id": 9,
            "gridPos": {"h": 6, "w": 8, "x": 16, "y": 32},
            "type": "stat",
            "title": "Connection Churn",
            "description": "TIME_WAIT connections indicate recent closures",
            "targets": [
              {
                "expr": "sum(process_network_connections{state=\"TIME_WAIT\"})",
                "legendFormat": "TIME_WAIT"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "short",
                "color": {"mode": "thresholds"},
                "thresholds": {
                  "steps": [
                    {"color": "green", "value": null},
                    {"color": "yellow", "value": 50},
                    {"color": "orange", "value": 100},
                    {"color": "red", "value": 200}
                  ]
                }
              }
            }
          }
        ]
      }
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"application-network-dashboard.json":"{\n  \"uid\": \"app-network-analysis\",\n  \"title\": \"Application Network Analysis\",\n  \"description\": \"Per-process network connection analysis and trends\",\n  \"tags\": [\"network\", \"process\", \"application\"],\n  \"timezone\": \"browser\",\n  \"schemaVersion\": 27,\n  \"version\": 1,\n  \"refresh\": \"30s\",\n  \"time\": {\n    \"from\": \"now-1h\",\n    \"to\": \"now\"\n  },\n  \"panels\": [\n    {\n      \"id\": 1,\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 0},\n      \"type\": \"table\",\n      \"title\": \"Top Processes by Connection Count\",\n      \"targets\": [\n        {\n          \"expr\": \"topk(20, sum by (pid) (process_network_connections))\",\n          \"format\": \"table\",\n          \"instant\": true\n        }\n      ],\n      \"transformations\": [\n        {\n          \"id\": \"organize\",\n          \"options\": {\n            \"excludeByName\": {\n              \"Time\": true,\n              \"job\": true,\n              \"instance\": true\n            },\n            \"renameByName\": {\n              \"pid\": \"Process ID\",\n              \"Value\": \"Total Connections\"\n            }\n          }\n        },\n        {\n          \"id\": \"sortBy\",\n          \"options\": {\n            \"fields\": {},\n            \"sort\": [\n              {\n                \"field\": \"Total Connections\",\n                \"desc\": true\n              }\n            ]\n          }\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"custom\": {\n            \"align\": \"auto\",\n            \"displayMode\": \"gradient-gauge\"\n          }\n        },\n        \"overrides\": [\n          {\n            \"matcher\": {\"id\": \"byName\", \"options\": \"Total Connections\"},\n            \"properties\": [\n              {\n                \"id\": \"color\",\n                \"value\": {\n                  \"mode\": \"continuous-GrYlRd\"\n                }\n              }\n            ]\n          }\n        ]\n      }\n    },\n    {\n      \"id\": 2,\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 0},\n      \"type\": \"piechart\",\n      \"title\": \"Connection States Distribution\",\n      \"targets\": [\n        {\n          \"expr\": \"sum by (state) (process_network_connections{protocol=\\\"tcp\\\"})\",\n          \"legendFormat\": \"{{state}}\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"decimals\": 0,\n          \"color\": {\"mode\": \"palette-classic\"}\n        }\n      },\n      \"options\": {\n        \"pieType\": \"donut\",\n        \"displayLabels\": [\"name\", \"percent\", \"value\"],\n        \"legendDisplayMode\": \"table\",\n        \"legendValues\": [\"value\", \"percent\"]\n      }\n    },\n    {\n      \"id\": 3,\n      \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 8},\n      \"type\": \"table\",\n      \"title\": \"Process Connection Details\",\n      \"targets\": [\n        {\n          \"expr\": \"process_network_connections\",\n          \"format\": \"table\",\n          \"instant\": true\n        }\n      ],\n      \"transformations\": [\n        {\n          \"id\": \"organize\",\n          \"options\": {\n            \"excludeByName\": {\n              \"Time\": true,\n              \"job\": true,\n              \"instance\": true,\n              \"__name__\": true\n            },\n            \"renameByName\": {\n              \"pid\": \"Process ID\",\n              \"state\": \"State\",\n              \"protocol\": \"Protocol\",\n              \"Value\": \"Count\"\n            }\n          }\n        },\n        {\n          \"id\": \"groupBy\",\n          \"options\": {\n            \"fields\": {\n              \"Process ID\": {\n                \"aggregations\": [],\n                \"operation\": \"groupby\"\n              },\n              \"State\": {\n                \"aggregations\": [],\n                \"operation\": \"groupby\"\n              },\n              \"Protocol\": {\n                \"aggregations\": [],\n                \"operation\": \"groupby\"\n              },\n              \"Count\": {\n                \"aggregations\": [\"sum\"],\n                \"operation\": \"aggregate\"\n              }\n            }\n          }\n        },\n        {\n          \"id\": \"sortBy\",\n          \"options\": {\n            \"fields\": {},\n            \"sort\": [\n              {\n                \"field\": \"Count (sum)\",\n                \"desc\": true\n              }\n            ]\n          }\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"custom\": {\n            \"align\": \"auto\",\n            \"displayMode\": \"color-background\",\n            \"filterable\": true\n          }\n        },\n        \"overrides\": [\n          {\n            \"matcher\": {\"id\": \"byName\", \"options\": \"State\"},\n            \"properties\": [\n              {\n                \"id\": \"mappings\",\n                \"value\": [\n                  {\"type\": \"value\", \"value\": \"LISTEN\", \"text\": \"LISTEN\", \"color\": \"blue\"},\n                  {\"type\": \"value\", \"value\": \"ESTAB\", \"text\": \"ESTABLISHED\", \"color\": \"green\"},\n                  {\"type\": \"value\", \"value\": \"TIME_WAIT\", \"text\": \"TIME_WAIT\", \"color\": \"yellow\"},\n                  {\"type\": \"value\", \"value\": \"CLOSE_WAIT\", \"text\": \"CLOSE_WAIT\", \"color\": \"orange\"},\n                  {\"type\": \"value\", \"value\": \"SYN_SENT\", \"text\": \"SYN_SENT\", \"color\": \"purple\"}\n                ]\n              }\n            ]\n          }\n        ]\n      }\n    },\n    {\n      \"id\": 4,\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 16},\n      \"type\": \"timeseries\",\n      \"title\": \"Connection Count Trends\",\n      \"targets\": [\n        {\n          \"expr\": \"sum by (state) (process_network_connections{protocol=\\\"tcp\\\"})\",\n          \"legendFormat\": \"{{state}}\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 10,\n            \"showPoints\": \"never\",\n            \"spanNulls\": true,\n            \"stacking\": {\n              \"mode\": \"normal\",\n              \"group\": \"A\"\n            }\n          }\n        }\n      }\n    },\n    {\n      \"id\": 5,\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 16},\n      \"type\": \"stat\",\n      \"title\": \"Protocol Distribution\",\n      \"targets\": [\n        {\n          \"expr\": \"sum by (protocol) (process_network_connections)\",\n          \"legendFormat\": \"{{protocol | upper}}\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"color\": {\"mode\": \"palette-classic\"}\n        }\n      },\n      \"options\": {\n        \"graphMode\": \"area\",\n        \"orientation\": \"horizontal\",\n        \"textMode\": \"auto\",\n        \"colorMode\": \"value\",\n        \"justifyMode\": \"auto\"\n      }\n    },\n    {\n      \"id\": 6,\n      \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 24},\n      \"type\": \"timeseries\",\n      \"title\": \"Top 10 Processes - Connection History\",\n      \"targets\": [\n        {\n          \"expr\": \"topk(10, sum by (pid) (process_network_connections))\",\n          \"legendFormat\": \"PID: {{pid}}\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 10,\n            \"showPoints\": \"never\",\n            \"spanNulls\": true\n          }\n        }\n      }\n    },\n    {\n      \"id\": 7,\n      \"gridPos\": {\"h\": 6, \"w\": 8, \"x\": 0, \"y\": 32},\n      \"type\": \"stat\",\n      \"title\": \"Listening Services\",\n      \"description\": \"Number of processes with listening sockets\",\n      \"targets\": [\n        {\n          \"expr\": \"count(count by (pid) (process_network_connections{state=\\\"LISTEN\\\"}))\",\n          \"legendFormat\": \"Services\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"color\": {\"mode\": \"thresholds\"},\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 50},\n              {\"color\": \"red\", \"value\": 100}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"id\": 8,\n      \"gridPos\": {\"h\": 6, \"w\": 8, \"x\": 8, \"y\": 32},\n      \"type\": \"stat\",\n      \"title\": \"Active Connections\",\n      \"description\": \"Total established connections\",\n      \"targets\": [\n        {\n          \"expr\": \"sum(process_network_connections{state=\\\"ESTAB\\\"})\",\n          \"legendFormat\": \"Established\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"color\": {\"mode\": \"thresholds\"},\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 100},\n              {\"color\": \"red\", \"value\": 500}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"id\": 9,\n      \"gridPos\": {\"h\": 6, \"w\": 8, \"x\": 16, \"y\": 32},\n      \"type\": \"stat\",\n      \"title\": \"Connection Churn\",\n      \"description\": \"TIME_WAIT connections indicate recent closures\",\n      \"targets\": [\n        {\n          \"expr\": \"sum(process_network_connections{state=\\\"TIME_WAIT\\\"})\",\n          \"legendFormat\": \"TIME_WAIT\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"color\": {\"mode\": \"thresholds\"},\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 50},\n              {\"color\": \"orange\", \"value\": 100},\n              {\"color\": \"red\", \"value\": 200}\n            ]\n          }\n        }\n      }\n    }\n  ]\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"grafana_dashboard":"1"},"name":"application-network-dashboard","namespace":"monitoring"}}
    creationTimestamp: "2025-05-29T20:28:33Z"
    labels:
      grafana_dashboard: "1"
    name: application-network-dashboard
    namespace: monitoring
    resourceVersion: "81021"
    uid: b5196ee7-6de9-4233-a784-e9ff97dbe4c6
- apiVersion: v1
  data:
    backup.sh: |
      #!/bin/bash
      set -e

      BACKUP_DIR="/backups"
      TIMESTAMP=$(date +%Y%m%d_%H%M%S)

      echo "Starting backup at $(date)"

      # Create backup directory
      mkdir -p "$BACKUP_DIR/prometheus/$TIMESTAMP"
      mkdir -p "$BACKUP_DIR/grafana/$TIMESTAMP"
      mkdir -p "$BACKUP_DIR/configs/$TIMESTAMP"

      # Backup Prometheus data
      echo "Backing up Prometheus data..."
      if [ -d "/prometheus-data" ]; then
        tar -czf "$BACKUP_DIR/prometheus/$TIMESTAMP/prometheus-data.tar.gz" -C /prometheus-data .
        echo "Prometheus data backed up successfully"
      fi

      # Backup Grafana data
      echo "Backing up Grafana data..."
      if [ -d "/grafana-data" ]; then
        tar -czf "$BACKUP_DIR/grafana/$TIMESTAMP/grafana-data.tar.gz" -C /grafana-data .
        echo "Grafana data backed up successfully"
      fi

      # Backup configurations
      echo "Backing up configurations..."
      kubectl get configmap -n monitoring -o yaml > "$BACKUP_DIR/configs/$TIMESTAMP/configmaps.yaml"
      kubectl get secret -n monitoring -o yaml > "$BACKUP_DIR/configs/$TIMESTAMP/secrets.yaml"
      kubectl get pvc -n monitoring -o yaml > "$BACKUP_DIR/configs/$TIMESTAMP/pvcs.yaml"

      # Create metadata file
      cat > "$BACKUP_DIR/configs/$TIMESTAMP/metadata.json" <<EOF
      {
        "timestamp": "$TIMESTAMP",
        "date": "$(date)",
        "kubernetes_version": "$(kubectl version --short 2>/dev/null | grep Server | awk '{print $3}')",
        "namespace": "monitoring"
      }
      EOF

      # Cleanup old backups (keep last 7 days)
      echo "Cleaning up old backups..."
      find "$BACKUP_DIR/prometheus" -type d -mtime +7 -exec rm -rf {} + 2>/dev/null || true
      find "$BACKUP_DIR/grafana" -type d -mtime +7 -exec rm -rf {} + 2>/dev/null || true
      find "$BACKUP_DIR/configs" -type d -mtime +7 -exec rm -rf {} + 2>/dev/null || true

      # List current backups
      echo "Current backups:"
      du -sh "$BACKUP_DIR"/*/* 2>/dev/null | tail -20

      echo "Backup completed at $(date)"
    restore.sh: |
      #!/bin/bash
      set -e

      BACKUP_DIR="/backups"

      if [ -z "$1" ]; then
        echo "Usage: $0 <timestamp>"
        echo "Available backups:"
        ls -la "$BACKUP_DIR/configs/" | grep -E '^d' | awk '{print $9}' | grep -v '^\.$' | grep -v '^\.\.$'
        exit 1
      fi

      TIMESTAMP="$1"

      echo "Starting restore from backup $TIMESTAMP at $(date)"

      # Verify backup exists
      if [ ! -d "$BACKUP_DIR/configs/$TIMESTAMP" ]; then
        echo "Backup $TIMESTAMP not found!"
        exit 1
      fi

      # Show backup metadata
      if [ -f "$BACKUP_DIR/configs/$TIMESTAMP/metadata.json" ]; then
        echo "Backup metadata:"
        cat "$BACKUP_DIR/configs/$TIMESTAMP/metadata.json"
      fi

      read -p "Are you sure you want to restore from this backup? (yes/no) " -n 3 -r
      echo
      if [[ ! $REPLY =~ ^yes$ ]]; then
        echo "Restore cancelled"
        exit 1
      fi

      # Restore Prometheus data
      if [ -f "$BACKUP_DIR/prometheus/$TIMESTAMP/prometheus-data.tar.gz" ]; then
        echo "Restoring Prometheus data..."
        rm -rf /prometheus-data/*
        tar -xzf "$BACKUP_DIR/prometheus/$TIMESTAMP/prometheus-data.tar.gz" -C /prometheus-data/
        echo "Prometheus data restored"
      fi

      # Restore Grafana data
      if [ -f "$BACKUP_DIR/grafana/$TIMESTAMP/grafana-data.tar.gz" ]; then
        echo "Restoring Grafana data..."
        rm -rf /grafana-data/*
        tar -xzf "$BACKUP_DIR/grafana/$TIMESTAMP/grafana-data.tar.gz" -C /grafana-data/
        echo "Grafana data restored"
      fi

      echo "Restore completed at $(date)"
      echo "Please restart Prometheus and Grafana deployments to apply changes"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"backup.sh":"#!/bin/bash\nset -e\n\nBACKUP_DIR=\"/backups\"\nTIMESTAMP=$(date +%Y%m%d_%H%M%S)\n\necho \"Starting backup at $(date)\"\n\n# Create backup directory\nmkdir -p \"$BACKUP_DIR/prometheus/$TIMESTAMP\"\nmkdir -p \"$BACKUP_DIR/grafana/$TIMESTAMP\"\nmkdir -p \"$BACKUP_DIR/configs/$TIMESTAMP\"\n\n# Backup Prometheus data\necho \"Backing up Prometheus data...\"\nif [ -d \"/prometheus-data\" ]; then\n  tar -czf \"$BACKUP_DIR/prometheus/$TIMESTAMP/prometheus-data.tar.gz\" -C /prometheus-data .\n  echo \"Prometheus data backed up successfully\"\nfi\n\n# Backup Grafana data\necho \"Backing up Grafana data...\"\nif [ -d \"/grafana-data\" ]; then\n  tar -czf \"$BACKUP_DIR/grafana/$TIMESTAMP/grafana-data.tar.gz\" -C /grafana-data .\n  echo \"Grafana data backed up successfully\"\nfi\n\n# Backup configurations\necho \"Backing up configurations...\"\nkubectl get configmap -n monitoring -o yaml \u003e \"$BACKUP_DIR/configs/$TIMESTAMP/configmaps.yaml\"\nkubectl get secret -n monitoring -o yaml \u003e \"$BACKUP_DIR/configs/$TIMESTAMP/secrets.yaml\"\nkubectl get pvc -n monitoring -o yaml \u003e \"$BACKUP_DIR/configs/$TIMESTAMP/pvcs.yaml\"\n\n# Create metadata file\ncat \u003e \"$BACKUP_DIR/configs/$TIMESTAMP/metadata.json\" \u003c\u003cEOF\n{\n  \"timestamp\": \"$TIMESTAMP\",\n  \"date\": \"$(date)\",\n  \"kubernetes_version\": \"$(kubectl version --short 2\u003e/dev/null | grep Server | awk '{print $3}')\",\n  \"namespace\": \"monitoring\"\n}\nEOF\n\n# Cleanup old backups (keep last 7 days)\necho \"Cleaning up old backups...\"\nfind \"$BACKUP_DIR/prometheus\" -type d -mtime +7 -exec rm -rf {} + 2\u003e/dev/null || true\nfind \"$BACKUP_DIR/grafana\" -type d -mtime +7 -exec rm -rf {} + 2\u003e/dev/null || true\nfind \"$BACKUP_DIR/configs\" -type d -mtime +7 -exec rm -rf {} + 2\u003e/dev/null || true\n\n# List current backups\necho \"Current backups:\"\ndu -sh \"$BACKUP_DIR\"/*/* 2\u003e/dev/null | tail -20\n\necho \"Backup completed at $(date)\"\n","restore.sh":"#!/bin/bash\nset -e\n\nBACKUP_DIR=\"/backups\"\n\nif [ -z \"$1\" ]; then\n  echo \"Usage: $0 \u003ctimestamp\u003e\"\n  echo \"Available backups:\"\n  ls -la \"$BACKUP_DIR/configs/\" | grep -E '^d' | awk '{print $9}' | grep -v '^\\.$' | grep -v '^\\.\\.$'\n  exit 1\nfi\n\nTIMESTAMP=\"$1\"\n\necho \"Starting restore from backup $TIMESTAMP at $(date)\"\n\n# Verify backup exists\nif [ ! -d \"$BACKUP_DIR/configs/$TIMESTAMP\" ]; then\n  echo \"Backup $TIMESTAMP not found!\"\n  exit 1\nfi\n\n# Show backup metadata\nif [ -f \"$BACKUP_DIR/configs/$TIMESTAMP/metadata.json\" ]; then\n  echo \"Backup metadata:\"\n  cat \"$BACKUP_DIR/configs/$TIMESTAMP/metadata.json\"\nfi\n\nread -p \"Are you sure you want to restore from this backup? (yes/no) \" -n 3 -r\necho\nif [[ ! $REPLY =~ ^yes$ ]]; then\n  echo \"Restore cancelled\"\n  exit 1\nfi\n\n# Restore Prometheus data\nif [ -f \"$BACKUP_DIR/prometheus/$TIMESTAMP/prometheus-data.tar.gz\" ]; then\n  echo \"Restoring Prometheus data...\"\n  rm -rf /prometheus-data/*\n  tar -xzf \"$BACKUP_DIR/prometheus/$TIMESTAMP/prometheus-data.tar.gz\" -C /prometheus-data/\n  echo \"Prometheus data restored\"\nfi\n\n# Restore Grafana data\nif [ -f \"$BACKUP_DIR/grafana/$TIMESTAMP/grafana-data.tar.gz\" ]; then\n  echo \"Restoring Grafana data...\"\n  rm -rf /grafana-data/*\n  tar -xzf \"$BACKUP_DIR/grafana/$TIMESTAMP/grafana-data.tar.gz\" -C /grafana-data/\n  echo \"Grafana data restored\"\nfi\n\necho \"Restore completed at $(date)\"\necho \"Please restart Prometheus and Grafana deployments to apply changes\"\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"backup-scripts","namespace":"monitoring"}}
    creationTimestamp: "2025-05-28T00:25:41Z"
    name: backup-scripts
    namespace: monitoring
    resourceVersion: "6820"
    uid: d1b22c12-80f8-4c13-920c-6b362407ad52
- apiVersion: v1
  data:
    claude-code-alerts.yaml: "groups:\n- name: claude_code_alerts\n  interval: 30s\n
      \ rules:\n  # Process Health Alerts\n  # Removed ClaudeCodeHighCPU - false positive
      (CPU never exceeds 3-5%)\n  # REMOVED ClaudeCodeHighMemory - Inaccurate metrics
      tracking stale PIDs\n  # With 32GB memory limits, this is no longer a concern\n
      \     \n  # Removed ClaudeCodeTooManyConnections - scaling up parallel API calls\n
      \ \n  - alert: ClaudeCodeTooManyFileHandles\n    expr: claude_code_process_handles
      > 1000\n    for: 5m\n    labels:\n      severity: warning\n      component:
      claude-code\n    annotations:\n      summary: \"Too many file handles\"\n      description:
      \"Claude Code process {{ $labels.pid }} has {{ $value }} file handles open\"\n
      \     \n  # API Usage Alerts\n  - alert: ClaudeCodeHighAPIUsage\n    expr: increase(claude_code_api_requests_total[1h])
      > 1000\n    for: 5m\n    labels:\n      severity: warning\n      component:
      claude-code\n    annotations:\n      summary: \"High API usage detected\"\n
      \     description: \"Claude Code made {{ $value }} API requests in the last
      hour\"\n      \n  - alert: ClaudeCodeHighTokenUsage\n    expr: increase(claude_code_api_tokens_used_total[1h])
      > 100000\n    for: 5m\n    labels:\n      severity: warning\n      component:
      claude-code\n    annotations:\n      summary: \"High token usage detected\"\n
      \     description: \"Claude Code used {{ $value }} tokens in the last hour\"\n
      \     \n  - alert: ClaudeCodeHighCost\n    expr: increase(claude_code_api_cost_dollars_total[24h])
      > 10\n    for: 5m\n    labels:\n      severity: warning\n      component: claude-code\n
      \   annotations:\n      summary: \"High API cost detected\"\n      description:
      \"Claude Code API costs reached ${{ $value }} in the last 24 hours\"\n      \n
      \ - alert: ClaudeCodeAPIErrors\n    expr: rate(claude_code_api_requests_total{status!=\"200\"}[5m])
      > 0.1\n    for: 5m\n    labels:\n      severity: warning\n      component: claude-code\n
      \   annotations:\n      summary: \"Claude Code API errors\"\n      description:
      \"Claude Code API is experiencing {{ $value }} errors per second\"\n      \n
      \ # Process Stability Alerts\n  - alert: ClaudeCodeProcessRestarted\n    expr:
      changes(claude_code_process_start_time[10m]) > 0\n    for: 1m\n    labels:\n
      \     severity: info\n      component: claude-code\n    annotations:\n      summary:
      \"Claude Code process restarted\"\n      description: \"Claude Code process
      {{ $labels.pid }} ({{ $labels.cmd }}) was restarted\"\n      \n  # REMOVED:
      ClaudeCodeNoProcesses - Claude Code runs on-demand, not as a persistent service\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"claude-code-alerts.yaml":"groups:\n- name: claude_code_alerts\n  interval: 30s\n  rules:\n  # Process Health Alerts\n  # Removed ClaudeCodeHighCPU - false positive (CPU never exceeds 3-5%)\n  # REMOVED ClaudeCodeHighMemory - Inaccurate metrics tracking stale PIDs\n  # With 32GB memory limits, this is no longer a concern\n      \n  # Removed ClaudeCodeTooManyConnections - scaling up parallel API calls\n  \n  - alert: ClaudeCodeTooManyFileHandles\n    expr: claude_code_process_handles \u003e 1000\n    for: 5m\n    labels:\n      severity: warning\n      component: claude-code\n    annotations:\n      summary: \"Too many file handles\"\n      description: \"Claude Code process {{ $labels.pid }} has {{ $value }} file handles open\"\n      \n  # API Usage Alerts\n  - alert: ClaudeCodeHighAPIUsage\n    expr: increase(claude_code_api_requests_total[1h]) \u003e 1000\n    for: 5m\n    labels:\n      severity: warning\n      component: claude-code\n    annotations:\n      summary: \"High API usage detected\"\n      description: \"Claude Code made {{ $value }} API requests in the last hour\"\n      \n  - alert: ClaudeCodeHighTokenUsage\n    expr: increase(claude_code_api_tokens_used_total[1h]) \u003e 100000\n    for: 5m\n    labels:\n      severity: warning\n      component: claude-code\n    annotations:\n      summary: \"High token usage detected\"\n      description: \"Claude Code used {{ $value }} tokens in the last hour\"\n      \n  - alert: ClaudeCodeHighCost\n    expr: increase(claude_code_api_cost_dollars_total[24h]) \u003e 10\n    for: 5m\n    labels:\n      severity: warning\n      component: claude-code\n    annotations:\n      summary: \"High API cost detected\"\n      description: \"Claude Code API costs reached ${{ $value }} in the last 24 hours\"\n      \n  - alert: ClaudeCodeAPIErrors\n    expr: rate(claude_code_api_requests_total{status!=\"200\"}[5m]) \u003e 0.1\n    for: 5m\n    labels:\n      severity: warning\n      component: claude-code\n    annotations:\n      summary: \"Claude Code API errors\"\n      description: \"Claude Code API is experiencing {{ $value }} errors per second\"\n      \n  # Process Stability Alerts\n  - alert: ClaudeCodeProcessRestarted\n    expr: changes(claude_code_process_start_time[10m]) \u003e 0\n    for: 1m\n    labels:\n      severity: info\n      component: claude-code\n    annotations:\n      summary: \"Claude Code process restarted\"\n      description: \"Claude Code process {{ $labels.pid }} ({{ $labels.cmd }}) was restarted\"\n      \n  # REMOVED: ClaudeCodeNoProcesses - Claude Code runs on-demand, not as a persistent service\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"claude-code-alert-rules","namespace":"monitoring"}}
    creationTimestamp: "2025-05-28T15:25:41Z"
    name: claude-code-alert-rules
    namespace: monitoring
    resourceVersion: "5142859"
    uid: 0decf957-1815-4016-9627-22136480f177
- apiVersion: v1
  data:
    claude-code-dashboard.json: |
      {
        "id": null,
        "uid": "claude-code-monitoring",
        "title": "Claude Code API Monitoring",
        "tags": ["claude", "api", "processes"],
        "style": "dark",
        "timezone": "browser",
        "refresh": "30s",
        "schemaVersion": 27,
        "version": 2,
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "panels": [
          {
            "id": 1,
            "title": "Claude Sessions Overview",
            "type": "stat",
            "targets": [
              {
                "expr": "claude_code_session_count",
                "legendFormat": "Active Sessions",
                "refId": "A"
              },
              {
                "expr": "claude_code_process_count{type=\"total\"}",
                "legendFormat": "Total Processes",
                "refId": "B"
              },
              {
                "expr": "claude_code_total_connections",
                "legendFormat": "Network Connections",
                "refId": "C"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "color": {"mode": "thresholds"},
                "thresholds": {
                  "steps": [
                    {"color": "green", "value": null},
                    {"color": "yellow", "value": 10},
                    {"color": "red", "value": 50}
                  ]
                },
                "unit": "short"
              }
            },
            "gridPos": {"h": 4, "w": 8, "x": 0, "y": 0}
          },
          {
            "id": 2,
            "title": "Resource Usage",
            "type": "stat",
            "targets": [
              {
                "expr": "claude_code_total_cpu_percent",
                "legendFormat": "Total CPU %",
                "refId": "A"
              },
              {
                "expr": "claude_code_total_memory_mb{type=\"rss\"}",
                "legendFormat": "Total Memory MB",
                "refId": "B"
              },
              {
                "expr": "sum(claude_code_process_handles)",
                "legendFormat": "Total File Handles",
                "refId": "C"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "color": {"mode": "thresholds"},
                "thresholds": {
                  "steps": [
                    {"color": "green", "value": null},
                    {"color": "yellow", "value": 50},
                    {"color": "red", "value": 80}
                  ]
                }
              },
              "overrides": [
                {
                  "matcher": {"id": "byName", "options": "Total CPU %"},
                  "properties": [{"id": "unit", "value": "percent"}]
                },
                {
                  "matcher": {"id": "byName", "options": "Total Memory MB"},
                  "properties": [{"id": "unit", "value": "decmbytes"}]
                }
              ]
            },
            "gridPos": {"h": 4, "w": 8, "x": 8, "y": 0}
          },
          {
            "id": 3,
            "title": "Process Breakdown",
            "type": "stat",
            "targets": [
              {
                "expr": "claude_code_process_count{type=\"parent\"}",
                "legendFormat": "Parent Processes",
                "refId": "A"
              },
              {
                "expr": "claude_code_process_count{type=\"child\"}",
                "legendFormat": "Child Processes",
                "refId": "B"
              },
              {
                "expr": "sum(claude_code_process_threads)",
                "legendFormat": "Total Threads",
                "refId": "C"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "color": {"mode": "thresholds"},
                "thresholds": {
                  "steps": [
                    {"color": "green", "value": null},
                    {"color": "yellow", "value": 10},
                    {"color": "red", "value": 50}
                  ]
                },
                "unit": "short"
              }
            },
            "gridPos": {"h": 4, "w": 8, "x": 16, "y": 0}
          },
          {
            "id": 4,
            "title": "Memory Usage by Process",
            "type": "timeseries",
            "targets": [
              {
                "expr": "claude_code_process_memory_mb{type=\"rss\",role=\"parent\"}",
                "legendFormat": "{{role}} - {{cmd}} (PID {{pid}})",
                "refId": "A"
              },
              {
                "expr": "claude_code_process_memory_mb{type=\"rss\",role=\"child\"}",
                "legendFormat": "{{role}} - {{cmd}} (PID {{pid}})",
                "refId": "B"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "color": {"mode": "palette-classic"},
                "custom": {
                  "drawStyle": "line",
                  "lineInterpolation": "linear",
                  "lineWidth": 2,
                  "fillOpacity": 10,
                  "stacking": {
                    "mode": "normal",
                    "group": "A"
                  }
                },
                "unit": "decmbytes"
              }
            },
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 4}
          },
          {
            "id": 5,
            "title": "CPU Usage by Process",
            "type": "timeseries",
            "targets": [
              {
                "expr": "claude_code_process_cpu_percent",
                "legendFormat": "{{role}} - {{cmd}} (PID {{pid}})",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "color": {"mode": "palette-classic"},
                "custom": {
                  "drawStyle": "line",
                  "lineInterpolation": "linear",
                  "lineWidth": 2,
                  "fillOpacity": 10
                },
                "unit": "percent"
              }
            },
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 4}
          },
          {
            "id": 6,
            "title": "Process Tree Details",
            "type": "table",
            "targets": [
              {
                "expr": "claude_code_process_cpu_percent",
                "format": "table",
                "instant": true,
                "refId": "A"
              },
              {
                "expr": "claude_code_process_memory_mb{type=\"rss\"}",
                "format": "table",
                "instant": true,
                "refId": "B"
              },
              {
                "expr": "claude_code_process_threads",
                "format": "table",
                "instant": true,
                "refId": "C"
              },
              {
                "expr": "claude_code_process_handles",
                "format": "table",
                "instant": true,
                "refId": "D"
              },
              {
                "expr": "sum by (pid, ppid, cmd, role) (claude_code_process_connections)",
                "format": "table",
                "instant": true,
                "refId": "E"
              }
            ],
            "transformations": [
              {
                "id": "merge",
                "options": {}
              },
              {
                "id": "groupBy",
                "options": {
                  "fields": {
                    "pid": {
                      "aggregations": [],
                      "operation": "groupby"
                    },
                    "ppid": {
                      "aggregations": [],
                      "operation": "groupby"
                    },
                    "cmd": {
                      "aggregations": [],
                      "operation": "groupby"
                    },
                    "role": {
                      "aggregations": [],
                      "operation": "groupby"
                    },
                    "Value #A": {
                      "aggregations": ["lastNotNull"],
                      "operation": "aggregate"
                    },
                    "Value #B": {
                      "aggregations": ["lastNotNull"],
                      "operation": "aggregate"
                    },
                    "Value #C": {
                      "aggregations": ["lastNotNull"],
                      "operation": "aggregate"
                    },
                    "Value #D": {
                      "aggregations": ["lastNotNull"],
                      "operation": "aggregate"
                    },
                    "Value #E": {
                      "aggregations": ["lastNotNull"],
                      "operation": "aggregate"
                    }
                  }
                }
              },
              {
                "id": "organize",
                "options": {
                  "excludeByName": {
                    "Time": true,
                    "__name__": true,
                    "job": true,
                    "instance": true,
                    "type": true,
                    "state": true
                  },
                  "renameByName": {
                    "Value #A (lastNotNull)": "CPU %",
                    "Value #B (lastNotNull)": "Memory MB",
                    "Value #C (lastNotNull)": "Threads",
                    "Value #D (lastNotNull)": "File Handles",
                    "Value #E (lastNotNull)": "Connections",
                    "pid": "PID",
                    "ppid": "Parent PID",
                    "cmd": "Command",
                    "role": "Role"
                  },
                  "indexByName": {
                    "role": 0,
                    "pid": 1,
                    "ppid": 2,
                    "cmd": 3,
                    "Value #A (lastNotNull)": 4,
                    "Value #B (lastNotNull)": 5,
                    "Value #C (lastNotNull)": 6,
                    "Value #D (lastNotNull)": 7,
                    "Value #E (lastNotNull)": 8
                  }
                }
              },
              {
                "id": "sortBy",
                "options": {
                  "fields": {},
                  "sort": [
                    {
                      "field": "Parent PID"
                    }
                  ]
                }
              }
            ],
            "fieldConfig": {
              "defaults": {
                "custom": {
                  "displayMode": "color-background-solid",
                  "filterable": true,
                  "align": "left"
                }
              },
              "overrides": [
                {
                  "matcher": {"id": "byName", "options": "Role"},
                  "properties": [
                    {
                      "id": "custom.width",
                      "value": 80
                    }
                  ]
                },
                {
                  "matcher": {"id": "byName", "options": "CPU %"},
                  "properties": [
                    {"id": "unit", "value": "percent"},
                    {"id": "decimals", "value": 1},
                    {"id": "custom.displayMode", "value": "color-background"},
                    {"id": "custom.width", "value": 80}
                  ]
                },
                {
                  "matcher": {"id": "byName", "options": "Memory MB"},
                  "properties": [
                    {"id": "unit", "value": "decmbytes"},
                    {"id": "decimals", "value": 1},
                    {"id": "custom.width", "value": 100}
                  ]
                },
                {
                  "matcher": {"id": "byName", "options": "PID"},
                  "properties": [
                    {"id": "custom.width", "value": 60}
                  ]
                },
                {
                  "matcher": {"id": "byName", "options": "Parent PID"},
                  "properties": [
                    {"id": "custom.width", "value": 90}
                  ]
                },
                {
                  "matcher": {"id": "byName", "options": "Threads"},
                  "properties": [
                    {"id": "custom.width", "value": 70}
                  ]
                },
                {
                  "matcher": {"id": "byName", "options": "File Handles"},
                  "properties": [
                    {"id": "custom.width", "value": 100}
                  ]
                },
                {
                  "matcher": {"id": "byName", "options": "Connections"},
                  "properties": [
                    {"id": "custom.width", "value": 100}
                  ]
                }
              ]
            },
            "gridPos": {"h": 10, "w": 24, "x": 0, "y": 12}
          },
          {
            "id": 7,
            "title": "Network Connections by State",
            "type": "piechart",
            "targets": [
              {
                "expr": "sum by (state) (claude_code_process_connections)",
                "legendFormat": "{{state}}",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "color": {"mode": "palette-classic"},
                "unit": "short"
              }
            },
            "gridPos": {"h": 6, "w": 8, "x": 0, "y": 22}
          },
          {
            "id": 8,
            "title": "Memory Distribution",
            "type": "piechart",
            "targets": [
              {
                "expr": "sum by (role) (claude_code_process_memory_mb{type=\"rss\"})",
                "legendFormat": "{{role}}",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "color": {"mode": "palette-classic"},
                "unit": "decmbytes"
              }
            },
            "options": {
              "pieType": "donut",
              "displayLabels": ["name", "percent", "value"],
              "legendDisplayMode": "table",
              "legendValues": ["value", "percent"]
            },
            "gridPos": {"h": 6, "w": 8, "x": 8, "y": 22}
          },
          {
            "id": 9,
            "title": "Process Lifetime",
            "type": "table",
            "targets": [
              {
                "expr": "(time() - claude_code_process_start_time) / 3600",
                "format": "table",
                "instant": true,
                "refId": "A"
              }
            ],
            "transformations": [
              {
                "id": "organize",
                "options": {
                  "excludeByName": {
                    "Time": true,
                    "__name__": true,
                    "job": true,
                    "instance": true
                  },
                  "renameByName": {
                    "Value": "Uptime (hours)",
                    "pid": "PID",
                    "ppid": "Parent PID",
                    "cmd": "Command",
                    "role": "Role"
                  }
                }
              },
              {
                "id": "sortBy",
                "options": {
                  "fields": {},
                  "sort": [
                    {
                      "field": "Uptime (hours)",
                      "desc": true
                    }
                  ]
                }
              }
            ],
            "fieldConfig": {
              "defaults": {
                "decimals": 2,
                "custom": {
                  "align": "left"
                }
              }
            },
            "gridPos": {"h": 6, "w": 8, "x": 16, "y": 22}
          },
          {
            "id": 10,
            "title": "Resource Usage Over Time",
            "type": "timeseries",
            "targets": [
              {
                "expr": "claude_code_total_memory_mb{type=\"rss\"}",
                "legendFormat": "Total Memory (RSS)",
                "refId": "A"
              },
              {
                "expr": "sum(claude_code_process_handles)",
                "legendFormat": "Total File Handles",
                "refId": "B"
              },
              {
                "expr": "claude_code_total_connections",
                "legendFormat": "Total Connections",
                "refId": "C"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "color": {"mode": "palette-classic"},
                "custom": {
                  "drawStyle": "line",
                  "lineInterpolation": "linear",
                  "lineWidth": 2,
                  "fillOpacity": 10,
                  "axisPlacement": "auto",
                  "scaleDistribution": {
                    "type": "linear"
                  }
                }
              },
              "overrides": [
                {
                  "matcher": {"id": "byName", "options": "Total Memory (RSS)"},
                  "properties": [
                    {"id": "unit", "value": "decmbytes"},
                    {"id": "custom.axisPlacement", "value": "left"}
                  ]
                },
                {
                  "matcher": {"id": "byRegexp", "options": ".*Handles|.*Connections"},
                  "properties": [
                    {"id": "unit", "value": "short"},
                    {"id": "custom.axisPlacement", "value": "right"}
                  ]
                }
              ]
            },
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 28}
          }
        ]
      }
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"claude-code-dashboard.json":"{\n  \"id\": null,\n  \"uid\": \"claude-code-monitoring\",\n  \"title\": \"Claude Code API Monitoring\",\n  \"tags\": [\"claude\", \"api\", \"processes\"],\n  \"style\": \"dark\",\n  \"timezone\": \"browser\",\n  \"refresh\": \"30s\",\n  \"schemaVersion\": 27,\n  \"version\": 2,\n  \"time\": {\n    \"from\": \"now-1h\",\n    \"to\": \"now\"\n  },\n  \"panels\": [\n    {\n      \"id\": 1,\n      \"title\": \"Claude Sessions Overview\",\n      \"type\": \"stat\",\n      \"targets\": [\n        {\n          \"expr\": \"claude_code_session_count\",\n          \"legendFormat\": \"Active Sessions\",\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"claude_code_process_count{type=\\\"total\\\"}\",\n          \"legendFormat\": \"Total Processes\",\n          \"refId\": \"B\"\n        },\n        {\n          \"expr\": \"claude_code_total_connections\",\n          \"legendFormat\": \"Network Connections\",\n          \"refId\": \"C\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\"mode\": \"thresholds\"},\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 10},\n              {\"color\": \"red\", \"value\": 50}\n            ]\n          },\n          \"unit\": \"short\"\n        }\n      },\n      \"gridPos\": {\"h\": 4, \"w\": 8, \"x\": 0, \"y\": 0}\n    },\n    {\n      \"id\": 2,\n      \"title\": \"Resource Usage\",\n      \"type\": \"stat\",\n      \"targets\": [\n        {\n          \"expr\": \"claude_code_total_cpu_percent\",\n          \"legendFormat\": \"Total CPU %\",\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"claude_code_total_memory_mb{type=\\\"rss\\\"}\",\n          \"legendFormat\": \"Total Memory MB\",\n          \"refId\": \"B\"\n        },\n        {\n          \"expr\": \"sum(claude_code_process_handles)\",\n          \"legendFormat\": \"Total File Handles\",\n          \"refId\": \"C\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\"mode\": \"thresholds\"},\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 50},\n              {\"color\": \"red\", \"value\": 80}\n            ]\n          }\n        },\n        \"overrides\": [\n          {\n            \"matcher\": {\"id\": \"byName\", \"options\": \"Total CPU %\"},\n            \"properties\": [{\"id\": \"unit\", \"value\": \"percent\"}]\n          },\n          {\n            \"matcher\": {\"id\": \"byName\", \"options\": \"Total Memory MB\"},\n            \"properties\": [{\"id\": \"unit\", \"value\": \"decmbytes\"}]\n          }\n        ]\n      },\n      \"gridPos\": {\"h\": 4, \"w\": 8, \"x\": 8, \"y\": 0}\n    },\n    {\n      \"id\": 3,\n      \"title\": \"Process Breakdown\",\n      \"type\": \"stat\",\n      \"targets\": [\n        {\n          \"expr\": \"claude_code_process_count{type=\\\"parent\\\"}\",\n          \"legendFormat\": \"Parent Processes\",\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"claude_code_process_count{type=\\\"child\\\"}\",\n          \"legendFormat\": \"Child Processes\",\n          \"refId\": \"B\"\n        },\n        {\n          \"expr\": \"sum(claude_code_process_threads)\",\n          \"legendFormat\": \"Total Threads\",\n          \"refId\": \"C\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\"mode\": \"thresholds\"},\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 10},\n              {\"color\": \"red\", \"value\": 50}\n            ]\n          },\n          \"unit\": \"short\"\n        }\n      },\n      \"gridPos\": {\"h\": 4, \"w\": 8, \"x\": 16, \"y\": 0}\n    },\n    {\n      \"id\": 4,\n      \"title\": \"Memory Usage by Process\",\n      \"type\": \"timeseries\",\n      \"targets\": [\n        {\n          \"expr\": \"claude_code_process_memory_mb{type=\\\"rss\\\",role=\\\"parent\\\"}\",\n          \"legendFormat\": \"{{role}} - {{cmd}} (PID {{pid}})\",\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"claude_code_process_memory_mb{type=\\\"rss\\\",role=\\\"child\\\"}\",\n          \"legendFormat\": \"{{role}} - {{cmd}} (PID {{pid}})\",\n          \"refId\": \"B\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"drawStyle\": \"line\",\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 10,\n            \"stacking\": {\n              \"mode\": \"normal\",\n              \"group\": \"A\"\n            }\n          },\n          \"unit\": \"decmbytes\"\n        }\n      },\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 4}\n    },\n    {\n      \"id\": 5,\n      \"title\": \"CPU Usage by Process\",\n      \"type\": \"timeseries\",\n      \"targets\": [\n        {\n          \"expr\": \"claude_code_process_cpu_percent\",\n          \"legendFormat\": \"{{role}} - {{cmd}} (PID {{pid}})\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"drawStyle\": \"line\",\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 10\n          },\n          \"unit\": \"percent\"\n        }\n      },\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 4}\n    },\n    {\n      \"id\": 6,\n      \"title\": \"Process Tree Details\",\n      \"type\": \"table\",\n      \"targets\": [\n        {\n          \"expr\": \"claude_code_process_cpu_percent\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"claude_code_process_memory_mb{type=\\\"rss\\\"}\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"B\"\n        },\n        {\n          \"expr\": \"claude_code_process_threads\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"C\"\n        },\n        {\n          \"expr\": \"claude_code_process_handles\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"D\"\n        },\n        {\n          \"expr\": \"sum by (pid, ppid, cmd, role) (claude_code_process_connections)\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"E\"\n        }\n      ],\n      \"transformations\": [\n        {\n          \"id\": \"merge\",\n          \"options\": {}\n        },\n        {\n          \"id\": \"groupBy\",\n          \"options\": {\n            \"fields\": {\n              \"pid\": {\n                \"aggregations\": [],\n                \"operation\": \"groupby\"\n              },\n              \"ppid\": {\n                \"aggregations\": [],\n                \"operation\": \"groupby\"\n              },\n              \"cmd\": {\n                \"aggregations\": [],\n                \"operation\": \"groupby\"\n              },\n              \"role\": {\n                \"aggregations\": [],\n                \"operation\": \"groupby\"\n              },\n              \"Value #A\": {\n                \"aggregations\": [\"lastNotNull\"],\n                \"operation\": \"aggregate\"\n              },\n              \"Value #B\": {\n                \"aggregations\": [\"lastNotNull\"],\n                \"operation\": \"aggregate\"\n              },\n              \"Value #C\": {\n                \"aggregations\": [\"lastNotNull\"],\n                \"operation\": \"aggregate\"\n              },\n              \"Value #D\": {\n                \"aggregations\": [\"lastNotNull\"],\n                \"operation\": \"aggregate\"\n              },\n              \"Value #E\": {\n                \"aggregations\": [\"lastNotNull\"],\n                \"operation\": \"aggregate\"\n              }\n            }\n          }\n        },\n        {\n          \"id\": \"organize\",\n          \"options\": {\n            \"excludeByName\": {\n              \"Time\": true,\n              \"__name__\": true,\n              \"job\": true,\n              \"instance\": true,\n              \"type\": true,\n              \"state\": true\n            },\n            \"renameByName\": {\n              \"Value #A (lastNotNull)\": \"CPU %\",\n              \"Value #B (lastNotNull)\": \"Memory MB\",\n              \"Value #C (lastNotNull)\": \"Threads\",\n              \"Value #D (lastNotNull)\": \"File Handles\",\n              \"Value #E (lastNotNull)\": \"Connections\",\n              \"pid\": \"PID\",\n              \"ppid\": \"Parent PID\",\n              \"cmd\": \"Command\",\n              \"role\": \"Role\"\n            },\n            \"indexByName\": {\n              \"role\": 0,\n              \"pid\": 1,\n              \"ppid\": 2,\n              \"cmd\": 3,\n              \"Value #A (lastNotNull)\": 4,\n              \"Value #B (lastNotNull)\": 5,\n              \"Value #C (lastNotNull)\": 6,\n              \"Value #D (lastNotNull)\": 7,\n              \"Value #E (lastNotNull)\": 8\n            }\n          }\n        },\n        {\n          \"id\": \"sortBy\",\n          \"options\": {\n            \"fields\": {},\n            \"sort\": [\n              {\n                \"field\": \"Parent PID\"\n              }\n            ]\n          }\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"custom\": {\n            \"displayMode\": \"color-background-solid\",\n            \"filterable\": true,\n            \"align\": \"left\"\n          }\n        },\n        \"overrides\": [\n          {\n            \"matcher\": {\"id\": \"byName\", \"options\": \"Role\"},\n            \"properties\": [\n              {\n                \"id\": \"custom.width\",\n                \"value\": 80\n              }\n            ]\n          },\n          {\n            \"matcher\": {\"id\": \"byName\", \"options\": \"CPU %\"},\n            \"properties\": [\n              {\"id\": \"unit\", \"value\": \"percent\"},\n              {\"id\": \"decimals\", \"value\": 1},\n              {\"id\": \"custom.displayMode\", \"value\": \"color-background\"},\n              {\"id\": \"custom.width\", \"value\": 80}\n            ]\n          },\n          {\n            \"matcher\": {\"id\": \"byName\", \"options\": \"Memory MB\"},\n            \"properties\": [\n              {\"id\": \"unit\", \"value\": \"decmbytes\"},\n              {\"id\": \"decimals\", \"value\": 1},\n              {\"id\": \"custom.width\", \"value\": 100}\n            ]\n          },\n          {\n            \"matcher\": {\"id\": \"byName\", \"options\": \"PID\"},\n            \"properties\": [\n              {\"id\": \"custom.width\", \"value\": 60}\n            ]\n          },\n          {\n            \"matcher\": {\"id\": \"byName\", \"options\": \"Parent PID\"},\n            \"properties\": [\n              {\"id\": \"custom.width\", \"value\": 90}\n            ]\n          },\n          {\n            \"matcher\": {\"id\": \"byName\", \"options\": \"Threads\"},\n            \"properties\": [\n              {\"id\": \"custom.width\", \"value\": 70}\n            ]\n          },\n          {\n            \"matcher\": {\"id\": \"byName\", \"options\": \"File Handles\"},\n            \"properties\": [\n              {\"id\": \"custom.width\", \"value\": 100}\n            ]\n          },\n          {\n            \"matcher\": {\"id\": \"byName\", \"options\": \"Connections\"},\n            \"properties\": [\n              {\"id\": \"custom.width\", \"value\": 100}\n            ]\n          }\n        ]\n      },\n      \"gridPos\": {\"h\": 10, \"w\": 24, \"x\": 0, \"y\": 12}\n    },\n    {\n      \"id\": 7,\n      \"title\": \"Network Connections by State\",\n      \"type\": \"piechart\",\n      \"targets\": [\n        {\n          \"expr\": \"sum by (state) (claude_code_process_connections)\",\n          \"legendFormat\": \"{{state}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"unit\": \"short\"\n        }\n      },\n      \"gridPos\": {\"h\": 6, \"w\": 8, \"x\": 0, \"y\": 22}\n    },\n    {\n      \"id\": 8,\n      \"title\": \"Memory Distribution\",\n      \"type\": \"piechart\",\n      \"targets\": [\n        {\n          \"expr\": \"sum by (role) (claude_code_process_memory_mb{type=\\\"rss\\\"})\",\n          \"legendFormat\": \"{{role}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"unit\": \"decmbytes\"\n        }\n      },\n      \"options\": {\n        \"pieType\": \"donut\",\n        \"displayLabels\": [\"name\", \"percent\", \"value\"],\n        \"legendDisplayMode\": \"table\",\n        \"legendValues\": [\"value\", \"percent\"]\n      },\n      \"gridPos\": {\"h\": 6, \"w\": 8, \"x\": 8, \"y\": 22}\n    },\n    {\n      \"id\": 9,\n      \"title\": \"Process Lifetime\",\n      \"type\": \"table\",\n      \"targets\": [\n        {\n          \"expr\": \"(time() - claude_code_process_start_time) / 3600\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"transformations\": [\n        {\n          \"id\": \"organize\",\n          \"options\": {\n            \"excludeByName\": {\n              \"Time\": true,\n              \"__name__\": true,\n              \"job\": true,\n              \"instance\": true\n            },\n            \"renameByName\": {\n              \"Value\": \"Uptime (hours)\",\n              \"pid\": \"PID\",\n              \"ppid\": \"Parent PID\",\n              \"cmd\": \"Command\",\n              \"role\": \"Role\"\n            }\n          }\n        },\n        {\n          \"id\": \"sortBy\",\n          \"options\": {\n            \"fields\": {},\n            \"sort\": [\n              {\n                \"field\": \"Uptime (hours)\",\n                \"desc\": true\n              }\n            ]\n          }\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"decimals\": 2,\n          \"custom\": {\n            \"align\": \"left\"\n          }\n        }\n      },\n      \"gridPos\": {\"h\": 6, \"w\": 8, \"x\": 16, \"y\": 22}\n    },\n    {\n      \"id\": 10,\n      \"title\": \"Resource Usage Over Time\",\n      \"type\": \"timeseries\",\n      \"targets\": [\n        {\n          \"expr\": \"claude_code_total_memory_mb{type=\\\"rss\\\"}\",\n          \"legendFormat\": \"Total Memory (RSS)\",\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"sum(claude_code_process_handles)\",\n          \"legendFormat\": \"Total File Handles\",\n          \"refId\": \"B\"\n        },\n        {\n          \"expr\": \"claude_code_total_connections\",\n          \"legendFormat\": \"Total Connections\",\n          \"refId\": \"C\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"drawStyle\": \"line\",\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 10,\n            \"axisPlacement\": \"auto\",\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            }\n          }\n        },\n        \"overrides\": [\n          {\n            \"matcher\": {\"id\": \"byName\", \"options\": \"Total Memory (RSS)\"},\n            \"properties\": [\n              {\"id\": \"unit\", \"value\": \"decmbytes\"},\n              {\"id\": \"custom.axisPlacement\", \"value\": \"left\"}\n            ]\n          },\n          {\n            \"matcher\": {\"id\": \"byRegexp\", \"options\": \".*Handles|.*Connections\"},\n            \"properties\": [\n              {\"id\": \"unit\", \"value\": \"short\"},\n              {\"id\": \"custom.axisPlacement\", \"value\": \"right\"}\n            ]\n          }\n        ]\n      },\n      \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 28}\n    }\n  ]\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"grafana_dashboard":"1"},"name":"claude-code-dashboard","namespace":"monitoring"}}
    creationTimestamp: "2025-05-28T15:25:33Z"
    labels:
      grafana_dashboard: "1"
    name: claude-code-dashboard
    namespace: monitoring
    resourceVersion: "76273"
    uid: eac124a0-4984-4c6b-beab-a150b7a7ab50
- apiVersion: v1
  data:
    claude-code-exporter.py: "#!/usr/bin/env python3\nimport os\nimport time\nimport
      psutil\nimport socket\nimport subprocess\nimport json\nimport re\nfrom datetime
      import datetime\nfrom collections import defaultdict\nfrom prometheus_client
      import start_http_server, Gauge, Counter, Histogram, Info\n\n# Process metrics\nclaude_process_count
      = Gauge('claude_code_process_count', 'Number of Claude Code processes')\nclaude_process_cpu_percent
      = Gauge('claude_code_process_cpu_percent', 'CPU usage percentage', ['pid', 'cmd'])\nclaude_process_memory_mb
      = Gauge('claude_code_process_memory_mb', 'Memory usage in MB', ['pid', 'cmd',
      'type'])\nclaude_process_threads = Gauge('claude_code_process_threads', 'Number
      of threads', ['pid', 'cmd'])\nclaude_process_handles = Gauge('claude_code_process_handles',
      'Number of file handles', ['pid', 'cmd'])\nclaude_process_connections = Gauge('claude_code_process_connections',
      'Number of network connections', ['pid', 'cmd', 'state'])\nclaude_process_open_files
      = Gauge('claude_code_process_open_files', 'Number of open files', ['pid', 'cmd'])\nclaude_process_start_time
      = Gauge('claude_code_process_start_time', 'Process start time (unix timestamp)',
      ['pid', 'cmd'])\n\n# Port metrics\nclaude_open_ports = Gauge('claude_code_open_ports',
      'Open ports by Claude processes', ['pid', 'port', 'type'])\n\n# API metrics
      (these would need to be parsed from logs or config)\nclaude_api_requests_total
      = Counter('claude_code_api_requests_total', 'Total API requests', ['endpoint',
      'status'])\nclaude_api_tokens_used = Counter('claude_code_api_tokens_used_total',
      'Total tokens used', ['model', 'type'])\nclaude_api_cost_dollars = Counter('claude_code_api_cost_dollars_total',
      'Total API cost in dollars', ['model'])\nclaude_api_response_time = Histogram('claude_code_api_response_time_seconds',
      'API response time', ['endpoint'])\n\n# System-wide metrics\nclaude_total_cpu_percent
      = Gauge('claude_code_total_cpu_percent', 'Total CPU usage by all Claude processes')\nclaude_total_memory_mb
      = Gauge('claude_code_total_memory_mb', 'Total memory usage by all Claude processes')\nclaude_total_connections
      = Gauge('claude_code_total_connections', 'Total network connections')\n\n# Info
      metrics\nclaude_exporter_info = Info('claude_code_exporter_info', 'Claude Code
      exporter information')\n\ndef get_claude_processes():\n    \"\"\"Find all Claude
      Code related processes\"\"\"\n    claude_processes = []\n    \n    # Exclude
      patterns for monitoring/infrastructure processes\n    exclude_patterns = [\n
      \       'claude-code-exporter',\n        'claude-token-collector',\n        'claude-process-exporter',\n
      \       'process-watchdog',\n        'kubectl',\n        'prometheus',\n        'grafana',\n
      \       '/scripts/'  # Exclude scripts in monitoring containers\n    ]\n    \n
      \   for proc in psutil.process_iter(['pid', 'name', 'cmdline', 'create_time']):\n
      \       try:\n            cmdline = ' '.join(proc.info['cmdline'] or [])\n            name
      = proc.info['name']\n            \n            # Skip if it's an excluded monitoring
      process\n            if any(exclude in cmdline.lower() for exclude in exclude_patterns):\n
      \               continue\n            \n            # Look for actual Claude
      CLI processes\n            # The real Claude CLI runs as: node ... /claude claude\n
      \           # or: python3 ... /claude-tts claude\n            if ('claude' in
      cmdline.lower() and \n                ('/bin/claude' in cmdline or \n                 '/claude
      claude' in cmdline or\n                 'claude-tts claude' in cmdline or\n
      \                '.npm-global/bin/claude' in cmdline)):\n                claude_processes.append(proc)\n
      \                   \n        except (psutil.NoSuchProcess, psutil.AccessDenied):\n
      \           continue\n            \n    return claude_processes\n\ndef get_process_handles(pid):\n
      \   \"\"\"Get number of file handles for a process\"\"\"\n    try:\n        #
      Linux specific\n        return len(os.listdir(f'/proc/{pid}/fd'))\n    except:\n
      \       return 0\n\ndef get_process_connections_by_state(proc):\n    \"\"\"Get
      network connections grouped by state\"\"\"\n    connections_by_state = defaultdict(int)\n
      \   try:\n        for conn in proc.connections():\n            connections_by_state[conn.status]
      += 1\n    except (psutil.NoSuchProcess, psutil.AccessDenied):\n        pass\n
      \   return connections_by_state\n\ndef get_open_ports(proc):\n    \"\"\"Get
      open ports for a process\"\"\"\n    open_ports = []\n    try:\n        for conn
      in proc.connections():\n            if conn.status == 'LISTEN':\n                open_ports.append({\n
      \                   'port': conn.laddr.port,\n                    'type': 'tcp'
      if conn.type == socket.SOCK_STREAM else 'udp'\n                })\n    except
      (psutil.NoSuchProcess, psutil.AccessDenied):\n        pass\n    return open_ports\n\ndef
      parse_api_logs():\n    \"\"\"Parse Claude API usage from logs (placeholder -
      would need actual log parsing)\"\"\"\n    # This is a placeholder - in reality,
      you'd parse actual Claude Code logs\n    # or read from a configuration file
      where API usage is tracked\n    \n    # Check common log locations\n    log_locations
      = [\n        '/var/log/claude-code.log',\n        '/home/*/.claude-code/logs/*.log',\n
      \       '/tmp/claude-*.log'\n    ]\n    \n    api_stats = {\n        'requests':
      0,\n        'tokens': 0,\n        'cost': 0.0\n    }\n    \n    # TODO: Implement
      actual log parsing logic\n    # This would parse logs for API calls, token usage,
      and calculate costs\n    \n    return api_stats\n\ndef collect_claude_metrics():\n
      \   \"\"\"Collect metrics for all Claude processes\"\"\"\n    processes = get_claude_processes()\n
      \   \n    # Update process count\n    claude_process_count.set(len(processes))\n
      \   \n    total_cpu = 0\n    total_memory = 0\n    total_connections = 0\n    \n
      \   for proc in processes:\n        try:\n            pid = proc.pid\n            cmdline
      = ' '.join(proc.cmdline()[:3])  # First 3 args for label\n            \n            #
      CPU usage\n            cpu_percent = proc.cpu_percent(interval=0.1)\n            claude_process_cpu_percent.labels(pid=pid,
      cmd=cmdline).set(cpu_percent)\n            total_cpu += cpu_percent\n            \n
      \           # Memory usage\n            mem_info = proc.memory_info()\n            mem_rss_mb
      = mem_info.rss / 1024 / 1024\n            mem_vms_mb = mem_info.vms / 1024 /
      1024\n            claude_process_memory_mb.labels(pid=pid, cmd=cmdline, type='rss').set(mem_rss_mb)\n
      \           claude_process_memory_mb.labels(pid=pid, cmd=cmdline, type='vms').set(mem_vms_mb)\n
      \           total_memory += mem_rss_mb\n            \n            # Threads\n
      \           num_threads = proc.num_threads()\n            claude_process_threads.labels(pid=pid,
      cmd=cmdline).set(num_threads)\n            \n            # File handles\n            num_handles
      = get_process_handles(pid)\n            claude_process_handles.labels(pid=pid,
      cmd=cmdline).set(num_handles)\n            \n            # Open files\n            try:\n
      \               num_files = len(proc.open_files())\n                claude_process_open_files.labels(pid=pid,
      cmd=cmdline).set(num_files)\n            except:\n                pass\n            \n
      \           # Network connections by state\n            conn_states = get_process_connections_by_state(proc)\n
      \           for state, count in conn_states.items():\n                claude_process_connections.labels(pid=pid,
      cmd=cmdline, state=state).set(count)\n                total_connections += count\n
      \           \n            # Open ports\n            open_ports = get_open_ports(proc)\n
      \           for port_info in open_ports:\n                claude_open_ports.labels(\n
      \                   pid=pid, \n                    port=port_info['port'], \n
      \                   type=port_info['type']\n                ).set(1)\n            \n
      \           # Process start time\n            claude_process_start_time.labels(pid=pid,
      cmd=cmdline).set(proc.create_time())\n            \n        except (psutil.NoSuchProcess,
      psutil.AccessDenied):\n            continue\n    \n    # Update totals\n    claude_total_cpu_percent.set(total_cpu)\n
      \   claude_total_memory_mb.set(total_memory)\n    claude_total_connections.set(total_connections)\n
      \   \n    # Collect API metrics (placeholder)\n    api_stats = parse_api_logs()\n
      \   # Update API metrics based on parsed logs\n\ndef check_claude_cli():\n    \"\"\"Check
      if Claude CLI is installed and get version\"\"\"\n    try:\n        result =
      subprocess.run(['claude', '--version'], \n                              capture_output=True,
      text=True, timeout=5)\n        if result.returncode == 0:\n            version
      = result.stdout.strip()\n            return {'installed': True, 'version': version}\n
      \   except:\n        pass\n    return {'installed': False, 'version': 'unknown'}\n\nif
      __name__ == '__main__':\n    # Start Prometheus metrics server\n    start_http_server(9403)\n
      \   \n    # Check Claude CLI\n    cli_info = check_claude_cli()\n    claude_exporter_info.info({\n
      \       'version': '1.0',\n        'cli_installed': str(cli_info['installed']),\n
      \       'cli_version': cli_info['version']\n    })\n    \n    print(f\"Claude
      Code exporter started on port 9403\")\n    print(f\"Claude CLI installed: {cli_info['installed']}\")\n
      \   \n    # Collect metrics every 10 seconds\n    while True:\n        try:\n
      \           collect_claude_metrics()\n        except Exception as e:\n            print(f\"Error
      collecting metrics: {e}\")\n        time.sleep(10)\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"claude-code-exporter.py":"#!/usr/bin/env python3\nimport os\nimport time\nimport psutil\nimport socket\nimport subprocess\nimport json\nimport re\nfrom datetime import datetime\nfrom collections import defaultdict\nfrom prometheus_client import start_http_server, Gauge, Counter, Histogram, Info\n\n# Process metrics\nclaude_process_count = Gauge('claude_code_process_count', 'Number of Claude Code processes')\nclaude_process_cpu_percent = Gauge('claude_code_process_cpu_percent', 'CPU usage percentage', ['pid', 'cmd'])\nclaude_process_memory_mb = Gauge('claude_code_process_memory_mb', 'Memory usage in MB', ['pid', 'cmd', 'type'])\nclaude_process_threads = Gauge('claude_code_process_threads', 'Number of threads', ['pid', 'cmd'])\nclaude_process_handles = Gauge('claude_code_process_handles', 'Number of file handles', ['pid', 'cmd'])\nclaude_process_connections = Gauge('claude_code_process_connections', 'Number of network connections', ['pid', 'cmd', 'state'])\nclaude_process_open_files = Gauge('claude_code_process_open_files', 'Number of open files', ['pid', 'cmd'])\nclaude_process_start_time = Gauge('claude_code_process_start_time', 'Process start time (unix timestamp)', ['pid', 'cmd'])\n\n# Port metrics\nclaude_open_ports = Gauge('claude_code_open_ports', 'Open ports by Claude processes', ['pid', 'port', 'type'])\n\n# API metrics (these would need to be parsed from logs or config)\nclaude_api_requests_total = Counter('claude_code_api_requests_total', 'Total API requests', ['endpoint', 'status'])\nclaude_api_tokens_used = Counter('claude_code_api_tokens_used_total', 'Total tokens used', ['model', 'type'])\nclaude_api_cost_dollars = Counter('claude_code_api_cost_dollars_total', 'Total API cost in dollars', ['model'])\nclaude_api_response_time = Histogram('claude_code_api_response_time_seconds', 'API response time', ['endpoint'])\n\n# System-wide metrics\nclaude_total_cpu_percent = Gauge('claude_code_total_cpu_percent', 'Total CPU usage by all Claude processes')\nclaude_total_memory_mb = Gauge('claude_code_total_memory_mb', 'Total memory usage by all Claude processes')\nclaude_total_connections = Gauge('claude_code_total_connections', 'Total network connections')\n\n# Info metrics\nclaude_exporter_info = Info('claude_code_exporter_info', 'Claude Code exporter information')\n\ndef get_claude_processes():\n    \"\"\"Find all Claude Code related processes\"\"\"\n    claude_processes = []\n    \n    # Exclude patterns for monitoring/infrastructure processes\n    exclude_patterns = [\n        'claude-code-exporter',\n        'claude-token-collector',\n        'claude-process-exporter',\n        'process-watchdog',\n        'kubectl',\n        'prometheus',\n        'grafana',\n        '/scripts/'  # Exclude scripts in monitoring containers\n    ]\n    \n    for proc in psutil.process_iter(['pid', 'name', 'cmdline', 'create_time']):\n        try:\n            cmdline = ' '.join(proc.info['cmdline'] or [])\n            name = proc.info['name']\n            \n            # Skip if it's an excluded monitoring process\n            if any(exclude in cmdline.lower() for exclude in exclude_patterns):\n                continue\n            \n            # Look for actual Claude CLI processes\n            # The real Claude CLI runs as: node ... /claude claude\n            # or: python3 ... /claude-tts claude\n            if ('claude' in cmdline.lower() and \n                ('/bin/claude' in cmdline or \n                 '/claude claude' in cmdline or\n                 'claude-tts claude' in cmdline or\n                 '.npm-global/bin/claude' in cmdline)):\n                claude_processes.append(proc)\n                    \n        except (psutil.NoSuchProcess, psutil.AccessDenied):\n            continue\n            \n    return claude_processes\n\ndef get_process_handles(pid):\n    \"\"\"Get number of file handles for a process\"\"\"\n    try:\n        # Linux specific\n        return len(os.listdir(f'/proc/{pid}/fd'))\n    except:\n        return 0\n\ndef get_process_connections_by_state(proc):\n    \"\"\"Get network connections grouped by state\"\"\"\n    connections_by_state = defaultdict(int)\n    try:\n        for conn in proc.connections():\n            connections_by_state[conn.status] += 1\n    except (psutil.NoSuchProcess, psutil.AccessDenied):\n        pass\n    return connections_by_state\n\ndef get_open_ports(proc):\n    \"\"\"Get open ports for a process\"\"\"\n    open_ports = []\n    try:\n        for conn in proc.connections():\n            if conn.status == 'LISTEN':\n                open_ports.append({\n                    'port': conn.laddr.port,\n                    'type': 'tcp' if conn.type == socket.SOCK_STREAM else 'udp'\n                })\n    except (psutil.NoSuchProcess, psutil.AccessDenied):\n        pass\n    return open_ports\n\ndef parse_api_logs():\n    \"\"\"Parse Claude API usage from logs (placeholder - would need actual log parsing)\"\"\"\n    # This is a placeholder - in reality, you'd parse actual Claude Code logs\n    # or read from a configuration file where API usage is tracked\n    \n    # Check common log locations\n    log_locations = [\n        '/var/log/claude-code.log',\n        '/home/*/.claude-code/logs/*.log',\n        '/tmp/claude-*.log'\n    ]\n    \n    api_stats = {\n        'requests': 0,\n        'tokens': 0,\n        'cost': 0.0\n    }\n    \n    # TODO: Implement actual log parsing logic\n    # This would parse logs for API calls, token usage, and calculate costs\n    \n    return api_stats\n\ndef collect_claude_metrics():\n    \"\"\"Collect metrics for all Claude processes\"\"\"\n    processes = get_claude_processes()\n    \n    # Update process count\n    claude_process_count.set(len(processes))\n    \n    total_cpu = 0\n    total_memory = 0\n    total_connections = 0\n    \n    for proc in processes:\n        try:\n            pid = proc.pid\n            cmdline = ' '.join(proc.cmdline()[:3])  # First 3 args for label\n            \n            # CPU usage\n            cpu_percent = proc.cpu_percent(interval=0.1)\n            claude_process_cpu_percent.labels(pid=pid, cmd=cmdline).set(cpu_percent)\n            total_cpu += cpu_percent\n            \n            # Memory usage\n            mem_info = proc.memory_info()\n            mem_rss_mb = mem_info.rss / 1024 / 1024\n            mem_vms_mb = mem_info.vms / 1024 / 1024\n            claude_process_memory_mb.labels(pid=pid, cmd=cmdline, type='rss').set(mem_rss_mb)\n            claude_process_memory_mb.labels(pid=pid, cmd=cmdline, type='vms').set(mem_vms_mb)\n            total_memory += mem_rss_mb\n            \n            # Threads\n            num_threads = proc.num_threads()\n            claude_process_threads.labels(pid=pid, cmd=cmdline).set(num_threads)\n            \n            # File handles\n            num_handles = get_process_handles(pid)\n            claude_process_handles.labels(pid=pid, cmd=cmdline).set(num_handles)\n            \n            # Open files\n            try:\n                num_files = len(proc.open_files())\n                claude_process_open_files.labels(pid=pid, cmd=cmdline).set(num_files)\n            except:\n                pass\n            \n            # Network connections by state\n            conn_states = get_process_connections_by_state(proc)\n            for state, count in conn_states.items():\n                claude_process_connections.labels(pid=pid, cmd=cmdline, state=state).set(count)\n                total_connections += count\n            \n            # Open ports\n            open_ports = get_open_ports(proc)\n            for port_info in open_ports:\n                claude_open_ports.labels(\n                    pid=pid, \n                    port=port_info['port'], \n                    type=port_info['type']\n                ).set(1)\n            \n            # Process start time\n            claude_process_start_time.labels(pid=pid, cmd=cmdline).set(proc.create_time())\n            \n        except (psutil.NoSuchProcess, psutil.AccessDenied):\n            continue\n    \n    # Update totals\n    claude_total_cpu_percent.set(total_cpu)\n    claude_total_memory_mb.set(total_memory)\n    claude_total_connections.set(total_connections)\n    \n    # Collect API metrics (placeholder)\n    api_stats = parse_api_logs()\n    # Update API metrics based on parsed logs\n\ndef check_claude_cli():\n    \"\"\"Check if Claude CLI is installed and get version\"\"\"\n    try:\n        result = subprocess.run(['claude', '--version'], \n                              capture_output=True, text=True, timeout=5)\n        if result.returncode == 0:\n            version = result.stdout.strip()\n            return {'installed': True, 'version': version}\n    except:\n        pass\n    return {'installed': False, 'version': 'unknown'}\n\nif __name__ == '__main__':\n    # Start Prometheus metrics server\n    start_http_server(9403)\n    \n    # Check Claude CLI\n    cli_info = check_claude_cli()\n    claude_exporter_info.info({\n        'version': '1.0',\n        'cli_installed': str(cli_info['installed']),\n        'cli_version': cli_info['version']\n    })\n    \n    print(f\"Claude Code exporter started on port 9403\")\n    print(f\"Claude CLI installed: {cli_info['installed']}\")\n    \n    # Collect metrics every 10 seconds\n    while True:\n        try:\n            collect_claude_metrics()\n        except Exception as e:\n            print(f\"Error collecting metrics: {e}\")\n        time.sleep(10)\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"claude-code-exporter-script","namespace":"monitoring"}}
    creationTimestamp: "2025-05-28T15:25:23Z"
    name: claude-code-exporter-script
    namespace: monitoring
    resourceVersion: "3112936"
    uid: 3daf6753-c88f-4eee-b04c-844fb74934d2
- apiVersion: v1
  data:
    claude-memory-alerts.yml: "groups:\n- name: claude-code-memory-alerts\n  rules:\n
      \ # ALL CLAUDE MEMORY ALERTS DISABLED - Claude processes should use unlimited
      memory\n  # These alerts are intentionally commented out to prevent OOM protection\n
      \ \n  # # Claude Code Exporter Memory Alerts - DISABLED\n  # - alert: ClaudeCodeExporterHighMemoryUsage\n
      \ #   expr: container_memory_usage_bytes{pod=~\"claude-code-exporter-.*\"} /
      container_spec_memory_limit_bytes{pod=~\"claude-code-exporter-.*\"} > 0.8\n
      \ #   for: 2m\n  #   labels:\n  #     severity: warning\n  #     component:
      claude-code-exporter\n  #     alert_type: memory\n  #   annotations:\n  #     summary:
      \"Claude Code Exporter high memory usage\"\n  #     description: \"Claude Code
      Exporter pod {{ $labels.pod }} is using {{ $value | humanizePercentage }} of
      its memory limit for over 2 minutes\"\n  \n  # Only keep critical infrastructure
      alerts\n  - alert: ClaudeCodeExporterDown\n    expr: up{job=\"claude-code-exporter\"}
      == 0\n    for: 2m\n    labels:\n      severity: critical\n      component: claude-code-exporter\n
      \     alert_type: availability\n    annotations:\n      summary: \"Claude Code
      Exporter is down\"\n      description: \"Claude Code Exporter has been down
      for more than 2 minutes\"\n      \n  - alert: ClaudeCodeExporterCollectionErrors\n
      \   expr: rate(claude_code_exporter_collection_errors_total[5m]) > 0.5\n    for:
      5m\n    labels:\n      severity: warning\n      component: claude-code-exporter\n
      \     alert_type: collection_errors\n    annotations:\n      summary: \"Claude
      Code Exporter collection errors\"\n      description: \"Claude Code Exporter
      is experiencing {{ $value }} collection errors per second\"\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"claude-memory-alerts.yml":"groups:\n- name: claude-code-memory-alerts\n  rules:\n  # ALL CLAUDE MEMORY ALERTS DISABLED - Claude processes should use unlimited memory\n  # These alerts are intentionally commented out to prevent OOM protection\n  \n  # # Claude Code Exporter Memory Alerts - DISABLED\n  # - alert: ClaudeCodeExporterHighMemoryUsage\n  #   expr: container_memory_usage_bytes{pod=~\"claude-code-exporter-.*\"} / container_spec_memory_limit_bytes{pod=~\"claude-code-exporter-.*\"} \u003e 0.8\n  #   for: 2m\n  #   labels:\n  #     severity: warning\n  #     component: claude-code-exporter\n  #     alert_type: memory\n  #   annotations:\n  #     summary: \"Claude Code Exporter high memory usage\"\n  #     description: \"Claude Code Exporter pod {{ $labels.pod }} is using {{ $value | humanizePercentage }} of its memory limit for over 2 minutes\"\n  \n  # Only keep critical infrastructure alerts\n  - alert: ClaudeCodeExporterDown\n    expr: up{job=\"claude-code-exporter\"} == 0\n    for: 2m\n    labels:\n      severity: critical\n      component: claude-code-exporter\n      alert_type: availability\n    annotations:\n      summary: \"Claude Code Exporter is down\"\n      description: \"Claude Code Exporter has been down for more than 2 minutes\"\n      \n  - alert: ClaudeCodeExporterCollectionErrors\n    expr: rate(claude_code_exporter_collection_errors_total[5m]) \u003e 0.5\n    for: 5m\n    labels:\n      severity: warning\n      component: claude-code-exporter\n      alert_type: collection_errors\n    annotations:\n      summary: \"Claude Code Exporter collection errors\"\n      description: \"Claude Code Exporter is experiencing {{ $value }} collection errors per second\"\n"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"app":"prometheus"},"name":"claude-code-memory-alerts","namespace":"monitoring"}}
    creationTimestamp: "2025-06-04T05:52:59Z"
    labels:
      app: prometheus
    name: claude-code-memory-alerts
    namespace: monitoring
    resourceVersion: "3112959"
    uid: 051a930a-a1b6-4193-9281-baaf8a34d824
- apiVersion: v1
  data:
    token-patterns.yaml: |
      # Common token usage patterns to search for
      patterns:
        terminal:
          - regex: 'Tokens:\s*(\d+)\s*input,\s*(\d+)\s*output'
            groups: ['input', 'output']
          - regex: '(\d+)\s*tokens\s*\((\d+)\s*in,\s*(\d+)\s*out\)'
            groups: ['total', 'input', 'output']
          - regex: 'Usage:\s*\$?([\d.]+)'
            groups: ['cost']
        logs:
          - regex: '"input_tokens":\s*(\d+)'
            groups: ['input']
          - regex: '"output_tokens":\s*(\d+)'
            groups: ['output']
          - regex: '"total_tokens":\s*(\d+)'
            groups: ['total']
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"token-patterns.yaml":"# Common token usage patterns to search for\npatterns:\n  terminal:\n    - regex: 'Tokens:\\s*(\\d+)\\s*input,\\s*(\\d+)\\s*output'\n      groups: ['input', 'output']\n    - regex: '(\\d+)\\s*tokens\\s*\\((\\d+)\\s*in,\\s*(\\d+)\\s*out\\)'\n      groups: ['total', 'input', 'output']\n    - regex: 'Usage:\\s*\\$?([\\d.]+)'\n      groups: ['cost']\n  logs:\n    - regex: '\"input_tokens\":\\s*(\\d+)'\n      groups: ['input']\n    - regex: '\"output_tokens\":\\s*(\\d+)'\n      groups: ['output']\n    - regex: '\"total_tokens\":\\s*(\\d+)'\n      groups: ['total']\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"claude-token-collector-config","namespace":"monitoring"}}
    creationTimestamp: "2025-05-28T16:31:03Z"
    name: claude-token-collector-config
    namespace: monitoring
    resourceVersion: "35289"
    uid: cc9b8298-d00f-4566-93df-dee39ccb666a
- apiVersion: v1
  data:
    claude-token-collector.py: "#!/usr/bin/env python3\nimport os\nimport re\nimport
      json\nimport time\nimport subprocess\nfrom datetime import datetime, timedelta\nfrom
      collections import defaultdict\nfrom prometheus_client import Counter, Gauge,
      Histogram\nimport psutil\n\n# Token usage metrics\nclaude_tokens_input = Counter('claude_api_tokens_input_total',
      'Total input tokens used', ['model', 'project'])\nclaude_tokens_output = Counter('claude_api_tokens_output_total',
      'Total output tokens used', ['model', 'project'])\nclaude_tokens_total = Counter('claude_api_tokens_total',
      'Total tokens used', ['model', 'project'])\nclaude_api_calls = Counter('claude_api_calls_total',
      'Total API calls', ['model', 'project'])\nclaude_api_cost = Counter('claude_api_cost_dollars_total',
      'Total cost in dollars', ['model', 'project'])\n\n# Session metrics\nclaude_session_tokens
      = Gauge('claude_session_tokens', 'Tokens used in current session', ['session_id',
      'type'])\nclaude_session_cost = Gauge('claude_session_cost_dollars', 'Cost of
      current session', ['session_id'])\n\n# Rate metrics\nclaude_tokens_per_minute
      = Gauge('claude_tokens_per_minute', 'Token usage rate', ['model'])\nclaude_cost_per_hour
      = Gauge('claude_cost_per_hour_dollars', 'Cost rate per hour', ['model'])\n\n#
      Price mapping (as of 2024)\nCLAUDE_PRICING = {\n    'claude-3-opus': {'input':
      15.0 / 1000000, 'output': 75.0 / 1000000},\n    'claude-3-sonnet': {'input':
      3.0 / 1000000, 'output': 15.0 / 1000000},\n    'claude-3-haiku': {'input': 0.25
      / 1000000, 'output': 1.25 / 1000000},\n    'claude-2.1': {'input': 8.0 / 1000000,
      'output': 24.0 / 1000000},\n    'claude-2.0': {'input': 8.0 / 1000000, 'output':
      24.0 / 1000000},\n    'claude-instant': {'input': 0.8 / 1000000, 'output': 2.4
      / 1000000}\n}\n\ndef parse_claude_json():\n    \"\"\"Parse ~/.claude.json for
      project history and usage patterns\"\"\"\n    claude_json_path = os.path.expanduser('~/.claude.json')\n
      \   usage_data = defaultdict(lambda: {'calls': 0, 'projects': set()})\n    \n
      \   try:\n        with open(claude_json_path, 'r') as f:\n            data =
      json.load(f)\n            \n        # Extract project usage\n        for project_path,
      project_data in data.get('projects', {}).items():\n            project_name
      = os.path.basename(project_path)\n            history = project_data.get('history',
      [])\n            usage_data[project_name]['calls'] += len(history)\n            usage_data[project_name]['projects'].add(project_path)\n
      \           \n    except Exception as e:\n        print(f\"Error parsing claude.json:
      {e}\")\n        \n    return usage_data\n\ndef parse_terminal_output():\n    \"\"\"Parse
      terminal output for token usage patterns\"\"\"\n    token_pattern = re.compile(\n
      \       r'(?:Tokens|tokens):\\s*(\\d+)\\s*(?:input|in)?\\s*[,/]\\s*(\\d+)\\s*(?:output|out)?'\n
      \   )\n    cost_pattern = re.compile(\n        r'(?:Cost|cost|\\$):\\s*\\$?([\\d.]+)'\n
      \   )\n    model_pattern = re.compile(\n        r'(?:Model|model|Using):\\s*(claude-[\\w.-]+)'\n
      \   )\n    \n    usage_entries = []\n    \n    # Check terminal scrollback buffer
      (if accessible)\n    try:\n        # Try to get tmux or screen buffer\n        tmux_output
      = subprocess.run(['tmux', 'capture-pane', '-p'], \n                                   capture_output=True,
      text=True)\n        if tmux_output.returncode == 0:\n            lines = tmux_output.stdout.split('\\n')\n
      \           parse_terminal_lines(lines, usage_entries, \n                               token_pattern,
      cost_pattern, model_pattern)\n    except:\n        pass\n        \n    # Check
      recent shell history with timestamps\n    try:\n        # Read bash history
      with timestamps if HISTTIMEFORMAT is set\n        history_output = subprocess.run(['bash',
      '-c', 'history'], \n                                      capture_output=True,
      text=True)\n        if history_output.returncode == 0:\n            lines =
      history_output.stdout.split('\\n')\n            parse_terminal_lines(lines,
      usage_entries,\n                               token_pattern, cost_pattern,
      model_pattern)\n    except:\n        pass\n        \n    return usage_entries\n\ndef
      parse_terminal_lines(lines, usage_entries, token_pattern, cost_pattern, model_pattern):\n
      \   \"\"\"Parse terminal lines for token usage information\"\"\"\n    current_entry
      = {}\n    \n    for line in lines:\n        # Look for token counts\n        token_match
      = token_pattern.search(line)\n        if token_match:\n            current_entry['input_tokens']
      = int(token_match.group(1))\n            current_entry['output_tokens'] = int(token_match.group(2))\n
      \           current_entry['timestamp'] = datetime.now()\n            \n        #
      Look for cost\n        cost_match = cost_pattern.search(line)\n        if cost_match:\n
      \           current_entry['cost'] = float(cost_match.group(1))\n            \n
      \       # Look for model\n        model_match = model_pattern.search(line)\n
      \       if model_match:\n            current_entry['model'] = model_match.group(1)\n
      \           \n        # If we have a complete entry, add it\n        if 'input_tokens'
      in current_entry and 'output_tokens' in current_entry:\n            if 'model'
      not in current_entry:\n                current_entry['model'] = 'claude-3-sonnet'
      \ # Default\n            usage_entries.append(current_entry.copy())\n            current_entry
      = {}\n\ndef check_active_claude_sessions():\n    \"\"\"Check for active Claude
      CLI sessions and estimate token usage\"\"\"\n    active_sessions = []\n    \n
      \   for proc in psutil.process_iter(['pid', 'name', 'cmdline', 'create_time']):\n
      \       try:\n            cmdline = ' '.join(proc.info['cmdline'] or [])\n            if
      'claude' in cmdline.lower():\n                # Estimate session duration\n
      \               session_duration = time.time() - proc.info['create_time']\n
      \               \n                # Rough estimation based on session duration\n
      \               # Assume average conversation rate\n                estimated_calls
      = session_duration / 60  # One call per minute\n                estimated_tokens
      = estimated_calls * 1000  # 1000 tokens per call average\n                \n
      \               active_sessions.append({\n                    'pid': proc.info['pid'],\n
      \                   'duration': session_duration,\n                    'estimated_tokens':
      estimated_tokens,\n                    'estimated_cost': estimated_tokens *
      CLAUDE_PRICING['claude-3-sonnet']['input']\n                })\n                \n
      \       except (psutil.NoSuchProcess, psutil.AccessDenied):\n            continue\n
      \           \n    return active_sessions\n\ndef parse_claude_logs():\n    \"\"\"Parse
      any Claude-specific log files\"\"\"\n    log_locations = [\n        '~/.claude/logs/',\n
      \       '~/.local/share/claude/',\n        '~/.cache/claude/',\n        '/tmp/claude-*.log'\n
      \   ]\n    \n    usage_data = []\n    \n    for location in log_locations:\n
      \       expanded = os.path.expanduser(location)\n        try:\n            if
      os.path.isdir(expanded):\n                for log_file in os.listdir(expanded):\n
      \                   if log_file.endswith('.log'):\n                        parse_log_file(os.path.join(expanded,
      log_file), usage_data)\n            elif '*' in expanded:\n                import
      glob\n                for log_file in glob.glob(expanded):\n                    parse_log_file(log_file,
      usage_data)\n        except:\n            continue\n            \n    return
      usage_data\n\ndef parse_log_file(log_path, usage_data):\n    \"\"\"Parse individual
      log file for token usage\"\"\"\n    try:\n        with open(log_path, 'r') as
      f:\n            for line in f:\n                # Look for JSON entries\n                if
      '{' in line:\n                    try:\n                        entry = json.loads(line[line.index('{'):])\n
      \                       if 'tokens' in entry or 'usage' in entry:\n                            usage_data.append(entry)\n
      \                   except:\n                        pass\n    except:\n        pass\n\ndef
      update_metrics(usage_entries):\n    \"\"\"Update Prometheus metrics with collected
      usage data\"\"\"\n    total_cost_by_model = defaultdict(float)\n    total_tokens_by_model
      = defaultdict(int)\n    \n    for entry in usage_entries:\n        model = entry.get('model',
      'claude-3-sonnet')\n        input_tokens = entry.get('input_tokens', 0)\n        output_tokens
      = entry.get('output_tokens', 0)\n        total_tokens = input_tokens + output_tokens\n
      \       \n        # Calculate cost if not provided\n        if 'cost' not in
      entry and model in CLAUDE_PRICING:\n            cost = (input_tokens * CLAUDE_PRICING[model]['input']
      + \n                   output_tokens * CLAUDE_PRICING[model]['output'])\n            entry['cost']
      = cost\n        \n        project = entry.get('project', 'unknown')\n        \n
      \       # Update counters\n        claude_tokens_input.labels(model=model, project=project).inc(input_tokens)\n
      \       claude_tokens_output.labels(model=model, project=project).inc(output_tokens)\n
      \       claude_tokens_total.labels(model=model, project=project).inc(total_tokens)\n
      \       claude_api_calls.labels(model=model, project=project).inc()\n        claude_api_cost.labels(model=model,
      project=project).inc(entry.get('cost', 0))\n        \n        # Track for rate
      calculations\n        total_cost_by_model[model] += entry.get('cost', 0)\n        total_tokens_by_model[model]
      += total_tokens\n\ndef collect_all_usage():\n    \"\"\"Collect usage data from
      all sources\"\"\"\n    all_usage = []\n    \n    # Parse Claude JSON\n    project_usage
      = parse_claude_json()\n    \n    # Parse terminal output\n    terminal_usage
      = parse_terminal_output()\n    all_usage.extend(terminal_usage)\n    \n    #
      Check active sessions\n    active_sessions = check_active_claude_sessions()\n
      \   for session in active_sessions:\n        claude_session_tokens.labels(\n
      \           session_id=str(session['pid']),\n            type='estimated'\n
      \       ).set(session['estimated_tokens'])\n        claude_session_cost.labels(\n
      \           session_id=str(session['pid'])\n        ).set(session['estimated_cost'])\n
      \   \n    # Parse logs\n    log_usage = parse_claude_logs()\n    all_usage.extend(log_usage)\n
      \   \n    # Update metrics\n    if all_usage:\n        update_metrics(all_usage)\n\nif
      __name__ == '__main__':\n    from prometheus_client import start_http_server\n
      \   \n    # Start metrics server\n    start_http_server(9404)\n    print(\"Claude
      token collector started on port 9404\")\n    \n    # Collect metrics every 30
      seconds\n    while True:\n        try:\n            collect_all_usage()\n        except
      Exception as e:\n            print(f\"Error collecting usage: {e}\")\n        time.sleep(30)\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"claude-token-collector.py":"#!/usr/bin/env python3\nimport os\nimport re\nimport json\nimport time\nimport subprocess\nfrom datetime import datetime, timedelta\nfrom collections import defaultdict\nfrom prometheus_client import Counter, Gauge, Histogram\nimport psutil\n\n# Token usage metrics\nclaude_tokens_input = Counter('claude_api_tokens_input_total', 'Total input tokens used', ['model', 'project'])\nclaude_tokens_output = Counter('claude_api_tokens_output_total', 'Total output tokens used', ['model', 'project'])\nclaude_tokens_total = Counter('claude_api_tokens_total', 'Total tokens used', ['model', 'project'])\nclaude_api_calls = Counter('claude_api_calls_total', 'Total API calls', ['model', 'project'])\nclaude_api_cost = Counter('claude_api_cost_dollars_total', 'Total cost in dollars', ['model', 'project'])\n\n# Session metrics\nclaude_session_tokens = Gauge('claude_session_tokens', 'Tokens used in current session', ['session_id', 'type'])\nclaude_session_cost = Gauge('claude_session_cost_dollars', 'Cost of current session', ['session_id'])\n\n# Rate metrics\nclaude_tokens_per_minute = Gauge('claude_tokens_per_minute', 'Token usage rate', ['model'])\nclaude_cost_per_hour = Gauge('claude_cost_per_hour_dollars', 'Cost rate per hour', ['model'])\n\n# Price mapping (as of 2024)\nCLAUDE_PRICING = {\n    'claude-3-opus': {'input': 15.0 / 1000000, 'output': 75.0 / 1000000},\n    'claude-3-sonnet': {'input': 3.0 / 1000000, 'output': 15.0 / 1000000},\n    'claude-3-haiku': {'input': 0.25 / 1000000, 'output': 1.25 / 1000000},\n    'claude-2.1': {'input': 8.0 / 1000000, 'output': 24.0 / 1000000},\n    'claude-2.0': {'input': 8.0 / 1000000, 'output': 24.0 / 1000000},\n    'claude-instant': {'input': 0.8 / 1000000, 'output': 2.4 / 1000000}\n}\n\ndef parse_claude_json():\n    \"\"\"Parse ~/.claude.json for project history and usage patterns\"\"\"\n    claude_json_path = os.path.expanduser('~/.claude.json')\n    usage_data = defaultdict(lambda: {'calls': 0, 'projects': set()})\n    \n    try:\n        with open(claude_json_path, 'r') as f:\n            data = json.load(f)\n            \n        # Extract project usage\n        for project_path, project_data in data.get('projects', {}).items():\n            project_name = os.path.basename(project_path)\n            history = project_data.get('history', [])\n            usage_data[project_name]['calls'] += len(history)\n            usage_data[project_name]['projects'].add(project_path)\n            \n    except Exception as e:\n        print(f\"Error parsing claude.json: {e}\")\n        \n    return usage_data\n\ndef parse_terminal_output():\n    \"\"\"Parse terminal output for token usage patterns\"\"\"\n    token_pattern = re.compile(\n        r'(?:Tokens|tokens):\\s*(\\d+)\\s*(?:input|in)?\\s*[,/]\\s*(\\d+)\\s*(?:output|out)?'\n    )\n    cost_pattern = re.compile(\n        r'(?:Cost|cost|\\$):\\s*\\$?([\\d.]+)'\n    )\n    model_pattern = re.compile(\n        r'(?:Model|model|Using):\\s*(claude-[\\w.-]+)'\n    )\n    \n    usage_entries = []\n    \n    # Check terminal scrollback buffer (if accessible)\n    try:\n        # Try to get tmux or screen buffer\n        tmux_output = subprocess.run(['tmux', 'capture-pane', '-p'], \n                                   capture_output=True, text=True)\n        if tmux_output.returncode == 0:\n            lines = tmux_output.stdout.split('\\n')\n            parse_terminal_lines(lines, usage_entries, \n                               token_pattern, cost_pattern, model_pattern)\n    except:\n        pass\n        \n    # Check recent shell history with timestamps\n    try:\n        # Read bash history with timestamps if HISTTIMEFORMAT is set\n        history_output = subprocess.run(['bash', '-c', 'history'], \n                                      capture_output=True, text=True)\n        if history_output.returncode == 0:\n            lines = history_output.stdout.split('\\n')\n            parse_terminal_lines(lines, usage_entries,\n                               token_pattern, cost_pattern, model_pattern)\n    except:\n        pass\n        \n    return usage_entries\n\ndef parse_terminal_lines(lines, usage_entries, token_pattern, cost_pattern, model_pattern):\n    \"\"\"Parse terminal lines for token usage information\"\"\"\n    current_entry = {}\n    \n    for line in lines:\n        # Look for token counts\n        token_match = token_pattern.search(line)\n        if token_match:\n            current_entry['input_tokens'] = int(token_match.group(1))\n            current_entry['output_tokens'] = int(token_match.group(2))\n            current_entry['timestamp'] = datetime.now()\n            \n        # Look for cost\n        cost_match = cost_pattern.search(line)\n        if cost_match:\n            current_entry['cost'] = float(cost_match.group(1))\n            \n        # Look for model\n        model_match = model_pattern.search(line)\n        if model_match:\n            current_entry['model'] = model_match.group(1)\n            \n        # If we have a complete entry, add it\n        if 'input_tokens' in current_entry and 'output_tokens' in current_entry:\n            if 'model' not in current_entry:\n                current_entry['model'] = 'claude-3-sonnet'  # Default\n            usage_entries.append(current_entry.copy())\n            current_entry = {}\n\ndef check_active_claude_sessions():\n    \"\"\"Check for active Claude CLI sessions and estimate token usage\"\"\"\n    active_sessions = []\n    \n    for proc in psutil.process_iter(['pid', 'name', 'cmdline', 'create_time']):\n        try:\n            cmdline = ' '.join(proc.info['cmdline'] or [])\n            if 'claude' in cmdline.lower():\n                # Estimate session duration\n                session_duration = time.time() - proc.info['create_time']\n                \n                # Rough estimation based on session duration\n                # Assume average conversation rate\n                estimated_calls = session_duration / 60  # One call per minute\n                estimated_tokens = estimated_calls * 1000  # 1000 tokens per call average\n                \n                active_sessions.append({\n                    'pid': proc.info['pid'],\n                    'duration': session_duration,\n                    'estimated_tokens': estimated_tokens,\n                    'estimated_cost': estimated_tokens * CLAUDE_PRICING['claude-3-sonnet']['input']\n                })\n                \n        except (psutil.NoSuchProcess, psutil.AccessDenied):\n            continue\n            \n    return active_sessions\n\ndef parse_claude_logs():\n    \"\"\"Parse any Claude-specific log files\"\"\"\n    log_locations = [\n        '~/.claude/logs/',\n        '~/.local/share/claude/',\n        '~/.cache/claude/',\n        '/tmp/claude-*.log'\n    ]\n    \n    usage_data = []\n    \n    for location in log_locations:\n        expanded = os.path.expanduser(location)\n        try:\n            if os.path.isdir(expanded):\n                for log_file in os.listdir(expanded):\n                    if log_file.endswith('.log'):\n                        parse_log_file(os.path.join(expanded, log_file), usage_data)\n            elif '*' in expanded:\n                import glob\n                for log_file in glob.glob(expanded):\n                    parse_log_file(log_file, usage_data)\n        except:\n            continue\n            \n    return usage_data\n\ndef parse_log_file(log_path, usage_data):\n    \"\"\"Parse individual log file for token usage\"\"\"\n    try:\n        with open(log_path, 'r') as f:\n            for line in f:\n                # Look for JSON entries\n                if '{' in line:\n                    try:\n                        entry = json.loads(line[line.index('{'):])\n                        if 'tokens' in entry or 'usage' in entry:\n                            usage_data.append(entry)\n                    except:\n                        pass\n    except:\n        pass\n\ndef update_metrics(usage_entries):\n    \"\"\"Update Prometheus metrics with collected usage data\"\"\"\n    total_cost_by_model = defaultdict(float)\n    total_tokens_by_model = defaultdict(int)\n    \n    for entry in usage_entries:\n        model = entry.get('model', 'claude-3-sonnet')\n        input_tokens = entry.get('input_tokens', 0)\n        output_tokens = entry.get('output_tokens', 0)\n        total_tokens = input_tokens + output_tokens\n        \n        # Calculate cost if not provided\n        if 'cost' not in entry and model in CLAUDE_PRICING:\n            cost = (input_tokens * CLAUDE_PRICING[model]['input'] + \n                   output_tokens * CLAUDE_PRICING[model]['output'])\n            entry['cost'] = cost\n        \n        project = entry.get('project', 'unknown')\n        \n        # Update counters\n        claude_tokens_input.labels(model=model, project=project).inc(input_tokens)\n        claude_tokens_output.labels(model=model, project=project).inc(output_tokens)\n        claude_tokens_total.labels(model=model, project=project).inc(total_tokens)\n        claude_api_calls.labels(model=model, project=project).inc()\n        claude_api_cost.labels(model=model, project=project).inc(entry.get('cost', 0))\n        \n        # Track for rate calculations\n        total_cost_by_model[model] += entry.get('cost', 0)\n        total_tokens_by_model[model] += total_tokens\n\ndef collect_all_usage():\n    \"\"\"Collect usage data from all sources\"\"\"\n    all_usage = []\n    \n    # Parse Claude JSON\n    project_usage = parse_claude_json()\n    \n    # Parse terminal output\n    terminal_usage = parse_terminal_output()\n    all_usage.extend(terminal_usage)\n    \n    # Check active sessions\n    active_sessions = check_active_claude_sessions()\n    for session in active_sessions:\n        claude_session_tokens.labels(\n            session_id=str(session['pid']),\n            type='estimated'\n        ).set(session['estimated_tokens'])\n        claude_session_cost.labels(\n            session_id=str(session['pid'])\n        ).set(session['estimated_cost'])\n    \n    # Parse logs\n    log_usage = parse_claude_logs()\n    all_usage.extend(log_usage)\n    \n    # Update metrics\n    if all_usage:\n        update_metrics(all_usage)\n\nif __name__ == '__main__':\n    from prometheus_client import start_http_server\n    \n    # Start metrics server\n    start_http_server(9404)\n    print(\"Claude token collector started on port 9404\")\n    \n    # Collect metrics every 30 seconds\n    while True:\n        try:\n            collect_all_usage()\n        except Exception as e:\n            print(f\"Error collecting usage: {e}\")\n        time.sleep(30)\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"claude-token-collector-script","namespace":"monitoring"}}
    creationTimestamp: "2025-05-28T16:31:03Z"
    name: claude-token-collector-script
    namespace: monitoring
    resourceVersion: "35288"
    uid: 5b2e4eaf-2522-4a90-b8bf-2089a879d80d
- apiVersion: v1
  data:
    dead-mans-switch.yaml: "groups:\n- name: dead_mans_switch\n  interval: 30s\n  rules:\n
      \ # Always-firing heartbeat alert\n  - alert: ODINPrimeHeartbeat\n    expr:
      vector(1)\n    for: 0m\n    labels:\n      severity: none\n      component:
      monitoring\n      alertname: ODINPrimeHeartbeat\n    annotations:\n      summary:
      \"ODIN Prime monitoring heartbeat\"\n      description: \"This alert should
      always be firing. If it stops, the monitoring system is down.\"\n  \n  # Alert
      if heartbeat stops (monitoring is down)\n  - alert: ODINPrimeMonitoringDown\n
      \   expr: |\n      absent(ALERTS{alertname=\"ODINPrimeHeartbeat\",severity=\"none\"})
      == 1\n    for: 5m\n    labels:\n      severity: critical\n      component: monitoring\n
      \     notification: external\n    annotations:\n      summary: \"ODIN Prime
      monitoring system is DOWN!\"\n      description: \"The monitoring heartbeat
      has not fired for 5 minutes. Prometheus or AlertManager may be down.\"\n  \n
      \ # Alert if Prometheus scraping fails\n  - alert: PrometheusTargetDown\n    expr:
      up == 0\n    for: 5m\n    labels:\n      severity: critical\n      component:
      monitoring\n    annotations:\n      summary: \"Prometheus target {{ $labels.job
      }} is down\"\n      description: \"{{ $labels.instance }} has been down for
      more than 5 minutes.\"\n  \n  # Alert if AlertManager is not reachable\n  -
      alert: AlertManagerDown\n    expr: |\n      up{job=\"alertmanager\"} == 0 or\n
      \     absent(up{job=\"alertmanager\"}) == 1\n    for: 2m\n    labels:\n      severity:
      critical\n      component: alerting\n      notification: external\n    annotations:\n
      \     summary: \"AlertManager is unreachable\"\n      description: \"AlertManager
      has been down for more than 2 minutes. No alerts are being routed!\"\n  \n  #
      Alert if ODIN Prime pipeline is not processing\n  - alert: ODINPrimeAlertPipelineStalled\n
      \   expr: |\n      # No alerts received in 10 minutes (assuming normal activity)\n
      \     increase(odin_alerts_received_total[10m]) == 0 and\n      # But Prometheus
      is generating alerts\n      count(ALERTS) > 5\n    for: 10m\n    labels:\n      severity:
      critical\n      component: odin-prime\n    annotations:\n      summary: \"ODIN
      Prime alert pipeline appears stalled\"\n      description: \"No alerts have
      been processed in 10 minutes despite active alerts in Prometheus\"\n  \n  #
      Alert if no metrics are being collected\n  - alert: PrometheusNoData\n    expr:
      |\n      # Check if key metrics haven't updated\n      (time() - prometheus_tsdb_lowest_timestamp_seconds)
      > 600\n    for: 5m\n    labels:\n      severity: critical\n      component:
      monitoring\n    annotations:\n      summary: \"Prometheus is not ingesting new
      data\"\n      description: \"No new metrics have been ingested for over 10 minutes\"\n
      \ \n  # Meta-alert: Alert if no alerts are firing when they should be\n  - alert:
      NoAlertsWhenExpected\n    expr: |\n      # If disk space is low but no disk
      alert\n      (100 - (node_filesystem_avail_bytes / node_filesystem_size_bytes
      * 100) > 80) and\n      absent(ALERTS{alertname=~\"Disk.*\"}) == 1\n    for:
      10m\n    labels:\n      severity: warning\n      component: monitoring\n    annotations:\n
      \     summary: \"Expected alerts are not firing\"\n      description: \"System
      conditions warrant alerts but none are active. Alert rules may be broken.\"\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"dead-mans-switch.yaml":"groups:\n- name: dead_mans_switch\n  interval: 30s\n  rules:\n  # Always-firing heartbeat alert\n  - alert: ODINPrimeHeartbeat\n    expr: vector(1)\n    for: 0m\n    labels:\n      severity: none\n      component: monitoring\n      alertname: ODINPrimeHeartbeat\n    annotations:\n      summary: \"ODIN Prime monitoring heartbeat\"\n      description: \"This alert should always be firing. If it stops, the monitoring system is down.\"\n  \n  # Alert if heartbeat stops (monitoring is down)\n  - alert: ODINPrimeMonitoringDown\n    expr: |\n      absent(ALERTS{alertname=\"ODINPrimeHeartbeat\",severity=\"none\"}) == 1\n    for: 5m\n    labels:\n      severity: critical\n      component: monitoring\n      notification: external\n    annotations:\n      summary: \"ODIN Prime monitoring system is DOWN!\"\n      description: \"The monitoring heartbeat has not fired for 5 minutes. Prometheus or AlertManager may be down.\"\n  \n  # Alert if Prometheus scraping fails\n  - alert: PrometheusTargetDown\n    expr: up == 0\n    for: 5m\n    labels:\n      severity: critical\n      component: monitoring\n    annotations:\n      summary: \"Prometheus target {{ $labels.job }} is down\"\n      description: \"{{ $labels.instance }} has been down for more than 5 minutes.\"\n  \n  # Alert if AlertManager is not reachable\n  - alert: AlertManagerDown\n    expr: |\n      up{job=\"alertmanager\"} == 0 or\n      absent(up{job=\"alertmanager\"}) == 1\n    for: 2m\n    labels:\n      severity: critical\n      component: alerting\n      notification: external\n    annotations:\n      summary: \"AlertManager is unreachable\"\n      description: \"AlertManager has been down for more than 2 minutes. No alerts are being routed!\"\n  \n  # Alert if ODIN Prime pipeline is not processing\n  - alert: ODINPrimeAlertPipelineStalled\n    expr: |\n      # No alerts received in 10 minutes (assuming normal activity)\n      increase(odin_alerts_received_total[10m]) == 0 and\n      # But Prometheus is generating alerts\n      count(ALERTS) \u003e 5\n    for: 10m\n    labels:\n      severity: critical\n      component: odin-prime\n    annotations:\n      summary: \"ODIN Prime alert pipeline appears stalled\"\n      description: \"No alerts have been processed in 10 minutes despite active alerts in Prometheus\"\n  \n  # Alert if no metrics are being collected\n  - alert: PrometheusNoData\n    expr: |\n      # Check if key metrics haven't updated\n      (time() - prometheus_tsdb_lowest_timestamp_seconds) \u003e 600\n    for: 5m\n    labels:\n      severity: critical\n      component: monitoring\n    annotations:\n      summary: \"Prometheus is not ingesting new data\"\n      description: \"No new metrics have been ingested for over 10 minutes\"\n  \n  # Meta-alert: Alert if no alerts are firing when they should be\n  - alert: NoAlertsWhenExpected\n    expr: |\n      # If disk space is low but no disk alert\n      (100 - (node_filesystem_avail_bytes / node_filesystem_size_bytes * 100) \u003e 80) and\n      absent(ALERTS{alertname=~\"Disk.*\"}) == 1\n    for: 10m\n    labels:\n      severity: warning\n      component: monitoring\n    annotations:\n      summary: \"Expected alerts are not firing\"\n      description: \"System conditions warrant alerts but none are active. Alert rules may be broken.\"\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"dead-mans-switch-rules","namespace":"monitoring"}}
    creationTimestamp: "2025-06-08T01:21:17Z"
    name: dead-mans-switch-rules
    namespace: monitoring
    resourceVersion: "5213601"
    uid: f3c282b3-7348-4f49-a249-d535b743d7d6
- apiVersion: v1
  data:
    disk_anomaly_detector.py: "#!/usr/bin/env python3\nimport time\nimport numpy as
      np\nimport pandas as pd\nfrom datetime import datetime, timedelta\nimport requests\nimport
      logging\nimport json\nimport os\nimport pickle\nimport threading\nimport shutil\nfrom
      prometheus_client import start_http_server, Gauge, Counter, Histogram\nfrom
      sklearn.ensemble import IsolationForest\nfrom sklearn.preprocessing import StandardScaler\nfrom
      sklearn.linear_model import LinearRegression\nfrom http.server import HTTPServer,
      BaseHTTPRequestHandler\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#
      Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s
      - %(name)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger('disk-anomaly-detector')\n\n#
      Prometheus metrics\ndisk_anomaly_score = Gauge('disk_space_anomaly_score', 'Disk
      space anomaly score', ['device', 'mountpoint', 'anomaly_type', 'algorithm'])\ndisk_growth_anomaly
      = Gauge('disk_growth_anomaly_score', 'Disk growth rate anomaly', ['device',
      'mountpoint'])\ndisk_utilization_forecast = Gauge('disk_utilization_forecast_days',
      'Days until disk full prediction', ['device', 'mountpoint'])\ndisk_inode_anomaly
      = Gauge('disk_inode_anomaly_score', 'Inode usage anomaly', ['device', 'mountpoint'])\ndisk_io_anomaly
      = Gauge('disk_io_anomaly_score', 'Disk I/O anomaly', ['device', 'operation'])\ndisk_temperature_anomaly
      = Gauge('disk_temperature_anomaly_score', 'Disk temperature anomaly', ['device'])\nmodel_training_duration
      = Histogram('disk_anomaly_model_training_duration_seconds', 'Model training
      duration')\nmodel_updates = Counter('disk_anomaly_model_updates_total', 'Total
      model updates', ['metric_type'])\ndetection_errors = Counter('disk_anomaly_detection_errors_total',
      'Total detection errors', ['metric_type'])\nhealth_status = Gauge('disk_anomaly_detector_health',
      'Health status of disk anomaly detector')\ndisk_metrics_processed = Counter('disk_anomaly_metrics_processed_total',
      'Total disk metrics processed', ['metric_type'])\n\n# Configuration\nPROMETHEUS_URL
      = os.getenv('PROMETHEUS_URL', 'http://prometheus:9090')\nMODEL_PATH = '/models'\nUPDATE_INTERVAL
      = int(os.getenv('UPDATE_INTERVAL', '180'))  # 3 minutes\nTRAINING_WINDOW = os.getenv('TRAINING_WINDOW',
      '14d')  # 14 days for disk trends\n\n# Disk Metrics Configuration\nDISK_METRICS
      = [\n    {\n        'name': 'disk_usage_percent',\n        'query': '(node_filesystem_size_bytes{fstype!~\"tmpfs|fuse.lxcfs|squashfs\"}
      - node_filesystem_avail_bytes{fstype!~\"tmpfs|fuse.lxcfs|squashfs\"}) / node_filesystem_size_bytes{fstype!~\"tmpfs|fuse.lxcfs|squashfs\"}
      * 100',\n        'algorithm': 'isolation_forest',\n        'sensitivity': 0.05,
      \ # Lower sensitivity for disk usage\n        'min_samples': 100,\n        'critical_threshold':
      85,  # Alert at 85% usage\n        'warning_threshold': 75   # Warning at 75%
      usage\n    },\n    {\n        'name': 'disk_growth_rate',\n        'query':
      'increase(node_filesystem_size_bytes{fstype!~\"tmpfs|fuse.lxcfs|squashfs\"}[1h])
      - increase(node_filesystem_avail_bytes{fstype!~\"tmpfs|fuse.lxcfs|squashfs\"}[1h])',\n
      \       'algorithm': 'statistical',\n        'z_threshold': 2.5,\n        'min_samples':
      50,\n        'time_based': True\n    },\n    {\n        'name': 'inode_usage_percent',\n
      \       'query': '(node_filesystem_files{fstype!~\"tmpfs|fuse.lxcfs|squashfs\"}
      - node_filesystem_files_free{fstype!~\"tmpfs|fuse.lxcfs|squashfs\"}) / node_filesystem_files{fstype!~\"tmpfs|fuse.lxcfs|squashfs\"}
      * 100',\n        'algorithm': 'statistical',\n        'z_threshold': 3,\n        'min_samples':
      50,\n        'critical_threshold': 90,\n        'warning_threshold': 80\n    },\n
      \   {\n        'name': 'disk_read_iops',\n        'query': 'rate(node_disk_reads_completed_total[5m])',\n
      \       'algorithm': 'isolation_forest',\n        'sensitivity': 0.1,\n        'min_samples':
      60\n    },\n    {\n        'name': 'disk_write_iops',\n        'query': 'rate(node_disk_writes_completed_total[5m])',\n
      \       'algorithm': 'isolation_forest',\n        'sensitivity': 0.1,\n        'min_samples':
      60\n    },\n    {\n        'name': 'disk_read_latency',\n        'query': 'rate(node_disk_read_time_seconds_total[5m])
      / rate(node_disk_reads_completed_total[5m])',\n        'algorithm': 'statistical',\n
      \       'z_threshold': 2,\n        'min_samples': 40\n    },\n    {\n        'name':
      'disk_write_latency',\n        'query': 'rate(node_disk_write_time_seconds_total[5m])
      / rate(node_disk_writes_completed_total[5m])',\n        'algorithm': 'statistical',\n
      \       'z_threshold': 2,\n        'min_samples': 40\n    }\n]\n\n# Critical
      disk paths to monitor closely\nCRITICAL_PATHS = [\n    '/',\n    '/var',\n    '/var/log',\n
      \   '/var/lib/odin',\n    '/tmp',\n    '/home'\n]\n\n# Global health status\nhealth_info
      = {\n    'healthy': True,\n    'last_update': datetime.now(),\n    'errors':
      [],\n    'prometheus_available': False,\n    'critical_alerts': [],\n    'forecast_warnings':
      []\n}\n\nclass HealthCheckHandler(BaseHTTPRequestHandler):\n    \"\"\"HTTP handler
      for health checks\"\"\"\n    def do_GET(self):\n        if self.path == '/health':\n
      \           self.send_health_response()\n        elif self.path == '/healthz':\n
      \           self.send_healthz_response()\n        elif self.path == '/ready':\n
      \           self.send_ready_response()\n        else:\n            self.send_error(404)\n
      \   \n    def send_health_response(self):\n        \"\"\"Detailed health check
      response\"\"\"\n        status_code = 200 if health_info['healthy'] else 503\n
      \       response = {\n            'status': 'healthy' if status_code == 200
      else 'unhealthy',\n            'timestamp': datetime.now().isoformat(),\n            'prometheus_available':
      health_info['prometheus_available'],\n            'last_update': health_info['last_update'].isoformat(),\n
      \           'critical_alerts_count': len(health_info['critical_alerts']),\n
      \           'forecast_warnings_count': len(health_info['forecast_warnings'])\n
      \       }\n        \n        if health_info['errors']:\n            response['recent_errors']
      = health_info['errors'][-5:]\n            \n        if health_info['critical_alerts']:\n
      \           response['critical_alerts'] = health_info['critical_alerts'][-10:]\n
      \           \n        if health_info['forecast_warnings']:\n            response['forecast_warnings']
      = health_info['forecast_warnings'][-5:]\n            \n        self.send_response(status_code)\n
      \       self.send_header('Content-Type', 'application/json')\n        self.end_headers()\n
      \       import json\n        self.wfile.write(json.dumps(response).encode())\n
      \   \n    def send_healthz_response(self):\n        \"\"\"Simple health check
      for k8s\"\"\"\n        if health_info['healthy']:\n            self.send_response(200)\n
      \           self.end_headers()\n            self.wfile.write(b'OK')\n        else:\n
      \           self.send_response(503)\n            self.end_headers()\n            self.wfile.write(b'Unhealthy')\n
      \   \n    def send_ready_response(self):\n        \"\"\"Readiness check\"\"\"\n
      \       now = datetime.now()\n        if (now - health_info['last_update'] <
      timedelta(minutes=5) and \n            health_info['prometheus_available']):\n
      \           self.send_response(200)\n            self.end_headers()\n            self.wfile.write(b'Ready')\n
      \       else:\n            self.send_response(503)\n            self.end_headers()\n
      \           self.wfile.write(b'Not Ready')\n    \n    def log_message(self,
      format, *args):\n        # Suppress access logs\n        pass\n\ndef run_health_server():\n
      \   \"\"\"Run the health check HTTP server\"\"\"\n    server = HTTPServer(('',
      8080), HealthCheckHandler)\n    server.serve_forever()\n\nclass DiskAnomalyDetector:\n
      \   def __init__(self):\n        self.models = {}\n        self.scalers = {}\n
      \       self.thresholds = {}\n        self.forecasting_models = {}\n        self.baseline_usage
      = {}\n        os.makedirs(MODEL_PATH, exist_ok=True)\n        \n        self.load_models()\n
      \       self.load_baselines()\n        \n    def load_models(self):\n        \"\"\"Load
      saved models from disk\"\"\"\n        for metric in DISK_METRICS:\n            model_file
      = os.path.join(MODEL_PATH, f\"disk_{metric['name'].replace('/', '_')}.pkl\")\n
      \           if os.path.exists(model_file):\n                try:\n                    with
      open(model_file, 'rb') as f:\n                        data = pickle.load(f)\n
      \                       self.models[metric['name']] = data['model']\n                        self.scalers[metric['name']]
      = data.get('scaler')\n                        self.thresholds[metric['name']]
      = data.get('thresholds', {})\n                        self.forecasting_models[metric['name']]
      = data.get('forecasting_model')\n                        logger.info(f\"Loaded
      disk model for {metric['name']}\")\n                except Exception as e:\n
      \                   logger.error(f\"Failed to load disk model for {metric['name']}:
      {e}\")\n                    \n    def save_model(self, metric_name):\n        \"\"\"Save
      model to disk\"\"\"\n        if metric_name in self.models:\n            model_file
      = os.path.join(MODEL_PATH, f\"disk_{metric_name.replace('/', '_')}.pkl\")\n
      \           try:\n                with open(model_file, 'wb') as f:\n                    pickle.dump({\n
      \                       'model': self.models[metric_name],\n                        'scaler':
      self.scalers.get(metric_name),\n                        'thresholds': self.thresholds.get(metric_name,
      {}),\n                        'forecasting_model': self.forecasting_models.get(metric_name)\n
      \                   }, f)\n                logger.info(f\"Saved disk model for
      {metric_name}\")\n            except Exception as e:\n                logger.error(f\"Failed
      to save disk model for {metric_name}: {e}\")\n                \n    def load_baselines(self):\n
      \       \"\"\"Load disk usage baselines\"\"\"\n        baseline_file = os.path.join(MODEL_PATH,
      'disk_baselines.pkl')\n        if os.path.exists(baseline_file):\n            try:\n
      \               with open(baseline_file, 'rb') as f:\n                    self.baseline_usage
      = pickle.load(f)\n                    logger.info(f\"Loaded {len(self.baseline_usage)}
      disk baselines\")\n            except Exception as e:\n                logger.error(f\"Failed
      to load disk baselines: {e}\")\n                \n    def save_baselines(self):\n
      \       \"\"\"Save disk usage baselines\"\"\"\n        baseline_file = os.path.join(MODEL_PATH,
      'disk_baselines.pkl')\n        try:\n            with open(baseline_file, 'wb')
      as f:\n                pickle.dump(self.baseline_usage, f)\n            logger.info(f\"Saved
      {len(self.baseline_usage)} disk baselines\")\n        except Exception as e:\n
      \           logger.error(f\"Failed to save disk baselines: {e}\")\n            \n
      \   def query_prometheus(self, query, start_time=None, end_time=None, step='300s'):\n
      \       \"\"\"Query Prometheus for metric data\"\"\"\n        if not start_time:\n
      \           end_time = datetime.now()\n            start_time = end_time - timedelta(days=14)
      \ # 14 days for disk trends\n            \n        params = {\n            'query':
      query,\n            'start': start_time.timestamp(),\n            'end': end_time.timestamp(),\n
      \           'step': step\n        }\n        \n        try:\n            response
      = requests.get(f\"{PROMETHEUS_URL}/api/v1/query_range\", params=params, timeout=30)\n
      \           response.raise_for_status()\n            data = response.json()\n
      \           \n            health_info['prometheus_available'] = True\n            \n
      \           if data['status'] == 'success' and data['data']['result']:\n                #
      Process multiple time series\n                all_data = []\n                for
      result in data['data']['result']:\n                    for timestamp, value
      in result['values']:\n                        row = {'timestamp': float(timestamp),
      'value': float(value)}\n                        # Add labels as additional features\n
      \                       for label, label_value in result['metric'].items():\n
      \                           if label not in ['__name__', 'instance', 'job']:\n
      \                               row[label] = label_value\n                        all_data.append(row)\n
      \               \n                if all_data:\n                    return pd.DataFrame(all_data)\n
      \                   \n        except Exception as e:\n            logger.error(f\"Failed
      to query Prometheus: {e}\")\n            health_info['prometheus_available']
      = False\n            health_info['errors'].append(f\"Prometheus error: {str(e)}\")\n
      \           detection_errors.labels(metric_type=query).inc()\n            \n
      \       return pd.DataFrame()\n        \n    def query_instant(self, query):\n
      \       \"\"\"Query Prometheus for instant values\"\"\"\n        try:\n            response
      = requests.get(f\"{PROMETHEUS_URL}/api/v1/query\", params={'query': query},
      timeout=10)\n            response.raise_for_status()\n            data = response.json()\n
      \           \n            health_info['prometheus_available'] = True\n            \n
      \           if data['status'] == 'success' and data['data']['result']:\n                results
      = []\n                for result in data['data']['result']:\n                    row
      = {\n                        'value': float(result['value'][1]),\n                        'labels':
      result['metric']\n                    }\n                    results.append(row)\n
      \               return results\n                \n        except Exception as
      e:\n            logger.error(f\"Failed to query instant value: {e}\")\n            health_info['prometheus_available']
      = False\n            \n        return []\n        \n    def predict_disk_full(self,
      device, mountpoint, historical_data):\n        \"\"\"Predict when disk will
      be full based on growth trends\"\"\"\n        if len(historical_data) < 10:\n
      \           return None\n            \n        try:\n            # Prepare time
      series data\n            df = historical_data.sort_values('timestamp')\n            df['days_from_start']
      = (df['timestamp'] - df['timestamp'].min()) / 86400  # Convert to days\n            \n
      \           # Filter out obvious outliers\n            q1 = df['value'].quantile(0.25)\n
      \           q3 = df['value'].quantile(0.75)\n            iqr = q3 - q1\n            df_clean
      = df[(df['value'] >= q1 - 1.5*iqr) & (df['value'] <= q3 + 1.5*iqr)]\n            \n
      \           if len(df_clean) < 5:\n                return None\n            \n
      \           # Fit linear regression to predict trend\n            X = df_clean[['days_from_start']].values\n
      \           y = df_clean['value'].values\n            \n            model =
      LinearRegression()\n            model.fit(X, y)\n            \n            #
      Current usage and growth rate\n            current_usage = y[-1]\n            growth_per_day
      = model.coef_[0]\n            \n            # Predict days until 95% full\n
      \           if growth_per_day > 0:\n                days_until_full = (95 -
      current_usage) / growth_per_day\n                \n                if days_until_full
      > 0:\n                    self.forecasting_models[f\"{device}_{mountpoint}\"]
      = model\n                    \n                    # Generate alerts based on
      forecast\n                    if days_until_full < 7:\n                        severity
      = 'critical'\n                    elif days_until_full < 30:\n                        severity
      = 'warning'\n                    else:\n                        severity = 'info'\n
      \                       \n                    forecast_info = {\n                        'device':
      device,\n                        'mountpoint': mountpoint,\n                        'days_until_full':
      days_until_full,\n                        'current_usage': current_usage,\n
      \                       'growth_per_day': growth_per_day,\n                        'severity':
      severity,\n                        'timestamp': datetime.now().isoformat()\n
      \                   }\n                    \n                    if severity
      in ['critical', 'warning']:\n                        health_info['forecast_warnings'].append(forecast_info)\n
      \                       logger.warning(f\"Disk forecast alert for {device} ({mountpoint}):
      {days_until_full:.1f} days until full\")\n                    \n                    return
      days_until_full\n                    \n        except Exception as e:\n            logger.error(f\"Failed
      to predict disk full for {device}: {e}\")\n            \n        return None\n
      \       \n    def check_critical_thresholds(self, metric_config, device, mountpoint,
      current_value):\n        \"\"\"Check if current value exceeds critical thresholds\"\"\"\n
      \       if 'critical_threshold' in metric_config:\n            if current_value
      >= metric_config['critical_threshold']:\n                alert_info = {\n                    'device':
      device,\n                    'mountpoint': mountpoint,\n                    'metric':
      metric_config['name'],\n                    'value': current_value,\n                    'threshold':
      metric_config['critical_threshold'],\n                    'severity': 'critical',\n
      \                   'timestamp': datetime.now().isoformat()\n                }\n
      \               health_info['critical_alerts'].append(alert_info)\n                logger.critical(f\"Critical
      threshold exceeded: {device} ({mountpoint}) {metric_config['name']} = {current_value}%\")\n
      \               return True\n                \n        if 'warning_threshold'
      in metric_config:\n            if current_value >= metric_config['warning_threshold']:\n
      \               alert_info = {\n                    'device': device,\n                    'mountpoint':
      mountpoint,\n                    'metric': metric_config['name'],\n                    'value':
      current_value,\n                    'threshold': metric_config['warning_threshold'],\n
      \                   'severity': 'warning',\n                    'timestamp':
      datetime.now().isoformat()\n                }\n                health_info['critical_alerts'].append(alert_info)\n
      \               logger.warning(f\"Warning threshold exceeded: {device} ({mountpoint})
      {metric_config['name']} = {current_value}%\")\n                return True\n
      \               \n        return False\n        \n    def train_isolation_forest(self,
      metric_config, data):\n        \"\"\"Train Isolation Forest model for disk metrics\"\"\"\n
      \       if len(data) < metric_config['min_samples']:\n            logger.warning(f\"Insufficient
      data for disk {metric_config['name']}: {len(data)} samples\")\n            return
      None, None\n            \n        # Prepare features - include device metadata\n
      \       feature_cols = ['value']\n        if 'device' in data.columns:\n            #
      Convert categorical to numeric\n            data['device_hash'] = pd.Categorical(data['device']).codes\n
      \           feature_cols.append('device_hash')\n        if 'mountpoint' in data.columns:\n
      \           data['mountpoint_hash'] = pd.Categorical(data['mountpoint']).codes\n
      \           feature_cols.append('mountpoint_hash')\n            \n        #
      Add time-based features\n        data['hour'] = pd.to_datetime(data['timestamp'],
      unit='s').dt.hour\n        data['dayofweek'] = pd.to_datetime(data['timestamp'],
      unit='s').dt.dayofweek\n        feature_cols.extend(['hour', 'dayofweek'])\n
      \       \n        X = data[feature_cols].values\n        \n        # Scale features\n
      \       scaler = StandardScaler()\n        X_scaled = scaler.fit_transform(X)\n
      \       \n        # Train model\n        model = IsolationForest(\n            contamination=metric_config['sensitivity'],\n
      \           random_state=42,\n            n_estimators=100\n        )\n        \n
      \       with model_training_duration.time():\n            model.fit(X_scaled)\n
      \           \n        model_updates.labels(metric_type=metric_config['name']).inc()\n
      \       \n        return model, scaler\n        \n    def train_statistical_model(self,
      metric_config, data):\n        \"\"\"Train statistical anomaly detection model\"\"\"\n
      \       if len(data) < metric_config['min_samples']:\n            logger.warning(f\"Insufficient
      data for disk {metric_config['name']}: {len(data)} samples\")\n            return
      None\n            \n        values = data['value'].values\n        \n        #
      Calculate statistics per device if available\n        thresholds = {\n            'global':
      {\n                'mean': np.mean(values),\n                'std': np.std(values),\n
      \               'p99': np.percentile(values, 99),\n                'p95': np.percentile(values,
      95),\n                'p05': np.percentile(values, 5),\n                'p01':
      np.percentile(values, 1)\n            }\n        }\n        \n        # Per-device
      thresholds if device data available\n        if 'device' in data.columns:\n
      \           thresholds['per_device'] = {}\n            for device in data['device'].unique():\n
      \               device_data = data[data['device'] == device]['value'].values\n
      \               if len(device_data) >= 10:  # Minimum samples per device\n                    thresholds['per_device'][device]
      = {\n                        'mean': np.mean(device_data),\n                        'std':
      np.std(device_data),\n                        'p95': np.percentile(device_data,
      95)\n                    }\n        \n        model_updates.labels(metric_type=metric_config['name']).inc()\n
      \       \n        return thresholds\n        \n    def detect_disk_anomalies(self,
      metric_config):\n        \"\"\"Detect anomalies for disk metrics\"\"\"\n        try:\n
      \           # Query current values\n            current_results = self.query_instant(metric_config['query'])\n
      \           \n            if not current_results:\n                logger.debug(f\"No
      data for disk {metric_config['name']}\")\n                return\n                \n
      \           for result in current_results:\n                current_value =
      result['value']\n                labels = result['labels']\n                \n
      \               # Extract device and mountpoint from labels\n                device
      = labels.get('device', labels.get('instance', 'unknown'))\n                mountpoint
      = labels.get('mountpoint', labels.get('fstype', 'unknown'))\n                \n
      \               disk_metrics_processed.labels(metric_type=metric_config['name']).inc()\n
      \               \n                # Check critical thresholds first\n                is_critical
      = self.check_critical_thresholds(metric_config, device, mountpoint, current_value)\n
      \               \n                # Run forecasting for usage metrics\n                if
      metric_config['name'] == 'disk_usage_percent':\n                    historical_data
      = self.query_prometheus(\n                        metric_config['query'] + f'{{device=\"{device}\",mountpoint=\"{mountpoint}\"}}',\n
      \                       start_time=datetime.now() - timedelta(days=7)\n                    )\n
      \                   if not historical_data.empty:\n                        days_until_full
      = self.predict_disk_full(device, mountpoint, historical_data)\n                        if
      days_until_full:\n                            disk_utilization_forecast.labels(\n
      \                               device=device,\n                                mountpoint=mountpoint\n
      \                           ).set(days_until_full)\n                \n                if
      metric_config['algorithm'] == 'isolation_forest':\n                    if metric_config['name']
      in self.models:\n                        model = self.models[metric_config['name']]\n
      \                       scaler = self.scalers[metric_config['name']]\n                        \n
      \                       # Prepare features\n                        now = datetime.now()\n
      \                       hour = now.hour\n                        dayofweek =
      now.weekday()\n                        \n                        # Create feature
      vector matching training\n                        features = [current_value,
      hour, dayofweek]\n                        X = np.array([features])\n                        X_scaled
      = scaler.transform(X)\n                        \n                        # Get
      anomaly score\n                        score = model.decision_function(X_scaled)[0]\n
      \                       normalized_score = 50 + (score * 50)\n                        normalized_score
      = max(0, min(100, normalized_score))\n                        \n                        disk_anomaly_score.labels(\n
      \                           device=device,\n                            mountpoint=mountpoint,\n
      \                           anomaly_type=metric_config['name'],\n                            algorithm='isolation_forest'\n
      \                       ).set(100 - normalized_score)\n                        \n
      \                       # Alert on high anomaly scores\n                        if
      (100 - normalized_score) > 80:\n                            logger.warning(f\"High
      disk anomaly detected: {device} ({mountpoint}) - {metric_config['name']} score:
      {100-normalized_score}\")\n                        \n                        logger.debug(f\"Disk
      {metric_config['name']} [{device}:{mountpoint}]: value={current_value}, score={100-normalized_score}\")\n
      \                       \n                elif metric_config['algorithm'] ==
      'statistical':\n                    if metric_config['name'] in self.thresholds:\n
      \                       thresholds = self.thresholds[metric_config['name']]\n
      \                       \n                        # Use device-specific thresholds
      if available\n                        threshold_data = thresholds['global']\n
      \                       if ('per_device' in thresholds and \n                            device
      in thresholds['per_device']):\n                            threshold_data =
      thresholds['per_device'][device]\n                        \n                        #
      Calculate z-score\n                        z_score = abs((current_value - threshold_data['mean'])
      / (threshold_data['std'] + 1e-10))\n                        \n                        #
      Convert to 0-100 scale\n                        score = min(100, (z_score /
      metric_config['z_threshold']) * 100)\n                        \n                        disk_anomaly_score.labels(\n
      \                           device=device,\n                            mountpoint=mountpoint,\n
      \                           anomaly_type=metric_config['name'],\n                            algorithm='statistical'\n
      \                       ).set(score)\n                        \n                        #
      Alert on high anomaly scores\n                        if score > 80:\n                            logger.warning(f\"High
      disk anomaly detected: {device} ({mountpoint}) - {metric_config['name']} z-score:
      {z_score}\")\n                        \n                        logger.debug(f\"Disk
      {metric_config['name']} [{device}:{mountpoint}]: value={current_value}, z-score={z_score},
      score={score}\")\n                    \n        except Exception as e:\n            logger.error(f\"Error
      detecting disk anomalies for {metric_config['name']}: {e}\")\n            detection_errors.labels(metric_type=metric_config['name']).inc()\n
      \           \n    def update_models(self):\n        \"\"\"Update all disk anomaly
      detection models\"\"\"\n        logger.info(\"Updating disk anomaly detection
      models...\")\n        \n        for metric_config in DISK_METRICS:\n            try:\n
      \               # Query training data\n                training_data = self.query_prometheus(metric_config['query'])\n
      \               \n                if training_data.empty:\n                    logger.warning(f\"No
      training data for disk {metric_config['name']}\")\n                    continue\n
      \                   \n                if metric_config['algorithm'] == 'isolation_forest':\n
      \                   model, scaler = self.train_isolation_forest(metric_config,
      training_data)\n                    if model:\n                        self.models[metric_config['name']]
      = model\n                        self.scalers[metric_config['name']] = scaler\n
      \                       self.save_model(metric_config['name'])\n                        \n
      \               elif metric_config['algorithm'] == 'statistical':\n                    thresholds
      = self.train_statistical_model(metric_config, training_data)\n                    if
      thresholds:\n                        self.thresholds[metric_config['name']]
      = thresholds\n                        self.save_model(metric_config['name'])\n
      \                       \n                logger.info(f\"Updated disk model
      for {metric_config['name']}\")\n                \n            except Exception
      as e:\n                logger.error(f\"Failed to update disk model for {metric_config['name']}:
      {e}\")\n                health_info['errors'].append(f\"Model update error:
      {str(e)}\")\n                \n        # Save updated baselines\n        self.save_baselines()\n
      \               \n    def run(self):\n        \"\"\"Main disk anomaly detection
      loop\"\"\"\n        # Initial model training\n        self.update_models()\n
      \       \n        last_model_update = time.time()\n        \n        while True:\n
      \           try:\n                # Detect anomalies for all metrics\n                for
      metric_config in DISK_METRICS:\n                    self.detect_disk_anomalies(metric_config)\n
      \                   \n                # Update models periodically (every 12
      hours)\n                if time.time() - last_model_update > 43200:\n                    self.update_models()\n
      \                   last_model_update = time.time()\n                    \n
      \               # Update health status\n                health_info['healthy']
      = health_info['prometheus_available']\n                health_info['last_update']
      = datetime.now()\n                health_status.set(1 if health_info['healthy']
      else 0)\n                \n                # Clean old alerts (keep last 24
      hours)\n                cutoff_time = datetime.now() - timedelta(hours=24)\n
      \               health_info['critical_alerts'] = [\n                    alert
      for alert in health_info['critical_alerts']\n                    if datetime.fromisoformat(alert['timestamp'])
      > cutoff_time\n                ]\n                health_info['forecast_warnings']
      = [\n                    warning for warning in health_info['forecast_warnings']\n
      \                   if datetime.fromisoformat(warning['timestamp']) > cutoff_time\n
      \               ]\n                \n                time.sleep(UPDATE_INTERVAL)\n
      \               \n            except Exception as e:\n                logger.error(f\"Error
      in disk anomaly detection loop: {e}\")\n                health_info['healthy']
      = False\n                health_info['errors'].append(f\"Main loop error: {str(e)}\")\n
      \               health_status.set(0)\n                time.sleep(60)\n\ndef
      main():\n    # Start Prometheus metrics server\n    start_http_server(9408)\n
      \   logger.info(\"Started disk anomaly detection metrics server on port 9408\")\n
      \   \n    # Start health check server in a separate thread\n    health_thread
      = threading.Thread(target=run_health_server, daemon=True)\n    health_thread.start()\n
      \   logger.info(\"Started health check server on port 8080\")\n    \n    # Start
      disk anomaly detector\n    detector = DiskAnomalyDetector()\n    detector.run()\n\nif
      __name__ == '__main__':\n    main()\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"disk_anomaly_detector.py":"#!/usr/bin/env python3\nimport time\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta\nimport requests\nimport logging\nimport json\nimport os\nimport pickle\nimport threading\nimport shutil\nfrom prometheus_client import start_http_server, Gauge, Counter, Histogram\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom http.server import HTTPServer, BaseHTTPRequestHandler\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger('disk-anomaly-detector')\n\n# Prometheus metrics\ndisk_anomaly_score = Gauge('disk_space_anomaly_score', 'Disk space anomaly score', ['device', 'mountpoint', 'anomaly_type', 'algorithm'])\ndisk_growth_anomaly = Gauge('disk_growth_anomaly_score', 'Disk growth rate anomaly', ['device', 'mountpoint'])\ndisk_utilization_forecast = Gauge('disk_utilization_forecast_days', 'Days until disk full prediction', ['device', 'mountpoint'])\ndisk_inode_anomaly = Gauge('disk_inode_anomaly_score', 'Inode usage anomaly', ['device', 'mountpoint'])\ndisk_io_anomaly = Gauge('disk_io_anomaly_score', 'Disk I/O anomaly', ['device', 'operation'])\ndisk_temperature_anomaly = Gauge('disk_temperature_anomaly_score', 'Disk temperature anomaly', ['device'])\nmodel_training_duration = Histogram('disk_anomaly_model_training_duration_seconds', 'Model training duration')\nmodel_updates = Counter('disk_anomaly_model_updates_total', 'Total model updates', ['metric_type'])\ndetection_errors = Counter('disk_anomaly_detection_errors_total', 'Total detection errors', ['metric_type'])\nhealth_status = Gauge('disk_anomaly_detector_health', 'Health status of disk anomaly detector')\ndisk_metrics_processed = Counter('disk_anomaly_metrics_processed_total', 'Total disk metrics processed', ['metric_type'])\n\n# Configuration\nPROMETHEUS_URL = os.getenv('PROMETHEUS_URL', 'http://prometheus:9090')\nMODEL_PATH = '/models'\nUPDATE_INTERVAL = int(os.getenv('UPDATE_INTERVAL', '180'))  # 3 minutes\nTRAINING_WINDOW = os.getenv('TRAINING_WINDOW', '14d')  # 14 days for disk trends\n\n# Disk Metrics Configuration\nDISK_METRICS = [\n    {\n        'name': 'disk_usage_percent',\n        'query': '(node_filesystem_size_bytes{fstype!~\"tmpfs|fuse.lxcfs|squashfs\"} - node_filesystem_avail_bytes{fstype!~\"tmpfs|fuse.lxcfs|squashfs\"}) / node_filesystem_size_bytes{fstype!~\"tmpfs|fuse.lxcfs|squashfs\"} * 100',\n        'algorithm': 'isolation_forest',\n        'sensitivity': 0.05,  # Lower sensitivity for disk usage\n        'min_samples': 100,\n        'critical_threshold': 85,  # Alert at 85% usage\n        'warning_threshold': 75   # Warning at 75% usage\n    },\n    {\n        'name': 'disk_growth_rate',\n        'query': 'increase(node_filesystem_size_bytes{fstype!~\"tmpfs|fuse.lxcfs|squashfs\"}[1h]) - increase(node_filesystem_avail_bytes{fstype!~\"tmpfs|fuse.lxcfs|squashfs\"}[1h])',\n        'algorithm': 'statistical',\n        'z_threshold': 2.5,\n        'min_samples': 50,\n        'time_based': True\n    },\n    {\n        'name': 'inode_usage_percent',\n        'query': '(node_filesystem_files{fstype!~\"tmpfs|fuse.lxcfs|squashfs\"} - node_filesystem_files_free{fstype!~\"tmpfs|fuse.lxcfs|squashfs\"}) / node_filesystem_files{fstype!~\"tmpfs|fuse.lxcfs|squashfs\"} * 100',\n        'algorithm': 'statistical',\n        'z_threshold': 3,\n        'min_samples': 50,\n        'critical_threshold': 90,\n        'warning_threshold': 80\n    },\n    {\n        'name': 'disk_read_iops',\n        'query': 'rate(node_disk_reads_completed_total[5m])',\n        'algorithm': 'isolation_forest',\n        'sensitivity': 0.1,\n        'min_samples': 60\n    },\n    {\n        'name': 'disk_write_iops',\n        'query': 'rate(node_disk_writes_completed_total[5m])',\n        'algorithm': 'isolation_forest',\n        'sensitivity': 0.1,\n        'min_samples': 60\n    },\n    {\n        'name': 'disk_read_latency',\n        'query': 'rate(node_disk_read_time_seconds_total[5m]) / rate(node_disk_reads_completed_total[5m])',\n        'algorithm': 'statistical',\n        'z_threshold': 2,\n        'min_samples': 40\n    },\n    {\n        'name': 'disk_write_latency',\n        'query': 'rate(node_disk_write_time_seconds_total[5m]) / rate(node_disk_writes_completed_total[5m])',\n        'algorithm': 'statistical',\n        'z_threshold': 2,\n        'min_samples': 40\n    }\n]\n\n# Critical disk paths to monitor closely\nCRITICAL_PATHS = [\n    '/',\n    '/var',\n    '/var/log',\n    '/var/lib/odin',\n    '/tmp',\n    '/home'\n]\n\n# Global health status\nhealth_info = {\n    'healthy': True,\n    'last_update': datetime.now(),\n    'errors': [],\n    'prometheus_available': False,\n    'critical_alerts': [],\n    'forecast_warnings': []\n}\n\nclass HealthCheckHandler(BaseHTTPRequestHandler):\n    \"\"\"HTTP handler for health checks\"\"\"\n    def do_GET(self):\n        if self.path == '/health':\n            self.send_health_response()\n        elif self.path == '/healthz':\n            self.send_healthz_response()\n        elif self.path == '/ready':\n            self.send_ready_response()\n        else:\n            self.send_error(404)\n    \n    def send_health_response(self):\n        \"\"\"Detailed health check response\"\"\"\n        status_code = 200 if health_info['healthy'] else 503\n        response = {\n            'status': 'healthy' if status_code == 200 else 'unhealthy',\n            'timestamp': datetime.now().isoformat(),\n            'prometheus_available': health_info['prometheus_available'],\n            'last_update': health_info['last_update'].isoformat(),\n            'critical_alerts_count': len(health_info['critical_alerts']),\n            'forecast_warnings_count': len(health_info['forecast_warnings'])\n        }\n        \n        if health_info['errors']:\n            response['recent_errors'] = health_info['errors'][-5:]\n            \n        if health_info['critical_alerts']:\n            response['critical_alerts'] = health_info['critical_alerts'][-10:]\n            \n        if health_info['forecast_warnings']:\n            response['forecast_warnings'] = health_info['forecast_warnings'][-5:]\n            \n        self.send_response(status_code)\n        self.send_header('Content-Type', 'application/json')\n        self.end_headers()\n        import json\n        self.wfile.write(json.dumps(response).encode())\n    \n    def send_healthz_response(self):\n        \"\"\"Simple health check for k8s\"\"\"\n        if health_info['healthy']:\n            self.send_response(200)\n            self.end_headers()\n            self.wfile.write(b'OK')\n        else:\n            self.send_response(503)\n            self.end_headers()\n            self.wfile.write(b'Unhealthy')\n    \n    def send_ready_response(self):\n        \"\"\"Readiness check\"\"\"\n        now = datetime.now()\n        if (now - health_info['last_update'] \u003c timedelta(minutes=5) and \n            health_info['prometheus_available']):\n            self.send_response(200)\n            self.end_headers()\n            self.wfile.write(b'Ready')\n        else:\n            self.send_response(503)\n            self.end_headers()\n            self.wfile.write(b'Not Ready')\n    \n    def log_message(self, format, *args):\n        # Suppress access logs\n        pass\n\ndef run_health_server():\n    \"\"\"Run the health check HTTP server\"\"\"\n    server = HTTPServer(('', 8080), HealthCheckHandler)\n    server.serve_forever()\n\nclass DiskAnomalyDetector:\n    def __init__(self):\n        self.models = {}\n        self.scalers = {}\n        self.thresholds = {}\n        self.forecasting_models = {}\n        self.baseline_usage = {}\n        os.makedirs(MODEL_PATH, exist_ok=True)\n        \n        self.load_models()\n        self.load_baselines()\n        \n    def load_models(self):\n        \"\"\"Load saved models from disk\"\"\"\n        for metric in DISK_METRICS:\n            model_file = os.path.join(MODEL_PATH, f\"disk_{metric['name'].replace('/', '_')}.pkl\")\n            if os.path.exists(model_file):\n                try:\n                    with open(model_file, 'rb') as f:\n                        data = pickle.load(f)\n                        self.models[metric['name']] = data['model']\n                        self.scalers[metric['name']] = data.get('scaler')\n                        self.thresholds[metric['name']] = data.get('thresholds', {})\n                        self.forecasting_models[metric['name']] = data.get('forecasting_model')\n                        logger.info(f\"Loaded disk model for {metric['name']}\")\n                except Exception as e:\n                    logger.error(f\"Failed to load disk model for {metric['name']}: {e}\")\n                    \n    def save_model(self, metric_name):\n        \"\"\"Save model to disk\"\"\"\n        if metric_name in self.models:\n            model_file = os.path.join(MODEL_PATH, f\"disk_{metric_name.replace('/', '_')}.pkl\")\n            try:\n                with open(model_file, 'wb') as f:\n                    pickle.dump({\n                        'model': self.models[metric_name],\n                        'scaler': self.scalers.get(metric_name),\n                        'thresholds': self.thresholds.get(metric_name, {}),\n                        'forecasting_model': self.forecasting_models.get(metric_name)\n                    }, f)\n                logger.info(f\"Saved disk model for {metric_name}\")\n            except Exception as e:\n                logger.error(f\"Failed to save disk model for {metric_name}: {e}\")\n                \n    def load_baselines(self):\n        \"\"\"Load disk usage baselines\"\"\"\n        baseline_file = os.path.join(MODEL_PATH, 'disk_baselines.pkl')\n        if os.path.exists(baseline_file):\n            try:\n                with open(baseline_file, 'rb') as f:\n                    self.baseline_usage = pickle.load(f)\n                    logger.info(f\"Loaded {len(self.baseline_usage)} disk baselines\")\n            except Exception as e:\n                logger.error(f\"Failed to load disk baselines: {e}\")\n                \n    def save_baselines(self):\n        \"\"\"Save disk usage baselines\"\"\"\n        baseline_file = os.path.join(MODEL_PATH, 'disk_baselines.pkl')\n        try:\n            with open(baseline_file, 'wb') as f:\n                pickle.dump(self.baseline_usage, f)\n            logger.info(f\"Saved {len(self.baseline_usage)} disk baselines\")\n        except Exception as e:\n            logger.error(f\"Failed to save disk baselines: {e}\")\n            \n    def query_prometheus(self, query, start_time=None, end_time=None, step='300s'):\n        \"\"\"Query Prometheus for metric data\"\"\"\n        if not start_time:\n            end_time = datetime.now()\n            start_time = end_time - timedelta(days=14)  # 14 days for disk trends\n            \n        params = {\n            'query': query,\n            'start': start_time.timestamp(),\n            'end': end_time.timestamp(),\n            'step': step\n        }\n        \n        try:\n            response = requests.get(f\"{PROMETHEUS_URL}/api/v1/query_range\", params=params, timeout=30)\n            response.raise_for_status()\n            data = response.json()\n            \n            health_info['prometheus_available'] = True\n            \n            if data['status'] == 'success' and data['data']['result']:\n                # Process multiple time series\n                all_data = []\n                for result in data['data']['result']:\n                    for timestamp, value in result['values']:\n                        row = {'timestamp': float(timestamp), 'value': float(value)}\n                        # Add labels as additional features\n                        for label, label_value in result['metric'].items():\n                            if label not in ['__name__', 'instance', 'job']:\n                                row[label] = label_value\n                        all_data.append(row)\n                \n                if all_data:\n                    return pd.DataFrame(all_data)\n                    \n        except Exception as e:\n            logger.error(f\"Failed to query Prometheus: {e}\")\n            health_info['prometheus_available'] = False\n            health_info['errors'].append(f\"Prometheus error: {str(e)}\")\n            detection_errors.labels(metric_type=query).inc()\n            \n        return pd.DataFrame()\n        \n    def query_instant(self, query):\n        \"\"\"Query Prometheus for instant values\"\"\"\n        try:\n            response = requests.get(f\"{PROMETHEUS_URL}/api/v1/query\", params={'query': query}, timeout=10)\n            response.raise_for_status()\n            data = response.json()\n            \n            health_info['prometheus_available'] = True\n            \n            if data['status'] == 'success' and data['data']['result']:\n                results = []\n                for result in data['data']['result']:\n                    row = {\n                        'value': float(result['value'][1]),\n                        'labels': result['metric']\n                    }\n                    results.append(row)\n                return results\n                \n        except Exception as e:\n            logger.error(f\"Failed to query instant value: {e}\")\n            health_info['prometheus_available'] = False\n            \n        return []\n        \n    def predict_disk_full(self, device, mountpoint, historical_data):\n        \"\"\"Predict when disk will be full based on growth trends\"\"\"\n        if len(historical_data) \u003c 10:\n            return None\n            \n        try:\n            # Prepare time series data\n            df = historical_data.sort_values('timestamp')\n            df['days_from_start'] = (df['timestamp'] - df['timestamp'].min()) / 86400  # Convert to days\n            \n            # Filter out obvious outliers\n            q1 = df['value'].quantile(0.25)\n            q3 = df['value'].quantile(0.75)\n            iqr = q3 - q1\n            df_clean = df[(df['value'] \u003e= q1 - 1.5*iqr) \u0026 (df['value'] \u003c= q3 + 1.5*iqr)]\n            \n            if len(df_clean) \u003c 5:\n                return None\n            \n            # Fit linear regression to predict trend\n            X = df_clean[['days_from_start']].values\n            y = df_clean['value'].values\n            \n            model = LinearRegression()\n            model.fit(X, y)\n            \n            # Current usage and growth rate\n            current_usage = y[-1]\n            growth_per_day = model.coef_[0]\n            \n            # Predict days until 95% full\n            if growth_per_day \u003e 0:\n                days_until_full = (95 - current_usage) / growth_per_day\n                \n                if days_until_full \u003e 0:\n                    self.forecasting_models[f\"{device}_{mountpoint}\"] = model\n                    \n                    # Generate alerts based on forecast\n                    if days_until_full \u003c 7:\n                        severity = 'critical'\n                    elif days_until_full \u003c 30:\n                        severity = 'warning'\n                    else:\n                        severity = 'info'\n                        \n                    forecast_info = {\n                        'device': device,\n                        'mountpoint': mountpoint,\n                        'days_until_full': days_until_full,\n                        'current_usage': current_usage,\n                        'growth_per_day': growth_per_day,\n                        'severity': severity,\n                        'timestamp': datetime.now().isoformat()\n                    }\n                    \n                    if severity in ['critical', 'warning']:\n                        health_info['forecast_warnings'].append(forecast_info)\n                        logger.warning(f\"Disk forecast alert for {device} ({mountpoint}): {days_until_full:.1f} days until full\")\n                    \n                    return days_until_full\n                    \n        except Exception as e:\n            logger.error(f\"Failed to predict disk full for {device}: {e}\")\n            \n        return None\n        \n    def check_critical_thresholds(self, metric_config, device, mountpoint, current_value):\n        \"\"\"Check if current value exceeds critical thresholds\"\"\"\n        if 'critical_threshold' in metric_config:\n            if current_value \u003e= metric_config['critical_threshold']:\n                alert_info = {\n                    'device': device,\n                    'mountpoint': mountpoint,\n                    'metric': metric_config['name'],\n                    'value': current_value,\n                    'threshold': metric_config['critical_threshold'],\n                    'severity': 'critical',\n                    'timestamp': datetime.now().isoformat()\n                }\n                health_info['critical_alerts'].append(alert_info)\n                logger.critical(f\"Critical threshold exceeded: {device} ({mountpoint}) {metric_config['name']} = {current_value}%\")\n                return True\n                \n        if 'warning_threshold' in metric_config:\n            if current_value \u003e= metric_config['warning_threshold']:\n                alert_info = {\n                    'device': device,\n                    'mountpoint': mountpoint,\n                    'metric': metric_config['name'],\n                    'value': current_value,\n                    'threshold': metric_config['warning_threshold'],\n                    'severity': 'warning',\n                    'timestamp': datetime.now().isoformat()\n                }\n                health_info['critical_alerts'].append(alert_info)\n                logger.warning(f\"Warning threshold exceeded: {device} ({mountpoint}) {metric_config['name']} = {current_value}%\")\n                return True\n                \n        return False\n        \n    def train_isolation_forest(self, metric_config, data):\n        \"\"\"Train Isolation Forest model for disk metrics\"\"\"\n        if len(data) \u003c metric_config['min_samples']:\n            logger.warning(f\"Insufficient data for disk {metric_config['name']}: {len(data)} samples\")\n            return None, None\n            \n        # Prepare features - include device metadata\n        feature_cols = ['value']\n        if 'device' in data.columns:\n            # Convert categorical to numeric\n            data['device_hash'] = pd.Categorical(data['device']).codes\n            feature_cols.append('device_hash')\n        if 'mountpoint' in data.columns:\n            data['mountpoint_hash'] = pd.Categorical(data['mountpoint']).codes\n            feature_cols.append('mountpoint_hash')\n            \n        # Add time-based features\n        data['hour'] = pd.to_datetime(data['timestamp'], unit='s').dt.hour\n        data['dayofweek'] = pd.to_datetime(data['timestamp'], unit='s').dt.dayofweek\n        feature_cols.extend(['hour', 'dayofweek'])\n        \n        X = data[feature_cols].values\n        \n        # Scale features\n        scaler = StandardScaler()\n        X_scaled = scaler.fit_transform(X)\n        \n        # Train model\n        model = IsolationForest(\n            contamination=metric_config['sensitivity'],\n            random_state=42,\n            n_estimators=100\n        )\n        \n        with model_training_duration.time():\n            model.fit(X_scaled)\n            \n        model_updates.labels(metric_type=metric_config['name']).inc()\n        \n        return model, scaler\n        \n    def train_statistical_model(self, metric_config, data):\n        \"\"\"Train statistical anomaly detection model\"\"\"\n        if len(data) \u003c metric_config['min_samples']:\n            logger.warning(f\"Insufficient data for disk {metric_config['name']}: {len(data)} samples\")\n            return None\n            \n        values = data['value'].values\n        \n        # Calculate statistics per device if available\n        thresholds = {\n            'global': {\n                'mean': np.mean(values),\n                'std': np.std(values),\n                'p99': np.percentile(values, 99),\n                'p95': np.percentile(values, 95),\n                'p05': np.percentile(values, 5),\n                'p01': np.percentile(values, 1)\n            }\n        }\n        \n        # Per-device thresholds if device data available\n        if 'device' in data.columns:\n            thresholds['per_device'] = {}\n            for device in data['device'].unique():\n                device_data = data[data['device'] == device]['value'].values\n                if len(device_data) \u003e= 10:  # Minimum samples per device\n                    thresholds['per_device'][device] = {\n                        'mean': np.mean(device_data),\n                        'std': np.std(device_data),\n                        'p95': np.percentile(device_data, 95)\n                    }\n        \n        model_updates.labels(metric_type=metric_config['name']).inc()\n        \n        return thresholds\n        \n    def detect_disk_anomalies(self, metric_config):\n        \"\"\"Detect anomalies for disk metrics\"\"\"\n        try:\n            # Query current values\n            current_results = self.query_instant(metric_config['query'])\n            \n            if not current_results:\n                logger.debug(f\"No data for disk {metric_config['name']}\")\n                return\n                \n            for result in current_results:\n                current_value = result['value']\n                labels = result['labels']\n                \n                # Extract device and mountpoint from labels\n                device = labels.get('device', labels.get('instance', 'unknown'))\n                mountpoint = labels.get('mountpoint', labels.get('fstype', 'unknown'))\n                \n                disk_metrics_processed.labels(metric_type=metric_config['name']).inc()\n                \n                # Check critical thresholds first\n                is_critical = self.check_critical_thresholds(metric_config, device, mountpoint, current_value)\n                \n                # Run forecasting for usage metrics\n                if metric_config['name'] == 'disk_usage_percent':\n                    historical_data = self.query_prometheus(\n                        metric_config['query'] + f'{{device=\"{device}\",mountpoint=\"{mountpoint}\"}}',\n                        start_time=datetime.now() - timedelta(days=7)\n                    )\n                    if not historical_data.empty:\n                        days_until_full = self.predict_disk_full(device, mountpoint, historical_data)\n                        if days_until_full:\n                            disk_utilization_forecast.labels(\n                                device=device,\n                                mountpoint=mountpoint\n                            ).set(days_until_full)\n                \n                if metric_config['algorithm'] == 'isolation_forest':\n                    if metric_config['name'] in self.models:\n                        model = self.models[metric_config['name']]\n                        scaler = self.scalers[metric_config['name']]\n                        \n                        # Prepare features\n                        now = datetime.now()\n                        hour = now.hour\n                        dayofweek = now.weekday()\n                        \n                        # Create feature vector matching training\n                        features = [current_value, hour, dayofweek]\n                        X = np.array([features])\n                        X_scaled = scaler.transform(X)\n                        \n                        # Get anomaly score\n                        score = model.decision_function(X_scaled)[0]\n                        normalized_score = 50 + (score * 50)\n                        normalized_score = max(0, min(100, normalized_score))\n                        \n                        disk_anomaly_score.labels(\n                            device=device,\n                            mountpoint=mountpoint,\n                            anomaly_type=metric_config['name'],\n                            algorithm='isolation_forest'\n                        ).set(100 - normalized_score)\n                        \n                        # Alert on high anomaly scores\n                        if (100 - normalized_score) \u003e 80:\n                            logger.warning(f\"High disk anomaly detected: {device} ({mountpoint}) - {metric_config['name']} score: {100-normalized_score}\")\n                        \n                        logger.debug(f\"Disk {metric_config['name']} [{device}:{mountpoint}]: value={current_value}, score={100-normalized_score}\")\n                        \n                elif metric_config['algorithm'] == 'statistical':\n                    if metric_config['name'] in self.thresholds:\n                        thresholds = self.thresholds[metric_config['name']]\n                        \n                        # Use device-specific thresholds if available\n                        threshold_data = thresholds['global']\n                        if ('per_device' in thresholds and \n                            device in thresholds['per_device']):\n                            threshold_data = thresholds['per_device'][device]\n                        \n                        # Calculate z-score\n                        z_score = abs((current_value - threshold_data['mean']) / (threshold_data['std'] + 1e-10))\n                        \n                        # Convert to 0-100 scale\n                        score = min(100, (z_score / metric_config['z_threshold']) * 100)\n                        \n                        disk_anomaly_score.labels(\n                            device=device,\n                            mountpoint=mountpoint,\n                            anomaly_type=metric_config['name'],\n                            algorithm='statistical'\n                        ).set(score)\n                        \n                        # Alert on high anomaly scores\n                        if score \u003e 80:\n                            logger.warning(f\"High disk anomaly detected: {device} ({mountpoint}) - {metric_config['name']} z-score: {z_score}\")\n                        \n                        logger.debug(f\"Disk {metric_config['name']} [{device}:{mountpoint}]: value={current_value}, z-score={z_score}, score={score}\")\n                    \n        except Exception as e:\n            logger.error(f\"Error detecting disk anomalies for {metric_config['name']}: {e}\")\n            detection_errors.labels(metric_type=metric_config['name']).inc()\n            \n    def update_models(self):\n        \"\"\"Update all disk anomaly detection models\"\"\"\n        logger.info(\"Updating disk anomaly detection models...\")\n        \n        for metric_config in DISK_METRICS:\n            try:\n                # Query training data\n                training_data = self.query_prometheus(metric_config['query'])\n                \n                if training_data.empty:\n                    logger.warning(f\"No training data for disk {metric_config['name']}\")\n                    continue\n                    \n                if metric_config['algorithm'] == 'isolation_forest':\n                    model, scaler = self.train_isolation_forest(metric_config, training_data)\n                    if model:\n                        self.models[metric_config['name']] = model\n                        self.scalers[metric_config['name']] = scaler\n                        self.save_model(metric_config['name'])\n                        \n                elif metric_config['algorithm'] == 'statistical':\n                    thresholds = self.train_statistical_model(metric_config, training_data)\n                    if thresholds:\n                        self.thresholds[metric_config['name']] = thresholds\n                        self.save_model(metric_config['name'])\n                        \n                logger.info(f\"Updated disk model for {metric_config['name']}\")\n                \n            except Exception as e:\n                logger.error(f\"Failed to update disk model for {metric_config['name']}: {e}\")\n                health_info['errors'].append(f\"Model update error: {str(e)}\")\n                \n        # Save updated baselines\n        self.save_baselines()\n                \n    def run(self):\n        \"\"\"Main disk anomaly detection loop\"\"\"\n        # Initial model training\n        self.update_models()\n        \n        last_model_update = time.time()\n        \n        while True:\n            try:\n                # Detect anomalies for all metrics\n                for metric_config in DISK_METRICS:\n                    self.detect_disk_anomalies(metric_config)\n                    \n                # Update models periodically (every 12 hours)\n                if time.time() - last_model_update \u003e 43200:\n                    self.update_models()\n                    last_model_update = time.time()\n                    \n                # Update health status\n                health_info['healthy'] = health_info['prometheus_available']\n                health_info['last_update'] = datetime.now()\n                health_status.set(1 if health_info['healthy'] else 0)\n                \n                # Clean old alerts (keep last 24 hours)\n                cutoff_time = datetime.now() - timedelta(hours=24)\n                health_info['critical_alerts'] = [\n                    alert for alert in health_info['critical_alerts']\n                    if datetime.fromisoformat(alert['timestamp']) \u003e cutoff_time\n                ]\n                health_info['forecast_warnings'] = [\n                    warning for warning in health_info['forecast_warnings']\n                    if datetime.fromisoformat(warning['timestamp']) \u003e cutoff_time\n                ]\n                \n                time.sleep(UPDATE_INTERVAL)\n                \n            except Exception as e:\n                logger.error(f\"Error in disk anomaly detection loop: {e}\")\n                health_info['healthy'] = False\n                health_info['errors'].append(f\"Main loop error: {str(e)}\")\n                health_status.set(0)\n                time.sleep(60)\n\ndef main():\n    # Start Prometheus metrics server\n    start_http_server(9408)\n    logger.info(\"Started disk anomaly detection metrics server on port 9408\")\n    \n    # Start health check server in a separate thread\n    health_thread = threading.Thread(target=run_health_server, daemon=True)\n    health_thread.start()\n    logger.info(\"Started health check server on port 8080\")\n    \n    # Start disk anomaly detector\n    detector = DiskAnomalyDetector()\n    detector.run()\n\nif __name__ == '__main__':\n    main()\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"disk-anomaly-detector-script","namespace":"monitoring"}}
    creationTimestamp: "2025-05-31T20:27:41Z"
    name: disk-anomaly-detector-script
    namespace: monitoring
    resourceVersion: "673734"
    uid: 09a3e06b-640b-4f2e-a6ab-a0d992ead3c5
- apiVersion: v1
  data:
    disk-monitoring.json: |
      {
        "dashboard": {
          "id": null,
          "uid": "disk-monitoring",
          "title": "ODIN Disk Space Monitoring",
          "tags": ["odin", "disk", "storage"],
          "timezone": "browser",
          "schemaVersion": 38,
          "version": 0,
          "refresh": "30s",
          "panels": [
            {
              "datasource": "Prometheus",
              "fieldConfig": {
                "defaults": {
                  "mappings": [],
                  "thresholds": {
                    "mode": "absolute",
                    "steps": [
                      {"color": "green", "value": null},
                      {"color": "yellow", "value": 70},
                      {"color": "red", "value": 85}
                    ]
                  },
                  "unit": "percent"
                },
                "overrides": []
              },
              "gridPos": {"h": 8, "w": 6, "x": 0, "y": 0},
              "id": 1,
              "options": {
                "orientation": "auto",
                "reduceOptions": {
                  "values": false,
                  "calcs": ["lastNotNull"],
                  "fields": ""
                },
                "showThresholdLabels": false,
                "showThresholdMarkers": true
              },
              "pluginVersion": "10.0.0",
              "targets": [
                {
                  "expr": "100 - (node_filesystem_avail_bytes{mountpoint=\"/\"} / node_filesystem_size_bytes{mountpoint=\"/\"} * 100)",
                  "refId": "A"
                }
              ],
              "title": "Root Disk Usage",
              "type": "gauge"
            },
            {
              "datasource": "Prometheus",
              "fieldConfig": {
                "defaults": {
                  "mappings": [],
                  "thresholds": {
                    "mode": "absolute",
                    "steps": [
                      {"color": "green", "value": null},
                      {"color": "yellow", "value": 7},
                      {"color": "red", "value": 3}
                    ]
                  },
                  "unit": "d"
                },
                "overrides": []
              },
              "gridPos": {"h": 8, "w": 6, "x": 6, "y": 0},
              "id": 2,
              "options": {
                "orientation": "auto",
                "reduceOptions": {
                  "values": false,
                  "calcs": ["lastNotNull"],
                  "fields": ""
                },
                "showThresholdLabels": false,
                "showThresholdMarkers": true
              },
              "pluginVersion": "10.0.0",
              "targets": [
                {
                  "expr": "node_filesystem_avail_bytes{mountpoint=\"/\"} / (avg_over_time(rate(node_filesystem_size_bytes{mountpoint=\"/\"}[1h])[24h:1h]) * 24)",
                  "refId": "A"
                }
              ],
              "title": "Days Until Full (Predicted)",
              "type": "gauge"
            },
            {
              "datasource": "Prometheus",
              "fieldConfig": {
                "defaults": {
                  "custom": {
                    "hideFrom": {
                      "tooltip": false,
                      "viz": false,
                      "legend": false
                    }
                  },
                  "mappings": [],
                  "unit": "decbytes"
                },
                "overrides": []
              },
              "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0},
              "id": 3,
              "options": {
                "legend": {
                  "displayMode": "list",
                  "placement": "right",
                  "showLegend": true
                },
                "pieType": "pie",
                "tooltip": {
                  "mode": "single",
                  "sort": "none"
                }
              },
              "targets": [
                {
                  "expr": "topk(10, directory_size_bytes)",
                  "format": "time_series",
                  "legendFormat": "{{category}}",
                  "refId": "A"
                }
              ],
              "title": "Directory Space Usage",
              "type": "piechart"
            },
            {
              "datasource": "Prometheus",
              "fieldConfig": {
                "defaults": {
                  "custom": {
                    "drawStyle": "line",
                    "lineInterpolation": "linear",
                    "barAlignment": 0,
                    "lineWidth": 1,
                    "fillOpacity": 10,
                    "gradientMode": "none",
                    "spanNulls": false,
                    "showPoints": "never",
                    "pointSize": 5,
                    "stacking": {
                      "mode": "none",
                      "group": "A"
                    },
                    "axisPlacement": "auto",
                    "axisLabel": "",
                    "axisColorMode": "text",
                    "scaleDistribution": {
                      "type": "linear"
                    },
                    "axisCenteredZero": false,
                    "hideFrom": {
                      "tooltip": false,
                      "viz": false,
                      "legend": false
                    },
                    "thresholdsStyle": {
                      "mode": "off"
                    }
                  },
                  "mappings": [],
                  "unit": "Bps"
                },
                "overrides": []
              },
              "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8},
              "id": 4,
              "options": {
                "tooltip": {
                  "mode": "multi",
                  "sort": "none"
                },
                "legend": {
                  "showLegend": true,
                  "displayMode": "list",
                  "placement": "bottom",
                  "calcs": []
                }
              },
              "targets": [
                {
                  "expr": "directory_growth_bytes_per_hour / 3600",
                  "legendFormat": "{{category}}",
                  "refId": "A"
                }
              ],
              "title": "Directory Growth Rate",
              "type": "timeseries"
            },
            {
              "datasource": "Prometheus",
              "fieldConfig": {
                "defaults": {
                  "custom": {
                    "align": "auto",
                    "displayMode": "auto",
                    "inspect": false
                  },
                  "mappings": [],
                  "thresholds": {
                    "mode": "absolute",
                    "steps": [
                      {"color": "green", "value": null}
                    ]
                  },
                  "unit": "decbytes"
                },
                "overrides": [
                  {
                    "matcher": {"id": "byName", "options": "Growth (MB/hr)"},
                    "properties": [
                      {
                        "id": "unit",
                        "value": "MB/hr"
                      },
                      {
                        "id": "custom.displayMode",
                        "value": "color-background"
                      },
                      {
                        "id": "thresholds",
                        "value": {
                          "mode": "absolute",
                          "steps": [
                            {"color": "green", "value": null},
                            {"color": "yellow", "value": 100},
                            {"color": "red", "value": 500}
                          ]
                        }
                      }
                    ]
                  }
                ]
              },
              "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8},
              "id": 5,
              "options": {
                "showHeader": true,
                "cellHeight": "sm"
              },
              "pluginVersion": "10.0.0",
              "targets": [
                {
                  "expr": "sort_desc(directory_size_bytes)",
                  "format": "table",
                  "instant": true,
                  "refId": "A"
                },
                {
                  "expr": "sort_desc(directory_growth_bytes_per_hour / 1024 / 1024)",
                  "format": "table",
                  "instant": true,
                  "refId": "B"
                }
              ],
              "title": "Directory Details",
              "transformations": [
                {
                  "id": "merge",
                  "options": {}
                },
                {
                  "id": "organize",
                  "options": {
                    "excludeByName": {
                      "Time": true,
                      "__name__": true
                    },
                    "renameByName": {
                      "Value #A": "Size",
                      "Value #B": "Growth (MB/hr)",
                      "category": "Category",
                      "path": "Path"
                    }
                  }
                }
              ],
              "type": "table"
            },
            {
              "datasource": "Prometheus",
              "fieldConfig": {
                "defaults": {
                  "custom": {
                    "drawStyle": "bars",
                    "lineInterpolation": "linear",
                    "barAlignment": 0,
                    "lineWidth": 1,
                    "fillOpacity": 80,
                    "gradientMode": "none",
                    "spanNulls": false,
                    "showPoints": "never",
                    "pointSize": 5,
                    "stacking": {
                      "mode": "normal",
                      "group": "A"
                    },
                    "axisPlacement": "auto",
                    "axisLabel": "",
                    "axisColorMode": "text",
                    "scaleDistribution": {
                      "type": "linear"
                    },
                    "axisCenteredZero": false,
                    "hideFrom": {
                      "tooltip": false,
                      "viz": false,
                      "legend": false
                    },
                    "thresholdsStyle": {
                      "mode": "off"
                    }
                  },
                  "mappings": [],
                  "unit": "decbytes"
                },
                "overrides": []
              },
              "gridPos": {"h": 8, "w": 24, "x": 0, "y": 16},
              "id": 6,
              "options": {
                "tooltip": {
                  "mode": "multi",
                  "sort": "none"
                },
                "legend": {
                  "showLegend": true,
                  "displayMode": "list",
                  "placement": "right",
                  "calcs": []
                }
              },
              "targets": [
                {
                  "expr": "docker_space_usage_bytes",
                  "legendFormat": "{{type}}",
                  "refId": "A"
                }
              ],
              "title": "Docker Space Breakdown",
              "type": "timeseries"
            }
          ]
        }
      }
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"disk-monitoring.json":"{\n  \"dashboard\": {\n    \"id\": null,\n    \"uid\": \"disk-monitoring\",\n    \"title\": \"ODIN Disk Space Monitoring\",\n    \"tags\": [\"odin\", \"disk\", \"storage\"],\n    \"timezone\": \"browser\",\n    \"schemaVersion\": 38,\n    \"version\": 0,\n    \"refresh\": \"30s\",\n    \"panels\": [\n      {\n        \"datasource\": \"Prometheus\",\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"mappings\": [],\n            \"thresholds\": {\n              \"mode\": \"absolute\",\n              \"steps\": [\n                {\"color\": \"green\", \"value\": null},\n                {\"color\": \"yellow\", \"value\": 70},\n                {\"color\": \"red\", \"value\": 85}\n              ]\n            },\n            \"unit\": \"percent\"\n          },\n          \"overrides\": []\n        },\n        \"gridPos\": {\"h\": 8, \"w\": 6, \"x\": 0, \"y\": 0},\n        \"id\": 1,\n        \"options\": {\n          \"orientation\": \"auto\",\n          \"reduceOptions\": {\n            \"values\": false,\n            \"calcs\": [\"lastNotNull\"],\n            \"fields\": \"\"\n          },\n          \"showThresholdLabels\": false,\n          \"showThresholdMarkers\": true\n        },\n        \"pluginVersion\": \"10.0.0\",\n        \"targets\": [\n          {\n            \"expr\": \"100 - (node_filesystem_avail_bytes{mountpoint=\\\"/\\\"} / node_filesystem_size_bytes{mountpoint=\\\"/\\\"} * 100)\",\n            \"refId\": \"A\"\n          }\n        ],\n        \"title\": \"Root Disk Usage\",\n        \"type\": \"gauge\"\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"mappings\": [],\n            \"thresholds\": {\n              \"mode\": \"absolute\",\n              \"steps\": [\n                {\"color\": \"green\", \"value\": null},\n                {\"color\": \"yellow\", \"value\": 7},\n                {\"color\": \"red\", \"value\": 3}\n              ]\n            },\n            \"unit\": \"d\"\n          },\n          \"overrides\": []\n        },\n        \"gridPos\": {\"h\": 8, \"w\": 6, \"x\": 6, \"y\": 0},\n        \"id\": 2,\n        \"options\": {\n          \"orientation\": \"auto\",\n          \"reduceOptions\": {\n            \"values\": false,\n            \"calcs\": [\"lastNotNull\"],\n            \"fields\": \"\"\n          },\n          \"showThresholdLabels\": false,\n          \"showThresholdMarkers\": true\n        },\n        \"pluginVersion\": \"10.0.0\",\n        \"targets\": [\n          {\n            \"expr\": \"node_filesystem_avail_bytes{mountpoint=\\\"/\\\"} / (avg_over_time(rate(node_filesystem_size_bytes{mountpoint=\\\"/\\\"}[1h])[24h:1h]) * 24)\",\n            \"refId\": \"A\"\n          }\n        ],\n        \"title\": \"Days Until Full (Predicted)\",\n        \"type\": \"gauge\"\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"custom\": {\n              \"hideFrom\": {\n                \"tooltip\": false,\n                \"viz\": false,\n                \"legend\": false\n              }\n            },\n            \"mappings\": [],\n            \"unit\": \"decbytes\"\n          },\n          \"overrides\": []\n        },\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 0},\n        \"id\": 3,\n        \"options\": {\n          \"legend\": {\n            \"displayMode\": \"list\",\n            \"placement\": \"right\",\n            \"showLegend\": true\n          },\n          \"pieType\": \"pie\",\n          \"tooltip\": {\n            \"mode\": \"single\",\n            \"sort\": \"none\"\n          }\n        },\n        \"targets\": [\n          {\n            \"expr\": \"topk(10, directory_size_bytes)\",\n            \"format\": \"time_series\",\n            \"legendFormat\": \"{{category}}\",\n            \"refId\": \"A\"\n          }\n        ],\n        \"title\": \"Directory Space Usage\",\n        \"type\": \"piechart\"\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"custom\": {\n              \"drawStyle\": \"line\",\n              \"lineInterpolation\": \"linear\",\n              \"barAlignment\": 0,\n              \"lineWidth\": 1,\n              \"fillOpacity\": 10,\n              \"gradientMode\": \"none\",\n              \"spanNulls\": false,\n              \"showPoints\": \"never\",\n              \"pointSize\": 5,\n              \"stacking\": {\n                \"mode\": \"none\",\n                \"group\": \"A\"\n              },\n              \"axisPlacement\": \"auto\",\n              \"axisLabel\": \"\",\n              \"axisColorMode\": \"text\",\n              \"scaleDistribution\": {\n                \"type\": \"linear\"\n              },\n              \"axisCenteredZero\": false,\n              \"hideFrom\": {\n                \"tooltip\": false,\n                \"viz\": false,\n                \"legend\": false\n              },\n              \"thresholdsStyle\": {\n                \"mode\": \"off\"\n              }\n            },\n            \"mappings\": [],\n            \"unit\": \"Bps\"\n          },\n          \"overrides\": []\n        },\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 8},\n        \"id\": 4,\n        \"options\": {\n          \"tooltip\": {\n            \"mode\": \"multi\",\n            \"sort\": \"none\"\n          },\n          \"legend\": {\n            \"showLegend\": true,\n            \"displayMode\": \"list\",\n            \"placement\": \"bottom\",\n            \"calcs\": []\n          }\n        },\n        \"targets\": [\n          {\n            \"expr\": \"directory_growth_bytes_per_hour / 3600\",\n            \"legendFormat\": \"{{category}}\",\n            \"refId\": \"A\"\n          }\n        ],\n        \"title\": \"Directory Growth Rate\",\n        \"type\": \"timeseries\"\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"custom\": {\n              \"align\": \"auto\",\n              \"displayMode\": \"auto\",\n              \"inspect\": false\n            },\n            \"mappings\": [],\n            \"thresholds\": {\n              \"mode\": \"absolute\",\n              \"steps\": [\n                {\"color\": \"green\", \"value\": null}\n              ]\n            },\n            \"unit\": \"decbytes\"\n          },\n          \"overrides\": [\n            {\n              \"matcher\": {\"id\": \"byName\", \"options\": \"Growth (MB/hr)\"},\n              \"properties\": [\n                {\n                  \"id\": \"unit\",\n                  \"value\": \"MB/hr\"\n                },\n                {\n                  \"id\": \"custom.displayMode\",\n                  \"value\": \"color-background\"\n                },\n                {\n                  \"id\": \"thresholds\",\n                  \"value\": {\n                    \"mode\": \"absolute\",\n                    \"steps\": [\n                      {\"color\": \"green\", \"value\": null},\n                      {\"color\": \"yellow\", \"value\": 100},\n                      {\"color\": \"red\", \"value\": 500}\n                    ]\n                  }\n                }\n              ]\n            }\n          ]\n        },\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 8},\n        \"id\": 5,\n        \"options\": {\n          \"showHeader\": true,\n          \"cellHeight\": \"sm\"\n        },\n        \"pluginVersion\": \"10.0.0\",\n        \"targets\": [\n          {\n            \"expr\": \"sort_desc(directory_size_bytes)\",\n            \"format\": \"table\",\n            \"instant\": true,\n            \"refId\": \"A\"\n          },\n          {\n            \"expr\": \"sort_desc(directory_growth_bytes_per_hour / 1024 / 1024)\",\n            \"format\": \"table\",\n            \"instant\": true,\n            \"refId\": \"B\"\n          }\n        ],\n        \"title\": \"Directory Details\",\n        \"transformations\": [\n          {\n            \"id\": \"merge\",\n            \"options\": {}\n          },\n          {\n            \"id\": \"organize\",\n            \"options\": {\n              \"excludeByName\": {\n                \"Time\": true,\n                \"__name__\": true\n              },\n              \"renameByName\": {\n                \"Value #A\": \"Size\",\n                \"Value #B\": \"Growth (MB/hr)\",\n                \"category\": \"Category\",\n                \"path\": \"Path\"\n              }\n            }\n          }\n        ],\n        \"type\": \"table\"\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"custom\": {\n              \"drawStyle\": \"bars\",\n              \"lineInterpolation\": \"linear\",\n              \"barAlignment\": 0,\n              \"lineWidth\": 1,\n              \"fillOpacity\": 80,\n              \"gradientMode\": \"none\",\n              \"spanNulls\": false,\n              \"showPoints\": \"never\",\n              \"pointSize\": 5,\n              \"stacking\": {\n                \"mode\": \"normal\",\n                \"group\": \"A\"\n              },\n              \"axisPlacement\": \"auto\",\n              \"axisLabel\": \"\",\n              \"axisColorMode\": \"text\",\n              \"scaleDistribution\": {\n                \"type\": \"linear\"\n              },\n              \"axisCenteredZero\": false,\n              \"hideFrom\": {\n                \"tooltip\": false,\n                \"viz\": false,\n                \"legend\": false\n              },\n              \"thresholdsStyle\": {\n                \"mode\": \"off\"\n              }\n            },\n            \"mappings\": [],\n            \"unit\": \"decbytes\"\n          },\n          \"overrides\": []\n        },\n        \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 16},\n        \"id\": 6,\n        \"options\": {\n          \"tooltip\": {\n            \"mode\": \"multi\",\n            \"sort\": \"none\"\n          },\n          \"legend\": {\n            \"showLegend\": true,\n            \"displayMode\": \"list\",\n            \"placement\": \"right\",\n            \"calcs\": []\n          }\n        },\n        \"targets\": [\n          {\n            \"expr\": \"docker_space_usage_bytes\",\n            \"legendFormat\": \"{{type}}\",\n            \"refId\": \"A\"\n          }\n        ],\n        \"title\": \"Docker Space Breakdown\",\n        \"type\": \"timeseries\"\n      }\n    ]\n  }\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"disk-monitoring-dashboard","namespace":"monitoring"}}
    creationTimestamp: "2025-06-08T14:58:03Z"
    name: disk-monitoring-dashboard
    namespace: monitoring
    resourceVersion: "5572998"
    uid: eaf62fd9-1c63-4494-adde-3e562c04162e
- apiVersion: v1
  data:
    disk-space-alerts.yaml: "groups:\n- name: disk_space_alerts\n  interval: 30s\n
      \ rules:\n  # 20% Warning Threshold\n  - alert: DiskSpaceWarning20Percent\n
      \   expr: |\n      (\n        node_filesystem_avail_bytes{fstype!~\"tmpfs|fuse.lxcfs|squashfs|vfat\",mountpoint=\"/\"}
      \n        / node_filesystem_size_bytes{fstype!~\"tmpfs|fuse.lxcfs|squashfs|vfat\",mountpoint=\"/\"}\n
      \     ) * 100 < 20\n    for: 5m\n    labels:\n      severity: warning\n      component:
      system\n      tier: infrastructure\n    annotations:\n      summary: \"Low disk
      space warning on {{ $labels.instance }}\"\n      description: \"Root filesystem
      has only {{ $value | humanize }}% free space remaining on {{ $labels.instance
      }}\"\n      runbook_url: \"https://github.com/odin/runbooks/disk-space\"\n  \n
      \ # 10% Critical Threshold\n  - alert: DiskSpaceCritical10Percent\n    expr:
      |\n      (\n        node_filesystem_avail_bytes{fstype!~\"tmpfs|fuse.lxcfs|squashfs|vfat\",mountpoint=\"/\"}
      \n        / node_filesystem_size_bytes{fstype!~\"tmpfs|fuse.lxcfs|squashfs|vfat\",mountpoint=\"/\"}\n
      \     ) * 100 < 10\n    for: 2m\n    labels:\n      severity: critical\n      component:
      system\n      tier: infrastructure\n    annotations:\n      summary: \"Critical:
      Disk space very low on {{ $labels.instance }}\"\n      description: \"Root filesystem
      has only {{ $value | humanize }}% free space remaining on {{ $labels.instance
      }}. Immediate action required!\"\n      runbook_url: \"https://github.com/odin/runbooks/disk-space\"\n
      \ \n  # 5% Emergency Threshold\n  - alert: DiskSpaceEmergency5Percent\n    expr:
      |\n      (\n        node_filesystem_avail_bytes{fstype!~\"tmpfs|fuse.lxcfs|squashfs|vfat\",mountpoint=\"/\"}
      \n        / node_filesystem_size_bytes{fstype!~\"tmpfs|fuse.lxcfs|squashfs|vfat\",mountpoint=\"/\"}\n
      \     ) * 100 < 5\n    for: 1m\n    labels:\n      severity: critical\n      component:
      system\n      tier: infrastructure\n      emergency: \"true\"\n      page: \"true\"\n
      \   annotations:\n      summary: \"EMERGENCY: Disk space critically low on {{
      $labels.instance }}\"\n      description: \"Root filesystem has only {{ $value
      | humanize }}% free space. System failure imminent! Free space immediately!\"\n
      \     runbook_url: \"https://github.com/odin/runbooks/disk-space-emergency\"\n
      \ \n  # Monitor other important mount points\n  - alert: DataVolumeLowSpace\n
      \   expr: |\n      (\n        node_filesystem_avail_bytes{fstype!~\"tmpfs|fuse.lxcfs|squashfs|vfat\",mountpoint=~\"/var/lib.*|/data.*|/opt.*\"}
      \n        / node_filesystem_size_bytes{fstype!~\"tmpfs|fuse.lxcfs|squashfs|vfat\",mountpoint=~\"/var/lib.*|/data.*|/opt.*\"}\n
      \     ) * 100 < 15\n    for: 5m\n    labels:\n      severity: warning\n      component:
      system\n      tier: infrastructure\n    annotations:\n      summary: \"Data
      volume low on space\"\n      description: \"{{ $labels.mountpoint }} on {{ $labels.instance
      }} has only {{ $value | humanize }}% free space\"\n  \n  # Disk filling up rapidly\n
      \ - alert: DiskFillingUp\n    expr: |\n      (\n        node_filesystem_avail_bytes{fstype!~\"tmpfs|fuse.lxcfs|squashfs|vfat\"}
      \n        / node_filesystem_size_bytes{fstype!~\"tmpfs|fuse.lxcfs|squashfs|vfat\"}\n
      \     ) * 100 < 20 \n      and \n      predict_linear(node_filesystem_avail_bytes{fstype!~\"tmpfs|fuse.lxcfs|squashfs|vfat\"}[6h],
      24*60*60) < 0\n    for: 10m\n    labels:\n      severity: warning\n      component:
      system\n      tier: infrastructure\n    annotations:\n      summary: \"Disk
      will be full within 24 hours\"\n      description: \"{{ $labels.mountpoint }}
      on {{ $labels.instance }} is filling up. At current rate, disk will be full
      within 24 hours.\"\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"disk-space-alerts.yaml":"groups:\n- name: disk_space_alerts\n  interval: 30s\n  rules:\n  # 20% Warning Threshold\n  - alert: DiskSpaceWarning20Percent\n    expr: |\n      (\n        node_filesystem_avail_bytes{fstype!~\"tmpfs|fuse.lxcfs|squashfs|vfat\",mountpoint=\"/\"} \n        / node_filesystem_size_bytes{fstype!~\"tmpfs|fuse.lxcfs|squashfs|vfat\",mountpoint=\"/\"}\n      ) * 100 \u003c 20\n    for: 5m\n    labels:\n      severity: warning\n      component: system\n      tier: infrastructure\n    annotations:\n      summary: \"Low disk space warning on {{ $labels.instance }}\"\n      description: \"Root filesystem has only {{ $value | humanize }}% free space remaining on {{ $labels.instance }}\"\n      runbook_url: \"https://github.com/odin/runbooks/disk-space\"\n  \n  # 10% Critical Threshold\n  - alert: DiskSpaceCritical10Percent\n    expr: |\n      (\n        node_filesystem_avail_bytes{fstype!~\"tmpfs|fuse.lxcfs|squashfs|vfat\",mountpoint=\"/\"} \n        / node_filesystem_size_bytes{fstype!~\"tmpfs|fuse.lxcfs|squashfs|vfat\",mountpoint=\"/\"}\n      ) * 100 \u003c 10\n    for: 2m\n    labels:\n      severity: critical\n      component: system\n      tier: infrastructure\n    annotations:\n      summary: \"Critical: Disk space very low on {{ $labels.instance }}\"\n      description: \"Root filesystem has only {{ $value | humanize }}% free space remaining on {{ $labels.instance }}. Immediate action required!\"\n      runbook_url: \"https://github.com/odin/runbooks/disk-space\"\n  \n  # 5% Emergency Threshold\n  - alert: DiskSpaceEmergency5Percent\n    expr: |\n      (\n        node_filesystem_avail_bytes{fstype!~\"tmpfs|fuse.lxcfs|squashfs|vfat\",mountpoint=\"/\"} \n        / node_filesystem_size_bytes{fstype!~\"tmpfs|fuse.lxcfs|squashfs|vfat\",mountpoint=\"/\"}\n      ) * 100 \u003c 5\n    for: 1m\n    labels:\n      severity: critical\n      component: system\n      tier: infrastructure\n      emergency: \"true\"\n      page: \"true\"\n    annotations:\n      summary: \"EMERGENCY: Disk space critically low on {{ $labels.instance }}\"\n      description: \"Root filesystem has only {{ $value | humanize }}% free space. System failure imminent! Free space immediately!\"\n      runbook_url: \"https://github.com/odin/runbooks/disk-space-emergency\"\n  \n  # Monitor other important mount points\n  - alert: DataVolumeLowSpace\n    expr: |\n      (\n        node_filesystem_avail_bytes{fstype!~\"tmpfs|fuse.lxcfs|squashfs|vfat\",mountpoint=~\"/var/lib.*|/data.*|/opt.*\"} \n        / node_filesystem_size_bytes{fstype!~\"tmpfs|fuse.lxcfs|squashfs|vfat\",mountpoint=~\"/var/lib.*|/data.*|/opt.*\"}\n      ) * 100 \u003c 15\n    for: 5m\n    labels:\n      severity: warning\n      component: system\n      tier: infrastructure\n    annotations:\n      summary: \"Data volume low on space\"\n      description: \"{{ $labels.mountpoint }} on {{ $labels.instance }} has only {{ $value | humanize }}% free space\"\n  \n  # Disk filling up rapidly\n  - alert: DiskFillingUp\n    expr: |\n      (\n        node_filesystem_avail_bytes{fstype!~\"tmpfs|fuse.lxcfs|squashfs|vfat\"} \n        / node_filesystem_size_bytes{fstype!~\"tmpfs|fuse.lxcfs|squashfs|vfat\"}\n      ) * 100 \u003c 20 \n      and \n      predict_linear(node_filesystem_avail_bytes{fstype!~\"tmpfs|fuse.lxcfs|squashfs|vfat\"}[6h], 24*60*60) \u003c 0\n    for: 10m\n    labels:\n      severity: warning\n      component: system\n      tier: infrastructure\n    annotations:\n      summary: \"Disk will be full within 24 hours\"\n      description: \"{{ $labels.mountpoint }} on {{ $labels.instance }} is filling up. At current rate, disk will be full within 24 hours.\"\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"disk-space-alerts","namespace":"monitoring"}}
    creationTimestamp: "2025-06-06T22:36:26Z"
    name: disk-space-alerts
    namespace: monitoring
    resourceVersion: "4502331"
    uid: a5e470db-5576-4ca2-8789-05711bb6dc1f
- apiVersion: v1
  data:
    disk_usage_monitor.py: "#!/usr/bin/env python3\n\"\"\"\nEnhanced Disk Usage Monitor
      for ODIN\nTracks directory-level growth and identifies space consumers\n\"\"\"\nimport
      os\nimport time\nimport json\nimport subprocess\nfrom datetime import datetime,
      timedelta\nfrom prometheus_client import start_http_server, Gauge, Counter,
      Info\nimport logging\nimport sqlite3\nfrom pathlib import Path\nimport asyncio\nimport
      aiohttp\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger('disk-usage-monitor')\n\n#
      Prometheus metrics\ndirectory_size_bytes = Gauge('directory_size_bytes', 'Size
      of directory in bytes', \n                            ['path', 'category'])\ndirectory_growth_rate
      = Gauge('directory_growth_bytes_per_hour', 'Growth rate in bytes/hour', \n                             ['path',
      'category'])\ndirectory_file_count = Gauge('directory_file_count', 'Number of
      files in directory', \n                           ['path', 'category'])\nlargest_files
      = Info('largest_files_info', 'Information about largest files')\ndocker_space_usage
      = Gauge('docker_space_usage_bytes', 'Docker space usage', \n                          ['type'])
      \ # images, containers, volumes, build_cache\nlog_rotation_pending = Gauge('log_files_pending_rotation',
      'Log files over rotation size', \n                           ['directory'])\n\n#
      Configuration\nHOST_ROOT = os.environ.get('HOST_ROOT', '/host')\nMONITORED_PATHS
      = {\n    f'{HOST_ROOT}/var/log': 'logs',\n    f'{HOST_ROOT}/var/lib/docker':
      'docker',\n    f'{HOST_ROOT}/var/lib/containerd': 'containerd',\n    f'{HOST_ROOT}/var/lib/rancher/k3s':
      'k3s',\n    f'{HOST_ROOT}/var/lib/odin': 'odin_data',\n    f'{HOST_ROOT}/var/lib/odin-prime':
      'odin_prime_data',\n    f'{HOST_ROOT}/tmp': 'temp',\n    f'{HOST_ROOT}/home':
      'home',\n    f'{HOST_ROOT}/var/cache': 'cache',\n    f'{HOST_ROOT}/var/lib/prometheus':
      'prometheus',\n    f'{HOST_ROOT}/var/lib/grafana': 'grafana',\n    f'{HOST_ROOT}/var/lib/loki':
      'loki',\n    f'{HOST_ROOT}/var/lib/snapd': 'snapd',\n    f'{HOST_ROOT}/opt':
      'opt',\n    f'{HOST_ROOT}/usr': 'usr',\n    f'{HOST_ROOT}/var/lib': 'var_lib_total'\n}\n\n#
      Size thresholds for alerts\nLARGE_FILE_THRESHOLD = 1 * 1024 * 1024 * 1024  #
      1GB\nLOG_ROTATION_SIZE = 100 * 1024 * 1024  # 100MB\n\nclass DiskUsageMonitor:\n
      \   def __init__(self):\n        self.db_path = '/tmp/disk_usage_history.db'\n
      \       self.init_database()\n        \n    def init_database(self):\n        \"\"\"Initialize
      SQLite database for historical tracking\"\"\"\n        conn = sqlite3.connect(self.db_path)\n
      \       cursor = conn.cursor()\n        cursor.execute('''\n            CREATE
      TABLE IF NOT EXISTS directory_sizes (\n                timestamp INTEGER,\n
      \               path TEXT,\n                size_bytes INTEGER,\n                file_count
      INTEGER,\n                PRIMARY KEY (timestamp, path)\n            )\n        ''')\n
      \       conn.commit()\n        conn.close()\n        \n    def get_directory_size(self,
      path):\n        \"\"\"Get directory size and file count\"\"\"\n        if not
      os.path.exists(path):\n            return 0, 0\n            \n        total_size
      = 0\n        file_count = 0\n        \n        try:\n            # Use du for
      faster results on large directories\n            result = subprocess.run(\n
      \               ['du', '-sb', path], \n                capture_output=True,
      \n                text=True, \n                timeout=30\n            )\n            if
      result.returncode == 0:\n                total_size = int(result.stdout.split()[0])\n
      \           \n            # Count files\n            for root, dirs, files in
      os.walk(path):\n                file_count += len(files)\n                #
      Limit depth for performance\n                if root.count(os.sep) - path.count(os.sep)
      > 3:\n                    dirs.clear()\n                    \n        except
      Exception as e:\n            logger.error(f\"Error scanning {path}: {e}\")\n
      \           \n        return total_size, file_count\n        \n    def find_large_files(self,
      path, limit=10):\n        \"\"\"Find the largest files in a directory\"\"\"\n
      \       large_files = []\n        \n        try:\n            for root, dirs,
      files in os.walk(path):\n                for file in files:\n                    filepath
      = os.path.join(root, file)\n                    try:\n                        size
      = os.path.getsize(filepath)\n                        if size > LARGE_FILE_THRESHOLD:\n
      \                           large_files.append((filepath, size))\n                    except:\n
      \                       pass\n                # Limit depth\n                if
      root.count(os.sep) - path.count(os.sep) > 3:\n                    dirs.clear()\n
      \                   \n            # Sort by size and return top N\n            large_files.sort(key=lambda
      x: x[1], reverse=True)\n            return large_files[:limit]\n            \n
      \       except Exception as e:\n            logger.error(f\"Error finding large
      files in {path}: {e}\")\n            return []\n            \n    def check_log_rotation(self,
      log_dir='/var/log'):\n        \"\"\"Check for log files that need rotation\"\"\"\n
      \       pending_rotation = 0\n        \n        try:\n            for root,
      dirs, files in os.walk(log_dir):\n                for file in files:\n                    if
      file.endswith('.log'):\n                        filepath = os.path.join(root,
      file)\n                        try:\n                            size = os.path.getsize(filepath)\n
      \                           if size > LOG_ROTATION_SIZE:\n                                pending_rotation
      += 1\n                                logger.warning(f\"Large log file: {filepath}
      ({size/1024/1024:.1f}MB)\")\n                        except:\n                            pass\n
      \                           \n        except Exception as e:\n            logger.error(f\"Error
      checking log rotation: {e}\")\n            \n        return pending_rotation\n
      \       \n    def get_docker_usage(self):\n        \"\"\"Get Docker space usage
      breakdown\"\"\"\n        usage = {\n            'images': 0,\n            'containers':
      0,\n            'volumes': 0,\n            'build_cache': 0\n        }\n        \n
      \       try:\n            # Docker system df\n            result = subprocess.run(\n
      \               ['docker', 'system', 'df', '--format', 'json'],\n                capture_output=True,\n
      \               text=True,\n                timeout=10\n            )\n            \n
      \           if result.returncode == 0:\n                data = json.loads(result.stdout)\n
      \               for item in data:\n                    if item['Type'] == 'Images':\n
      \                       usage['images'] = item['Size']\n                    elif
      item['Type'] == 'Containers':\n                        usage['containers'] =
      item['Size']\n                    elif item['Type'] == 'Local Volumes':\n                        usage['volumes']
      = item['Size']\n                    elif item['Type'] == 'Build Cache':\n                        usage['build_cache']
      = item['Size']\n                        \n        except Exception as e:\n            logger.error(f\"Error
      getting Docker usage: {e}\")\n            \n        return usage\n        \n
      \   def calculate_growth_rate(self, path):\n        \"\"\"Calculate growth rate
      from historical data\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        cursor
      = conn.cursor()\n        \n        # Get data from last 24 hours\n        yesterday
      = int((datetime.now() - timedelta(hours=24)).timestamp())\n        cursor.execute('''\n
      \           SELECT timestamp, size_bytes \n            FROM directory_sizes
      \n            WHERE path = ? AND timestamp > ?\n            ORDER BY timestamp\n
      \       ''', (path, yesterday))\n        \n        data = cursor.fetchall()\n
      \       conn.close()\n        \n        if len(data) < 2:\n            return
      0\n            \n        # Calculate average growth rate\n        first_time,
      first_size = data[0]\n        last_time, last_size = data[-1]\n        \n        hours_elapsed
      = (last_time - first_time) / 3600\n        if hours_elapsed > 0:\n            growth_rate
      = (last_size - first_size) / hours_elapsed\n            return growth_rate\n
      \           \n        return 0\n        \n    def store_metrics(self, path,
      size, file_count):\n        \"\"\"Store metrics in database\"\"\"\n        conn
      = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n
      \       timestamp = int(datetime.now().timestamp())\n        cursor.execute('''\n
      \           INSERT OR REPLACE INTO directory_sizes \n            (timestamp,
      path, size_bytes, file_count)\n            VALUES (?, ?, ?, ?)\n        ''',
      (timestamp, path, size, file_count))\n        \n        # Clean up old data
      (keep 7 days)\n        week_ago = int((datetime.now() - timedelta(days=7)).timestamp())\n
      \       cursor.execute('DELETE FROM directory_sizes WHERE timestamp < ?', (week_ago,))\n
      \       \n        conn.commit()\n        conn.close()\n        \n    def update_metrics(self):\n
      \       \"\"\"Update all metrics\"\"\"\n        logger.info(\"Updating disk
      usage metrics...\")\n        \n        # Monitor each configured path\n        for
      path, category in MONITORED_PATHS.items():\n            size, file_count = self.get_directory_size(path)\n
      \           \n            # Strip HOST_ROOT prefix for cleaner metric labels\n
      \           display_path = path.replace(HOST_ROOT, '')\n            \n            #
      Update Prometheus metrics\n            directory_size_bytes.labels(path=display_path,
      category=category).set(size)\n            directory_file_count.labels(path=display_path,
      category=category).set(file_count)\n            \n            # Store in database\n
      \           self.store_metrics(display_path, size, file_count)\n            \n
      \           # Calculate growth rate\n            growth_rate = self.calculate_growth_rate(display_path)\n
      \           directory_growth_rate.labels(path=display_path, category=category).set(growth_rate)\n
      \           \n            logger.info(f\"{display_path}: {size/1024/1024/1024:.2f}GB,
      {file_count} files, \"\n                      f\"growth: {growth_rate/1024/1024:.2f}MB/hour\")\n
      \       \n        # Find largest files\n        all_large_files = []\n        for
      path in [f'{HOST_ROOT}/var/log', f'{HOST_ROOT}/tmp', f'{HOST_ROOT}/home']:\n
      \           large_files = self.find_large_files(path, limit=5)\n            all_large_files.extend(large_files)\n
      \       \n        # Sort and get top 10\n        all_large_files.sort(key=lambda
      x: x[1], reverse=True)\n        top_files = all_large_files[:10]\n        \n
      \       # Update largest files metric\n        files_info = {\n            f\"file_{i}\":
      f\"{filepath}:{size/1024/1024/1024:.2f}GB\"\n            for i, (filepath, size)
      in enumerate(top_files)\n        }\n        largest_files.info(files_info)\n
      \       \n        # Check log rotation\n        pending = self.check_log_rotation()\n
      \       log_rotation_pending.labels(directory='/var/log').set(pending)\n        \n
      \       # Docker usage\n        docker_usage = self.get_docker_usage()\n        for
      usage_type, size in docker_usage.items():\n            docker_space_usage.labels(type=usage_type).set(size)\n
      \           \ndef main():\n    # Start Prometheus metrics server\n    start_http_server(9410)\n
      \   logger.info(\"Disk usage monitor started on port 9410\")\n    \n    monitor
      = DiskUsageMonitor()\n    \n    # Update metrics every 5 minutes\n    while
      True:\n        try:\n            monitor.update_metrics()\n        except Exception
      as e:\n            logger.error(f\"Error updating metrics: {e}\")\n        \n
      \       time.sleep(300)  # 5 minutes\n        \nif __name__ == \"__main__\":\n
      \   main()\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"disk_usage_monitor.py":"#!/usr/bin/env python3\n\"\"\"\nEnhanced Disk Usage Monitor for ODIN\nTracks directory-level growth and identifies space consumers\n\"\"\"\nimport os\nimport time\nimport json\nimport subprocess\nfrom datetime import datetime, timedelta\nfrom prometheus_client import start_http_server, Gauge, Counter, Info\nimport logging\nimport sqlite3\nfrom pathlib import Path\nimport asyncio\nimport aiohttp\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger('disk-usage-monitor')\n\n# Prometheus metrics\ndirectory_size_bytes = Gauge('directory_size_bytes', 'Size of directory in bytes', \n                            ['path', 'category'])\ndirectory_growth_rate = Gauge('directory_growth_bytes_per_hour', 'Growth rate in bytes/hour', \n                             ['path', 'category'])\ndirectory_file_count = Gauge('directory_file_count', 'Number of files in directory', \n                           ['path', 'category'])\nlargest_files = Info('largest_files_info', 'Information about largest files')\ndocker_space_usage = Gauge('docker_space_usage_bytes', 'Docker space usage', \n                          ['type'])  # images, containers, volumes, build_cache\nlog_rotation_pending = Gauge('log_files_pending_rotation', 'Log files over rotation size', \n                           ['directory'])\n\n# Configuration\nHOST_ROOT = os.environ.get('HOST_ROOT', '/host')\nMONITORED_PATHS = {\n    f'{HOST_ROOT}/var/log': 'logs',\n    f'{HOST_ROOT}/var/lib/docker': 'docker',\n    f'{HOST_ROOT}/var/lib/containerd': 'containerd',\n    f'{HOST_ROOT}/var/lib/rancher/k3s': 'k3s',\n    f'{HOST_ROOT}/var/lib/odin': 'odin_data',\n    f'{HOST_ROOT}/var/lib/odin-prime': 'odin_prime_data',\n    f'{HOST_ROOT}/tmp': 'temp',\n    f'{HOST_ROOT}/home': 'home',\n    f'{HOST_ROOT}/var/cache': 'cache',\n    f'{HOST_ROOT}/var/lib/prometheus': 'prometheus',\n    f'{HOST_ROOT}/var/lib/grafana': 'grafana',\n    f'{HOST_ROOT}/var/lib/loki': 'loki',\n    f'{HOST_ROOT}/var/lib/snapd': 'snapd',\n    f'{HOST_ROOT}/opt': 'opt',\n    f'{HOST_ROOT}/usr': 'usr',\n    f'{HOST_ROOT}/var/lib': 'var_lib_total'\n}\n\n# Size thresholds for alerts\nLARGE_FILE_THRESHOLD = 1 * 1024 * 1024 * 1024  # 1GB\nLOG_ROTATION_SIZE = 100 * 1024 * 1024  # 100MB\n\nclass DiskUsageMonitor:\n    def __init__(self):\n        self.db_path = '/tmp/disk_usage_history.db'\n        self.init_database()\n        \n    def init_database(self):\n        \"\"\"Initialize SQLite database for historical tracking\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        cursor.execute('''\n            CREATE TABLE IF NOT EXISTS directory_sizes (\n                timestamp INTEGER,\n                path TEXT,\n                size_bytes INTEGER,\n                file_count INTEGER,\n                PRIMARY KEY (timestamp, path)\n            )\n        ''')\n        conn.commit()\n        conn.close()\n        \n    def get_directory_size(self, path):\n        \"\"\"Get directory size and file count\"\"\"\n        if not os.path.exists(path):\n            return 0, 0\n            \n        total_size = 0\n        file_count = 0\n        \n        try:\n            # Use du for faster results on large directories\n            result = subprocess.run(\n                ['du', '-sb', path], \n                capture_output=True, \n                text=True, \n                timeout=30\n            )\n            if result.returncode == 0:\n                total_size = int(result.stdout.split()[0])\n            \n            # Count files\n            for root, dirs, files in os.walk(path):\n                file_count += len(files)\n                # Limit depth for performance\n                if root.count(os.sep) - path.count(os.sep) \u003e 3:\n                    dirs.clear()\n                    \n        except Exception as e:\n            logger.error(f\"Error scanning {path}: {e}\")\n            \n        return total_size, file_count\n        \n    def find_large_files(self, path, limit=10):\n        \"\"\"Find the largest files in a directory\"\"\"\n        large_files = []\n        \n        try:\n            for root, dirs, files in os.walk(path):\n                for file in files:\n                    filepath = os.path.join(root, file)\n                    try:\n                        size = os.path.getsize(filepath)\n                        if size \u003e LARGE_FILE_THRESHOLD:\n                            large_files.append((filepath, size))\n                    except:\n                        pass\n                # Limit depth\n                if root.count(os.sep) - path.count(os.sep) \u003e 3:\n                    dirs.clear()\n                    \n            # Sort by size and return top N\n            large_files.sort(key=lambda x: x[1], reverse=True)\n            return large_files[:limit]\n            \n        except Exception as e:\n            logger.error(f\"Error finding large files in {path}: {e}\")\n            return []\n            \n    def check_log_rotation(self, log_dir='/var/log'):\n        \"\"\"Check for log files that need rotation\"\"\"\n        pending_rotation = 0\n        \n        try:\n            for root, dirs, files in os.walk(log_dir):\n                for file in files:\n                    if file.endswith('.log'):\n                        filepath = os.path.join(root, file)\n                        try:\n                            size = os.path.getsize(filepath)\n                            if size \u003e LOG_ROTATION_SIZE:\n                                pending_rotation += 1\n                                logger.warning(f\"Large log file: {filepath} ({size/1024/1024:.1f}MB)\")\n                        except:\n                            pass\n                            \n        except Exception as e:\n            logger.error(f\"Error checking log rotation: {e}\")\n            \n        return pending_rotation\n        \n    def get_docker_usage(self):\n        \"\"\"Get Docker space usage breakdown\"\"\"\n        usage = {\n            'images': 0,\n            'containers': 0,\n            'volumes': 0,\n            'build_cache': 0\n        }\n        \n        try:\n            # Docker system df\n            result = subprocess.run(\n                ['docker', 'system', 'df', '--format', 'json'],\n                capture_output=True,\n                text=True,\n                timeout=10\n            )\n            \n            if result.returncode == 0:\n                data = json.loads(result.stdout)\n                for item in data:\n                    if item['Type'] == 'Images':\n                        usage['images'] = item['Size']\n                    elif item['Type'] == 'Containers':\n                        usage['containers'] = item['Size']\n                    elif item['Type'] == 'Local Volumes':\n                        usage['volumes'] = item['Size']\n                    elif item['Type'] == 'Build Cache':\n                        usage['build_cache'] = item['Size']\n                        \n        except Exception as e:\n            logger.error(f\"Error getting Docker usage: {e}\")\n            \n        return usage\n        \n    def calculate_growth_rate(self, path):\n        \"\"\"Calculate growth rate from historical data\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        # Get data from last 24 hours\n        yesterday = int((datetime.now() - timedelta(hours=24)).timestamp())\n        cursor.execute('''\n            SELECT timestamp, size_bytes \n            FROM directory_sizes \n            WHERE path = ? AND timestamp \u003e ?\n            ORDER BY timestamp\n        ''', (path, yesterday))\n        \n        data = cursor.fetchall()\n        conn.close()\n        \n        if len(data) \u003c 2:\n            return 0\n            \n        # Calculate average growth rate\n        first_time, first_size = data[0]\n        last_time, last_size = data[-1]\n        \n        hours_elapsed = (last_time - first_time) / 3600\n        if hours_elapsed \u003e 0:\n            growth_rate = (last_size - first_size) / hours_elapsed\n            return growth_rate\n            \n        return 0\n        \n    def store_metrics(self, path, size, file_count):\n        \"\"\"Store metrics in database\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        timestamp = int(datetime.now().timestamp())\n        cursor.execute('''\n            INSERT OR REPLACE INTO directory_sizes \n            (timestamp, path, size_bytes, file_count)\n            VALUES (?, ?, ?, ?)\n        ''', (timestamp, path, size, file_count))\n        \n        # Clean up old data (keep 7 days)\n        week_ago = int((datetime.now() - timedelta(days=7)).timestamp())\n        cursor.execute('DELETE FROM directory_sizes WHERE timestamp \u003c ?', (week_ago,))\n        \n        conn.commit()\n        conn.close()\n        \n    def update_metrics(self):\n        \"\"\"Update all metrics\"\"\"\n        logger.info(\"Updating disk usage metrics...\")\n        \n        # Monitor each configured path\n        for path, category in MONITORED_PATHS.items():\n            size, file_count = self.get_directory_size(path)\n            \n            # Strip HOST_ROOT prefix for cleaner metric labels\n            display_path = path.replace(HOST_ROOT, '')\n            \n            # Update Prometheus metrics\n            directory_size_bytes.labels(path=display_path, category=category).set(size)\n            directory_file_count.labels(path=display_path, category=category).set(file_count)\n            \n            # Store in database\n            self.store_metrics(display_path, size, file_count)\n            \n            # Calculate growth rate\n            growth_rate = self.calculate_growth_rate(display_path)\n            directory_growth_rate.labels(path=display_path, category=category).set(growth_rate)\n            \n            logger.info(f\"{display_path}: {size/1024/1024/1024:.2f}GB, {file_count} files, \"\n                      f\"growth: {growth_rate/1024/1024:.2f}MB/hour\")\n        \n        # Find largest files\n        all_large_files = []\n        for path in [f'{HOST_ROOT}/var/log', f'{HOST_ROOT}/tmp', f'{HOST_ROOT}/home']:\n            large_files = self.find_large_files(path, limit=5)\n            all_large_files.extend(large_files)\n        \n        # Sort and get top 10\n        all_large_files.sort(key=lambda x: x[1], reverse=True)\n        top_files = all_large_files[:10]\n        \n        # Update largest files metric\n        files_info = {\n            f\"file_{i}\": f\"{filepath}:{size/1024/1024/1024:.2f}GB\"\n            for i, (filepath, size) in enumerate(top_files)\n        }\n        largest_files.info(files_info)\n        \n        # Check log rotation\n        pending = self.check_log_rotation()\n        log_rotation_pending.labels(directory='/var/log').set(pending)\n        \n        # Docker usage\n        docker_usage = self.get_docker_usage()\n        for usage_type, size in docker_usage.items():\n            docker_space_usage.labels(type=usage_type).set(size)\n            \ndef main():\n    # Start Prometheus metrics server\n    start_http_server(9410)\n    logger.info(\"Disk usage monitor started on port 9410\")\n    \n    monitor = DiskUsageMonitor()\n    \n    # Update metrics every 5 minutes\n    while True:\n        try:\n            monitor.update_metrics()\n        except Exception as e:\n            logger.error(f\"Error updating metrics: {e}\")\n        \n        time.sleep(300)  # 5 minutes\n        \nif __name__ == \"__main__\":\n    main()\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"disk-usage-monitor","namespace":"monitoring"}}
    creationTimestamp: "2025-06-08T14:29:32Z"
    name: disk-usage-monitor
    namespace: monitoring
    resourceVersion: "5595252"
    uid: c0e295f2-4fd0-411c-8386-a1ef36c4f1f7
- apiVersion: v1
  data:
    dns-exporter.py: "#!/usr/bin/env python3\nimport time\nimport dns.resolver\nimport
      statistics\nfrom prometheus_client import start_http_server, Histogram, Counter,
      Gauge, Info\n\n# DNS query metrics\ndns_query_duration = Histogram('dns_query_duration_seconds',
      'DNS query response time', ['server', 'domain', 'type'])\ndns_query_success
      = Counter('dns_query_success_total', 'Successful DNS queries', ['server', 'domain',
      'type'])\ndns_query_failure = Counter('dns_query_failure_total', 'Failed DNS
      queries', ['server', 'domain', 'type', 'error'])\ndns_resolver_rtt = Gauge('dns_resolver_rtt_seconds',
      'DNS resolver round-trip time', ['server'])\n\n# Test domains and record types\nTEST_DOMAINS
      = [\n    ('google.com', 'A'),\n    ('cloudflare.com', 'A'),\n    ('github.com',
      'A'),\n    ('8.8.8.8.in-addr.arpa', 'PTR'),\n    ('_sip._tcp.google.com', 'SRV'),\n
      \   ('google.com', 'AAAA')\n]\n\ndef get_system_resolvers():\n    \"\"\"Get
      system DNS resolvers from /etc/resolv.conf\"\"\"\n    resolvers = []\n    try:\n
      \       with open('/etc/resolv.conf', 'r') as f:\n            for line in f:\n
      \               if line.startswith('nameserver'):\n                    resolver_ip
      = line.split()[1]\n                    resolvers.append(resolver_ip)\n    except:\n
      \       resolvers = ['8.8.8.8', '1.1.1.1']  # Fallback\n    return resolvers\n\ndef
      test_dns_performance():\n    \"\"\"Test DNS query performance against configured
      resolvers\"\"\"\n    resolvers = get_system_resolvers()\n    \n    for resolver_ip
      in resolvers:\n        resolver = dns.resolver.Resolver()\n        resolver.nameservers
      = [resolver_ip]\n        resolver.timeout = 5.0\n        resolver.lifetime =
      5.0\n        \n        response_times = []\n        \n        for domain, record_type
      in TEST_DOMAINS:\n            try:\n                start_time = time.time()\n
      \               resolver.resolve(domain, record_type)\n                duration
      = time.time() - start_time\n                \n                dns_query_duration.labels(\n
      \                   server=resolver_ip,\n                    domain=domain,\n
      \                   type=record_type\n                ).observe(duration)\n
      \               \n                dns_query_success.labels(\n                    server=resolver_ip,\n
      \                   domain=domain,\n                    type=record_type\n                ).inc()\n
      \               \n                response_times.append(duration)\n                \n
      \           except dns.resolver.NXDOMAIN:\n                dns_query_failure.labels(\n
      \                   server=resolver_ip,\n                    domain=domain,\n
      \                   type=record_type,\n                    error='NXDOMAIN'\n
      \               ).inc()\n            except dns.resolver.Timeout:\n                dns_query_failure.labels(\n
      \                   server=resolver_ip,\n                    domain=domain,\n
      \                   type=record_type,\n                    error='TIMEOUT'\n
      \               ).inc()\n            except Exception as e:\n                dns_query_failure.labels(\n
      \                   server=resolver_ip,\n                    domain=domain,\n
      \                   type=record_type,\n                    error=type(e).__name__\n
      \               ).inc()\n        \n        # Update average RTT for this resolver\n
      \       if response_times:\n            avg_rtt = statistics.mean(response_times)\n
      \           dns_resolver_rtt.labels(server=resolver_ip).set(avg_rtt)\n\nif __name__
      == '__main__':\n    # Start Prometheus metrics server\n    start_http_server(9405)\n
      \   print(\"DNS exporter started on port 9405\")\n    \n    # Test DNS performance
      every 30 seconds\n    while True:\n        try:\n            test_dns_performance()\n
      \       except Exception as e:\n            print(f\"Error testing DNS: {e}\")\n
      \       time.sleep(30)\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"dns-exporter.py":"#!/usr/bin/env python3\nimport time\nimport dns.resolver\nimport statistics\nfrom prometheus_client import start_http_server, Histogram, Counter, Gauge, Info\n\n# DNS query metrics\ndns_query_duration = Histogram('dns_query_duration_seconds', 'DNS query response time', ['server', 'domain', 'type'])\ndns_query_success = Counter('dns_query_success_total', 'Successful DNS queries', ['server', 'domain', 'type'])\ndns_query_failure = Counter('dns_query_failure_total', 'Failed DNS queries', ['server', 'domain', 'type', 'error'])\ndns_resolver_rtt = Gauge('dns_resolver_rtt_seconds', 'DNS resolver round-trip time', ['server'])\n\n# Test domains and record types\nTEST_DOMAINS = [\n    ('google.com', 'A'),\n    ('cloudflare.com', 'A'),\n    ('github.com', 'A'),\n    ('8.8.8.8.in-addr.arpa', 'PTR'),\n    ('_sip._tcp.google.com', 'SRV'),\n    ('google.com', 'AAAA')\n]\n\ndef get_system_resolvers():\n    \"\"\"Get system DNS resolvers from /etc/resolv.conf\"\"\"\n    resolvers = []\n    try:\n        with open('/etc/resolv.conf', 'r') as f:\n            for line in f:\n                if line.startswith('nameserver'):\n                    resolver_ip = line.split()[1]\n                    resolvers.append(resolver_ip)\n    except:\n        resolvers = ['8.8.8.8', '1.1.1.1']  # Fallback\n    return resolvers\n\ndef test_dns_performance():\n    \"\"\"Test DNS query performance against configured resolvers\"\"\"\n    resolvers = get_system_resolvers()\n    \n    for resolver_ip in resolvers:\n        resolver = dns.resolver.Resolver()\n        resolver.nameservers = [resolver_ip]\n        resolver.timeout = 5.0\n        resolver.lifetime = 5.0\n        \n        response_times = []\n        \n        for domain, record_type in TEST_DOMAINS:\n            try:\n                start_time = time.time()\n                resolver.resolve(domain, record_type)\n                duration = time.time() - start_time\n                \n                dns_query_duration.labels(\n                    server=resolver_ip,\n                    domain=domain,\n                    type=record_type\n                ).observe(duration)\n                \n                dns_query_success.labels(\n                    server=resolver_ip,\n                    domain=domain,\n                    type=record_type\n                ).inc()\n                \n                response_times.append(duration)\n                \n            except dns.resolver.NXDOMAIN:\n                dns_query_failure.labels(\n                    server=resolver_ip,\n                    domain=domain,\n                    type=record_type,\n                    error='NXDOMAIN'\n                ).inc()\n            except dns.resolver.Timeout:\n                dns_query_failure.labels(\n                    server=resolver_ip,\n                    domain=domain,\n                    type=record_type,\n                    error='TIMEOUT'\n                ).inc()\n            except Exception as e:\n                dns_query_failure.labels(\n                    server=resolver_ip,\n                    domain=domain,\n                    type=record_type,\n                    error=type(e).__name__\n                ).inc()\n        \n        # Update average RTT for this resolver\n        if response_times:\n            avg_rtt = statistics.mean(response_times)\n            dns_resolver_rtt.labels(server=resolver_ip).set(avg_rtt)\n\nif __name__ == '__main__':\n    # Start Prometheus metrics server\n    start_http_server(9405)\n    print(\"DNS exporter started on port 9405\")\n    \n    # Test DNS performance every 30 seconds\n    while True:\n        try:\n            test_dns_performance()\n        except Exception as e:\n            print(f\"Error testing DNS: {e}\")\n        time.sleep(30)\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"dns-exporter-script","namespace":"monitoring"}}
    creationTimestamp: "2025-05-29T20:52:41Z"
    name: dns-exporter-script
    namespace: monitoring
    resourceVersion: "81744"
    uid: 3f29cd71-7572-43e4-8757-d11d2cc1f446
- apiVersion: v1
  data:
    email_bridge.py: "#!/usr/bin/env python3\nimport smtplib\nimport json\nimport
      logging\nfrom datetime import datetime\nfrom email.mime.text import MIMEText\nfrom
      email.mime.multipart import MIMEMultipart\nfrom http.server import HTTPServer,
      BaseHTTPRequestHandler\nimport threading\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO,
      format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger('email-bridge')\n\n#
      Email configuration\nSMTP_HOST = 'smtp.gmail.com'\nSMTP_PORT = 587\nFROM_EMAIL
      = 'odin-alerts@gmail.com'\nTO_EMAIL = 'jason.holt@andominia.com'\nUSERNAME =
      'jason.holt@andominia.com'\nPASSWORD = 'dhmw fxpu zhyf oacw'  # Generate at:
      https://myaccount.google.com/apppasswords\n\ndef send_email(subject, body):\n
      \   \"\"\"Send email via Gmail SMTP\"\"\"\n    try:\n        msg = MIMEMultipart()\n
      \       msg['From'] = FROM_EMAIL\n        msg['To'] = TO_EMAIL\n        msg['Subject']
      = subject\n        \n        msg.attach(MIMEText(body, 'plain'))\n        \n
      \       server = smtplib.SMTP(SMTP_HOST, SMTP_PORT)\n        server.starttls()\n
      \       server.login(USERNAME, PASSWORD)\n        text = msg.as_string()\n        server.sendmail(FROM_EMAIL,
      TO_EMAIL, text)\n        server.quit()\n        \n        logger.info(f\"Email
      sent successfully: {subject}\")\n        return True\n        \n    except Exception
      as e:\n        logger.error(f\"Failed to send email: {e}\")\n        return
      False\n\ndef format_alert_email(alerts_data):\n    \"\"\"Format alert data into
      readable email\"\"\"\n    try:\n        alerts = json.loads(alerts_data)\n        \n
      \       if not alerts.get('alerts'):\n            return None, None\n            \n
      \       # Get first alert for subject\n        first_alert = alerts['alerts'][0]\n
      \       alertname = first_alert['labels'].get('alertname', 'Unknown Alert')\n
      \       \n        subject = f\"\U0001F6A8 ODIN Alert: {alertname}\"\n        \n
      \       # Build email body\n        body_lines = [\n            \"ODIN Monitoring
      Alert\",\n            \"=\" * 50,\n            f\"Time: {datetime.now().strftime('%Y-%m-%d
      %H:%M:%S')}\",\n            f\"Status: {alerts.get('status', 'Unknown')}\",\n
      \           \"\"\n        ]\n        \n        for i, alert in enumerate(alerts['alerts'],
      1):\n            labels = alert.get('labels', {})\n            annotations =
      alert.get('annotations', {})\n            \n            body_lines.extend([\n
      \               f\"Alert #{i}: {labels.get('alertname', 'Unknown')}\",\n                f\"Severity:
      {labels.get('severity', 'Unknown')}\",\n                f\"Summary: {annotations.get('summary',
      'No summary')}\",\n                f\"Description: {annotations.get('description',
      'No description')}\",\n                \"\"\n            ])\n            \n
      \           # Add relevant labels\n            if labels.get('instance'):\n
      \               body_lines.append(f\"Instance: {labels['instance']}\")\n            if
      labels.get('service'):\n                body_lines.append(f\"Service: {labels['service']}\")\n
      \           if labels.get('pod'):\n                body_lines.append(f\"Pod:
      {labels['pod']}\")\n            if labels.get('namespace'):\n                body_lines.append(f\"Namespace:
      {labels['namespace']}\")\n                \n            body_lines.append(\"-\"
      * 30)\n            \n        body_lines.extend([\n            \"\",\n            \"Quick
      Links:\",\n            \"• Grafana: http://localhost:31494\",\n            \"•
      Prometheus: http://localhost:31493\", \n            \"• AlertManager: http://localhost:31495\"\n
      \       ])\n        \n        return subject, \"\\n\".join(body_lines)\n        \n
      \   except Exception as e:\n        logger.error(f\"Failed to format alert email:
      {e}\")\n        return f\"ODIN Alert - Parse Error\", f\"Failed to parse alert
      data: {e}\"\n\nclass EmailBridgeHandler(BaseHTTPRequestHandler):\n    \"\"\"HTTP
      handler for webhook alerts\"\"\"\n    \n    def do_POST(self):\n        try:\n
      \           content_length = int(self.headers['Content-Length'])\n            post_data
      = self.rfile.read(content_length)\n            \n            # Parse alert data\n
      \           alert_data = post_data.decode('utf-8')\n            logger.info(f\"Received
      alert webhook: {len(alert_data)} bytes\")\n            \n            # Format
      and send email\n            subject, body = format_alert_email(alert_data)\n
      \           \n            if subject and body:\n                success = send_email(subject,
      body)\n                \n                if success:\n                    self.send_response(200)\n
      \                   self.send_header('Content-Type', 'text/plain')\n                    self.end_headers()\n
      \                   self.wfile.write(b'Email sent successfully')\n                else:\n
      \                   self.send_response(500)\n                    self.send_header('Content-Type',
      'text/plain')\n                    self.end_headers()\n                    self.wfile.write(b'Failed
      to send email')\n            else:\n                self.send_response(400)\n
      \               self.send_header('Content-Type', 'text/plain')\n                self.end_headers()\n
      \               self.wfile.write(b'Invalid alert data')\n                \n
      \       except Exception as e:\n            logger.error(f\"Error processing
      webhook: {e}\")\n            self.send_response(500)\n            self.send_header('Content-Type',
      'text/plain')\n            self.end_headers()\n            self.wfile.write(f'Error:
      {str(e)}'.encode())\n    \n    def do_GET(self):\n        if self.path == '/health':\n
      \           self.send_response(200)\n            self.send_header('Content-Type',
      'text/plain')\n            self.end_headers()\n            self.wfile.write(b'Email
      bridge healthy')\n        else:\n            self.send_response(404)\n            self.end_headers()\n
      \   \n    def log_message(self, format, *args):\n        # Custom logging to
      avoid spam\n        pass\n\ndef main():\n    logger.info(\"Starting ODIN Email
      Bridge on port 8081\")\n    \n    server = HTTPServer(('0.0.0.0', 8081), EmailBridgeHandler)\n
      \   server.serve_forever()\n\nif __name__ == '__main__':\n    main()\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: "{\"apiVersion\":\"v1\",\"data\":{\"email_bridge.py\":\"#!/usr/bin/env
        python3\\nimport smtplib\\nimport json\\nimport logging\\nfrom datetime import
        datetime\\nfrom email.mime.text import MIMEText\\nfrom email.mime.multipart
        import MIMEMultipart\\nfrom http.server import HTTPServer, BaseHTTPRequestHandler\\nimport
        threading\\n\\n# Configure logging\\nlogging.basicConfig(level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s')\\nlogger = logging.getLogger('email-bridge')\\n\\n#
        Email configuration\\nSMTP_HOST = 'smtp.gmail.com'\\nSMTP_PORT = 587\\nFROM_EMAIL
        = 'odin-alerts@gmail.com'\\nTO_EMAIL = 'jason.holt@andominia.com'\\nUSERNAME
        = 'jason.holt@andominia.com'\\nPASSWORD = 'dhmw fxpu zhyf oacw'  # Generate
        at: https://myaccount.google.com/apppasswords\\n\\ndef send_email(subject,
        body):\\n    \\\"\\\"\\\"Send email via Gmail SMTP\\\"\\\"\\\"\\n    try:\\n
        \       msg = MIMEMultipart()\\n        msg['From'] = FROM_EMAIL\\n        msg['To']
        = TO_EMAIL\\n        msg['Subject'] = subject\\n        \\n        msg.attach(MIMEText(body,
        'plain'))\\n        \\n        server = smtplib.SMTP(SMTP_HOST, SMTP_PORT)\\n
        \       server.starttls()\\n        server.login(USERNAME, PASSWORD)\\n        text
        = msg.as_string()\\n        server.sendmail(FROM_EMAIL, TO_EMAIL, text)\\n
        \       server.quit()\\n        \\n        logger.info(f\\\"Email sent successfully:
        {subject}\\\")\\n        return True\\n        \\n    except Exception as
        e:\\n        logger.error(f\\\"Failed to send email: {e}\\\")\\n        return
        False\\n\\ndef format_alert_email(alerts_data):\\n    \\\"\\\"\\\"Format alert
        data into readable email\\\"\\\"\\\"\\n    try:\\n        alerts = json.loads(alerts_data)\\n
        \       \\n        if not alerts.get('alerts'):\\n            return None,
        None\\n            \\n        # Get first alert for subject\\n        first_alert
        = alerts['alerts'][0]\\n        alertname = first_alert['labels'].get('alertname',
        'Unknown Alert')\\n        \\n        subject = f\\\"\U0001F6A8 ODIN Alert:
        {alertname}\\\"\\n        \\n        # Build email body\\n        body_lines
        = [\\n            \\\"ODIN Monitoring Alert\\\",\\n            \\\"=\\\" *
        50,\\n            f\\\"Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\\",\\n
        \           f\\\"Status: {alerts.get('status', 'Unknown')}\\\",\\n            \\\"\\\"\\n
        \       ]\\n        \\n        for i, alert in enumerate(alerts['alerts'],
        1):\\n            labels = alert.get('labels', {})\\n            annotations
        = alert.get('annotations', {})\\n            \\n            body_lines.extend([\\n
        \               f\\\"Alert #{i}: {labels.get('alertname', 'Unknown')}\\\",\\n
        \               f\\\"Severity: {labels.get('severity', 'Unknown')}\\\",\\n
        \               f\\\"Summary: {annotations.get('summary', 'No summary')}\\\",\\n
        \               f\\\"Description: {annotations.get('description', 'No description')}\\\",\\n
        \               \\\"\\\"\\n            ])\\n            \\n            # Add
        relevant labels\\n            if labels.get('instance'):\\n                body_lines.append(f\\\"Instance:
        {labels['instance']}\\\")\\n            if labels.get('service'):\\n                body_lines.append(f\\\"Service:
        {labels['service']}\\\")\\n            if labels.get('pod'):\\n                body_lines.append(f\\\"Pod:
        {labels['pod']}\\\")\\n            if labels.get('namespace'):\\n                body_lines.append(f\\\"Namespace:
        {labels['namespace']}\\\")\\n                \\n            body_lines.append(\\\"-\\\"
        * 30)\\n            \\n        body_lines.extend([\\n            \\\"\\\",\\n
        \           \\\"Quick Links:\\\",\\n            \\\"• Grafana: http://localhost:31494\\\",\\n
        \           \\\"• Prometheus: http://localhost:31493\\\", \\n            \\\"•
        AlertManager: http://localhost:31495\\\"\\n        ])\\n        \\n        return
        subject, \\\"\\\\n\\\".join(body_lines)\\n        \\n    except Exception
        as e:\\n        logger.error(f\\\"Failed to format alert email: {e}\\\")\\n
        \       return f\\\"ODIN Alert - Parse Error\\\", f\\\"Failed to parse alert
        data: {e}\\\"\\n\\nclass EmailBridgeHandler(BaseHTTPRequestHandler):\\n    \\\"\\\"\\\"HTTP
        handler for webhook alerts\\\"\\\"\\\"\\n    \\n    def do_POST(self):\\n
        \       try:\\n            content_length = int(self.headers['Content-Length'])\\n
        \           post_data = self.rfile.read(content_length)\\n            \\n
        \           # Parse alert data\\n            alert_data = post_data.decode('utf-8')\\n
        \           logger.info(f\\\"Received alert webhook: {len(alert_data)} bytes\\\")\\n
        \           \\n            # Format and send email\\n            subject,
        body = format_alert_email(alert_data)\\n            \\n            if subject
        and body:\\n                success = send_email(subject, body)\\n                \\n
        \               if success:\\n                    self.send_response(200)\\n
        \                   self.send_header('Content-Type', 'text/plain')\\n                    self.end_headers()\\n
        \                   self.wfile.write(b'Email sent successfully')\\n                else:\\n
        \                   self.send_response(500)\\n                    self.send_header('Content-Type',
        'text/plain')\\n                    self.end_headers()\\n                    self.wfile.write(b'Failed
        to send email')\\n            else:\\n                self.send_response(400)\\n
        \               self.send_header('Content-Type', 'text/plain')\\n                self.end_headers()\\n
        \               self.wfile.write(b'Invalid alert data')\\n                \\n
        \       except Exception as e:\\n            logger.error(f\\\"Error processing
        webhook: {e}\\\")\\n            self.send_response(500)\\n            self.send_header('Content-Type',
        'text/plain')\\n            self.end_headers()\\n            self.wfile.write(f'Error:
        {str(e)}'.encode())\\n    \\n    def do_GET(self):\\n        if self.path
        == '/health':\\n            self.send_response(200)\\n            self.send_header('Content-Type',
        'text/plain')\\n            self.end_headers()\\n            self.wfile.write(b'Email
        bridge healthy')\\n        else:\\n            self.send_response(404)\\n
        \           self.end_headers()\\n    \\n    def log_message(self, format,
        *args):\\n        # Custom logging to avoid spam\\n        pass\\n\\ndef main():\\n
        \   logger.info(\\\"Starting ODIN Email Bridge on port 8081\\\")\\n    \\n
        \   server = HTTPServer(('0.0.0.0', 8081), EmailBridgeHandler)\\n    server.serve_forever()\\n\\nif
        __name__ == '__main__':\\n    main()\\n\"},\"kind\":\"ConfigMap\",\"metadata\":{\"annotations\":{},\"name\":\"email-bridge-script\",\"namespace\":\"monitoring\"}}\n"
    creationTimestamp: "2025-06-01T15:28:58Z"
    name: email-bridge-script
    namespace: monitoring
    resourceVersion: "1167745"
    uid: 52b75094-f5da-4487-95e9-9ce8f95691ee
- apiVersion: v1
  data:
    enhanced-disk-alerts.yaml: "groups:\n- name: enhanced_disk_monitoring\n  interval:
      30s\n  rules:\n  # Directory-specific growth alerts\n  - alert: LogDirectoryGrowthHigh\n
      \   expr: |\n      directory_growth_bytes_per_hour{category=\"logs\"} > 1073741824
      \ # 1GB/hour\n    for: 30m\n    labels:\n      severity: warning\n      component:
      disk\n      category: logs\n    annotations:\n      summary: \"Log directory
      growing rapidly\"\n      description: \"/var/log is growing at {{ $value | humanizeDuration
      }}/hour on {{ $labels.instance }}\"\n      suggested_action: \"Check for verbose
      logging or failed log rotation\"\n  \n  - alert: DockerSpaceHighUsage\n    expr:
      |\n      docker_space_usage_bytes{type=\"images\"} > 50000000000  # 50GB\n    for:
      10m\n    labels:\n      severity: warning\n      component: docker\n      category:
      storage\n    annotations:\n      summary: \"Docker images using excessive space\"\n
      \     description: \"Docker images using {{ $value | humanize1024 }}B. Run 'docker
      image prune -a' to clean unused images\"\n  \n  - alert: DockerBuildCacheHigh\n
      \   expr: |\n      docker_space_usage_bytes{type=\"build_cache\"} > 10000000000
      \ # 10GB\n    for: 10m\n    labels:\n      severity: warning\n      component:
      docker\n      category: storage\n    annotations:\n      summary: \"Docker build
      cache is large\"\n      description: \"Docker build cache using {{ $value |
      humanize1024 }}B. Run 'docker builder prune' to clean\"\n  \n  - alert: TempDirectoryLarge\n
      \   expr: |\n      directory_size_bytes{category=\"temp\"} > 5368709120  # 5GB\n
      \   for: 15m\n    labels:\n      severity: warning\n      component: disk\n
      \     category: temp\n    annotations:\n      summary: \"Temp directory using
      excessive space\"\n      description: \"/tmp is using {{ $value | humanize1024
      }}B. Clean up temporary files\"\n  \n  - alert: LogFilesNeedRotation\n    expr:
      |\n      log_files_pending_rotation > 5\n    for: 30m\n    labels:\n      severity:
      warning\n      component: logs\n    annotations:\n      summary: \"Multiple
      log files need rotation\"\n      description: \"{{ $value }} log files exceed
      rotation size. Check logrotate configuration\"\n  \n  # Predictive alerts based
      on growth rate\n  - alert: DiskWillFillIn3Days\n    expr: |\n      (node_filesystem_avail_bytes{mountpoint=\"/\"}
      / directory_growth_bytes_per_hour{path=\"/\"}) < 72\n      and directory_growth_bytes_per_hour{path=\"/\"}
      > 0\n    for: 1h\n    labels:\n      severity: warning\n      component: disk\n
      \     predictive: \"true\"\n    annotations:\n      summary: \"Root disk will
      be full in less than 3 days\"\n      description: \"At current growth rate of
      {{ $labels.directory_growth_bytes_per_hour | humanize1024 }}B/hour, disk will
      be full in {{ $value }} hours\"\n  \n  - alert: PrometheusDataGrowthHigh\n    expr:
      |\n      directory_growth_bytes_per_hour{category=\"prometheus\"} > 536870912
      \ # 500MB/hour\n    for: 1h\n    labels:\n      severity: warning\n      component:
      prometheus\n    annotations:\n      summary: \"Prometheus data growing rapidly\"\n
      \     description: \"Prometheus data growing at {{ $value | humanize1024 }}B/hour.
      Consider adjusting retention or cardinality\"\n  \n  - alert: LokiDataGrowthHigh\n
      \   expr: |\n      directory_growth_bytes_per_hour{category=\"loki\"} > 1073741824
      \ # 1GB/hour\n    for: 1h\n    labels:\n      severity: warning\n      component:
      loki\n    annotations:\n      summary: \"Loki log data growing rapidly\"\n      description:
      \"Loki data growing at {{ $value | humanize1024 }}B/hour. Check log volume and
      retention policy\"\n  \n  # ODIN-specific alerts\n  - alert: ODINDataVolumeHigh\n
      \   expr: |\n      (directory_size_bytes{category=~\"odin.*\"} / 1073741824)
      > 10  # 10GB\n    for: 30m\n    labels:\n      severity: warning\n      component:
      odin\n    annotations:\n      summary: \"ODIN data volume high\"\n      description:
      \"{{ $labels.path }} is using {{ $value | humanize1024 }}B\"\n  \n  # Critical
      space consumers\n  - alert: SingleFileOverGB\n    expr: |\n      changes(largest_files_info[1h])
      > 0\n    labels:\n      severity: info\n      component: disk\n    annotations:\n
      \     summary: \"Large files detected on system\"\n      description: \"Check
      largest_files_info metric for files over 1GB\"\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"enhanced-disk-alerts.yaml":"groups:\n- name: enhanced_disk_monitoring\n  interval: 30s\n  rules:\n  # Directory-specific growth alerts\n  - alert: LogDirectoryGrowthHigh\n    expr: |\n      directory_growth_bytes_per_hour{category=\"logs\"} \u003e 1073741824  # 1GB/hour\n    for: 30m\n    labels:\n      severity: warning\n      component: disk\n      category: logs\n    annotations:\n      summary: \"Log directory growing rapidly\"\n      description: \"/var/log is growing at {{ $value | humanizeDuration }}/hour on {{ $labels.instance }}\"\n      suggested_action: \"Check for verbose logging or failed log rotation\"\n  \n  - alert: DockerSpaceHighUsage\n    expr: |\n      docker_space_usage_bytes{type=\"images\"} \u003e 50000000000  # 50GB\n    for: 10m\n    labels:\n      severity: warning\n      component: docker\n      category: storage\n    annotations:\n      summary: \"Docker images using excessive space\"\n      description: \"Docker images using {{ $value | humanize1024 }}B. Run 'docker image prune -a' to clean unused images\"\n  \n  - alert: DockerBuildCacheHigh\n    expr: |\n      docker_space_usage_bytes{type=\"build_cache\"} \u003e 10000000000  # 10GB\n    for: 10m\n    labels:\n      severity: warning\n      component: docker\n      category: storage\n    annotations:\n      summary: \"Docker build cache is large\"\n      description: \"Docker build cache using {{ $value | humanize1024 }}B. Run 'docker builder prune' to clean\"\n  \n  - alert: TempDirectoryLarge\n    expr: |\n      directory_size_bytes{category=\"temp\"} \u003e 5368709120  # 5GB\n    for: 15m\n    labels:\n      severity: warning\n      component: disk\n      category: temp\n    annotations:\n      summary: \"Temp directory using excessive space\"\n      description: \"/tmp is using {{ $value | humanize1024 }}B. Clean up temporary files\"\n  \n  - alert: LogFilesNeedRotation\n    expr: |\n      log_files_pending_rotation \u003e 5\n    for: 30m\n    labels:\n      severity: warning\n      component: logs\n    annotations:\n      summary: \"Multiple log files need rotation\"\n      description: \"{{ $value }} log files exceed rotation size. Check logrotate configuration\"\n  \n  # Predictive alerts based on growth rate\n  - alert: DiskWillFillIn3Days\n    expr: |\n      (node_filesystem_avail_bytes{mountpoint=\"/\"} / directory_growth_bytes_per_hour{path=\"/\"}) \u003c 72\n      and directory_growth_bytes_per_hour{path=\"/\"} \u003e 0\n    for: 1h\n    labels:\n      severity: warning\n      component: disk\n      predictive: \"true\"\n    annotations:\n      summary: \"Root disk will be full in less than 3 days\"\n      description: \"At current growth rate of {{ $labels.directory_growth_bytes_per_hour | humanize1024 }}B/hour, disk will be full in {{ $value }} hours\"\n  \n  - alert: PrometheusDataGrowthHigh\n    expr: |\n      directory_growth_bytes_per_hour{category=\"prometheus\"} \u003e 536870912  # 500MB/hour\n    for: 1h\n    labels:\n      severity: warning\n      component: prometheus\n    annotations:\n      summary: \"Prometheus data growing rapidly\"\n      description: \"Prometheus data growing at {{ $value | humanize1024 }}B/hour. Consider adjusting retention or cardinality\"\n  \n  - alert: LokiDataGrowthHigh\n    expr: |\n      directory_growth_bytes_per_hour{category=\"loki\"} \u003e 1073741824  # 1GB/hour\n    for: 1h\n    labels:\n      severity: warning\n      component: loki\n    annotations:\n      summary: \"Loki log data growing rapidly\"\n      description: \"Loki data growing at {{ $value | humanize1024 }}B/hour. Check log volume and retention policy\"\n  \n  # ODIN-specific alerts\n  - alert: ODINDataVolumeHigh\n    expr: |\n      (directory_size_bytes{category=~\"odin.*\"} / 1073741824) \u003e 10  # 10GB\n    for: 30m\n    labels:\n      severity: warning\n      component: odin\n    annotations:\n      summary: \"ODIN data volume high\"\n      description: \"{{ $labels.path }} is using {{ $value | humanize1024 }}B\"\n  \n  # Critical space consumers\n  - alert: SingleFileOverGB\n    expr: |\n      changes(largest_files_info[1h]) \u003e 0\n    labels:\n      severity: info\n      component: disk\n    annotations:\n      summary: \"Large files detected on system\"\n      description: \"Check largest_files_info metric for files over 1GB\"\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"enhanced-disk-alerts","namespace":"monitoring"}}
    creationTimestamp: "2025-06-08T14:29:53Z"
    name: enhanced-disk-alerts
    namespace: monitoring
    resourceVersion: "5560613"
    uid: fcc48f31-8c05-4539-b7d9-99be23e54d81
- apiVersion: v1
  data:
    enhanced-monitoring-rules.yml: "groups:\n- name: monitoring-stack-enhanced\n  rules:\n
      \ # Enhanced Pod Monitoring\n  - alert: PodOOMKilledEnhanced\n    expr: kube_pod_container_status_last_terminated_reason{reason=\"OOMKilled\"}
      == 1\n    for: 0m\n    labels:\n      severity: critical\n      component: monitoring-stack\n
      \   annotations:\n      summary: \"Pod {{ $labels.pod }} was OOM killed\"\n
      \     description: |\n        Pod {{ $labels.namespace }}/{{ $labels.pod }}
      container {{ $labels.container }} was OOM killed.\n        This indicates memory
      limits are too low or there's a memory leak.\n        \n        Current memory
      limit: {{ $labels.memory_limit }}\n        Restart count: {{ $labels.restart_count
      }}\n        \n  - alert: PodCrashLoopEnhanced\n    expr: rate(kube_pod_container_status_restarts_total[15m])
      > 0\n    for: 2m\n    labels:\n      severity: warning\n      component: monitoring-stack\n
      \   annotations:\n      summary: \"Pod {{ $labels.pod }} is crash looping\"\n
      \     description: |\n        Pod {{ $labels.namespace }}/{{ $labels.pod }}
      container {{ $labels.container }} is restarting frequently.\n        Restart
      rate: {{ $value }} restarts/minute over 15 minutes.\n        \n  - alert: MonitoringComponentDown\n
      \   expr: up{job=~\"prometheus|grafana|loki|alertmanager\"} == 0\n    for: 1m\n
      \   labels:\n      severity: critical\n      component: monitoring-stack\n    annotations:\n
      \     summary: \"Monitoring component {{ $labels.job }} is down\"\n      description:
      |\n        Critical monitoring component {{ $labels.job }} on {{ $labels.instance
      }} is down.\n        This affects overall monitoring capabilities.\n        \n
      \ # ML Anomaly Detection Alerts\n  - alert: AnomalyDetectorDown\n    expr: up{job=~\".*anomaly.*detector.*\"}
      == 0\n    for: 2m\n    labels:\n      severity: warning\n      component: ml-detection\n
      \   annotations:\n      summary: \"Anomaly detector {{ $labels.job }} is down\"\n
      \     description: |\n        ML anomaly detector {{ $labels.job }} is not responding.\n
      \       This affects intelligent anomaly detection capabilities.\n        \n
      \ - alert: HighAnomalyScore\n    expr: anomaly_score > 85\n    for: 5m\n    labels:\n
      \     severity: warning\n      component: ml-detection\n    annotations:\n      summary:
      \"High anomaly score detected\"\n      description: |\n        Anomaly score
      for {{ $labels.metric_name }} is {{ $value }}/100.\n        This indicates unusual
      behavior that requires investigation.\n        Algorithm: {{ $labels.algorithm
      }}\n        \n  - alert: AnomalyDetectionErrors\n    expr: increase(anomaly_detection_errors_total[1h])
      > 10\n    for: 0m\n    labels:\n      severity: warning\n      component: ml-detection\n
      \   annotations:\n      summary: \"Multiple anomaly detection errors\"\n      description:
      |\n        {{ $value }} anomaly detection errors in the last hour for {{ $labels.metric_type
      }}.\n        This may indicate issues with ML model training or data quality.\n
      \       \n  # Resource Monitoring Enhanced\n  - alert: PodHighMemoryUsage\n
      \   expr: (container_memory_working_set_bytes / container_spec_memory_limit_bytes)
      * 100 > 90\n    for: 5m\n    labels:\n      severity: warning\n      component:
      monitoring-stack\n    annotations:\n      summary: \"Pod {{ $labels.pod }} high
      memory usage\"\n      description: |\n        Pod {{ $labels.namespace }}/{{
      $labels.pod }} is using {{ $value }}% of memory limit.\n        Current usage:
      {{ $labels.memory_usage }}\n        Memory limit: {{ $labels.memory_limit }}\n
      \       \n  - alert: PodHighCPUUsage\n    expr: (rate(container_cpu_usage_seconds_total[5m])
      / container_spec_cpu_quota * container_spec_cpu_period) * 100 > 90\n    for:
      10m\n    labels:\n      severity: warning\n      component: monitoring-stack\n
      \   annotations:\n      summary: \"Pod {{ $labels.pod }} high CPU usage\"\n
      \     description: |\n        Pod {{ $labels.namespace }}/{{ $labels.pod }}
      is using {{ $value }}% of CPU limit.\n        This sustained high usage may
      affect performance.\n        \n  # GPU Monitoring Enhanced\n  - alert: GPUHighTemperature\n
      \   expr: nvidia_gpu_temperature_celsius > 85\n    for: 3m\n    labels:\n      severity:
      critical\n      component: gpu\n    annotations:\n      summary: \"GPU temperature
      critical\"\n      description: |\n        GPU temperature is {{ $value }}°C,
      above safe operating limit of 85°C.\n        This may cause thermal throttling
      or hardware damage.\n        \n  - alert: GPUHighPowerDraw\n    expr: nvidia_gpu_power_draw_watts
      > 300\n    for: 5m\n    labels:\n      severity: warning\n      component: gpu\n
      \   annotations:\n      summary: \"GPU high power consumption\"\n      description:
      |\n        GPU power draw is {{ $value }}W, above normal operating range.\n
      \       Current power: {{ $value }}W\n        Max power limit: 320W\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"enhanced-monitoring-rules.yml":"groups:\n- name: monitoring-stack-enhanced\n  rules:\n  # Enhanced Pod Monitoring\n  - alert: PodOOMKilledEnhanced\n    expr: kube_pod_container_status_last_terminated_reason{reason=\"OOMKilled\"} == 1\n    for: 0m\n    labels:\n      severity: critical\n      component: monitoring-stack\n    annotations:\n      summary: \"Pod {{ $labels.pod }} was OOM killed\"\n      description: |\n        Pod {{ $labels.namespace }}/{{ $labels.pod }} container {{ $labels.container }} was OOM killed.\n        This indicates memory limits are too low or there's a memory leak.\n        \n        Current memory limit: {{ $labels.memory_limit }}\n        Restart count: {{ $labels.restart_count }}\n        \n  - alert: PodCrashLoopEnhanced\n    expr: rate(kube_pod_container_status_restarts_total[15m]) \u003e 0\n    for: 2m\n    labels:\n      severity: warning\n      component: monitoring-stack\n    annotations:\n      summary: \"Pod {{ $labels.pod }} is crash looping\"\n      description: |\n        Pod {{ $labels.namespace }}/{{ $labels.pod }} container {{ $labels.container }} is restarting frequently.\n        Restart rate: {{ $value }} restarts/minute over 15 minutes.\n        \n  - alert: MonitoringComponentDown\n    expr: up{job=~\"prometheus|grafana|loki|alertmanager\"} == 0\n    for: 1m\n    labels:\n      severity: critical\n      component: monitoring-stack\n    annotations:\n      summary: \"Monitoring component {{ $labels.job }} is down\"\n      description: |\n        Critical monitoring component {{ $labels.job }} on {{ $labels.instance }} is down.\n        This affects overall monitoring capabilities.\n        \n  # ML Anomaly Detection Alerts\n  - alert: AnomalyDetectorDown\n    expr: up{job=~\".*anomaly.*detector.*\"} == 0\n    for: 2m\n    labels:\n      severity: warning\n      component: ml-detection\n    annotations:\n      summary: \"Anomaly detector {{ $labels.job }} is down\"\n      description: |\n        ML anomaly detector {{ $labels.job }} is not responding.\n        This affects intelligent anomaly detection capabilities.\n        \n  - alert: HighAnomalyScore\n    expr: anomaly_score \u003e 85\n    for: 5m\n    labels:\n      severity: warning\n      component: ml-detection\n    annotations:\n      summary: \"High anomaly score detected\"\n      description: |\n        Anomaly score for {{ $labels.metric_name }} is {{ $value }}/100.\n        This indicates unusual behavior that requires investigation.\n        Algorithm: {{ $labels.algorithm }}\n        \n  - alert: AnomalyDetectionErrors\n    expr: increase(anomaly_detection_errors_total[1h]) \u003e 10\n    for: 0m\n    labels:\n      severity: warning\n      component: ml-detection\n    annotations:\n      summary: \"Multiple anomaly detection errors\"\n      description: |\n        {{ $value }} anomaly detection errors in the last hour for {{ $labels.metric_type }}.\n        This may indicate issues with ML model training or data quality.\n        \n  # Resource Monitoring Enhanced\n  - alert: PodHighMemoryUsage\n    expr: (container_memory_working_set_bytes / container_spec_memory_limit_bytes) * 100 \u003e 90\n    for: 5m\n    labels:\n      severity: warning\n      component: monitoring-stack\n    annotations:\n      summary: \"Pod {{ $labels.pod }} high memory usage\"\n      description: |\n        Pod {{ $labels.namespace }}/{{ $labels.pod }} is using {{ $value }}% of memory limit.\n        Current usage: {{ $labels.memory_usage }}\n        Memory limit: {{ $labels.memory_limit }}\n        \n  - alert: PodHighCPUUsage\n    expr: (rate(container_cpu_usage_seconds_total[5m]) / container_spec_cpu_quota * container_spec_cpu_period) * 100 \u003e 90\n    for: 10m\n    labels:\n      severity: warning\n      component: monitoring-stack\n    annotations:\n      summary: \"Pod {{ $labels.pod }} high CPU usage\"\n      description: |\n        Pod {{ $labels.namespace }}/{{ $labels.pod }} is using {{ $value }}% of CPU limit.\n        This sustained high usage may affect performance.\n        \n  # GPU Monitoring Enhanced\n  - alert: GPUHighTemperature\n    expr: nvidia_gpu_temperature_celsius \u003e 85\n    for: 3m\n    labels:\n      severity: critical\n      component: gpu\n    annotations:\n      summary: \"GPU temperature critical\"\n      description: |\n        GPU temperature is {{ $value }}°C, above safe operating limit of 85°C.\n        This may cause thermal throttling or hardware damage.\n        \n  - alert: GPUHighPowerDraw\n    expr: nvidia_gpu_power_draw_watts \u003e 300\n    for: 5m\n    labels:\n      severity: warning\n      component: gpu\n    annotations:\n      summary: \"GPU high power consumption\"\n      description: |\n        GPU power draw is {{ $value }}W, above normal operating range.\n        Current power: {{ $value }}W\n        Max power limit: 320W\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"enhanced-monitoring-alerts","namespace":"monitoring"}}
    creationTimestamp: "2025-06-01T04:36:26Z"
    name: enhanced-monitoring-alerts
    namespace: monitoring
    resourceVersion: "879751"
    uid: 09402fdd-f181-449a-8743-214279f94f18
- apiVersion: v1
  data:
    pod-monitoring.yml: "groups:\n- name: pod-monitoring-enhanced\n  rules:\n  # Enhanced
      Pod OOM Detection\n  - alert: PodOOMKilledEnhanced\n    expr: kube_pod_container_status_last_terminated_reason{reason=\"OOMKilled\",
      namespace=\"monitoring\"} == 1\n    for: 0m\n    labels:\n      severity: critical\n
      \     component: monitoring-stack\n      alert_type: pod_health\n    annotations:\n
      \     summary: \"Pod {{ $labels.pod }} was OOM killed\"\n      description:
      |\n        Pod {{ $labels.namespace }}/{{ $labels.pod }} container {{ $labels.container
      }} was killed due to out of memory.\n        This indicates memory limits are
      too low or there's a memory leak.\n        Restart count: {{ $labels.restart_count
      }}\n        \n  # Enhanced Crash Loop Detection  \n  - alert: PodCrashLoopEnhanced\n
      \   expr: rate(kube_pod_container_status_restarts_total{namespace=\"monitoring\"}[15m])
      > 0\n    for: 2m\n    labels:\n      severity: warning\n      component: monitoring-stack\n
      \     alert_type: pod_health\n    annotations:\n      summary: \"Pod {{ $labels.pod
      }} is crash looping\"\n      description: |\n        Pod {{ $labels.namespace
      }}/{{ $labels.pod }} container {{ $labels.container }} is restarting frequently.\n
      \       Restart rate: {{ $value }} restarts/minute over 15 minutes.\n        \n
      \ # Proactive Memory Warning\n  - alert: PodHighMemoryUsage\n    expr: (container_memory_working_set_bytes{namespace=\"monitoring\",
      container!=\"\", container!=\"POD\"} / container_spec_memory_limit_bytes{namespace=\"monitoring\",
      container!=\"\", container!=\"POD\"}) * 100 > 85\n    for: 5m\n    labels:\n
      \     severity: warning\n      component: monitoring-stack\n      alert_type:
      resource_usage\n    annotations:\n      summary: \"Pod {{ $labels.pod }} high
      memory usage\"\n      description: |\n        Pod {{ $labels.namespace }}/{{
      $labels.pod }} container {{ $labels.container }} is using {{ $value }}% of memory
      limit.\n        This may lead to OOM kill if not addressed.\n        \n  # Monitoring
      Component Health\n  - alert: MonitoringComponentDown\n    expr: up{job=~\"prometheus|grafana|loki|alertmanager\",
      namespace=\"monitoring\"} == 0\n    for: 1m\n    labels:\n      severity: critical\n
      \     component: monitoring-stack\n      alert_type: service_health\n    annotations:\n
      \     summary: \"Monitoring component {{ $labels.job }} is down\"\n      description:
      |\n        Critical monitoring component {{ $labels.job }} on {{ $labels.instance
      }} is down.\n        This affects overall monitoring capabilities.\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"pod-monitoring.yml":"groups:\n- name: pod-monitoring-enhanced\n  rules:\n  # Enhanced Pod OOM Detection\n  - alert: PodOOMKilledEnhanced\n    expr: kube_pod_container_status_last_terminated_reason{reason=\"OOMKilled\", namespace=\"monitoring\"} == 1\n    for: 0m\n    labels:\n      severity: critical\n      component: monitoring-stack\n      alert_type: pod_health\n    annotations:\n      summary: \"Pod {{ $labels.pod }} was OOM killed\"\n      description: |\n        Pod {{ $labels.namespace }}/{{ $labels.pod }} container {{ $labels.container }} was killed due to out of memory.\n        This indicates memory limits are too low or there's a memory leak.\n        Restart count: {{ $labels.restart_count }}\n        \n  # Enhanced Crash Loop Detection  \n  - alert: PodCrashLoopEnhanced\n    expr: rate(kube_pod_container_status_restarts_total{namespace=\"monitoring\"}[15m]) \u003e 0\n    for: 2m\n    labels:\n      severity: warning\n      component: monitoring-stack\n      alert_type: pod_health\n    annotations:\n      summary: \"Pod {{ $labels.pod }} is crash looping\"\n      description: |\n        Pod {{ $labels.namespace }}/{{ $labels.pod }} container {{ $labels.container }} is restarting frequently.\n        Restart rate: {{ $value }} restarts/minute over 15 minutes.\n        \n  # Proactive Memory Warning\n  - alert: PodHighMemoryUsage\n    expr: (container_memory_working_set_bytes{namespace=\"monitoring\", container!=\"\", container!=\"POD\"} / container_spec_memory_limit_bytes{namespace=\"monitoring\", container!=\"\", container!=\"POD\"}) * 100 \u003e 85\n    for: 5m\n    labels:\n      severity: warning\n      component: monitoring-stack\n      alert_type: resource_usage\n    annotations:\n      summary: \"Pod {{ $labels.pod }} high memory usage\"\n      description: |\n        Pod {{ $labels.namespace }}/{{ $labels.pod }} container {{ $labels.container }} is using {{ $value }}% of memory limit.\n        This may lead to OOM kill if not addressed.\n        \n  # Monitoring Component Health\n  - alert: MonitoringComponentDown\n    expr: up{job=~\"prometheus|grafana|loki|alertmanager\", namespace=\"monitoring\"} == 0\n    for: 1m\n    labels:\n      severity: critical\n      component: monitoring-stack\n      alert_type: service_health\n    annotations:\n      summary: \"Monitoring component {{ $labels.job }} is down\"\n      description: |\n        Critical monitoring component {{ $labels.job }} on {{ $labels.instance }} is down.\n        This affects overall monitoring capabilities.\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"enhanced-pod-monitoring-rules","namespace":"monitoring"}}
    creationTimestamp: "2025-06-01T04:42:13Z"
    name: enhanced-pod-monitoring-rules
    namespace: monitoring
    resourceVersion: "882593"
    uid: 516a2e5a-21da-4cf8-a6d8-1b0632c7b350
- apiVersion: v1
  data:
    gpu-alerts.yaml: "groups:\n- name: gpu_alerts\n  interval: 30s\n  rules:\n  #
      GPU Temperature Alerts\n  - alert: GPUHighTemperature\n    expr: nvidia_gpu_temperature_celsius
      > 80\n    for: 2m\n    labels:\n      severity: warning\n      component: gpu\n
      \   annotations:\n      summary: \"GPU temperature is high ({{ $value }}°C)\"\n
      \     description: \"GPU {{ $labels.gpu }} temperature is {{ $value }}°C, above
      80°C threshold on {{ $labels.instance }}\"\n      \n  - alert: GPUCriticalTemperature\n
      \   expr: nvidia_gpu_temperature_celsius > 85\n    for: 1m\n    labels:\n      severity:
      critical\n      component: gpu\n    annotations:\n      summary: \"GPU temperature
      is critical ({{ $value }}°C)\"\n      description: \"GPU {{ $labels.gpu }} temperature
      is {{ $value }}°C, above 85°C critical threshold on {{ $labels.instance }}.
      Immediate action required!\"\n      \n  # GPU Power Alerts\n  - alert: GPUHighPowerDraw\n
      \   expr: nvidia_gpu_power_draw_watts > 300\n    for: 5m\n    labels:\n      severity:
      warning\n      component: gpu\n    annotations:\n      summary: \"GPU power
      draw is high ({{ $value }}W)\"\n      description: \"GPU {{ $labels.gpu }} is
      drawing {{ $value }}W, above 300W threshold on {{ $labels.instance }}\"\n      \n
      \ - alert: GPUPowerAnomaly\n    expr: |\n      abs(nvidia_gpu_power_draw_watts
      - avg_over_time(nvidia_gpu_power_draw_watts[30m])) \n      > (2 * stddev_over_time(nvidia_gpu_power_draw_watts[30m]))\n
      \   for: 5m\n    labels:\n      severity: warning\n      component: gpu\n    annotations:\n
      \     summary: \"GPU power draw anomaly detected\"\n      description: \"GPU
      {{ $labels.gpu }} power draw deviates significantly from normal pattern on {{
      $labels.instance }}\"\n      \n  # GPU Memory Alerts\n  - alert: GPUMemoryHighUsage\n
      \   expr: (nvidia_gpu_memory_used_mb / nvidia_gpu_memory_total_mb) * 100 > 90\n
      \   for: 5m\n    labels:\n      severity: warning\n      component: gpu\n    annotations:\n
      \     summary: \"GPU memory usage is high ({{ $value }}%)\"\n      description:
      \"GPU {{ $labels.gpu }} memory usage is {{ $value }}% on {{ $labels.instance
      }}\"\n      \n  - alert: GPUMemoryCritical\n    expr: (nvidia_gpu_memory_used_mb
      / nvidia_gpu_memory_total_mb) * 100 > 95\n    for: 2m\n    labels:\n      severity:
      critical\n      component: gpu\n    annotations:\n      summary: \"GPU memory
      usage is critical ({{ $value }}%)\"\n      description: \"GPU {{ $labels.gpu
      }} memory usage is {{ $value }}% on {{ $labels.instance }}. Applications may
      crash!\"\n      \n  # GPU Utilization Alerts\n  - alert: GPUSustainedHighUtilization\n
      \   expr: avg_over_time(nvidia_gpu_utilization_percent[10m]) > 95\n    for:
      15m\n    labels:\n      severity: warning\n      component: gpu\n    annotations:\n
      \     summary: \"GPU sustained high utilization\"\n      description: \"GPU
      {{ $labels.gpu }} has been at {{ $value }}% utilization for 15 minutes on {{
      $labels.instance }}\"\n      \n  # GPU Health Alerts\n  - alert: GPUMetricsDown\n
      \   expr: up{job=\"power-exporter\"} == 0\n    for: 2m\n    labels:\n      severity:
      critical\n      component: gpu\n    annotations:\n      summary: \"GPU metrics
      collection is down\"\n      description: \"Power exporter is not collecting
      GPU metrics on {{ $labels.instance }}\"\n      \n  - alert: GPUFanSpeedHigh\n
      \   expr: nvidia_gpu_fan_speed_percent > 80\n    for: 5m\n    labels:\n      severity:
      warning\n      component: gpu\n    annotations:\n      summary: \"GPU fan speed
      is high ({{ $value }}%)\"\n      description: \"GPU {{ $labels.gpu }} fan is
      running at {{ $value }}% on {{ $labels.instance }}, indicating thermal stress\"\n
      \     \n- name: gpu_performance_alerts\n  interval: 60s\n  rules:\n  # Thermal
      Throttling Detection\n  - alert: GPUThermalThrottling\n    expr: |\n      (nvidia_gpu_temperature_celsius
      > 83) \n      and \n      (rate(nvidia_gpu_utilization_percent[5m]) < -10)\n
      \   for: 2m\n    labels:\n      severity: critical\n      component: gpu\n    annotations:\n
      \     summary: \"GPU thermal throttling detected\"\n      description: \"GPU
      {{ $labels.gpu }} appears to be thermal throttling on {{ $labels.instance }}.
      Temperature: {{ $value }}°C\"\n      \n  # Combined Alerts\n  - alert: GPUUnderStress\n
      \   expr: |\n      (nvidia_gpu_temperature_celsius > 78) \n      and \n      (nvidia_gpu_power_draw_watts
      > 280) \n      and \n      (nvidia_gpu_utilization_percent > 90)\n    for: 5m\n
      \   labels:\n      severity: warning\n      component: gpu\n    annotations:\n
      \     summary: \"GPU under heavy stress\"\n      description: \"GPU {{ $labels.gpu
      }} is under heavy stress - Temp: {{ $value }}°C, Power: >280W, Util: >90% on
      {{ $labels.instance }}\"\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"gpu-alerts.yaml":"groups:\n- name: gpu_alerts\n  interval: 30s\n  rules:\n  # GPU Temperature Alerts\n  - alert: GPUHighTemperature\n    expr: nvidia_gpu_temperature_celsius \u003e 80\n    for: 2m\n    labels:\n      severity: warning\n      component: gpu\n    annotations:\n      summary: \"GPU temperature is high ({{ $value }}°C)\"\n      description: \"GPU {{ $labels.gpu }} temperature is {{ $value }}°C, above 80°C threshold on {{ $labels.instance }}\"\n      \n  - alert: GPUCriticalTemperature\n    expr: nvidia_gpu_temperature_celsius \u003e 85\n    for: 1m\n    labels:\n      severity: critical\n      component: gpu\n    annotations:\n      summary: \"GPU temperature is critical ({{ $value }}°C)\"\n      description: \"GPU {{ $labels.gpu }} temperature is {{ $value }}°C, above 85°C critical threshold on {{ $labels.instance }}. Immediate action required!\"\n      \n  # GPU Power Alerts\n  - alert: GPUHighPowerDraw\n    expr: nvidia_gpu_power_draw_watts \u003e 300\n    for: 5m\n    labels:\n      severity: warning\n      component: gpu\n    annotations:\n      summary: \"GPU power draw is high ({{ $value }}W)\"\n      description: \"GPU {{ $labels.gpu }} is drawing {{ $value }}W, above 300W threshold on {{ $labels.instance }}\"\n      \n  - alert: GPUPowerAnomaly\n    expr: |\n      abs(nvidia_gpu_power_draw_watts - avg_over_time(nvidia_gpu_power_draw_watts[30m])) \n      \u003e (2 * stddev_over_time(nvidia_gpu_power_draw_watts[30m]))\n    for: 5m\n    labels:\n      severity: warning\n      component: gpu\n    annotations:\n      summary: \"GPU power draw anomaly detected\"\n      description: \"GPU {{ $labels.gpu }} power draw deviates significantly from normal pattern on {{ $labels.instance }}\"\n      \n  # GPU Memory Alerts\n  - alert: GPUMemoryHighUsage\n    expr: (nvidia_gpu_memory_used_mb / nvidia_gpu_memory_total_mb) * 100 \u003e 90\n    for: 5m\n    labels:\n      severity: warning\n      component: gpu\n    annotations:\n      summary: \"GPU memory usage is high ({{ $value }}%)\"\n      description: \"GPU {{ $labels.gpu }} memory usage is {{ $value }}% on {{ $labels.instance }}\"\n      \n  - alert: GPUMemoryCritical\n    expr: (nvidia_gpu_memory_used_mb / nvidia_gpu_memory_total_mb) * 100 \u003e 95\n    for: 2m\n    labels:\n      severity: critical\n      component: gpu\n    annotations:\n      summary: \"GPU memory usage is critical ({{ $value }}%)\"\n      description: \"GPU {{ $labels.gpu }} memory usage is {{ $value }}% on {{ $labels.instance }}. Applications may crash!\"\n      \n  # GPU Utilization Alerts\n  - alert: GPUSustainedHighUtilization\n    expr: avg_over_time(nvidia_gpu_utilization_percent[10m]) \u003e 95\n    for: 15m\n    labels:\n      severity: warning\n      component: gpu\n    annotations:\n      summary: \"GPU sustained high utilization\"\n      description: \"GPU {{ $labels.gpu }} has been at {{ $value }}% utilization for 15 minutes on {{ $labels.instance }}\"\n      \n  # GPU Health Alerts\n  - alert: GPUMetricsDown\n    expr: up{job=\"power-exporter\"} == 0\n    for: 2m\n    labels:\n      severity: critical\n      component: gpu\n    annotations:\n      summary: \"GPU metrics collection is down\"\n      description: \"Power exporter is not collecting GPU metrics on {{ $labels.instance }}\"\n      \n  - alert: GPUFanSpeedHigh\n    expr: nvidia_gpu_fan_speed_percent \u003e 80\n    for: 5m\n    labels:\n      severity: warning\n      component: gpu\n    annotations:\n      summary: \"GPU fan speed is high ({{ $value }}%)\"\n      description: \"GPU {{ $labels.gpu }} fan is running at {{ $value }}% on {{ $labels.instance }}, indicating thermal stress\"\n      \n- name: gpu_performance_alerts\n  interval: 60s\n  rules:\n  # Thermal Throttling Detection\n  - alert: GPUThermalThrottling\n    expr: |\n      (nvidia_gpu_temperature_celsius \u003e 83) \n      and \n      (rate(nvidia_gpu_utilization_percent[5m]) \u003c -10)\n    for: 2m\n    labels:\n      severity: critical\n      component: gpu\n    annotations:\n      summary: \"GPU thermal throttling detected\"\n      description: \"GPU {{ $labels.gpu }} appears to be thermal throttling on {{ $labels.instance }}. Temperature: {{ $value }}°C\"\n      \n  # Combined Alerts\n  - alert: GPUUnderStress\n    expr: |\n      (nvidia_gpu_temperature_celsius \u003e 78) \n      and \n      (nvidia_gpu_power_draw_watts \u003e 280) \n      and \n      (nvidia_gpu_utilization_percent \u003e 90)\n    for: 5m\n    labels:\n      severity: warning\n      component: gpu\n    annotations:\n      summary: \"GPU under heavy stress\"\n      description: \"GPU {{ $labels.gpu }} is under heavy stress - Temp: {{ $value }}°C, Power: \u003e280W, Util: \u003e90% on {{ $labels.instance }}\"\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"gpu-alert-rules","namespace":"monitoring"}}
    creationTimestamp: "2025-05-28T13:20:14Z"
    name: gpu-alert-rules
    namespace: monitoring
    resourceVersion: "29340"
    uid: f746a9de-6e5e-4918-876a-e5189485aa1b
- apiVersion: v1
  data:
    gpu-monitoring.json: |
      {
        "id": null,
        "uid": "gpu-monitoring-v2",
        "title": "GPU Monitoring - RTX 4080",
        "tags": ["gpu", "nvidia", "performance"],
        "timezone": "browser",
        "schemaVersion": 30,
        "version": 1,
        "refresh": "10s",
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "panels": [
          {
            "id": 1,
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0},
            "type": "timeseries",
            "title": "GPU Temperature",
            "targets": [
              {
                "expr": "nvidia_gpu_temperature_celsius",
                "legendFormat": "{{name}} (GPU {{gpu}})"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "celsius",
                "decimals": 1,
                "color": {"mode": "palette-classic"},
                "custom": {
                  "lineInterpolation": "smooth",
                  "lineWidth": 2,
                  "fillOpacity": 10,
                  "showPoints": "never"
                },
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"color": "green", "value": null},
                    {"color": "yellow", "value": 70},
                    {"color": "orange", "value": 80},
                    {"color": "red", "value": 90}
                  ]
                }
              }
            }
          },
          {
            "id": 2,
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0},
            "type": "timeseries",
            "title": "GPU Power Consumption",
            "targets": [
              {
                "expr": "node_gpu_power_watts",
                "legendFormat": "GPU {{gpu}}"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "watt",
                "decimals": 1,
                "color": {"mode": "palette-classic"},
                "custom": {
                  "lineInterpolation": "smooth",
                  "lineWidth": 2,
                  "fillOpacity": 10,
                  "showPoints": "never"
                },
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"color": "green", "value": null},
                    {"color": "yellow", "value": 100},
                    {"color": "orange", "value": 150},
                    {"color": "red", "value": 200}
                  ]
                }
              }
            }
          },
          {
            "id": 3,
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8},
            "type": "timeseries",
            "title": "GPU Memory Usage",
            "targets": [
              {
                "expr": "nvidia_gpu_memory_used_mb",
                "legendFormat": "Used - {{name}}"
              },
              {
                "expr": "nvidia_gpu_memory_total_mb",
                "legendFormat": "Total - {{name}}"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "decmbytes",
                "decimals": 0,
                "color": {"mode": "palette-classic"},
                "custom": {
                  "lineInterpolation": "smooth",
                  "lineWidth": 2,
                  "fillOpacity": 10,
                  "showPoints": "never"
                }
              }
            }
          },
          {
            "id": 4,
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8},
            "type": "timeseries",
            "title": "GPU Utilization",
            "targets": [
              {
                "expr": "nvidia_gpu_utilization_percent",
                "legendFormat": "{{name}} (GPU {{gpu}})"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "percent",
                "decimals": 1,
                "min": 0,
                "max": 100,
                "color": {"mode": "palette-classic"},
                "custom": {
                  "lineInterpolation": "smooth",
                  "lineWidth": 2,
                  "fillOpacity": 20,
                  "showPoints": "never"
                }
              }
            }
          },
          {
            "id": 5,
            "gridPos": {"h": 6, "w": 6, "x": 0, "y": 16},
            "type": "gauge",
            "title": "Current GPU Temperature",
            "targets": [
              {
                "expr": "nvidia_gpu_temperature_celsius",
                "instant": true
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "celsius",
                "decimals": 1,
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"color": "green", "value": null},
                    {"color": "yellow", "value": 70},
                    {"color": "orange", "value": 80},
                    {"color": "red", "value": 90}
                  ]
                }
              }
            },
            "options": {
              "orientation": "auto",
              "showThresholdLabels": true,
              "showThresholdMarkers": true
            }
          },
          {
            "id": 6,
            "gridPos": {"h": 6, "w": 6, "x": 6, "y": 16},
            "type": "gauge",
            "title": "Current GPU Power",
            "targets": [
              {
                "expr": "node_gpu_power_watts",
                "instant": true
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "watt",
                "decimals": 0,
                "min": 0,
                "max": 250,
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"color": "green", "value": null},
                    {"color": "yellow", "value": 100},
                    {"color": "orange", "value": 150},
                    {"color": "red", "value": 200}
                  ]
                }
              }
            },
            "options": {
              "orientation": "auto",
              "showThresholdLabels": true,
              "showThresholdMarkers": true
            }
          },
          {
            "id": 7,
            "gridPos": {"h": 6, "w": 6, "x": 12, "y": 16},
            "type": "stat",
            "title": "GPU Memory Used",
            "targets": [
              {
                "expr": "(nvidia_gpu_memory_used_mb / nvidia_gpu_memory_total_mb) * 100",
                "instant": true
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "percent",
                "decimals": 1,
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"color": "green", "value": null},
                    {"color": "yellow", "value": 70},
                    {"color": "orange", "value": 85},
                    {"color": "red", "value": 95}
                  ]
                }
              }
            },
            "options": {
              "colorMode": "background",
              "graphMode": "area",
              "textMode": "auto"
            }
          },
          {
            "id": 8,
            "gridPos": {"h": 6, "w": 6, "x": 18, "y": 16},
            "type": "timeseries",
            "title": "GPU Fan Speed",
            "targets": [
              {
                "expr": "nvidia_gpu_fan_speed_percent",
                "legendFormat": "Fan Speed %"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "percent",
                "decimals": 0,
                "min": 0,
                "max": 100,
                "color": {"mode": "palette-classic"},
                "custom": {
                  "lineInterpolation": "smooth",
                  "lineWidth": 2,
                  "fillOpacity": 10,
                  "showPoints": "never"
                }
              }
            }
          }
        ]
      }
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"gpu-monitoring.json":"{\n  \"id\": null,\n  \"uid\": \"gpu-monitoring-v2\",\n  \"title\": \"GPU Monitoring - RTX 4080\",\n  \"tags\": [\"gpu\", \"nvidia\", \"performance\"],\n  \"timezone\": \"browser\",\n  \"schemaVersion\": 30,\n  \"version\": 1,\n  \"refresh\": \"10s\",\n  \"time\": {\n    \"from\": \"now-1h\",\n    \"to\": \"now\"\n  },\n  \"panels\": [\n    {\n      \"id\": 1,\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 0},\n      \"type\": \"timeseries\",\n      \"title\": \"GPU Temperature\",\n      \"targets\": [\n        {\n          \"expr\": \"nvidia_gpu_temperature_celsius\",\n          \"legendFormat\": \"{{name}} (GPU {{gpu}})\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"celsius\",\n          \"decimals\": 1,\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 10,\n            \"showPoints\": \"never\"\n          },\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 70},\n              {\"color\": \"orange\", \"value\": 80},\n              {\"color\": \"red\", \"value\": 90}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"id\": 2,\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 0},\n      \"type\": \"timeseries\",\n      \"title\": \"GPU Power Consumption\",\n      \"targets\": [\n        {\n          \"expr\": \"node_gpu_power_watts\",\n          \"legendFormat\": \"GPU {{gpu}}\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"watt\",\n          \"decimals\": 1,\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 10,\n            \"showPoints\": \"never\"\n          },\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 100},\n              {\"color\": \"orange\", \"value\": 150},\n              {\"color\": \"red\", \"value\": 200}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"id\": 3,\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 8},\n      \"type\": \"timeseries\",\n      \"title\": \"GPU Memory Usage\",\n      \"targets\": [\n        {\n          \"expr\": \"nvidia_gpu_memory_used_mb\",\n          \"legendFormat\": \"Used - {{name}}\"\n        },\n        {\n          \"expr\": \"nvidia_gpu_memory_total_mb\",\n          \"legendFormat\": \"Total - {{name}}\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"decmbytes\",\n          \"decimals\": 0,\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 10,\n            \"showPoints\": \"never\"\n          }\n        }\n      }\n    },\n    {\n      \"id\": 4,\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 8},\n      \"type\": \"timeseries\",\n      \"title\": \"GPU Utilization\",\n      \"targets\": [\n        {\n          \"expr\": \"nvidia_gpu_utilization_percent\",\n          \"legendFormat\": \"{{name}} (GPU {{gpu}})\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"percent\",\n          \"decimals\": 1,\n          \"min\": 0,\n          \"max\": 100,\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 20,\n            \"showPoints\": \"never\"\n          }\n        }\n      }\n    },\n    {\n      \"id\": 5,\n      \"gridPos\": {\"h\": 6, \"w\": 6, \"x\": 0, \"y\": 16},\n      \"type\": \"gauge\",\n      \"title\": \"Current GPU Temperature\",\n      \"targets\": [\n        {\n          \"expr\": \"nvidia_gpu_temperature_celsius\",\n          \"instant\": true\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"celsius\",\n          \"decimals\": 1,\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 70},\n              {\"color\": \"orange\", \"value\": 80},\n              {\"color\": \"red\", \"value\": 90}\n            ]\n          }\n        }\n      },\n      \"options\": {\n        \"orientation\": \"auto\",\n        \"showThresholdLabels\": true,\n        \"showThresholdMarkers\": true\n      }\n    },\n    {\n      \"id\": 6,\n      \"gridPos\": {\"h\": 6, \"w\": 6, \"x\": 6, \"y\": 16},\n      \"type\": \"gauge\",\n      \"title\": \"Current GPU Power\",\n      \"targets\": [\n        {\n          \"expr\": \"node_gpu_power_watts\",\n          \"instant\": true\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"watt\",\n          \"decimals\": 0,\n          \"min\": 0,\n          \"max\": 250,\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 100},\n              {\"color\": \"orange\", \"value\": 150},\n              {\"color\": \"red\", \"value\": 200}\n            ]\n          }\n        }\n      },\n      \"options\": {\n        \"orientation\": \"auto\",\n        \"showThresholdLabels\": true,\n        \"showThresholdMarkers\": true\n      }\n    },\n    {\n      \"id\": 7,\n      \"gridPos\": {\"h\": 6, \"w\": 6, \"x\": 12, \"y\": 16},\n      \"type\": \"stat\",\n      \"title\": \"GPU Memory Used\",\n      \"targets\": [\n        {\n          \"expr\": \"(nvidia_gpu_memory_used_mb / nvidia_gpu_memory_total_mb) * 100\",\n          \"instant\": true\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"percent\",\n          \"decimals\": 1,\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 70},\n              {\"color\": \"orange\", \"value\": 85},\n              {\"color\": \"red\", \"value\": 95}\n            ]\n          }\n        }\n      },\n      \"options\": {\n        \"colorMode\": \"background\",\n        \"graphMode\": \"area\",\n        \"textMode\": \"auto\"\n      }\n    },\n    {\n      \"id\": 8,\n      \"gridPos\": {\"h\": 6, \"w\": 6, \"x\": 18, \"y\": 16},\n      \"type\": \"timeseries\",\n      \"title\": \"GPU Fan Speed\",\n      \"targets\": [\n        {\n          \"expr\": \"nvidia_gpu_fan_speed_percent\",\n          \"legendFormat\": \"Fan Speed %\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"percent\",\n          \"decimals\": 0,\n          \"min\": 0,\n          \"max\": 100,\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 10,\n            \"showPoints\": \"never\"\n          }\n        }\n      }\n    }\n  ]\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"gpu-monitoring-dashboard","namespace":"monitoring"}}
    creationTimestamp: "2025-05-28T01:09:30Z"
    name: gpu-monitoring-dashboard
    namespace: monitoring
    resourceVersion: "8891"
    uid: 897268ac-4b9b-4a30-909b-4f33831bda30
- apiVersion: v1
  data:
    odin-grafana-rules.yaml: "apiVersion: 1\ngroups:\n  - name: ODIN Platform Alerts\n
      \   orgId: 1\n    folder: ODIN Alerts\n    interval: 1m\n    rules:\n      #
      Dashboard health\n      - uid: dashboard-health-1\n        title: Dashboard
      Loading Slow\n        condition: A\n        data:\n          - refId: A\n            queryType:
      ''\n            model:\n              datasourceUid: prometheus\n              expr:
      histogram_quantile(0.95, rate(grafana_http_request_duration_seconds_bucket{handler=\"/api/dashboards/uid/:uid\"}[5m]))
      > 2\n              intervalMs: 1000\n              maxDataPoints: 43200\n        noDataState:
      NoData\n        execErrState: Alerting\n        for: 5m\n        annotations:\n
      \         summary: Grafana dashboard loading is slow\n          description:
      '95th percentile dashboard load time is {{ $value }}s'\n        labels:\n          severity:
      warning\n          component: grafana\n          \n      # Data source health\n
      \     - uid: datasource-health-1\n        title: Data Source Query Failures\n
      \       condition: A\n        data:\n          - refId: A\n            queryType:
      ''\n            model:\n              datasourceUid: prometheus\n              expr:
      rate(grafana_datasource_request_errors_total[5m]) > 0.1\n              intervalMs:
      1000\n              maxDataPoints: 43200\n        noDataState: NoData\n        execErrState:
      Alerting\n        for: 5m\n        annotations:\n          summary: Data source
      queries are failing\n          description: 'Data source {{ $labels.datasource
      }} is experiencing {{ $value }} errors per second'\n        labels:\n          severity:
      warning\n          component: grafana\n          \n      # Alert notification
      failures\n      - uid: notification-health-1\n        title: Alert Notification
      Failures\n        condition: A\n        data:\n          - refId: A\n            queryType:
      ''\n            model:\n              datasourceUid: prometheus\n              expr:
      increase(grafana_alerting_notification_failed_total[5m]) > 5\n              intervalMs:
      1000\n              maxDataPoints: 43200\n        noDataState: NoData\n        execErrState:
      Alerting\n        for: 5m\n        annotations:\n          summary: Alert notifications
      are failing\n          description: '{{ $value }} alert notifications failed
      in the last 5 minutes'\n        labels:\n          severity: critical\n          component:
      grafana\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"odin-grafana-rules.yaml":"apiVersion: 1\ngroups:\n  - name: ODIN Platform Alerts\n    orgId: 1\n    folder: ODIN Alerts\n    interval: 1m\n    rules:\n      # Dashboard health\n      - uid: dashboard-health-1\n        title: Dashboard Loading Slow\n        condition: A\n        data:\n          - refId: A\n            queryType: ''\n            model:\n              datasourceUid: prometheus\n              expr: histogram_quantile(0.95, rate(grafana_http_request_duration_seconds_bucket{handler=\"/api/dashboards/uid/:uid\"}[5m])) \u003e 2\n              intervalMs: 1000\n              maxDataPoints: 43200\n        noDataState: NoData\n        execErrState: Alerting\n        for: 5m\n        annotations:\n          summary: Grafana dashboard loading is slow\n          description: '95th percentile dashboard load time is {{ $value }}s'\n        labels:\n          severity: warning\n          component: grafana\n          \n      # Data source health\n      - uid: datasource-health-1\n        title: Data Source Query Failures\n        condition: A\n        data:\n          - refId: A\n            queryType: ''\n            model:\n              datasourceUid: prometheus\n              expr: rate(grafana_datasource_request_errors_total[5m]) \u003e 0.1\n              intervalMs: 1000\n              maxDataPoints: 43200\n        noDataState: NoData\n        execErrState: Alerting\n        for: 5m\n        annotations:\n          summary: Data source queries are failing\n          description: 'Data source {{ $labels.datasource }} is experiencing {{ $value }} errors per second'\n        labels:\n          severity: warning\n          component: grafana\n          \n      # Alert notification failures\n      - uid: notification-health-1\n        title: Alert Notification Failures\n        condition: A\n        data:\n          - refId: A\n            queryType: ''\n            model:\n              datasourceUid: prometheus\n              expr: increase(grafana_alerting_notification_failed_total[5m]) \u003e 5\n              intervalMs: 1000\n              maxDataPoints: 43200\n        noDataState: NoData\n        execErrState: Alerting\n        for: 5m\n        annotations:\n          summary: Alert notifications are failing\n          description: '{{ $value }} alert notifications failed in the last 5 minutes'\n        labels:\n          severity: critical\n          component: grafana\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"grafana-alert-rules","namespace":"monitoring"}}
    creationTimestamp: "2025-05-29T23:07:31Z"
    name: grafana-alert-rules
    namespace: monitoring
    resourceVersion: "85797"
    uid: 155640e0-e0cb-4784-b9d9-86a4bf37038d
- apiVersion: v1
  data:
    provisioning-alerting.yaml: "apiVersion: 1\n\n# Contact points configuration\ncontactPoints:\n
      \ - orgId: 1\n    name: default-contact\n    receivers:\n      - uid: default-webhook\n
      \       type: webhook\n        settings:\n          url: http://webhook-logger:8080/grafana\n
      \         httpMethod: POST\n        disableResolveMessage: false\n        \n
      \ - orgId: 1\n    name: critical-contact\n    receivers:\n      - uid: critical-webhook\n
      \       type: webhook\n        settings:\n          url: http://webhook-logger:8080/grafana-critical\n
      \         httpMethod: POST\n        disableResolveMessage: false\n        \n
      \ - orgId: 1\n    name: ops-team\n    receivers:\n      - uid: ops-webhook\n
      \       type: webhook\n        settings:\n          url: http://webhook-logger:8080/ops\n
      \         httpMethod: POST\n        disableResolveMessage: false\n        \n#
      Notification policies\npolicies:\n  - orgId: 1\n    receiver: default-contact\n
      \   group_by: ['grafana_folder', 'alertname']\n    group_wait: 30s\n    group_interval:
      5m\n    repeat_interval: 12h\n    routes:\n      # Critical alerts get immediate
      notification\n      - receiver: critical-contact\n        match:\n          severity:
      critical\n        group_wait: 0s\n        group_interval: 1m\n        repeat_interval:
      1h\n        \n      # K3s and monitoring stack alerts\n      - receiver: ops-team\n
      \       match_re:\n          component: 'k3s|monitoring-stack'\n        group_wait:
      1m\n        group_interval: 5m\n        repeat_interval: 4h\n        \n# Mute
      timings (maintenance windows)\nmuteTimes:\n  - orgId: 1\n    name: weekends\n
      \   intervals:\n      - times:\n          - start: '00:00'\n            end:
      '24:00'\n        weekdays: ['saturday', 'sunday']\n        \n  - orgId: 1\n
      \   name: night-hours\n    intervals:\n      - times:\n          - start: '22:00'\n
      \           end: '06:00'\n        weekdays: ['monday', 'tuesday', 'wednesday',
      'thursday', 'friday']\n        \n# Alert rule templates\ntemplates:\n  - orgId:
      1\n    name: odin-templates\n    template: |\n      {{ define \"odin.message\"
      }}\n      {{ if gt (len .Alerts.Firing) 0 }}\n      \U0001F525 FIRING: {{ len
      .Alerts.Firing }} alert(s)\n      {{ range .Alerts.Firing }}\n      • {{ .Labels.alertname
      }}: {{ .Annotations.summary }}\n      {{ end }}\n      {{ end }}\n      {{ if
      gt (len .Alerts.Resolved) 0 }}\n      ✅ RESOLVED: {{ len .Alerts.Resolved }}
      alert(s)\n      {{ range .Alerts.Resolved }}\n      • {{ .Labels.alertname }}\n
      \     {{ end }}\n      {{ end }}\n      {{ end }}\n      \n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: "{\"apiVersion\":\"v1\",\"data\":{\"provisioning-alerting.yaml\":\"apiVersion:
        1\\n\\n# Contact points configuration\\ncontactPoints:\\n  - orgId: 1\\n    name:
        default-contact\\n    receivers:\\n      - uid: default-webhook\\n        type:
        webhook\\n        settings:\\n          url: http://webhook-logger:8080/grafana\\n
        \         httpMethod: POST\\n        disableResolveMessage: false\\n        \\n
        \ - orgId: 1\\n    name: critical-contact\\n    receivers:\\n      - uid:
        critical-webhook\\n        type: webhook\\n        settings:\\n          url:
        http://webhook-logger:8080/grafana-critical\\n          httpMethod: POST\\n
        \       disableResolveMessage: false\\n        \\n  - orgId: 1\\n    name:
        ops-team\\n    receivers:\\n      - uid: ops-webhook\\n        type: webhook\\n
        \       settings:\\n          url: http://webhook-logger:8080/ops\\n          httpMethod:
        POST\\n        disableResolveMessage: false\\n        \\n# Notification policies\\npolicies:\\n
        \ - orgId: 1\\n    receiver: default-contact\\n    group_by: ['grafana_folder',
        'alertname']\\n    group_wait: 30s\\n    group_interval: 5m\\n    repeat_interval:
        12h\\n    routes:\\n      # Critical alerts get immediate notification\\n
        \     - receiver: critical-contact\\n        match:\\n          severity:
        critical\\n        group_wait: 0s\\n        group_interval: 1m\\n        repeat_interval:
        1h\\n        \\n      # K3s and monitoring stack alerts\\n      - receiver:
        ops-team\\n        match_re:\\n          component: 'k3s|monitoring-stack'\\n
        \       group_wait: 1m\\n        group_interval: 5m\\n        repeat_interval:
        4h\\n        \\n# Mute timings (maintenance windows)\\nmuteTimes:\\n  - orgId:
        1\\n    name: weekends\\n    intervals:\\n      - times:\\n          - start:
        '00:00'\\n            end: '24:00'\\n        weekdays: ['saturday', 'sunday']\\n
        \       \\n  - orgId: 1\\n    name: night-hours\\n    intervals:\\n      -
        times:\\n          - start: '22:00'\\n            end: '06:00'\\n        weekdays:
        ['monday', 'tuesday', 'wednesday', 'thursday', 'friday']\\n        \\n# Alert
        rule templates\\ntemplates:\\n  - orgId: 1\\n    name: odin-templates\\n    template:
        |\\n      {{ define \\\"odin.message\\\" }}\\n      {{ if gt (len .Alerts.Firing)
        0 }}\\n      \U0001F525 FIRING: {{ len .Alerts.Firing }} alert(s)\\n      {{
        range .Alerts.Firing }}\\n      • {{ .Labels.alertname }}: {{ .Annotations.summary
        }}\\n      {{ end }}\\n      {{ end }}\\n      {{ if gt (len .Alerts.Resolved)
        0 }}\\n      ✅ RESOLVED: {{ len .Alerts.Resolved }} alert(s)\\n      {{ range
        .Alerts.Resolved }}\\n      • {{ .Labels.alertname }}\\n      {{ end }}\\n
        \     {{ end }}\\n      {{ end }}\\n      \\n\"},\"kind\":\"ConfigMap\",\"metadata\":{\"annotations\":{},\"name\":\"grafana-alerting-config\",\"namespace\":\"monitoring\"}}\n"
    creationTimestamp: "2025-05-29T23:07:31Z"
    name: grafana-alerting-config
    namespace: monitoring
    resourceVersion: "85796"
    uid: 6f336698-379f-4e89-a9e5-6e526ddaab47
- apiVersion: v1
  data:
    default_avatar.svg: "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"128\" height=\"128\"
      viewBox=\"0 0 128 128\">\n  <defs>\n    <linearGradient id=\"avatarGrad\" x1=\"0%\"
      y1=\"0%\" x2=\"100%\" y2=\"100%\">\n      <stop offset=\"0%\" style=\"stop-color:#00ff88;stop-opacity:1\"
      />\n      <stop offset=\"100%\" style=\"stop-color:#0099ff;stop-opacity:1\"
      />\n    </linearGradient>\n  </defs>\n  \n  <!-- Background circle -->\n  <circle
      cx=\"64\" cy=\"64\" r=\"60\" fill=\"#1a1a1a\" stroke=\"url(#avatarGrad)\" stroke-width=\"3\"/>\n
      \ \n  <!-- ODIN text -->\n  <text x=\"64\" y=\"75\" font-family=\"Arial, sans-serif\"
      font-size=\"32\" font-weight=\"bold\" \n        text-anchor=\"middle\" fill=\"url(#avatarGrad)\">ODIN</text>\n
      \ \n  <!-- Small network indicators -->\n  <circle cx=\"20\" cy=\"20\" r=\"4\"
      fill=\"#00ff88\" opacity=\"0.8\"/>\n  <circle cx=\"108\" cy=\"20\" r=\"4\" fill=\"#0099ff\"
      opacity=\"0.8\"/>\n  <circle cx=\"20\" cy=\"108\" r=\"3\" fill=\"#00ff88\" opacity=\"0.6\"/>\n
      \ <circle cx=\"108\" cy=\"108\" r=\"3\" fill=\"#0099ff\" opacity=\"0.6\"/>\n</svg>\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"default_avatar.svg":"\u003csvg xmlns=\"http://www.w3.org/2000/svg\" width=\"128\" height=\"128\" viewBox=\"0 0 128 128\"\u003e\n  \u003cdefs\u003e\n    \u003clinearGradient id=\"avatarGrad\" x1=\"0%\" y1=\"0%\" x2=\"100%\" y2=\"100%\"\u003e\n      \u003cstop offset=\"0%\" style=\"stop-color:#00ff88;stop-opacity:1\" /\u003e\n      \u003cstop offset=\"100%\" style=\"stop-color:#0099ff;stop-opacity:1\" /\u003e\n    \u003c/linearGradient\u003e\n  \u003c/defs\u003e\n  \n  \u003c!-- Background circle --\u003e\n  \u003ccircle cx=\"64\" cy=\"64\" r=\"60\" fill=\"#1a1a1a\" stroke=\"url(#avatarGrad)\" stroke-width=\"3\"/\u003e\n  \n  \u003c!-- ODIN text --\u003e\n  \u003ctext x=\"64\" y=\"75\" font-family=\"Arial, sans-serif\" font-size=\"32\" font-weight=\"bold\" \n        text-anchor=\"middle\" fill=\"url(#avatarGrad)\"\u003eODIN\u003c/text\u003e\n  \n  \u003c!-- Small network indicators --\u003e\n  \u003ccircle cx=\"20\" cy=\"20\" r=\"4\" fill=\"#00ff88\" opacity=\"0.8\"/\u003e\n  \u003ccircle cx=\"108\" cy=\"20\" r=\"4\" fill=\"#0099ff\" opacity=\"0.8\"/\u003e\n  \u003ccircle cx=\"20\" cy=\"108\" r=\"3\" fill=\"#00ff88\" opacity=\"0.6\"/\u003e\n  \u003ccircle cx=\"108\" cy=\"108\" r=\"3\" fill=\"#0099ff\" opacity=\"0.6\"/\u003e\n\u003c/svg\u003e\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"grafana-avatar-override","namespace":"monitoring"}}
    creationTimestamp: "2025-05-30T21:54:42Z"
    name: grafana-avatar-override
    namespace: monitoring
    resourceVersion: "229221"
    uid: 4779704e-2245-4874-8b67-b15db348ad46
- apiVersion: v1
  data:
    grafana.ini: |
      [server]
      domain = odin.local
      root_url = http://odin.local:31494/

      [branding]
      app_title = ODIN - Omnipresent Diagnostics and Intelligence Network
      app_subtitle = System Monitoring Dashboard
      welcome_banner_title = Welcome to ODIN
      welcome_banner_text = Omnipresent Diagnostics and Intelligence Network

      [theme]
      default_theme = dark

      [users]
      default_theme = dark

      [user]
      disable_gravatar = true

      [ui]
      app_title = ODIN Monitoring

      [auth.anonymous]
      enabled = false

      [security]
      admin_user = admin
      admin_password = admin
      cookie_secure = false

      [dashboards]
      default_home_dashboard_path = /d/system-overview/odin-system-overview

      [panels]
      disable_sanitize_html = true

      [footer]
      enabled = true
      text = <script>setInterval(function(){document.querySelectorAll('img[alt*="avatar"], div[class*="UserAvatar"]').forEach(function(e){if(e.tagName==='IMG'){e.src='/public/img/grafana_icon.svg';e.style.borderRadius='50%';e.style.padding='2px';e.style.background='#1a1a1a';}else{e.style.backgroundImage='url(/public/img/grafana_icon.svg)';e.style.backgroundSize='contain';e.style.backgroundPosition='center';e.textContent='';}});},500);</script>
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"grafana.ini":"[server]\ndomain = odin.local\nroot_url = http://odin.local:31494/\n\n[branding]\napp_title = ODIN - Omnipresent Diagnostics and Intelligence Network\napp_subtitle = System Monitoring Dashboard\nwelcome_banner_title = Welcome to ODIN\nwelcome_banner_text = Omnipresent Diagnostics and Intelligence Network\n\n[theme]\ndefault_theme = dark\n\n[users]\ndefault_theme = dark\n\n[user]\ndisable_gravatar = true\n\n[ui]\napp_title = ODIN Monitoring\n\n[auth.anonymous]\nenabled = false\n\n[security]\nadmin_user = admin\nadmin_password = admin\ncookie_secure = false\n\n[dashboards]\ndefault_home_dashboard_path = /d/system-overview/odin-system-overview\n\n[panels]\ndisable_sanitize_html = true\n\n[footer]\nenabled = true\ntext = \u003cscript\u003esetInterval(function(){document.querySelectorAll('img[alt*=\"avatar\"], div[class*=\"UserAvatar\"]').forEach(function(e){if(e.tagName==='IMG'){e.src='/public/img/grafana_icon.svg';e.style.borderRadius='50%';e.style.padding='2px';e.style.background='#1a1a1a';}else{e.style.backgroundImage='url(/public/img/grafana_icon.svg)';e.style.backgroundSize='contain';e.style.backgroundPosition='center';e.textContent='';}});},500);\u003c/script\u003e\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"grafana-config","namespace":"monitoring"}}
    creationTimestamp: "2025-05-29T03:57:28Z"
    name: grafana-config
    namespace: monitoring
    resourceVersion: "236079"
    uid: 42cbc8ad-4b0b-41aa-a0a9-b6841a9992d4
- apiVersion: v1
  data:
    custom-logo.css: |
      /* ODIN Custom Logo Sizing */

      /* Login page logo - make it much larger */
      .login-branding {
        width: 100% !important;
        max-width: 800px !important;
        margin: 0 auto !important;
      }

      .login-branding img {
        width: 100% !important;
        height: auto !important;
        max-width: 720px !important;
        max-height: 360px !important;
      }

      .login-branding-logo {
        width: 100% !important;
        height: auto !important;
        max-width: 720px !important;
        max-height: 360px !important;
      }

      /* Adjust login form container to accommodate larger logo */
      .login-outer-box {
        padding-top: 20px !important;
      }

      .login-inner-box {
        margin-top: 20px !important;
      }

      /* Make the login container wider */
      .login {
        max-width: 900px !important;
        width: 90% !important;
      }

      /* Side menu logo */
      .sidemenu__logo img {
        width: 180px !important;
        height: 90px !important;
        max-width: 180px !important;
        object-fit: contain !important;
      }

      .sidemenu__logo {
        padding: 20px 10px !important;
        height: auto !important;
      }

      /* Override any SVG size constraints */
      .login-branding svg,
      .sidemenu__logo svg {
        width: 100% !important;
        height: 100% !important;
      }
    custom-logo.js: "// Override logo size constraints\n(function() {\n  // Wait for
      page load\n  window.addEventListener('load', function() {\n    // Find and resize
      login logo\n    const loginLogo = document.querySelector('.login-branding img,
      .login-branding-logo');\n    if (loginLogo) {\n      loginLogo.style.width =
      '720px';\n      loginLogo.style.height = '360px';\n      loginLogo.style.maxWidth
      = '720px';\n      loginLogo.style.maxHeight = '360px';\n    }\n    \n    //
      Find and resize side menu logo\n    const sideMenuLogo = document.querySelector('.sidemenu__logo
      img');\n    if (sideMenuLogo) {\n      sideMenuLogo.style.width = '180px';\n
      \     sideMenuLogo.style.height = '90px';\n    }\n  });\n})();\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"custom-logo.css":"/* ODIN Custom Logo Sizing */\n\n/* Login page logo - make it much larger */\n.login-branding {\n  width: 100% !important;\n  max-width: 800px !important;\n  margin: 0 auto !important;\n}\n\n.login-branding img {\n  width: 100% !important;\n  height: auto !important;\n  max-width: 720px !important;\n  max-height: 360px !important;\n}\n\n.login-branding-logo {\n  width: 100% !important;\n  height: auto !important;\n  max-width: 720px !important;\n  max-height: 360px !important;\n}\n\n/* Adjust login form container to accommodate larger logo */\n.login-outer-box {\n  padding-top: 20px !important;\n}\n\n.login-inner-box {\n  margin-top: 20px !important;\n}\n\n/* Make the login container wider */\n.login {\n  max-width: 900px !important;\n  width: 90% !important;\n}\n\n/* Side menu logo */\n.sidemenu__logo img {\n  width: 180px !important;\n  height: 90px !important;\n  max-width: 180px !important;\n  object-fit: contain !important;\n}\n\n.sidemenu__logo {\n  padding: 20px 10px !important;\n  height: auto !important;\n}\n\n/* Override any SVG size constraints */\n.login-branding svg,\n.sidemenu__logo svg {\n  width: 100% !important;\n  height: 100% !important;\n}\n","custom-logo.js":"// Override logo size constraints\n(function() {\n  // Wait for page load\n  window.addEventListener('load', function() {\n    // Find and resize login logo\n    const loginLogo = document.querySelector('.login-branding img, .login-branding-logo');\n    if (loginLogo) {\n      loginLogo.style.width = '720px';\n      loginLogo.style.height = '360px';\n      loginLogo.style.maxWidth = '720px';\n      loginLogo.style.maxHeight = '360px';\n    }\n    \n    // Find and resize side menu logo\n    const sideMenuLogo = document.querySelector('.sidemenu__logo img');\n    if (sideMenuLogo) {\n      sideMenuLogo.style.width = '180px';\n      sideMenuLogo.style.height = '90px';\n    }\n  });\n})();\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"grafana-custom-branding","namespace":"monitoring"}}
    creationTimestamp: "2025-05-30T21:41:48Z"
    name: grafana-custom-branding
    namespace: monitoring
    resourceVersion: "227351"
    uid: b3bb9515-a774-4d29-bf1a-e9583536997f
- apiVersion: v1
  data:
    dashboards.yaml: |
      apiVersion: 1
      providers:
      - name: 'default'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards
      - name: 'phase2'
        orgId: 1
        folder: 'Phase 2'
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards-phase2
      - name: 'health'
        orgId: 1
        folder: 'Monitoring Health'
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards-health
      - name: 'razerblade-system'
        orgId: 1
        folder: 'Razer Blade'
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards-razerblade/system
      - name: 'razerblade-process'
        orgId: 1
        folder: 'Razer Blade'
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards-razerblade/process
      - name: 'razerblade-power'
        orgId: 1
        folder: 'Razer Blade'
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards-razerblade/power
      - name: 'razerblade-network'
        orgId: 1
        folder: 'Razer Blade'
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards-razerblade/network
      - name: 'razerblade-performance'
        orgId: 1
        folder: 'Razer Blade'
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards-razerblade/performance
      - name: 'logs-comprehensive'
        orgId: 1
        folder: 'ODIN Logs'
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards-logs-comprehensive
      - name: 'simple-logs'
        orgId: 1
        folder: 'ODIN Logs'
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards-simple-logs
      - name: 'overview'
        orgId: 1
        folder: 'ODIN'
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards-overview
      - name: 'claude'
        orgId: 1
        folder: 'ODIN'
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards-claude
      - name: 'razerblade-gpu'
        orgId: 1
        folder: 'Razer Blade'
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards-razerblade/gpu
      - name: 'logs'
        orgId: 1
        folder: 'Log Analysis'
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards-logs
      - name: 'anomaly'
        orgId: 1
        folder: 'ML Anomaly Detection'
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards-anomaly
      - name: 'network'
        orgId: 1
        folder: 'Network Monitoring'
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards-network
      - name: 'network-overview'
        orgId: 1
        folder: 'Network Monitoring'
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards-network-overview
      - name: 'udm-logs'
        orgId: 1
        folder: 'UDM Pro'
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards-udm-logs
      - name: 'udm-netflow'
        orgId: 1
        folder: 'UDM Pro'
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards-udm-netflow
      - name: 'udm-test'
        orgId: 1
        folder: 'UDM Pro'
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards-udm-test
      - name: 'udm-fixed-logs'
        orgId: 1
        folder: 'UDM Pro'
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards-udm-fixed-logs
      - name: 'udm-fixed-netflow'
        orgId: 1
        folder: 'UDM Pro'
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards-udm-fixed-netflow
      - name: 'nvidia-rtx'
        orgId: 1
        folder: 'GPU'
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards-nvidia-rtx
      - name: 'unifi-api'
        orgId: 1
        folder: 'Network'
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards-unifi-api
      # ODIN Prime dashboards
      - name: 'odin-prime-overview'
        orgId: 1
        folder: 'ODIN Prime'
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards-odin-prime/overview
      - name: 'odin-prime-claude'
        orgId: 1
        folder: 'ODIN Prime'
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards-odin-prime/claude
      - name: 'odin-prime-automation'
        orgId: 1
        folder: 'ODIN Prime'
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards-odin-prime/automation
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"dashboards.yaml":"apiVersion: 1\nproviders:\n- name: 'default'\n  orgId: 1\n  folder: ''\n  type: file\n  disableDeletion: false\n  updateIntervalSeconds: 10\n  allowUiUpdates: true\n  options:\n    path: /var/lib/grafana/dashboards\n- name: 'phase2'\n  orgId: 1\n  folder: 'Phase 2'\n  type: file\n  disableDeletion: false\n  updateIntervalSeconds: 10\n  allowUiUpdates: true\n  options:\n    path: /var/lib/grafana/dashboards-phase2\n- name: 'health'\n  orgId: 1\n  folder: 'Monitoring Health'\n  type: file\n  disableDeletion: false\n  updateIntervalSeconds: 10\n  allowUiUpdates: true\n  options:\n    path: /var/lib/grafana/dashboards-health\n- name: 'razerblade-system'\n  orgId: 1\n  folder: 'Razer Blade'\n  type: file\n  disableDeletion: false\n  updateIntervalSeconds: 10\n  allowUiUpdates: true\n  options:\n    path: /var/lib/grafana/dashboards-razerblade/system\n- name: 'razerblade-process'\n  orgId: 1\n  folder: 'Razer Blade'\n  type: file\n  disableDeletion: false\n  updateIntervalSeconds: 10\n  allowUiUpdates: true\n  options:\n    path: /var/lib/grafana/dashboards-razerblade/process\n- name: 'razerblade-power'\n  orgId: 1\n  folder: 'Razer Blade'\n  type: file\n  disableDeletion: false\n  updateIntervalSeconds: 10\n  allowUiUpdates: true\n  options:\n    path: /var/lib/grafana/dashboards-razerblade/power\n- name: 'razerblade-network'\n  orgId: 1\n  folder: 'Razer Blade'\n  type: file\n  disableDeletion: false\n  updateIntervalSeconds: 10\n  allowUiUpdates: true\n  options:\n    path: /var/lib/grafana/dashboards-razerblade/network\n- name: 'razerblade-performance'\n  orgId: 1\n  folder: 'Razer Blade'\n  type: file\n  disableDeletion: false\n  updateIntervalSeconds: 10\n  allowUiUpdates: true\n  options:\n    path: /var/lib/grafana/dashboards-razerblade/performance\n- name: 'logs-comprehensive'\n  orgId: 1\n  folder: 'ODIN Logs'\n  type: file\n  disableDeletion: false\n  updateIntervalSeconds: 10\n  allowUiUpdates: true\n  options:\n    path: /var/lib/grafana/dashboards-logs-comprehensive\n- name: 'simple-logs'\n  orgId: 1\n  folder: 'ODIN Logs'\n  type: file\n  disableDeletion: false\n  updateIntervalSeconds: 10\n  allowUiUpdates: true\n  options:\n    path: /var/lib/grafana/dashboards-simple-logs\n- name: 'overview'\n  orgId: 1\n  folder: 'ODIN'\n  type: file\n  disableDeletion: false\n  updateIntervalSeconds: 10\n  allowUiUpdates: true\n  options:\n    path: /var/lib/grafana/dashboards-overview\n- name: 'claude'\n  orgId: 1\n  folder: 'ODIN'\n  type: file\n  disableDeletion: false\n  updateIntervalSeconds: 10\n  allowUiUpdates: true\n  options:\n    path: /var/lib/grafana/dashboards-claude\n- name: 'razerblade-gpu'\n  orgId: 1\n  folder: 'Razer Blade'\n  type: file\n  disableDeletion: false\n  updateIntervalSeconds: 10\n  allowUiUpdates: true\n  options:\n    path: /var/lib/grafana/dashboards-razerblade/gpu\n- name: 'logs'\n  orgId: 1\n  folder: 'Log Analysis'\n  type: file\n  disableDeletion: false\n  updateIntervalSeconds: 10\n  allowUiUpdates: true\n  options:\n    path: /var/lib/grafana/dashboards-logs\n- name: 'anomaly'\n  orgId: 1\n  folder: 'ML Anomaly Detection'\n  type: file\n  disableDeletion: false\n  updateIntervalSeconds: 10\n  allowUiUpdates: true\n  options:\n    path: /var/lib/grafana/dashboards-anomaly\n- name: 'network'\n  orgId: 1\n  folder: 'Network Monitoring'\n  type: file\n  disableDeletion: false\n  updateIntervalSeconds: 10\n  allowUiUpdates: true\n  options:\n    path: /var/lib/grafana/dashboards-network\n- name: 'network-overview'\n  orgId: 1\n  folder: 'Network Monitoring'\n  type: file\n  disableDeletion: false\n  updateIntervalSeconds: 10\n  allowUiUpdates: true\n  options:\n    path: /var/lib/grafana/dashboards-network-overview\n- name: 'udm-logs'\n  orgId: 1\n  folder: 'UDM Pro'\n  type: file\n  disableDeletion: false\n  updateIntervalSeconds: 10\n  allowUiUpdates: true\n  options:\n    path: /var/lib/grafana/dashboards-udm-logs\n- name: 'udm-netflow'\n  orgId: 1\n  folder: 'UDM Pro'\n  type: file\n  disableDeletion: false\n  updateIntervalSeconds: 10\n  allowUiUpdates: true\n  options:\n    path: /var/lib/grafana/dashboards-udm-netflow\n- name: 'udm-test'\n  orgId: 1\n  folder: 'UDM Pro'\n  type: file\n  disableDeletion: false\n  updateIntervalSeconds: 10\n  allowUiUpdates: true\n  options:\n    path: /var/lib/grafana/dashboards-udm-test\n- name: 'udm-fixed-logs'\n  orgId: 1\n  folder: 'UDM Pro'\n  type: file\n  disableDeletion: false\n  updateIntervalSeconds: 10\n  allowUiUpdates: true\n  options:\n    path: /var/lib/grafana/dashboards-udm-fixed-logs\n- name: 'udm-fixed-netflow'\n  orgId: 1\n  folder: 'UDM Pro'\n  type: file\n  disableDeletion: false\n  updateIntervalSeconds: 10\n  allowUiUpdates: true\n  options:\n    path: /var/lib/grafana/dashboards-udm-fixed-netflow\n- name: 'nvidia-rtx'\n  orgId: 1\n  folder: 'GPU'\n  type: file\n  disableDeletion: false\n  updateIntervalSeconds: 10\n  allowUiUpdates: true\n  options:\n    path: /var/lib/grafana/dashboards-nvidia-rtx\n- name: 'unifi-api'\n  orgId: 1\n  folder: 'Network'\n  type: file\n  disableDeletion: false\n  updateIntervalSeconds: 10\n  allowUiUpdates: true\n  options:\n    path: /var/lib/grafana/dashboards-unifi-api\n# ODIN Prime dashboards\n- name: 'odin-prime-overview'\n  orgId: 1\n  folder: 'ODIN Prime'\n  type: file\n  disableDeletion: false\n  updateIntervalSeconds: 10\n  allowUiUpdates: true\n  options:\n    path: /var/lib/grafana/dashboards-odin-prime/overview\n- name: 'odin-prime-claude'\n  orgId: 1\n  folder: 'ODIN Prime'\n  type: file\n  disableDeletion: false\n  updateIntervalSeconds: 10\n  allowUiUpdates: true\n  options:\n    path: /var/lib/grafana/dashboards-odin-prime/claude\n- name: 'odin-prime-automation'\n  orgId: 1\n  folder: 'ODIN Prime'\n  type: file\n  disableDeletion: false\n  updateIntervalSeconds: 10\n  allowUiUpdates: true\n  options:\n    path: /var/lib/grafana/dashboards-odin-prime/automation\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"grafana-dashboard-provider","namespace":"monitoring"}}
    creationTimestamp: "2025-05-27T22:05:55Z"
    name: grafana-dashboard-provider
    namespace: monitoring
    resourceVersion: "3889544"
    uid: 0487a4a1-983b-4896-b9f7-a1868f921809
- apiVersion: v1
  data:
    anomaly-provider.yaml: |
      apiVersion: 1
      providers:
      - name: 'anomaly'
        orgId: 1
        folder: 'ML Anomaly Detection'
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards-anomaly
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"anomaly-provider.yaml":"apiVersion: 1\nproviders:\n- name: 'anomaly'\n  orgId: 1\n  folder: 'ML Anomaly Detection'\n  type: file\n  disableDeletion: false\n  updateIntervalSeconds: 10\n  allowUiUpdates: true\n  options:\n    path: /var/lib/grafana/dashboards-anomaly\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"grafana-dashboard-provider-anomaly","namespace":"monitoring"}}
    creationTimestamp: "2025-05-30T01:47:32Z"
    name: grafana-dashboard-provider-anomaly
    namespace: monitoring
    resourceVersion: "90649"
    uid: f7fd24be-ea75-4d54-b2da-8c2a3ac993fe
- apiVersion: v1
  data:
    disk-dashboard-provider.yaml: |
      apiVersion: 1
      providers:
      - name: 'disk-monitoring'
        orgId: 1
        folder: 'ODIN Infrastructure'
        type: file
        disableDeletion: false
        updateIntervalSeconds: 60
        allowUiUpdates: true
        options:
          path: /etc/grafana/provisioning/dashboards/disk-monitoring-dashboard
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"disk-dashboard-provider.yaml":"apiVersion: 1\nproviders:\n- name: 'disk-monitoring'\n  orgId: 1\n  folder: 'ODIN Infrastructure'\n  type: file\n  disableDeletion: false\n  updateIntervalSeconds: 60\n  allowUiUpdates: true\n  options:\n    path: /etc/grafana/provisioning/dashboards/disk-monitoring-dashboard\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"grafana-dashboard-provider-disk","namespace":"monitoring"}}
    creationTimestamp: "2025-06-08T14:58:38Z"
    name: grafana-dashboard-provider-disk
    namespace: monitoring
    resourceVersion: "5573255"
    uid: 79e1ddd8-754a-490e-aec1-74baafd0b292
- apiVersion: v1
  data:
    dashboards.yaml: |
      apiVersion: 1
      providers:
        - name: 'improved-anomaly'
          orgId: 1
          folder: 'ODIN Improved Dashboards'
          type: file
          disableDeletion: false
          updateIntervalSeconds: 10
          allowUiUpdates: true
          options:
            path: /var/lib/grafana/dashboards-improved
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"dashboards.yaml":"apiVersion: 1\nproviders:\n  - name: 'improved-anomaly'\n    orgId: 1\n    folder: 'ODIN Improved Dashboards'\n    type: file\n    disableDeletion: false\n    updateIntervalSeconds: 10\n    allowUiUpdates: true\n    options:\n      path: /var/lib/grafana/dashboards-improved\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"grafana-dashboard-provider-improved-standalone","namespace":"monitoring"}}
    creationTimestamp: "2025-06-07T02:24:19Z"
    name: grafana-dashboard-provider-improved-standalone
    namespace: monitoring
    resourceVersion: "4603049"
    uid: cc309b22-9cf0-46cd-8385-627165322adf
- apiVersion: v1
  data:
    ml-dashboards.yaml: |
      apiVersion: 1
      providers:
      - name: 'ml-anomaly-detection'
        orgId: 1
        folder: 'ML Anomaly Detection'
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards-ml-anomaly
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"ml-dashboards.yaml":"apiVersion: 1\nproviders:\n- name: 'ml-anomaly-detection'\n  orgId: 1\n  folder: 'ML Anomaly Detection'\n  type: file\n  disableDeletion: false\n  updateIntervalSeconds: 10\n  allowUiUpdates: true\n  options:\n    path: /var/lib/grafana/dashboards-ml-anomaly\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"grafana-dashboard-provider-ml-updated","namespace":"monitoring"}}
    creationTimestamp: "2025-06-02T19:23:52Z"
    name: grafana-dashboard-provider-ml-updated
    namespace: monitoring
    resourceVersion: "1894149"
    uid: 49b8330b-c078-4fb7-b1da-96e929b908b9
- apiVersion: v1
  data:
    provider.yaml: |
      apiVersion: 1
      providers:
      - name: 'process-anomaly-improved'
        orgId: 1
        folder: 'ODIN Anomaly Detection'
        type: file
        disableDeletion: false
        updateIntervalSeconds: 30
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards/process-anomaly-improved
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"provider.yaml":"apiVersion: 1\nproviders:\n- name: 'process-anomaly-improved'\n  orgId: 1\n  folder: 'ODIN Anomaly Detection'\n  type: file\n  disableDeletion: false\n  updateIntervalSeconds: 30\n  allowUiUpdates: true\n  options:\n    path: /var/lib/grafana/dashboards/process-anomaly-improved\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"grafana-dashboard-provider-process-anomaly-improved","namespace":"monitoring"}}
    creationTimestamp: "2025-06-07T02:08:09Z"
    name: grafana-dashboard-provider-process-anomaly-improved
    namespace: monitoring
    resourceVersion: "4595935"
    uid: 3b54f93c-a4c6-4c2d-a26c-12b8a91a86f3
- apiVersion: v1
  data:
    kubernetes-overview.json: |
      {
        "id": null,
        "title": "Kubernetes Cluster Overview",
        "tags": ["kubernetes"],
        "style": "dark",
        "timezone": "browser",
        "refresh": "30s",
        "schemaVersion": 27,
        "version": 1,
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "panels": [
          {
            "id": 1,
            "title": "Monitoring Stack Health",
            "type": "table",
            "targets": [
              {
                "expr": "up{job=~\"prometheus|node-exporter\"}",
                "format": "table",
                "instant": true,
                "refId": "A"
              }
            ],
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 0}
          },
          {
            "id": 2,
            "title": "Prometheus Query Rate",
            "type": "timeseries",
            "targets": [
              {
                "expr": "rate(prometheus_http_requests_total[5m])",
                "legendFormat": "{{ handler }}",
                "refId": "A"
              }
            ],
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 8}
          }
        ]
      }
    node-exporter-dashboard.json: |
      {
        "id": null,
        "title": "Node Exporter Full",
        "tags": ["node-exporter"],
        "style": "dark",
        "timezone": "browser",
        "refresh": "30s",
        "schemaVersion": 27,
        "version": 1,
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "panels": [
          {
            "id": 1,
            "title": "CPU Usage",
            "type": "stat",
            "targets": [
              {
                "expr": "100 - (avg(rate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)",
                "legendFormat": "CPU Usage %",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "percent",
                "min": 0,
                "max": 100,
                "thresholds": {
                  "steps": [
                    {"color": "green", "value": null},
                    {"color": "yellow", "value": 70},
                    {"color": "red", "value": 90}
                  ]
                }
              }
            },
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0}
          },
          {
            "id": 2,
            "title": "Memory Usage",
            "type": "stat",
            "targets": [
              {
                "expr": "(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100",
                "legendFormat": "Memory Usage %",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "percent",
                "min": 0,
                "max": 100,
                "thresholds": {
                  "steps": [
                    {"color": "green", "value": null},
                    {"color": "yellow", "value": 70},
                    {"color": "red", "value": 90}
                  ]
                }
              }
            },
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0}
          },
          {
            "id": 3,
            "title": "CPU Usage Over Time",
            "type": "timeseries",
            "targets": [
              {
                "expr": "100 - (avg(rate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)",
                "legendFormat": "CPU Usage %",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "percent",
                "min": 0,
                "max": 100
              }
            },
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 8}
          },
          {
            "id": 4,
            "title": "Memory Usage Over Time",
            "type": "timeseries",
            "targets": [
              {
                "expr": "node_memory_MemTotal_bytes",
                "legendFormat": "Total Memory",
                "refId": "A"
              },
              {
                "expr": "node_memory_MemAvailable_bytes",
                "legendFormat": "Available Memory",
                "refId": "B"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "bytes"
              }
            },
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 16}
          },
          {
            "id": 5,
            "title": "Disk Usage",
            "type": "table",
            "targets": [
              {
                "expr": "100 - ((node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes)",
                "legendFormat": "{{ mountpoint }}",
                "refId": "A",
                "format": "table",
                "instant": true
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "percent"
              }
            },
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 24}
          },
          {
            "id": 6,
            "title": "Network I/O",
            "type": "timeseries",
            "targets": [
              {
                "expr": "rate(node_network_receive_bytes_total[5m])",
                "legendFormat": "Receive {{ device }}",
                "refId": "A"
              },
              {
                "expr": "rate(node_network_transmit_bytes_total[5m])",
                "legendFormat": "Transmit {{ device }}",
                "refId": "B"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "Bps"
              }
            },
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 24}
          }
        ]
      }
    prometheus-overview.json: "{\n  \"id\": null,\n  \"title\": \"Prometheus Overview\",\n
      \ \"tags\": [\"prometheus\"],\n  \"style\": \"dark\",\n  \"timezone\": \"browser\",
      \n  \"refresh\": \"30s\",\n  \"schemaVersion\": 27,\n  \"version\": 1,\n  \"time\":
      {\n    \"from\": \"now-1h\",\n    \"to\": \"now\"\n  },\n  \"panels\": [\n    {\n
      \     \"id\": 1,\n      \"title\": \"Prometheus Targets\",\n      \"type\":
      \"stat\",\n      \"targets\": [\n        {\n          \"expr\": \"prometheus_sd_discovered_targets\",\n
      \         \"legendFormat\": \"Discovered Targets\",\n          \"refId\": \"A\"\n
      \       }\n      ],\n      \"gridPos\": {\"h\": 4, \"w\": 6, \"x\": 0, \"y\":
      0}\n    },\n    {\n      \"id\": 2,\n      \"title\": \"Query Rate\",\n      \"type\":
      \"timeseries\",\n      \"targets\": [\n        {\n          \"expr\": \"rate(prometheus_http_requests_total[5m])\",\n
      \         \"legendFormat\": \"{{ handler }}\",\n          \"refId\": \"A\"\n
      \       }\n      ],\n      \"gridPos\": {\"h\": 8, \"w\": 18, \"x\": 6, \"y\":
      0}\n    },\n    {\n      \"id\": 3,\n      \"title\": \"Storage Usage\", \n
      \     \"type\": \"timeseries\",\n      \"targets\": [\n        {\n          \"expr\":
      \"prometheus_tsdb_head_series\",\n          \"legendFormat\": \"Head Series\",\n
      \         \"refId\": \"A\"\n        }\n      ],\n      \"gridPos\": {\"h\":
      8, \"w\": 24, \"x\": 0, \"y\": 8}\n    }\n  ]\n}\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"kubernetes-overview.json":"{\n  \"id\": null,\n  \"title\": \"Kubernetes Cluster Overview\",\n  \"tags\": [\"kubernetes\"],\n  \"style\": \"dark\",\n  \"timezone\": \"browser\",\n  \"refresh\": \"30s\",\n  \"schemaVersion\": 27,\n  \"version\": 1,\n  \"time\": {\n    \"from\": \"now-1h\",\n    \"to\": \"now\"\n  },\n  \"panels\": [\n    {\n      \"id\": 1,\n      \"title\": \"Monitoring Stack Health\",\n      \"type\": \"table\",\n      \"targets\": [\n        {\n          \"expr\": \"up{job=~\\\"prometheus|node-exporter\\\"}\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 0}\n    },\n    {\n      \"id\": 2,\n      \"title\": \"Prometheus Query Rate\",\n      \"type\": \"timeseries\",\n      \"targets\": [\n        {\n          \"expr\": \"rate(prometheus_http_requests_total[5m])\",\n          \"legendFormat\": \"{{ handler }}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 8}\n    }\n  ]\n}\n","node-exporter-dashboard.json":"{\n  \"id\": null,\n  \"title\": \"Node Exporter Full\",\n  \"tags\": [\"node-exporter\"],\n  \"style\": \"dark\",\n  \"timezone\": \"browser\",\n  \"refresh\": \"30s\",\n  \"schemaVersion\": 27,\n  \"version\": 1,\n  \"time\": {\n    \"from\": \"now-1h\",\n    \"to\": \"now\"\n  },\n  \"panels\": [\n    {\n      \"id\": 1,\n      \"title\": \"CPU Usage\",\n      \"type\": \"stat\",\n      \"targets\": [\n        {\n          \"expr\": \"100 - (avg(rate(node_cpu_seconds_total{mode=\\\"idle\\\"}[5m])) * 100)\",\n          \"legendFormat\": \"CPU Usage %\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"percent\",\n          \"min\": 0,\n          \"max\": 100,\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 70},\n              {\"color\": \"red\", \"value\": 90}\n            ]\n          }\n        }\n      },\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 0}\n    },\n    {\n      \"id\": 2,\n      \"title\": \"Memory Usage\",\n      \"type\": \"stat\",\n      \"targets\": [\n        {\n          \"expr\": \"(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100\",\n          \"legendFormat\": \"Memory Usage %\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"percent\",\n          \"min\": 0,\n          \"max\": 100,\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 70},\n              {\"color\": \"red\", \"value\": 90}\n            ]\n          }\n        }\n      },\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 0}\n    },\n    {\n      \"id\": 3,\n      \"title\": \"CPU Usage Over Time\",\n      \"type\": \"timeseries\",\n      \"targets\": [\n        {\n          \"expr\": \"100 - (avg(rate(node_cpu_seconds_total{mode=\\\"idle\\\"}[5m])) * 100)\",\n          \"legendFormat\": \"CPU Usage %\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"percent\",\n          \"min\": 0,\n          \"max\": 100\n        }\n      },\n      \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 8}\n    },\n    {\n      \"id\": 4,\n      \"title\": \"Memory Usage Over Time\",\n      \"type\": \"timeseries\",\n      \"targets\": [\n        {\n          \"expr\": \"node_memory_MemTotal_bytes\",\n          \"legendFormat\": \"Total Memory\",\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"node_memory_MemAvailable_bytes\",\n          \"legendFormat\": \"Available Memory\",\n          \"refId\": \"B\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"bytes\"\n        }\n      },\n      \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 16}\n    },\n    {\n      \"id\": 5,\n      \"title\": \"Disk Usage\",\n      \"type\": \"table\",\n      \"targets\": [\n        {\n          \"expr\": \"100 - ((node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes)\",\n          \"legendFormat\": \"{{ mountpoint }}\",\n          \"refId\": \"A\",\n          \"format\": \"table\",\n          \"instant\": true\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"percent\"\n        }\n      },\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 24}\n    },\n    {\n      \"id\": 6,\n      \"title\": \"Network I/O\",\n      \"type\": \"timeseries\",\n      \"targets\": [\n        {\n          \"expr\": \"rate(node_network_receive_bytes_total[5m])\",\n          \"legendFormat\": \"Receive {{ device }}\",\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"rate(node_network_transmit_bytes_total[5m])\",\n          \"legendFormat\": \"Transmit {{ device }}\",\n          \"refId\": \"B\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"Bps\"\n        }\n      },\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 24}\n    }\n  ]\n}\n","prometheus-overview.json":"{\n  \"id\": null,\n  \"title\": \"Prometheus Overview\",\n  \"tags\": [\"prometheus\"],\n  \"style\": \"dark\",\n  \"timezone\": \"browser\", \n  \"refresh\": \"30s\",\n  \"schemaVersion\": 27,\n  \"version\": 1,\n  \"time\": {\n    \"from\": \"now-1h\",\n    \"to\": \"now\"\n  },\n  \"panels\": [\n    {\n      \"id\": 1,\n      \"title\": \"Prometheus Targets\",\n      \"type\": \"stat\",\n      \"targets\": [\n        {\n          \"expr\": \"prometheus_sd_discovered_targets\",\n          \"legendFormat\": \"Discovered Targets\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"gridPos\": {\"h\": 4, \"w\": 6, \"x\": 0, \"y\": 0}\n    },\n    {\n      \"id\": 2,\n      \"title\": \"Query Rate\",\n      \"type\": \"timeseries\",\n      \"targets\": [\n        {\n          \"expr\": \"rate(prometheus_http_requests_total[5m])\",\n          \"legendFormat\": \"{{ handler }}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"gridPos\": {\"h\": 8, \"w\": 18, \"x\": 6, \"y\": 0}\n    },\n    {\n      \"id\": 3,\n      \"title\": \"Storage Usage\", \n      \"type\": \"timeseries\",\n      \"targets\": [\n        {\n          \"expr\": \"prometheus_tsdb_head_series\",\n          \"legendFormat\": \"Head Series\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 8}\n    }\n  ]\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"grafana-dashboards","namespace":"monitoring"}}
    creationTimestamp: "2025-05-27T22:17:01Z"
    name: grafana-dashboards
    namespace: monitoring
    resourceVersion: "1349"
    uid: d8275bda-e961-4b5d-a395-4ce85d8d96cd
- apiVersion: v1
  data:
    prometheus.yaml: |
      apiVersion: 1
      datasources:
      - name: Prometheus
        type: prometheus
        access: proxy
        orgId: 1
        url: http://prometheus:9090
        isDefault: true
        editable: true
      - name: Loki
        type: loki
        access: proxy
        orgId: 1
        uid: loki
        url: http://loki.monitoring.svc.cluster.local:3100
        editable: true
        isDefault: false
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"prometheus.yaml":"apiVersion: 1\ndatasources:\n- name: Prometheus\n  type: prometheus\n  access: proxy\n  orgId: 1\n  url: http://prometheus:9090\n  isDefault: true\n  editable: true\n- name: Loki\n  type: loki\n  access: proxy\n  orgId: 1\n  uid: loki\n  url: http://loki.monitoring.svc.cluster.local:3100\n  editable: true\n  isDefault: false\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"grafana-datasources","namespace":"monitoring"}}
    creationTimestamp: "2025-05-27T22:05:55Z"
    name: grafana-datasources
    namespace: monitoring
    resourceVersion: "14253"
    uid: 4def8b34-43e0-4134-885f-1b3c3b6d741b
- apiVersion: v1
  data:
    patch.yaml: |
      spec:
        template:
          spec:
            containers:
            - name: grafana
              volumeMounts:
              - name: odin-prime-overview-dashboard
                mountPath: /var/lib/grafana/dashboards-odin-prime/overview
              - name: odin-prime-claude-dashboard
                mountPath: /var/lib/grafana/dashboards-odin-prime/claude
              - name: odin-prime-automation-dashboard
                mountPath: /var/lib/grafana/dashboards-odin-prime/automation
            volumes:
            - name: odin-prime-overview-dashboard
              configMap:
                name: odin-prime-overview-dashboard
            - name: odin-prime-claude-dashboard
              configMap:
                name: odin-prime-claude-dashboard
            - name: odin-prime-automation-dashboard
              configMap:
                name: odin-prime-automation-dashboard
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"patch.yaml":"spec:\n  template:\n    spec:\n      containers:\n      - name: grafana\n        volumeMounts:\n        - name: odin-prime-overview-dashboard\n          mountPath: /var/lib/grafana/dashboards-odin-prime/overview\n        - name: odin-prime-claude-dashboard\n          mountPath: /var/lib/grafana/dashboards-odin-prime/claude\n        - name: odin-prime-automation-dashboard\n          mountPath: /var/lib/grafana/dashboards-odin-prime/automation\n      volumes:\n      - name: odin-prime-overview-dashboard\n        configMap:\n          name: odin-prime-overview-dashboard\n      - name: odin-prime-claude-dashboard\n        configMap:\n          name: odin-prime-claude-dashboard\n      - name: odin-prime-automation-dashboard\n        configMap:\n          name: odin-prime-automation-dashboard\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"grafana-deployment-patch","namespace":"monitoring"}}
    creationTimestamp: "2025-06-05T23:35:10Z"
    name: grafana-deployment-patch
    namespace: monitoring
    resourceVersion: "3889546"
    uid: d6910aa2-1999-436d-b729-591b352e8a10
- apiVersion: v1
  data:
    favicon.ico: "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"32\" height=\"32\"
      viewBox=\"0 0 32 32\">\n  <rect width=\"32\" height=\"32\" fill=\"#1a1a1a\"/>\n
      \ <text x=\"16\" y=\"22\" font-family=\"Arial\" font-size=\"14\" font-weight=\"bold\"
      \n        text-anchor=\"middle\" fill=\"#00ff88\">O</text>\n  <circle cx=\"8\"
      cy=\"8\" r=\"2\" fill=\"#00ff88\"/>\n  <circle cx=\"24\" cy=\"8\" r=\"2\" fill=\"#0099ff\"/>\n
      \ <circle cx=\"8\" cy=\"24\" r=\"1\" fill=\"#00ff88\" opacity=\"0.7\"/>\n  <circle
      cx=\"24\" cy=\"24\" r=\"1\" fill=\"#0099ff\" opacity=\"0.7\"/>\n</svg>\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"favicon.ico":"\u003csvg xmlns=\"http://www.w3.org/2000/svg\" width=\"32\" height=\"32\" viewBox=\"0 0 32 32\"\u003e\n  \u003crect width=\"32\" height=\"32\" fill=\"#1a1a1a\"/\u003e\n  \u003ctext x=\"16\" y=\"22\" font-family=\"Arial\" font-size=\"14\" font-weight=\"bold\" \n        text-anchor=\"middle\" fill=\"#00ff88\"\u003eO\u003c/text\u003e\n  \u003ccircle cx=\"8\" cy=\"8\" r=\"2\" fill=\"#00ff88\"/\u003e\n  \u003ccircle cx=\"24\" cy=\"8\" r=\"2\" fill=\"#0099ff\"/\u003e\n  \u003ccircle cx=\"8\" cy=\"24\" r=\"1\" fill=\"#00ff88\" opacity=\"0.7\"/\u003e\n  \u003ccircle cx=\"24\" cy=\"24\" r=\"1\" fill=\"#0099ff\" opacity=\"0.7\"/\u003e\n\u003c/svg\u003e\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"grafana-favicon","namespace":"monitoring"}}
    creationTimestamp: "2025-05-29T03:57:28Z"
    name: grafana-favicon
    namespace: monitoring
    resourceVersion: "53721"
    uid: a47b7f0b-4ca3-4865-928b-79b947ae1076
- apiVersion: v1
  data:
    logo.svg: "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"1440\" height=\"720\"
      viewBox=\"0 0 1440 720\">\n  <defs>\n    <linearGradient id=\"grad1\" x1=\"0%\"
      y1=\"0%\" x2=\"100%\" y2=\"100%\">\n      <stop offset=\"0%\" style=\"stop-color:#00ff88;stop-opacity:1\"
      />\n      <stop offset=\"100%\" style=\"stop-color:#0099ff;stop-opacity:1\"
      />\n    </linearGradient>\n    <filter id=\"glow\">\n      <feGaussianBlur stdDeviation=\"8\"
      result=\"coloredBlur\"/>\n      <feMerge>\n        <feMergeNode in=\"coloredBlur\"/>\n
      \       <feMergeNode in=\"SourceGraphic\"/>\n      </feMerge>\n    </filter>\n
      \   <pattern id=\"grid\" width=\"60\" height=\"60\" patternUnits=\"userSpaceOnUse\">\n
      \     <path d=\"M 60 0 L 0 0 0 60\" fill=\"none\" stroke=\"#333\" stroke-width=\"0.5\"
      opacity=\"0.2\"/>\n    </pattern>\n  </defs>\n  \n  <!-- Background grid effect
      -->\n  <rect width=\"1440\" height=\"720\" fill=\"url(#grid)\" opacity=\"0.3\"/>\n
      \ \n  <!-- ODIN text with gradient - 4x original size -->\n  <text x=\"720\"
      y=\"300\" font-family=\"Arial Black, sans-serif\" font-size=\"240\" font-weight=\"900\"
      \n        text-anchor=\"middle\" fill=\"url(#grad1)\" filter=\"url(#glow)\"
      letter-spacing=\"-5\">ODIN</text>\n  \n  <!-- Subtitle - 4x original size -->\n
      \ <text x=\"720\" y=\"480\" font-family=\"Arial, sans-serif\" font-size=\"96\"
      font-weight=\"300\"\n        text-anchor=\"middle\" fill=\"#999\">Omnipresent
      Diagnostics</text>\n  <text x=\"720\" y=\"600\" font-family=\"Arial, sans-serif\"
      font-size=\"96\" font-weight=\"300\"\n        text-anchor=\"middle\" fill=\"#999\">Intelligence
      Network</text>\n  \n  <!-- Decorative elements - 4x original size -->\n  <circle
      cx=\"180\" cy=\"180\" r=\"36\" fill=\"#00ff88\" opacity=\"0.8\">\n    <animate
      attributeName=\"r\" values=\"36;40;36\" dur=\"3s\" repeatCount=\"indefinite\"/>\n
      \ </circle>\n  <circle cx=\"1260\" cy=\"180\" r=\"36\" fill=\"#0099ff\" opacity=\"0.8\">\n
      \   <animate attributeName=\"r\" values=\"36;40;36\" dur=\"3s\" repeatCount=\"indefinite\"/>\n
      \ </circle>\n  <circle cx=\"180\" cy=\"540\" r=\"24\" fill=\"#00ff88\" opacity=\"0.6\">\n
      \   <animate attributeName=\"opacity\" values=\"0.6;0.8;0.6\" dur=\"2s\" repeatCount=\"indefinite\"/>\n
      \ </circle>\n  <circle cx=\"1260\" cy=\"540\" r=\"24\" fill=\"#0099ff\" opacity=\"0.6\">\n
      \   <animate attributeName=\"opacity\" values=\"0.6;0.8;0.6\" dur=\"2s\" repeatCount=\"indefinite\"/>\n
      \ </circle>\n  \n  <!-- Connection lines - 4x original size -->\n  <line x1=\"216\"
      y1=\"180\" x2=\"1224\" y2=\"180\" stroke=\"#333\" stroke-width=\"12\" opacity=\"0.5\"/>\n
      \ <line x1=\"204\" y1=\"540\" x2=\"1236\" y2=\"540\" stroke=\"#333\" stroke-width=\"12\"
      opacity=\"0.5\"/>\n  \n  <!-- Network nodes -->\n  <circle cx=\"720\" cy=\"180\"
      r=\"12\" fill=\"#00ccff\" opacity=\"0.8\"/>\n  <circle cx=\"720\" cy=\"540\"
      r=\"12\" fill=\"#00ccff\" opacity=\"0.8\"/>\n  <circle cx=\"480\" cy=\"360\"
      r=\"8\" fill=\"#00ff88\" opacity=\"0.6\"/>\n  <circle cx=\"960\" cy=\"360\"
      r=\"8\" fill=\"#0099ff\" opacity=\"0.6\"/>\n  \n  <!-- Connection web -->\n
      \ <line x1=\"480\" y1=\"360\" x2=\"720\" y2=\"180\" stroke=\"#00ccff\" stroke-width=\"2\"
      opacity=\"0.4\"/>\n  <line x1=\"960\" y1=\"360\" x2=\"720\" y2=\"180\" stroke=\"#00ccff\"
      stroke-width=\"2\" opacity=\"0.4\"/>\n  <line x1=\"480\" y1=\"360\" x2=\"720\"
      y2=\"540\" stroke=\"#00ccff\" stroke-width=\"2\" opacity=\"0.4\"/>\n  <line
      x1=\"960\" y1=\"360\" x2=\"720\" y2=\"540\" stroke=\"#00ccff\" stroke-width=\"2\"
      opacity=\"0.4\"/>\n</svg>\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"logo.svg":"\u003csvg xmlns=\"http://www.w3.org/2000/svg\" width=\"1440\" height=\"720\" viewBox=\"0 0 1440 720\"\u003e\n  \u003cdefs\u003e\n    \u003clinearGradient id=\"grad1\" x1=\"0%\" y1=\"0%\" x2=\"100%\" y2=\"100%\"\u003e\n      \u003cstop offset=\"0%\" style=\"stop-color:#00ff88;stop-opacity:1\" /\u003e\n      \u003cstop offset=\"100%\" style=\"stop-color:#0099ff;stop-opacity:1\" /\u003e\n    \u003c/linearGradient\u003e\n    \u003cfilter id=\"glow\"\u003e\n      \u003cfeGaussianBlur stdDeviation=\"8\" result=\"coloredBlur\"/\u003e\n      \u003cfeMerge\u003e\n        \u003cfeMergeNode in=\"coloredBlur\"/\u003e\n        \u003cfeMergeNode in=\"SourceGraphic\"/\u003e\n      \u003c/feMerge\u003e\n    \u003c/filter\u003e\n    \u003cpattern id=\"grid\" width=\"60\" height=\"60\" patternUnits=\"userSpaceOnUse\"\u003e\n      \u003cpath d=\"M 60 0 L 0 0 0 60\" fill=\"none\" stroke=\"#333\" stroke-width=\"0.5\" opacity=\"0.2\"/\u003e\n    \u003c/pattern\u003e\n  \u003c/defs\u003e\n  \n  \u003c!-- Background grid effect --\u003e\n  \u003crect width=\"1440\" height=\"720\" fill=\"url(#grid)\" opacity=\"0.3\"/\u003e\n  \n  \u003c!-- ODIN text with gradient - 4x original size --\u003e\n  \u003ctext x=\"720\" y=\"300\" font-family=\"Arial Black, sans-serif\" font-size=\"240\" font-weight=\"900\" \n        text-anchor=\"middle\" fill=\"url(#grad1)\" filter=\"url(#glow)\" letter-spacing=\"-5\"\u003eODIN\u003c/text\u003e\n  \n  \u003c!-- Subtitle - 4x original size --\u003e\n  \u003ctext x=\"720\" y=\"480\" font-family=\"Arial, sans-serif\" font-size=\"96\" font-weight=\"300\"\n        text-anchor=\"middle\" fill=\"#999\"\u003eOmnipresent Diagnostics\u003c/text\u003e\n  \u003ctext x=\"720\" y=\"600\" font-family=\"Arial, sans-serif\" font-size=\"96\" font-weight=\"300\"\n        text-anchor=\"middle\" fill=\"#999\"\u003eIntelligence Network\u003c/text\u003e\n  \n  \u003c!-- Decorative elements - 4x original size --\u003e\n  \u003ccircle cx=\"180\" cy=\"180\" r=\"36\" fill=\"#00ff88\" opacity=\"0.8\"\u003e\n    \u003canimate attributeName=\"r\" values=\"36;40;36\" dur=\"3s\" repeatCount=\"indefinite\"/\u003e\n  \u003c/circle\u003e\n  \u003ccircle cx=\"1260\" cy=\"180\" r=\"36\" fill=\"#0099ff\" opacity=\"0.8\"\u003e\n    \u003canimate attributeName=\"r\" values=\"36;40;36\" dur=\"3s\" repeatCount=\"indefinite\"/\u003e\n  \u003c/circle\u003e\n  \u003ccircle cx=\"180\" cy=\"540\" r=\"24\" fill=\"#00ff88\" opacity=\"0.6\"\u003e\n    \u003canimate attributeName=\"opacity\" values=\"0.6;0.8;0.6\" dur=\"2s\" repeatCount=\"indefinite\"/\u003e\n  \u003c/circle\u003e\n  \u003ccircle cx=\"1260\" cy=\"540\" r=\"24\" fill=\"#0099ff\" opacity=\"0.6\"\u003e\n    \u003canimate attributeName=\"opacity\" values=\"0.6;0.8;0.6\" dur=\"2s\" repeatCount=\"indefinite\"/\u003e\n  \u003c/circle\u003e\n  \n  \u003c!-- Connection lines - 4x original size --\u003e\n  \u003cline x1=\"216\" y1=\"180\" x2=\"1224\" y2=\"180\" stroke=\"#333\" stroke-width=\"12\" opacity=\"0.5\"/\u003e\n  \u003cline x1=\"204\" y1=\"540\" x2=\"1236\" y2=\"540\" stroke=\"#333\" stroke-width=\"12\" opacity=\"0.5\"/\u003e\n  \n  \u003c!-- Network nodes --\u003e\n  \u003ccircle cx=\"720\" cy=\"180\" r=\"12\" fill=\"#00ccff\" opacity=\"0.8\"/\u003e\n  \u003ccircle cx=\"720\" cy=\"540\" r=\"12\" fill=\"#00ccff\" opacity=\"0.8\"/\u003e\n  \u003ccircle cx=\"480\" cy=\"360\" r=\"8\" fill=\"#00ff88\" opacity=\"0.6\"/\u003e\n  \u003ccircle cx=\"960\" cy=\"360\" r=\"8\" fill=\"#0099ff\" opacity=\"0.6\"/\u003e\n  \n  \u003c!-- Connection web --\u003e\n  \u003cline x1=\"480\" y1=\"360\" x2=\"720\" y2=\"180\" stroke=\"#00ccff\" stroke-width=\"2\" opacity=\"0.4\"/\u003e\n  \u003cline x1=\"960\" y1=\"360\" x2=\"720\" y2=\"180\" stroke=\"#00ccff\" stroke-width=\"2\" opacity=\"0.4\"/\u003e\n  \u003cline x1=\"480\" y1=\"360\" x2=\"720\" y2=\"540\" stroke=\"#00ccff\" stroke-width=\"2\" opacity=\"0.4\"/\u003e\n  \u003cline x1=\"960\" y1=\"360\" x2=\"720\" y2=\"540\" stroke=\"#00ccff\" stroke-width=\"2\" opacity=\"0.4\"/\u003e\n\u003c/svg\u003e\n"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"grafana_logo":"odin"},"name":"grafana-logo","namespace":"monitoring"}}
    creationTimestamp: "2025-05-29T03:57:28Z"
    labels:
      grafana_logo: odin
    name: grafana-logo
    namespace: monitoring
    resourceVersion: "226425"
    uid: 5b2f21a6-7ce1-4f9d-9ae2-c603d66f80ad
- apiVersion: v1
  data:
    grafana-metrics-dashboard.json: |-
      {
        "annotations": {
          "list": [
            {
              "builtIn": 1,
              "datasource": {
                "type": "grafana",
                "uid": "-- Grafana --"
              },
              "enable": true,
              "hide": true,
              "iconColor": "rgba(0, 211, 255, 1)",
              "name": "Annotations & Alerts",
              "type": "dashboard"
            }
          ]
        },
        "editable": true,
        "fiscalYearStartMonth": 0,
        "graphTooltip": 1,
        "id": null,
        "links": [],
        "liveNow": false,
        "panels": [
          {
            "datasource": {
              "type": "prometheus",
              "uid": "${datasource}"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    }
                  ]
                }
              },
              "overrides": []
            },
            "gridPos": {
              "h": 3,
              "w": 4,
              "x": 0,
              "y": 0
            },
            "id": 1,
            "options": {
              "colorMode": "value",
              "graphMode": "none",
              "justifyMode": "center",
              "orientation": "auto",
              "reduceOptions": {
                "calcs": ["lastNotNull"],
                "fields": "",
                "values": false
              },
              "text": {},
              "textMode": "auto"
            },
            "pluginVersion": "10.0.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "${datasource}"
                },
                "expr": "grafana_build_info",
                "instant": true,
                "legendFormat": "{{version}}",
                "refId": "A"
              }
            ],
            "title": "Grafana Version",
            "type": "stat"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "${datasource}"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    }
                  ]
                },
                "unit": "dateTimeFromNow"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 3,
              "w": 4,
              "x": 4,
              "y": 0
            },
            "id": 2,
            "options": {
              "colorMode": "value",
              "graphMode": "none",
              "justifyMode": "center",
              "orientation": "auto",
              "reduceOptions": {
                "calcs": ["lastNotNull"],
                "fields": "",
                "values": false
              },
              "text": {},
              "textMode": "auto"
            },
            "pluginVersion": "10.0.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "${datasource}"
                },
                "expr": "process_start_time_seconds{job=\"grafana\"} * 1000",
                "instant": true,
                "refId": "A"
              }
            ],
            "title": "Uptime",
            "type": "stat"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "${datasource}"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    }
                  ]
                },
                "unit": "short"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 3,
              "w": 4,
              "x": 8,
              "y": 0
            },
            "id": 3,
            "options": {
              "colorMode": "value",
              "graphMode": "none",
              "justifyMode": "center",
              "orientation": "auto",
              "reduceOptions": {
                "calcs": ["lastNotNull"],
                "fields": "",
                "values": false
              },
              "text": {},
              "textMode": "auto"
            },
            "pluginVersion": "10.0.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "${datasource}"
                },
                "expr": "grafana_stat_totals_dashboard",
                "instant": true,
                "refId": "A"
              }
            ],
            "title": "Total Dashboards",
            "type": "stat"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "${datasource}"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "yellow",
                      "value": 5
                    },
                    {
                      "color": "red",
                      "value": 10
                    }
                  ]
                },
                "unit": "short"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 3,
              "w": 4,
              "x": 12,
              "y": 0
            },
            "id": 4,
            "options": {
              "colorMode": "value",
              "graphMode": "none",
              "justifyMode": "center",
              "orientation": "auto",
              "reduceOptions": {
                "calcs": ["lastNotNull"],
                "fields": "",
                "values": false
              },
              "text": {},
              "textMode": "auto"
            },
            "pluginVersion": "10.0.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "${datasource}"
                },
                "expr": "grafana_alerting_active_alerts",
                "instant": true,
                "refId": "A"
              }
            ],
            "title": "Active Alerts",
            "type": "stat"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "${datasource}"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    }
                  ]
                },
                "unit": "bytes"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 3,
              "w": 4,
              "x": 16,
              "y": 0
            },
            "id": 5,
            "options": {
              "colorMode": "value",
              "graphMode": "none",
              "justifyMode": "center",
              "orientation": "auto",
              "reduceOptions": {
                "calcs": ["lastNotNull"],
                "fields": "",
                "values": false
              },
              "text": {},
              "textMode": "auto"
            },
            "pluginVersion": "10.0.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "${datasource}"
                },
                "expr": "go_memstats_heap_inuse_bytes{job=\"grafana\"}",
                "instant": true,
                "refId": "A"
              }
            ],
            "title": "Memory Usage",
            "type": "stat"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "${datasource}"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    }
                  ]
                },
                "unit": "short"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 3,
              "w": 4,
              "x": 20,
              "y": 0
            },
            "id": 6,
            "options": {
              "colorMode": "value",
              "graphMode": "none",
              "justifyMode": "center",
              "orientation": "auto",
              "reduceOptions": {
                "calcs": ["lastNotNull"],
                "fields": "",
                "values": false
              },
              "text": {},
              "textMode": "auto"
            },
            "pluginVersion": "10.0.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "${datasource}"
                },
                "expr": "go_goroutines{job=\"grafana\"}",
                "instant": true,
                "refId": "A"
              }
            ],
            "title": "Goroutines",
            "type": "stat"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "${datasource}"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisCenteredZero": false,
                  "axisColorMode": "text",
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 10,
                  "gradientMode": "none",
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  },
                  "insertNulls": false,
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "never",
                  "spanNulls": false,
                  "stacking": {
                    "group": "A",
                    "mode": "none"
                  },
                  "thresholdsStyle": {
                    "mode": "off"
                  }
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    }
                  ]
                },
                "unit": "reqps"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 0,
              "y": 3
            },
            "id": 7,
            "options": {
              "legend": {
                "calcs": ["mean", "lastNotNull"],
                "displayMode": "table",
                "placement": "bottom",
                "showLegend": true
              },
              "tooltip": {
                "mode": "multi",
                "sort": "desc"
              }
            },
            "pluginVersion": "10.0.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "${datasource}"
                },
                "expr": "rate(grafana_http_request_total[5m])",
                "legendFormat": "{{handler}} {{method}} {{status_code}}",
                "refId": "A"
              }
            ],
            "title": "HTTP Request Rate",
            "type": "timeseries"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "${datasource}"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisCenteredZero": false,
                  "axisColorMode": "text",
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 10,
                  "gradientMode": "none",
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  },
                  "insertNulls": false,
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "never",
                  "spanNulls": false,
                  "stacking": {
                    "group": "A",
                    "mode": "none"
                  },
                  "thresholdsStyle": {
                    "mode": "off"
                  }
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    }
                  ]
                },
                "unit": "s"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 12,
              "y": 3
            },
            "id": 8,
            "options": {
              "legend": {
                "calcs": ["mean", "max"],
                "displayMode": "table",
                "placement": "bottom",
                "showLegend": true
              },
              "tooltip": {
                "mode": "multi",
                "sort": "desc"
              }
            },
            "pluginVersion": "10.0.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "${datasource}"
                },
                "expr": "histogram_quantile(0.95, sum(rate(grafana_http_request_duration_seconds_bucket[5m])) by (le, handler))",
                "legendFormat": "p95 {{handler}}",
                "refId": "A"
              },
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "${datasource}"
                },
                "expr": "histogram_quantile(0.50, sum(rate(grafana_http_request_duration_seconds_bucket[5m])) by (le, handler))",
                "legendFormat": "p50 {{handler}}",
                "refId": "B"
              }
            ],
            "title": "Request Latency Percentiles",
            "type": "timeseries"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "${datasource}"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisCenteredZero": false,
                  "axisColorMode": "text",
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 10,
                  "gradientMode": "none",
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  },
                  "insertNulls": false,
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "never",
                  "spanNulls": false,
                  "stacking": {
                    "group": "A",
                    "mode": "none"
                  },
                  "thresholdsStyle": {
                    "mode": "off"
                  }
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    }
                  ]
                },
                "unit": "bytes"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 0,
              "y": 11
            },
            "id": 9,
            "options": {
              "legend": {
                "calcs": ["mean", "lastNotNull"],
                "displayMode": "table",
                "placement": "bottom",
                "showLegend": true
              },
              "tooltip": {
                "mode": "multi",
                "sort": "desc"
              }
            },
            "pluginVersion": "10.0.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "${datasource}"
                },
                "expr": "go_memstats_heap_inuse_bytes{job=\"grafana\"}",
                "legendFormat": "Heap In Use",
                "refId": "A"
              },
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "${datasource}"
                },
                "expr": "go_memstats_heap_alloc_bytes{job=\"grafana\"}",
                "legendFormat": "Heap Allocated",
                "refId": "B"
              },
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "${datasource}"
                },
                "expr": "go_memstats_sys_bytes{job=\"grafana\"}",
                "legendFormat": "System Memory",
                "refId": "C"
              }
            ],
            "title": "Memory Usage",
            "type": "timeseries"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "${datasource}"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisCenteredZero": false,
                  "axisColorMode": "text",
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 10,
                  "gradientMode": "none",
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  },
                  "insertNulls": false,
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "never",
                  "spanNulls": false,
                  "stacking": {
                    "group": "A",
                    "mode": "none"
                  },
                  "thresholdsStyle": {
                    "mode": "off"
                  }
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    }
                  ]
                },
                "unit": "short"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 12,
              "y": 11
            },
            "id": 10,
            "options": {
              "legend": {
                "calcs": ["mean", "lastNotNull"],
                "displayMode": "table",
                "placement": "bottom",
                "showLegend": true
              },
              "tooltip": {
                "mode": "multi",
                "sort": "desc"
              }
            },
            "pluginVersion": "10.0.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "${datasource}"
                },
                "expr": "grafana_database_conn_idle_total",
                "legendFormat": "Idle Connections",
                "refId": "A"
              },
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "${datasource}"
                },
                "expr": "grafana_database_conn_in_use_total",
                "legendFormat": "In Use",
                "refId": "B"
              },
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "${datasource}"
                },
                "expr": "grafana_database_conn_open_total",
                "legendFormat": "Open Total",
                "refId": "C"
              }
            ],
            "title": "Database Connection Pool",
            "type": "timeseries"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "${datasource}"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisCenteredZero": false,
                  "axisColorMode": "text",
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 10,
                  "gradientMode": "none",
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  },
                  "insertNulls": false,
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "never",
                  "spanNulls": false,
                  "stacking": {
                    "group": "A",
                    "mode": "none"
                  },
                  "thresholdsStyle": {
                    "mode": "off"
                  }
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    }
                  ]
                },
                "unit": "ms"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 0,
              "y": 19
            },
            "id": 11,
            "options": {
              "legend": {
                "calcs": ["mean", "lastNotNull"],
                "displayMode": "table",
                "placement": "bottom",
                "showLegend": true
              },
              "tooltip": {
                "mode": "multi",
                "sort": "desc"
              }
            },
            "pluginVersion": "10.0.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "${datasource}"
                },
                "expr": "histogram_quantile(0.95, sum(rate(grafana_alerting_execution_time_milliseconds_bucket[5m])) by (le))",
                "legendFormat": "p95",
                "refId": "A"
              },
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "${datasource}"
                },
                "expr": "histogram_quantile(0.50, sum(rate(grafana_alerting_execution_time_milliseconds_bucket[5m])) by (le))",
                "legendFormat": "p50",
                "refId": "B"
              }
            ],
            "title": "Alert Evaluation Time",
            "type": "timeseries"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "${datasource}"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  }
                },
                "mappings": []
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 12,
              "y": 19
            },
            "id": 12,
            "options": {
              "legend": {
                "displayMode": "list",
                "placement": "bottom",
                "showLegend": true
              },
              "pieType": "pie",
              "tooltip": {
                "mode": "single",
                "sort": "none"
              }
            },
            "pluginVersion": "10.0.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "${datasource}"
                },
                "expr": "sum by (status_code) (increase(grafana_api_response_status_total[1h]))",
                "instant": true,
                "legendFormat": "{{status_code}}",
                "refId": "A"
              }
            ],
            "title": "API Response Status Codes (1h)",
            "type": "piechart"
          }
        ],
        "refresh": "30s",
        "schemaVersion": 38,
        "style": "dark",
        "tags": ["odin", "grafana", "monitoring"],
        "templating": {
          "list": [
            {
              "current": {
                "selected": false,
                "text": "Prometheus",
                "value": "prometheus"
              },
              "hide": 0,
              "includeAll": false,
              "label": "Data Source",
              "multi": false,
              "name": "datasource",
              "options": [],
              "query": "prometheus",
              "queryValue": "",
              "refresh": 1,
              "regex": "",
              "skipUrlSync": false,
              "type": "datasource"
            }
          ]
        },
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "timepicker": {
          "refresh_intervals": ["10s", "30s", "1m", "5m", "15m", "30m", "1h", "2h", "1d"]
        },
        "timezone": "",
        "title": "Grafana Metrics",
        "uid": "grafana-metrics",
        "version": 1,
        "weekStart": ""
      }
  kind: ConfigMap
  metadata:
    creationTimestamp: "2025-05-30T19:46:26Z"
    name: grafana-metrics-dashboard
    namespace: monitoring
    resourceVersion: "207393"
    uid: da8a9fd7-960e-4739-96ab-20ed0e0fd436
- apiVersion: v1
  data:
    host-process-monitoring.json: |
      {
        "id": null,
        "uid": "host-process-monitoring",
        "title": "Host Process Monitoring - Ubuntu 22.04",
        "tags": ["processes", "system", "razerblade", "host"],
        "timezone": "browser",
        "schemaVersion": 38,
        "version": 3,
        "refresh": "30s",
        "panels": [
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0},
            "id": 1,
            "type": "timeseries",
            "title": "Top CPU Consuming Processes",
            "targets": [
              {
                "expr": "topk(5, sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m])) * 100)",
                "legendFormat": "{{ groupname }}"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "percent",
                "decimals": 1,
                "min": 0,
                "max": 100
              }
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0},
            "id": 2,
            "type": "table",
            "title": "Top Memory Consuming Processes (Resident Memory)",
            "targets": [
              {
                "expr": "topk(10, sum by (groupname) (namedprocess_namegroup_memory_bytes{memtype=\"resident\"}))",
                "format": "table",
                "instant": true
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "bytes",
                "decimals": 0,
                "custom": {
                  "align": "auto",
                  "displayMode": "color-background-solid"
                }
              },
              "overrides": [
                {
                  "matcher": {
                    "id": "byName",
                    "options": "groupname"
                  },
                  "properties": [
                    {
                      "id": "displayName",
                      "value": "Process Name"
                    },
                    {
                      "id": "custom.width",
                      "value": 200
                    }
                  ]
                },
                {
                  "matcher": {
                    "id": "byName",
                    "options": "Value"
                  },
                  "properties": [
                    {
                      "id": "displayName",
                      "value": "Memory"
                    },
                    {
                      "id": "custom.displayMode",
                      "value": "gradient-gauge"
                    }
                  ]
                }
              ]
            },
            "transformations": [
              {
                "id": "organize",
                "options": {
                  "excludeByName": {
                    "Time": true
                  }
                }
              }
            ]
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8},
            "id": 3,
            "type": "graph",
            "title": "Process CPU Usage Over Time",
            "targets": [
              {
                "expr": "topk(5, sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m])) * 100)",
                "legendFormat": "{{ groupname }}"
              }
            ],
            "yaxes": [
              {
                "format": "percent",
                "label": "CPU %",
                "min": 0
              },
              {
                "format": "short"
              }
            ]
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8},
            "id": 4,
            "type": "timeseries",
            "title": "Process Memory Usage Over Time (Resident)",
            "targets": [
              {
                "expr": "topk(5, sum by (groupname) (namedprocess_namegroup_memory_bytes{memtype=\"resident\"}))",
                "legendFormat": "{{ groupname }}"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "bytes",
                "decimals": 0,
                "min": 0,
                "custom": {
                  "drawStyle": "line",
                  "lineInterpolation": "linear",
                  "lineWidth": 2,
                  "fillOpacity": 10,
                  "showPoints": "never"
                }
              },
              "overrides": []
            },
            "options": {
              "legend": {
                "displayMode": "table",
                "placement": "right",
                "calcs": ["mean", "max"],
                "showLegend": true
              }
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 16},
            "id": 5,
            "type": "stat",
            "title": "Total Processes",
            "targets": [
              {
                "expr": "sum(namedprocess_namegroup_num_procs)"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "short",
                "decimals": 0
              }
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 16},
            "id": 6,
            "type": "stat",
            "title": "Total Threads",
            "targets": [
              {
                "expr": "sum(namedprocess_namegroup_num_threads)"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "short",
                "decimals": 0
              }
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 24},
            "id": 7,
            "type": "piechart",
            "title": "CPU Usage by Process",
            "targets": [
              {
                "expr": "topk(10, sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m])) * 100)",
                "legendFormat": "{{ groupname }}"
              }
            ],
            "options": {
              "reduceOptions": {
                "values": false,
                "calcs": ["lastNotNull"]
              },
              "pieType": "donut",
              "displayLabels": ["name", "value"],
              "legendDisplayMode": "table",
              "legendPlacement": "right"
            },
            "fieldConfig": {
              "defaults": {
                "unit": "percent",
                "decimals": 1
              }
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 24},
            "id": 8,
            "type": "piechart",
            "title": "Memory Usage by Process (Resident)",
            "targets": [
              {
                "expr": "topk(10, sum by (groupname) (namedprocess_namegroup_memory_bytes{memtype=\"resident\"}))",
                "legendFormat": "{{ groupname }}"
              }
            ],
            "options": {
              "reduceOptions": {
                "values": false,
                "calcs": ["lastNotNull"]
              },
              "pieType": "donut",
              "displayLabels": ["name", "value"],
              "legendDisplayMode": "table",
              "legendPlacement": "right"
            },
            "fieldConfig": {
              "defaults": {
                "unit": "bytes",
                "decimals": 1
              }
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 32},
            "id": 9,
            "type": "table",
            "title": "Process Details",
            "targets": [
              {
                "expr": "sum by (groupname) (namedprocess_namegroup_num_procs)",
                "format": "table",
                "instant": true
              },
              {
                "expr": "sum by (groupname) (namedprocess_namegroup_num_threads)",
                "format": "table",
                "instant": true
              },
              {
                "expr": "sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m])) * 100",
                "format": "table",
                "instant": true
              },
              {
                "expr": "sum by (groupname) (namedprocess_namegroup_memory_bytes{memtype=\"resident\"})",
                "format": "table",
                "instant": true
              }
            ],
            "transformations": [
              {
                "id": "merge"
              },
              {
                "id": "organize",
                "options": {
                  "excludeByName": {
                    "Time": true,
                    "Time 1": true,
                    "Time 2": true,
                    "Time 3": true,
                    "Time 4": true
                  },
                  "renameByName": {
                    "groupname": "Process",
                    "Value #A": "Count",
                    "Value #B": "Threads",
                    "Value #C": "CPU %",
                    "Value #D": "Memory"
                  }
                }
              },
              {
                "id": "sortBy",
                "options": {
                  "sort": [
                    {
                      "field": "Memory",
                      "desc": true
                    }
                  ]
                }
              }
            ],
            "fieldConfig": {
              "defaults": {
                "custom": {
                  "align": "auto",
                  "displayMode": "auto"
                }
              },
              "overrides": [
                {
                  "matcher": {
                    "id": "byName",
                    "options": "CPU %"
                  },
                  "properties": [
                    {
                      "id": "unit",
                      "value": "percent"
                    },
                    {
                      "id": "decimals",
                      "value": 1
                    },
                    {
                      "id": "custom.displayMode",
                      "value": "gradient-gauge"
                    }
                  ]
                },
                {
                  "matcher": {
                    "id": "byName",
                    "options": "Memory"
                  },
                  "properties": [
                    {
                      "id": "unit",
                      "value": "bytes"
                    },
                    {
                      "id": "custom.displayMode",
                      "value": "gradient-gauge"
                    }
                  ]
                }
              ]
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 40},
            "id": 10,
            "type": "graph",
            "title": "Memory Types Comparison",
            "targets": [
              {
                "expr": "topk(3, sum by (groupname) (namedprocess_namegroup_memory_bytes{memtype=\"resident\"}))",
                "legendFormat": "{{ groupname }} - Resident"
              },
              {
                "expr": "topk(3, sum by (groupname) (namedprocess_namegroup_memory_bytes{memtype=\"virtual\"}))",
                "legendFormat": "{{ groupname }} - Virtual"
              }
            ],
            "yaxes": [
              {
                "format": "bytes",
                "label": "Memory",
                "logBase": 1
              },
              {
                "format": "short"
              }
            ],
            "seriesOverrides": [
              {
                "alias": "/-Virtual/",
                "dashes": true,
                "lines": true
              }
            ]
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 40},
            "id": 11,
            "type": "graph",
            "title": "Process States",
            "targets": [
              {
                "expr": "sum(namedprocess_namegroup_states) by (state)",
                "legendFormat": "{{ state }}"
              }
            ],
            "yaxes": [
              {
                "format": "short",
                "label": "Count"
              },
              {
                "format": "short"
              }
            ]
          },
          {
            "id": 12,
            "gridPos": {
              "h": 10,
              "w": 24,
              "x": 0,
              "y": 48
            },
            "type": "heatmap",
            "title": "Process CPU Usage Heatmap",
            "datasource": "Prometheus",
            "fieldConfig": {
              "defaults": {
                "custom": {
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  }
                }
              },
              "overrides": []
            },
            "options": {
              "calculate": false,
              "yAxis": {
                "axisPlacement": "left",
                "reverse": false,
                "unit": "short",
                "decimals": 0
              },
              "rowsFrame": {
                "layout": "auto"
              },
              "color": {
                "mode": "scheme",
                "fill": "dark-orange",
                "scale": "exponential",
                "exponent": 0.5,
                "scheme": "Spectral",
                "steps": 64,
                "reverse": false,
                "min": 0,
                "max": null
              },
              "cellGap": 1,
              "filterValues": {
                "le": 1e-09
              },
              "tooltip": {
                "show": true,
                "yHistogram": false
              },
              "legend": {
                "show": true
              },
              "exemplars": {
                "color": "rgba(255,0,255,0.7)"
              }
            },
            "targets": [
              {
                "expr": "sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m])) * 100",
                "format": "heatmap",
                "interval": "30s",
                "legendFormat": "{{groupname}}",
                "refId": "A"
              }
            ],
            "transformations": []
          }
        ]
      }
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"host-process-monitoring.json":"{\n  \"id\": null,\n  \"uid\": \"host-process-monitoring\",\n  \"title\": \"Host Process Monitoring - Ubuntu 22.04\",\n  \"tags\": [\"processes\", \"system\", \"razerblade\", \"host\"],\n  \"timezone\": \"browser\",\n  \"schemaVersion\": 38,\n  \"version\": 3,\n  \"refresh\": \"30s\",\n  \"panels\": [\n    {\n      \"datasource\": \"Prometheus\",\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 0},\n      \"id\": 1,\n      \"type\": \"timeseries\",\n      \"title\": \"Top CPU Consuming Processes\",\n      \"targets\": [\n        {\n          \"expr\": \"topk(5, sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m])) * 100)\",\n          \"legendFormat\": \"{{ groupname }}\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"percent\",\n          \"decimals\": 1,\n          \"min\": 0,\n          \"max\": 100\n        }\n      }\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 0},\n      \"id\": 2,\n      \"type\": \"table\",\n      \"title\": \"Top Memory Consuming Processes (Resident Memory)\",\n      \"targets\": [\n        {\n          \"expr\": \"topk(10, sum by (groupname) (namedprocess_namegroup_memory_bytes{memtype=\\\"resident\\\"}))\",\n          \"format\": \"table\",\n          \"instant\": true\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"bytes\",\n          \"decimals\": 0,\n          \"custom\": {\n            \"align\": \"auto\",\n            \"displayMode\": \"color-background-solid\"\n          }\n        },\n        \"overrides\": [\n          {\n            \"matcher\": {\n              \"id\": \"byName\",\n              \"options\": \"groupname\"\n            },\n            \"properties\": [\n              {\n                \"id\": \"displayName\",\n                \"value\": \"Process Name\"\n              },\n              {\n                \"id\": \"custom.width\",\n                \"value\": 200\n              }\n            ]\n          },\n          {\n            \"matcher\": {\n              \"id\": \"byName\",\n              \"options\": \"Value\"\n            },\n            \"properties\": [\n              {\n                \"id\": \"displayName\",\n                \"value\": \"Memory\"\n              },\n              {\n                \"id\": \"custom.displayMode\",\n                \"value\": \"gradient-gauge\"\n              }\n            ]\n          }\n        ]\n      },\n      \"transformations\": [\n        {\n          \"id\": \"organize\",\n          \"options\": {\n            \"excludeByName\": {\n              \"Time\": true\n            }\n          }\n        }\n      ]\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 8},\n      \"id\": 3,\n      \"type\": \"graph\",\n      \"title\": \"Process CPU Usage Over Time\",\n      \"targets\": [\n        {\n          \"expr\": \"topk(5, sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m])) * 100)\",\n          \"legendFormat\": \"{{ groupname }}\"\n        }\n      ],\n      \"yaxes\": [\n        {\n          \"format\": \"percent\",\n          \"label\": \"CPU %\",\n          \"min\": 0\n        },\n        {\n          \"format\": \"short\"\n        }\n      ]\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 8},\n      \"id\": 4,\n      \"type\": \"timeseries\",\n      \"title\": \"Process Memory Usage Over Time (Resident)\",\n      \"targets\": [\n        {\n          \"expr\": \"topk(5, sum by (groupname) (namedprocess_namegroup_memory_bytes{memtype=\\\"resident\\\"}))\",\n          \"legendFormat\": \"{{ groupname }}\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"bytes\",\n          \"decimals\": 0,\n          \"min\": 0,\n          \"custom\": {\n            \"drawStyle\": \"line\",\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 10,\n            \"showPoints\": \"never\"\n          }\n        },\n        \"overrides\": []\n      },\n      \"options\": {\n        \"legend\": {\n          \"displayMode\": \"table\",\n          \"placement\": \"right\",\n          \"calcs\": [\"mean\", \"max\"],\n          \"showLegend\": true\n        }\n      }\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 16},\n      \"id\": 5,\n      \"type\": \"stat\",\n      \"title\": \"Total Processes\",\n      \"targets\": [\n        {\n          \"expr\": \"sum(namedprocess_namegroup_num_procs)\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"decimals\": 0\n        }\n      }\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 16},\n      \"id\": 6,\n      \"type\": \"stat\",\n      \"title\": \"Total Threads\",\n      \"targets\": [\n        {\n          \"expr\": \"sum(namedprocess_namegroup_num_threads)\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"decimals\": 0\n        }\n      }\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 24},\n      \"id\": 7,\n      \"type\": \"piechart\",\n      \"title\": \"CPU Usage by Process\",\n      \"targets\": [\n        {\n          \"expr\": \"topk(10, sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m])) * 100)\",\n          \"legendFormat\": \"{{ groupname }}\"\n        }\n      ],\n      \"options\": {\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"]\n        },\n        \"pieType\": \"donut\",\n        \"displayLabels\": [\"name\", \"value\"],\n        \"legendDisplayMode\": \"table\",\n        \"legendPlacement\": \"right\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"percent\",\n          \"decimals\": 1\n        }\n      }\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 24},\n      \"id\": 8,\n      \"type\": \"piechart\",\n      \"title\": \"Memory Usage by Process (Resident)\",\n      \"targets\": [\n        {\n          \"expr\": \"topk(10, sum by (groupname) (namedprocess_namegroup_memory_bytes{memtype=\\\"resident\\\"}))\",\n          \"legendFormat\": \"{{ groupname }}\"\n        }\n      ],\n      \"options\": {\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"]\n        },\n        \"pieType\": \"donut\",\n        \"displayLabels\": [\"name\", \"value\"],\n        \"legendDisplayMode\": \"table\",\n        \"legendPlacement\": \"right\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"bytes\",\n          \"decimals\": 1\n        }\n      }\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 32},\n      \"id\": 9,\n      \"type\": \"table\",\n      \"title\": \"Process Details\",\n      \"targets\": [\n        {\n          \"expr\": \"sum by (groupname) (namedprocess_namegroup_num_procs)\",\n          \"format\": \"table\",\n          \"instant\": true\n        },\n        {\n          \"expr\": \"sum by (groupname) (namedprocess_namegroup_num_threads)\",\n          \"format\": \"table\",\n          \"instant\": true\n        },\n        {\n          \"expr\": \"sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m])) * 100\",\n          \"format\": \"table\",\n          \"instant\": true\n        },\n        {\n          \"expr\": \"sum by (groupname) (namedprocess_namegroup_memory_bytes{memtype=\\\"resident\\\"})\",\n          \"format\": \"table\",\n          \"instant\": true\n        }\n      ],\n      \"transformations\": [\n        {\n          \"id\": \"merge\"\n        },\n        {\n          \"id\": \"organize\",\n          \"options\": {\n            \"excludeByName\": {\n              \"Time\": true,\n              \"Time 1\": true,\n              \"Time 2\": true,\n              \"Time 3\": true,\n              \"Time 4\": true\n            },\n            \"renameByName\": {\n              \"groupname\": \"Process\",\n              \"Value #A\": \"Count\",\n              \"Value #B\": \"Threads\",\n              \"Value #C\": \"CPU %\",\n              \"Value #D\": \"Memory\"\n            }\n          }\n        },\n        {\n          \"id\": \"sortBy\",\n          \"options\": {\n            \"sort\": [\n              {\n                \"field\": \"Memory\",\n                \"desc\": true\n              }\n            ]\n          }\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"custom\": {\n            \"align\": \"auto\",\n            \"displayMode\": \"auto\"\n          }\n        },\n        \"overrides\": [\n          {\n            \"matcher\": {\n              \"id\": \"byName\",\n              \"options\": \"CPU %\"\n            },\n            \"properties\": [\n              {\n                \"id\": \"unit\",\n                \"value\": \"percent\"\n              },\n              {\n                \"id\": \"decimals\",\n                \"value\": 1\n              },\n              {\n                \"id\": \"custom.displayMode\",\n                \"value\": \"gradient-gauge\"\n              }\n            ]\n          },\n          {\n            \"matcher\": {\n              \"id\": \"byName\",\n              \"options\": \"Memory\"\n            },\n            \"properties\": [\n              {\n                \"id\": \"unit\",\n                \"value\": \"bytes\"\n              },\n              {\n                \"id\": \"custom.displayMode\",\n                \"value\": \"gradient-gauge\"\n              }\n            ]\n          }\n        ]\n      }\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 40},\n      \"id\": 10,\n      \"type\": \"graph\",\n      \"title\": \"Memory Types Comparison\",\n      \"targets\": [\n        {\n          \"expr\": \"topk(3, sum by (groupname) (namedprocess_namegroup_memory_bytes{memtype=\\\"resident\\\"}))\",\n          \"legendFormat\": \"{{ groupname }} - Resident\"\n        },\n        {\n          \"expr\": \"topk(3, sum by (groupname) (namedprocess_namegroup_memory_bytes{memtype=\\\"virtual\\\"}))\",\n          \"legendFormat\": \"{{ groupname }} - Virtual\"\n        }\n      ],\n      \"yaxes\": [\n        {\n          \"format\": \"bytes\",\n          \"label\": \"Memory\",\n          \"logBase\": 1\n        },\n        {\n          \"format\": \"short\"\n        }\n      ],\n      \"seriesOverrides\": [\n        {\n          \"alias\": \"/-Virtual/\",\n          \"dashes\": true,\n          \"lines\": true\n        }\n      ]\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 40},\n      \"id\": 11,\n      \"type\": \"graph\",\n      \"title\": \"Process States\",\n      \"targets\": [\n        {\n          \"expr\": \"sum(namedprocess_namegroup_states) by (state)\",\n          \"legendFormat\": \"{{ state }}\"\n        }\n      ],\n      \"yaxes\": [\n        {\n          \"format\": \"short\",\n          \"label\": \"Count\"\n        },\n        {\n          \"format\": \"short\"\n        }\n      ]\n    },\n    {\n      \"id\": 12,\n      \"gridPos\": {\n        \"h\": 10,\n        \"w\": 24,\n        \"x\": 0,\n        \"y\": 48\n      },\n      \"type\": \"heatmap\",\n      \"title\": \"Process CPU Usage Heatmap\",\n      \"datasource\": \"Prometheus\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"custom\": {\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            }\n          }\n        },\n        \"overrides\": []\n      },\n      \"options\": {\n        \"calculate\": false,\n        \"yAxis\": {\n          \"axisPlacement\": \"left\",\n          \"reverse\": false,\n          \"unit\": \"short\",\n          \"decimals\": 0\n        },\n        \"rowsFrame\": {\n          \"layout\": \"auto\"\n        },\n        \"color\": {\n          \"mode\": \"scheme\",\n          \"fill\": \"dark-orange\",\n          \"scale\": \"exponential\",\n          \"exponent\": 0.5,\n          \"scheme\": \"Spectral\",\n          \"steps\": 64,\n          \"reverse\": false,\n          \"min\": 0,\n          \"max\": null\n        },\n        \"cellGap\": 1,\n        \"filterValues\": {\n          \"le\": 1e-09\n        },\n        \"tooltip\": {\n          \"show\": true,\n          \"yHistogram\": false\n        },\n        \"legend\": {\n          \"show\": true\n        },\n        \"exemplars\": {\n          \"color\": \"rgba(255,0,255,0.7)\"\n        }\n      },\n      \"targets\": [\n        {\n          \"expr\": \"sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m])) * 100\",\n          \"format\": \"heatmap\",\n          \"interval\": \"30s\",\n          \"legendFormat\": \"{{groupname}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"transformations\": []\n    }\n  ]\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"host-process-dashboard","namespace":"monitoring"}}
    creationTimestamp: "2025-05-30T02:37:12Z"
    name: host-process-dashboard
    namespace: monitoring
    resourceVersion: "215976"
    uid: def19797-8cd6-4cb4-93d1-8341daf84166
- apiVersion: v1
  data:
    host-process-monitoring-fixed.json: "{\n  \"dashboard\": {\n    \"id\": null,\n
      \   \"uid\": \"host-process-monitoring\",\n    \"title\": \"Host Process Monitoring
      - Ubuntu 22.04\",\n    \"tags\": [\"processes\", \"system\", \"razerblade\",
      \"host\"],\n    \"timezone\": \"browser\",\n    \"schemaVersion\": 38,\n    \"version\":
      2,\n    \"refresh\": \"30s\",\n    \"panels\": [\n      {\n        \"datasource\":
      \"Prometheus\",\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\":
      0},\n        \"id\": 1,\n        \"type\": \"timeseries\",\n        \"title\":
      \"Top CPU Consuming Processes\",\n        \"targets\": [\n          {\n            \"expr\":
      \"topk(5, sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m]))
      * 100)\",\n            \"legendFormat\": \"{{ groupname }}\"\n          }\n
      \       ],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"unit\":
      \"percent\",\n            \"decimals\": 1,\n            \"min\": 0,\n            \"max\":
      100\n          }\n        }\n      },\n      {\n        \"datasource\": \"Prometheus\",\n
      \       \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 0},\n        \"id\":
      2,\n        \"type\": \"table\",\n        \"title\": \"Top Memory Consuming
      Processes\",\n        \"targets\": [\n          {\n            \"expr\": \"topk(10,
      sum by (groupname) (namedprocess_namegroup_memory_bytes) / 1024 / 1024)\",\n
      \           \"format\": \"table\",\n            \"instant\": true\n          }\n
      \       ],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"unit\":
      \"none\",\n            \"decimals\": 0,\n            \"custom\": {\n              \"align\":
      \"auto\",\n              \"displayMode\": \"color-background-solid\"\n            }\n
      \         },\n          \"overrides\": [\n            {\n              \"matcher\":
      {\n                \"id\": \"byName\",\n                \"options\": \"groupname\"\n
      \             },\n              \"properties\": [\n                {\n                  \"id\":
      \"displayName\",\n                  \"value\": \"Process Name\"\n                },\n
      \               {\n                  \"id\": \"custom.width\",\n                  \"value\":
      200\n                }\n              ]\n            },\n            {\n              \"matcher\":
      {\n                \"id\": \"byName\",\n                \"options\": \"Value\"\n
      \             },\n              \"properties\": [\n                {\n                  \"id\":
      \"displayName\", \n                  \"value\": \"Memory (MB)\"\n                },\n
      \               {\n                  \"id\": \"custom.displayMode\",\n                  \"value\":
      \"gradient-gauge\"\n                },\n                {\n                  \"id\":
      \"unit\",\n                  \"value\": \"none\"\n                },\n                {\n
      \                 \"id\": \"decimals\",\n                  \"value\": 0\n                }\n
      \             ]\n            }\n          ]\n        },\n        \"transformations\":
      [\n          {\n            \"id\": \"organize\",\n            \"options\":
      {\n              \"excludeByName\": {\n                \"Time\": true\n              }\n
      \           }\n          }\n        ]\n      },\n      {\n        \"datasource\":
      \"Prometheus\",\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\":
      8},\n        \"id\": 3,\n        \"type\": \"graph\",\n        \"title\": \"Process
      CPU Usage Over Time\",\n        \"targets\": [\n          {\n            \"expr\":
      \"topk(5, sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m]))
      * 100)\",\n            \"legendFormat\": \"{{ groupname }}\"\n          }\n
      \       ],\n        \"yaxes\": [\n          {\n            \"format\": \"percent\",\n
      \           \"label\": \"CPU %\",\n            \"min\": 0\n          },\n          {\n
      \           \"format\": \"short\"\n          }\n        ]\n      },\n      {\n
      \       \"datasource\": \"Prometheus\",\n        \"gridPos\": {\"h\": 8, \"w\":
      12, \"x\": 12, \"y\": 8},\n        \"id\": 4,\n        \"type\": \"timeseries\",\n
      \       \"title\": \"Process Memory Usage Over Time\",\n        \"targets\":
      [\n          {\n            \"expr\": \"topk(5, sum by (groupname) (namedprocess_namegroup_memory_bytes)
      / 1024 / 1024 / 1024)\",\n            \"legendFormat\": \"{{ groupname }}\"\n
      \         }\n        ],\n        \"fieldConfig\": {\n          \"defaults\":
      {\n            \"unit\": \"GB\",\n            \"decimals\": 2,\n            \"min\":
      0,\n            \"custom\": {\n              \"drawStyle\": \"line\",\n              \"lineInterpolation\":
      \"linear\",\n              \"lineWidth\": 2,\n              \"fillOpacity\":
      10,\n              \"showPoints\": \"never\"\n            }\n          },\n
      \         \"overrides\": []\n        },\n        \"options\": {\n          \"legend\":
      {\n            \"displayMode\": \"table\",\n            \"placement\": \"right\",\n
      \           \"calcs\": [\"mean\", \"max\"],\n            \"showLegend\": true\n
      \         }\n        }\n      },\n      {\n        \"datasource\": \"Prometheus\",\n
      \       \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 16},\n        \"id\":
      5,\n        \"type\": \"stat\",\n        \"title\": \"Total Processes\",\n        \"targets\":
      [\n          {\n            \"expr\": \"sum(namedprocess_namegroup_num_procs)\"\n
      \         }\n        ],\n        \"fieldConfig\": {\n          \"defaults\":
      {\n            \"unit\": \"short\",\n            \"decimals\": 0\n          }\n
      \       }\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"gridPos\":
      {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 16},\n        \"id\": 6,\n        \"type\":
      \"stat\",\n        \"title\": \"Total Threads\",\n        \"targets\": [\n          {\n
      \           \"expr\": \"sum(namedprocess_namegroup_num_threads)\"\n          }\n
      \       ],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"unit\":
      \"short\",\n            \"decimals\": 0\n          }\n        }\n      },\n
      \     {\n        \"datasource\": \"Prometheus\",\n        \"gridPos\": {\"h\":
      8, \"w\": 12, \"x\": 0, \"y\": 24},\n        \"id\": 7,\n        \"type\": \"piechart\",\n
      \       \"title\": \"CPU Usage by Process\",\n        \"targets\": [\n          {\n
      \           \"expr\": \"topk(10, sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m]))
      * 100)\",\n            \"legendFormat\": \"{{ groupname }}\"\n          }\n
      \       ],\n        \"options\": {\n          \"reduceOptions\": {\n            \"values\":
      false,\n            \"calcs\": [\"lastNotNull\"]\n          },\n          \"pieType\":
      \"donut\",\n          \"displayLabels\": [\"name\", \"value\"],\n          \"legendDisplayMode\":
      \"table\",\n          \"legendPlacement\": \"right\"\n        },\n        \"fieldConfig\":
      {\n          \"defaults\": {\n            \"unit\": \"percent\",\n            \"decimals\":
      1\n          }\n        }\n      },\n      {\n        \"datasource\": \"Prometheus\",\n
      \       \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 24},\n        \"id\":
      8,\n        \"type\": \"piechart\",\n        \"title\": \"Memory Usage by Process\",\n
      \       \"targets\": [\n          {\n            \"expr\": \"topk(10, sum by
      (groupname) (namedprocess_namegroup_memory_bytes))\",\n            \"legendFormat\":
      \"{{ groupname }}\"\n          }\n        ],\n        \"options\": {\n          \"reduceOptions\":
      {\n            \"values\": false,\n            \"calcs\": [\"lastNotNull\"]\n
      \         },\n          \"pieType\": \"donut\",\n          \"displayLabels\":
      [\"name\", \"value\"],\n          \"legendDisplayMode\": \"table\",\n          \"legendPlacement\":
      \"right\"\n        },\n        \"fieldConfig\": {\n          \"defaults\": {\n
      \           \"unit\": \"decbytes\",\n            \"decimals\": 1\n          }\n
      \       }\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"gridPos\":
      {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 32},\n        \"id\": 9,\n        \"type\":
      \"table\",\n        \"title\": \"Process Details\",\n        \"targets\": [\n
      \         {\n            \"expr\": \"sum by (groupname) (namedprocess_namegroup_num_procs)\",\n
      \           \"format\": \"table\",\n            \"instant\": true\n          },\n
      \         {\n            \"expr\": \"sum by (groupname) (namedprocess_namegroup_num_threads)\",\n
      \           \"format\": \"table\",\n            \"instant\": true\n          },\n
      \         {\n            \"expr\": \"sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m]))
      * 100\",\n            \"format\": \"table\",\n            \"instant\": true\n
      \         },\n          {\n            \"expr\": \"sum by (groupname) (namedprocess_namegroup_memory_bytes)
      / 1024 / 1024\",\n            \"format\": \"table\", \n            \"instant\":
      true\n          }\n        ],\n        \"transformations\": [\n          {\n
      \           \"id\": \"merge\"\n          },\n          {\n            \"id\":
      \"organize\",\n            \"options\": {\n              \"excludeByName\":
      {\n                \"Time\": true,\n                \"Time 1\": true,\n                \"Time
      2\": true,\n                \"Time 3\": true,\n                \"Time 4\": true\n
      \             },\n              \"renameByName\": {\n                \"groupname\":
      \"Process\",\n                \"Value #A\": \"Count\",\n                \"Value
      #B\": \"Threads\",\n                \"Value #C\": \"CPU %\",\n                \"Value
      #D\": \"Memory (MB)\"\n              }\n            }\n          }\n        ],\n
      \       \"fieldConfig\": {\n          \"defaults\": {\n            \"custom\":
      {\n              \"align\": \"auto\",\n              \"displayMode\": \"auto\"\n
      \           }\n          },\n          \"overrides\": [\n            {\n              \"matcher\":
      {\n                \"id\": \"byName\",\n                \"options\": \"CPU %\"\n
      \             },\n              \"properties\": [\n                {\n                  \"id\":
      \"unit\",\n                  \"value\": \"percent\"\n                },\n                {\n
      \                 \"id\": \"decimals\",\n                  \"value\": 1\n                },\n
      \               {\n                  \"id\": \"custom.displayMode\",\n                  \"value\":
      \"gradient-gauge\"\n                }\n              ]\n            },\n            {\n
      \             \"matcher\": {\n                \"id\": \"byName\",\n                \"options\":
      \"Memory (MB)\"\n              },\n              \"properties\": [\n                {\n
      \                 \"id\": \"unit\",\n                  \"value\": \"none\"\n
      \               },\n                {\n                  \"id\": \"decimals\",\n
      \                 \"value\": 0\n                },\n                {\n                  \"id\":
      \"custom.displayMode\",\n                  \"value\": \"gradient-gauge\"\n                }\n
      \             ]\n            }\n          ]\n        }\n      },\n      {\n
      \       \"datasource\": \"Prometheus\",\n        \"gridPos\": {\"h\": 8, \"w\":
      12, \"x\": 0, \"y\": 40},\n        \"id\": 10,\n        \"type\": \"graph\",\n
      \       \"title\": \"Open File Descriptors by Process\",\n        \"targets\":
      [\n          {\n            \"expr\": \"topk(5, sum by (groupname) (namedprocess_namegroup_open_filedesc))\",\n
      \           \"legendFormat\": \"{{ groupname }}\"\n          }\n        ],\n
      \       \"yaxes\": [\n          {\n            \"format\": \"short\",\n            \"label\":
      \"File Descriptors\"\n          },\n          {\n            \"format\": \"short\"\n
      \         }\n        ]\n      },\n      {\n        \"datasource\": \"Prometheus\",\n
      \       \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 40},\n        \"id\":
      11,\n        \"type\": \"graph\",\n        \"title\": \"Process States\",\n
      \       \"targets\": [\n          {\n            \"expr\": \"sum(namedprocess_namegroup_states)
      by (state)\",\n            \"legendFormat\": \"{{ state }}\"\n          }\n
      \       ],\n        \"yaxes\": [\n          {\n            \"format\": \"short\",\n
      \           \"label\": \"Count\"\n          },\n          {\n            \"format\":
      \"short\"\n          }\n        ]\n      },\n      {\n        \"datasource\":
      \"Prometheus\",\n        \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\":
      48},\n        \"id\": 12,\n        \"type\": \"timeseries\",\n        \"title\":
      \"Process CPU Usage Distribution\",\n        \"targets\": [\n          {\n            \"expr\":
      \"sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m])) *
      100\",\n            \"legendFormat\": \"{{ groupname }}\"\n          }\n        ],\n
      \       \"fieldConfig\": {\n          \"defaults\": {\n            \"unit\":
      \"percent\",\n            \"decimals\": 1,\n            \"min\": 0,\n            \"custom\":
      {\n              \"drawStyle\": \"bars\",\n              \"lineWidth\": 0,\n
      \             \"fillOpacity\": 100,\n              \"stacking\": {\n                \"mode\":
      \"normal\",\n                \"group\": \"A\"\n              }\n            }\n
      \         }\n        },\n        \"options\": {\n          \"legend\": {\n            \"displayMode\":
      \"table\",\n            \"placement\": \"right\",\n            \"calcs\": [\"mean\",
      \"max\"],\n            \"showLegend\": true\n          }\n        }\n      }\n
      \   ]\n  }\n}\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"host-process-monitoring-fixed.json":"{\n  \"dashboard\": {\n    \"id\": null,\n    \"uid\": \"host-process-monitoring\",\n    \"title\": \"Host Process Monitoring - Ubuntu 22.04\",\n    \"tags\": [\"processes\", \"system\", \"razerblade\", \"host\"],\n    \"timezone\": \"browser\",\n    \"schemaVersion\": 38,\n    \"version\": 2,\n    \"refresh\": \"30s\",\n    \"panels\": [\n      {\n        \"datasource\": \"Prometheus\",\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 0},\n        \"id\": 1,\n        \"type\": \"timeseries\",\n        \"title\": \"Top CPU Consuming Processes\",\n        \"targets\": [\n          {\n            \"expr\": \"topk(5, sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m])) * 100)\",\n            \"legendFormat\": \"{{ groupname }}\"\n          }\n        ],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"unit\": \"percent\",\n            \"decimals\": 1,\n            \"min\": 0,\n            \"max\": 100\n          }\n        }\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 0},\n        \"id\": 2,\n        \"type\": \"table\",\n        \"title\": \"Top Memory Consuming Processes\",\n        \"targets\": [\n          {\n            \"expr\": \"topk(10, sum by (groupname) (namedprocess_namegroup_memory_bytes) / 1024 / 1024)\",\n            \"format\": \"table\",\n            \"instant\": true\n          }\n        ],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"unit\": \"none\",\n            \"decimals\": 0,\n            \"custom\": {\n              \"align\": \"auto\",\n              \"displayMode\": \"color-background-solid\"\n            }\n          },\n          \"overrides\": [\n            {\n              \"matcher\": {\n                \"id\": \"byName\",\n                \"options\": \"groupname\"\n              },\n              \"properties\": [\n                {\n                  \"id\": \"displayName\",\n                  \"value\": \"Process Name\"\n                },\n                {\n                  \"id\": \"custom.width\",\n                  \"value\": 200\n                }\n              ]\n            },\n            {\n              \"matcher\": {\n                \"id\": \"byName\",\n                \"options\": \"Value\"\n              },\n              \"properties\": [\n                {\n                  \"id\": \"displayName\", \n                  \"value\": \"Memory (MB)\"\n                },\n                {\n                  \"id\": \"custom.displayMode\",\n                  \"value\": \"gradient-gauge\"\n                },\n                {\n                  \"id\": \"unit\",\n                  \"value\": \"none\"\n                },\n                {\n                  \"id\": \"decimals\",\n                  \"value\": 0\n                }\n              ]\n            }\n          ]\n        },\n        \"transformations\": [\n          {\n            \"id\": \"organize\",\n            \"options\": {\n              \"excludeByName\": {\n                \"Time\": true\n              }\n            }\n          }\n        ]\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 8},\n        \"id\": 3,\n        \"type\": \"graph\",\n        \"title\": \"Process CPU Usage Over Time\",\n        \"targets\": [\n          {\n            \"expr\": \"topk(5, sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m])) * 100)\",\n            \"legendFormat\": \"{{ groupname }}\"\n          }\n        ],\n        \"yaxes\": [\n          {\n            \"format\": \"percent\",\n            \"label\": \"CPU %\",\n            \"min\": 0\n          },\n          {\n            \"format\": \"short\"\n          }\n        ]\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 8},\n        \"id\": 4,\n        \"type\": \"timeseries\",\n        \"title\": \"Process Memory Usage Over Time\",\n        \"targets\": [\n          {\n            \"expr\": \"topk(5, sum by (groupname) (namedprocess_namegroup_memory_bytes) / 1024 / 1024 / 1024)\",\n            \"legendFormat\": \"{{ groupname }}\"\n          }\n        ],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"unit\": \"GB\",\n            \"decimals\": 2,\n            \"min\": 0,\n            \"custom\": {\n              \"drawStyle\": \"line\",\n              \"lineInterpolation\": \"linear\",\n              \"lineWidth\": 2,\n              \"fillOpacity\": 10,\n              \"showPoints\": \"never\"\n            }\n          },\n          \"overrides\": []\n        },\n        \"options\": {\n          \"legend\": {\n            \"displayMode\": \"table\",\n            \"placement\": \"right\",\n            \"calcs\": [\"mean\", \"max\"],\n            \"showLegend\": true\n          }\n        }\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 16},\n        \"id\": 5,\n        \"type\": \"stat\",\n        \"title\": \"Total Processes\",\n        \"targets\": [\n          {\n            \"expr\": \"sum(namedprocess_namegroup_num_procs)\"\n          }\n        ],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"unit\": \"short\",\n            \"decimals\": 0\n          }\n        }\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 16},\n        \"id\": 6,\n        \"type\": \"stat\",\n        \"title\": \"Total Threads\",\n        \"targets\": [\n          {\n            \"expr\": \"sum(namedprocess_namegroup_num_threads)\"\n          }\n        ],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"unit\": \"short\",\n            \"decimals\": 0\n          }\n        }\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 24},\n        \"id\": 7,\n        \"type\": \"piechart\",\n        \"title\": \"CPU Usage by Process\",\n        \"targets\": [\n          {\n            \"expr\": \"topk(10, sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m])) * 100)\",\n            \"legendFormat\": \"{{ groupname }}\"\n          }\n        ],\n        \"options\": {\n          \"reduceOptions\": {\n            \"values\": false,\n            \"calcs\": [\"lastNotNull\"]\n          },\n          \"pieType\": \"donut\",\n          \"displayLabels\": [\"name\", \"value\"],\n          \"legendDisplayMode\": \"table\",\n          \"legendPlacement\": \"right\"\n        },\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"unit\": \"percent\",\n            \"decimals\": 1\n          }\n        }\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 24},\n        \"id\": 8,\n        \"type\": \"piechart\",\n        \"title\": \"Memory Usage by Process\",\n        \"targets\": [\n          {\n            \"expr\": \"topk(10, sum by (groupname) (namedprocess_namegroup_memory_bytes))\",\n            \"legendFormat\": \"{{ groupname }}\"\n          }\n        ],\n        \"options\": {\n          \"reduceOptions\": {\n            \"values\": false,\n            \"calcs\": [\"lastNotNull\"]\n          },\n          \"pieType\": \"donut\",\n          \"displayLabels\": [\"name\", \"value\"],\n          \"legendDisplayMode\": \"table\",\n          \"legendPlacement\": \"right\"\n        },\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"unit\": \"decbytes\",\n            \"decimals\": 1\n          }\n        }\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 32},\n        \"id\": 9,\n        \"type\": \"table\",\n        \"title\": \"Process Details\",\n        \"targets\": [\n          {\n            \"expr\": \"sum by (groupname) (namedprocess_namegroup_num_procs)\",\n            \"format\": \"table\",\n            \"instant\": true\n          },\n          {\n            \"expr\": \"sum by (groupname) (namedprocess_namegroup_num_threads)\",\n            \"format\": \"table\",\n            \"instant\": true\n          },\n          {\n            \"expr\": \"sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m])) * 100\",\n            \"format\": \"table\",\n            \"instant\": true\n          },\n          {\n            \"expr\": \"sum by (groupname) (namedprocess_namegroup_memory_bytes) / 1024 / 1024\",\n            \"format\": \"table\", \n            \"instant\": true\n          }\n        ],\n        \"transformations\": [\n          {\n            \"id\": \"merge\"\n          },\n          {\n            \"id\": \"organize\",\n            \"options\": {\n              \"excludeByName\": {\n                \"Time\": true,\n                \"Time 1\": true,\n                \"Time 2\": true,\n                \"Time 3\": true,\n                \"Time 4\": true\n              },\n              \"renameByName\": {\n                \"groupname\": \"Process\",\n                \"Value #A\": \"Count\",\n                \"Value #B\": \"Threads\",\n                \"Value #C\": \"CPU %\",\n                \"Value #D\": \"Memory (MB)\"\n              }\n            }\n          }\n        ],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"custom\": {\n              \"align\": \"auto\",\n              \"displayMode\": \"auto\"\n            }\n          },\n          \"overrides\": [\n            {\n              \"matcher\": {\n                \"id\": \"byName\",\n                \"options\": \"CPU %\"\n              },\n              \"properties\": [\n                {\n                  \"id\": \"unit\",\n                  \"value\": \"percent\"\n                },\n                {\n                  \"id\": \"decimals\",\n                  \"value\": 1\n                },\n                {\n                  \"id\": \"custom.displayMode\",\n                  \"value\": \"gradient-gauge\"\n                }\n              ]\n            },\n            {\n              \"matcher\": {\n                \"id\": \"byName\",\n                \"options\": \"Memory (MB)\"\n              },\n              \"properties\": [\n                {\n                  \"id\": \"unit\",\n                  \"value\": \"none\"\n                },\n                {\n                  \"id\": \"decimals\",\n                  \"value\": 0\n                },\n                {\n                  \"id\": \"custom.displayMode\",\n                  \"value\": \"gradient-gauge\"\n                }\n              ]\n            }\n          ]\n        }\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 40},\n        \"id\": 10,\n        \"type\": \"graph\",\n        \"title\": \"Open File Descriptors by Process\",\n        \"targets\": [\n          {\n            \"expr\": \"topk(5, sum by (groupname) (namedprocess_namegroup_open_filedesc))\",\n            \"legendFormat\": \"{{ groupname }}\"\n          }\n        ],\n        \"yaxes\": [\n          {\n            \"format\": \"short\",\n            \"label\": \"File Descriptors\"\n          },\n          {\n            \"format\": \"short\"\n          }\n        ]\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 40},\n        \"id\": 11,\n        \"type\": \"graph\",\n        \"title\": \"Process States\",\n        \"targets\": [\n          {\n            \"expr\": \"sum(namedprocess_namegroup_states) by (state)\",\n            \"legendFormat\": \"{{ state }}\"\n          }\n        ],\n        \"yaxes\": [\n          {\n            \"format\": \"short\",\n            \"label\": \"Count\"\n          },\n          {\n            \"format\": \"short\"\n          }\n        ]\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 48},\n        \"id\": 12,\n        \"type\": \"timeseries\",\n        \"title\": \"Process CPU Usage Distribution\",\n        \"targets\": [\n          {\n            \"expr\": \"sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m])) * 100\",\n            \"legendFormat\": \"{{ groupname }}\"\n          }\n        ],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"unit\": \"percent\",\n            \"decimals\": 1,\n            \"min\": 0,\n            \"custom\": {\n              \"drawStyle\": \"bars\",\n              \"lineWidth\": 0,\n              \"fillOpacity\": 100,\n              \"stacking\": {\n                \"mode\": \"normal\",\n                \"group\": \"A\"\n              }\n            }\n          }\n        },\n        \"options\": {\n          \"legend\": {\n            \"displayMode\": \"table\",\n            \"placement\": \"right\",\n            \"calcs\": [\"mean\", \"max\"],\n            \"showLegend\": true\n          }\n        }\n      }\n    ]\n  }\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"host-process-dashboard-fixed","namespace":"monitoring"}}
    creationTimestamp: "2025-05-30T02:27:55Z"
    name: host-process-dashboard-fixed
    namespace: monitoring
    resourceVersion: "92143"
    uid: bed903d8-a6d5-4499-b0ef-2942fc1cb9cc
- apiVersion: v1
  data:
    host-process-monitoring.json: |2
          {
            "dashboard": {
              "id": null,
              "uid": "host-process-monitoring",
              "title": "Host Process Monitoring - Ubuntu 22.04",
              "tags": ["processes", "system", "razerblade", "host"],
              "timezone": "browser",
              "schemaVersion": 38,
              "version": 3,
              "refresh": "30s",
              "panels": [
                {
                  "datasource": "Prometheus",
                  "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0},
                  "id": 1,
                  "type": "timeseries",
                  "title": "Top CPU Consuming Processes",
                  "targets": [
                    {
                      "expr": "topk(5, sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m])) * 100)",
                      "legendFormat": "{{ groupname }}"
                    }
                  ],
                  "fieldConfig": {
                    "defaults": {
                      "unit": "percent",
                      "decimals": 1,
                      "min": 0,
                      "max": 100
                    }
                  }
                },
                {
                  "datasource": "Prometheus",
                  "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0},
                  "id": 2,
                  "type": "table",
                  "title": "Top Memory Consuming Processes (Resident Memory)",
                  "targets": [
                    {
                      "expr": "topk(10, sum by (groupname) (namedprocess_namegroup_memory_bytes{memtype=\"resident\"}))",
                      "format": "table",
                      "instant": true
                    }
                  ],
                  "fieldConfig": {
                    "defaults": {
                      "unit": "bytes",
                      "decimals": 0,
                      "custom": {
                        "align": "auto",
                        "displayMode": "color-background-solid"
                      }
                    },
                    "overrides": [
                      {
                        "matcher": {
                          "id": "byName",
                          "options": "groupname"
                        },
                        "properties": [
                          {
                            "id": "displayName",
                            "value": "Process Name"
                          },
                          {
                            "id": "custom.width",
                            "value": 200
                          }
                        ]
                      },
                      {
                        "matcher": {
                          "id": "byName",
                          "options": "Value"
                        },
                        "properties": [
                          {
                            "id": "displayName",
                            "value": "Memory"
                          },
                          {
                            "id": "custom.displayMode",
                            "value": "gradient-gauge"
                          }
                        ]
                      }
                    ]
                  },
                  "transformations": [
                    {
                      "id": "organize",
                      "options": {
                        "excludeByName": {
                          "Time": true
                        }
                      }
                    }
                  ]
                },
                {
                  "datasource": "Prometheus",
                  "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8},
                  "id": 3,
                  "type": "graph",
                  "title": "Process CPU Usage Over Time",
                  "targets": [
                    {
                      "expr": "topk(5, sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m])) * 100)",
                      "legendFormat": "{{ groupname }}"
                    }
                  ],
                  "yaxes": [
                    {
                      "format": "percent",
                      "label": "CPU %",
                      "min": 0
                    },
                    {
                      "format": "short"
                    }
                  ]
                },
                {
                  "datasource": "Prometheus",
                  "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8},
                  "id": 4,
                  "type": "timeseries",
                  "title": "Process Memory Usage Over Time (Resident)",
                  "targets": [
                    {
                      "expr": "topk(5, sum by (groupname) (namedprocess_namegroup_memory_bytes{memtype=\"resident\"}))",
                      "legendFormat": "{{ groupname }}"
                    }
                  ],
                  "fieldConfig": {
                    "defaults": {
                      "unit": "bytes",
                      "decimals": 0,
                      "min": 0,
                      "custom": {
                        "drawStyle": "line",
                        "lineInterpolation": "linear",
                        "lineWidth": 2,
                        "fillOpacity": 10,
                        "showPoints": "never"
                      }
                    },
                    "overrides": []
                  },
                  "options": {
                    "legend": {
                      "displayMode": "table",
                      "placement": "right",
                      "calcs": ["mean", "max"],
                      "showLegend": true
                    }
                  }
                },
                {
                  "datasource": "Prometheus",
                  "gridPos": {"h": 8, "w": 12, "x": 0, "y": 16},
                  "id": 5,
                  "type": "stat",
                  "title": "Total Processes",
                  "targets": [
                    {
                      "expr": "sum(namedprocess_namegroup_num_procs)"
                    }
                  ],
                  "fieldConfig": {
                    "defaults": {
                      "unit": "short",
                      "decimals": 0
                    }
                  }
                },
                {
                  "datasource": "Prometheus",
                  "gridPos": {"h": 8, "w": 12, "x": 12, "y": 16},
                  "id": 6,
                  "type": "stat",
                  "title": "Total Threads",
                  "targets": [
                    {
                      "expr": "sum(namedprocess_namegroup_num_threads)"
                    }
                  ],
                  "fieldConfig": {
                    "defaults": {
                      "unit": "short",
                      "decimals": 0
                    }
                  }
                },
                {
                  "datasource": "Prometheus",
                  "gridPos": {"h": 8, "w": 12, "x": 0, "y": 24},
                  "id": 7,
                  "type": "piechart",
                  "title": "CPU Usage by Process",
                  "targets": [
                    {
                      "expr": "topk(10, sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m])) * 100)",
                      "legendFormat": "{{ groupname }}"
                    }
                  ],
                  "options": {
                    "reduceOptions": {
                      "values": false,
                      "calcs": ["lastNotNull"]
                    },
                    "pieType": "donut",
                    "displayLabels": ["name", "value"],
                    "legendDisplayMode": "table",
                    "legendPlacement": "right"
                  },
                  "fieldConfig": {
                    "defaults": {
                      "unit": "percent",
                      "decimals": 1
                    }
                  }
                },
                {
                  "datasource": "Prometheus",
                  "gridPos": {"h": 8, "w": 12, "x": 12, "y": 24},
                  "id": 8,
                  "type": "piechart",
                  "title": "Memory Usage by Process (Resident)",
                  "targets": [
                    {
                      "expr": "topk(10, sum by (groupname) (namedprocess_namegroup_memory_bytes{memtype=\"resident\"}))",
                      "legendFormat": "{{ groupname }}"
                    }
                  ],
                  "options": {
                    "reduceOptions": {
                      "values": false,
                      "calcs": ["lastNotNull"]
                    },
                    "pieType": "donut",
                    "displayLabels": ["name", "value"],
                    "legendDisplayMode": "table",
                    "legendPlacement": "right"
                  },
                  "fieldConfig": {
                    "defaults": {
                      "unit": "bytes",
                      "decimals": 1
                    }
                  }
                },
                {
                  "datasource": "Prometheus",
                  "gridPos": {"h": 8, "w": 24, "x": 0, "y": 32},
                  "id": 9,
                  "type": "table",
                  "title": "Process Details",
                  "targets": [
                    {
                      "expr": "sum by (groupname) (namedprocess_namegroup_num_procs)",
                      "format": "table",
                      "instant": true
                    },
                    {
                      "expr": "sum by (groupname) (namedprocess_namegroup_num_threads)",
                      "format": "table",
                      "instant": true
                    },
                    {
                      "expr": "sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m])) * 100",
                      "format": "table",
                      "instant": true
                    },
                    {
                      "expr": "sum by (groupname) (namedprocess_namegroup_memory_bytes{memtype=\"resident\"})",
                      "format": "table",
                      "instant": true
                    }
                  ],
                  "transformations": [
                    {
                      "id": "merge"
                    },
                    {
                      "id": "organize",
                      "options": {
                        "excludeByName": {
                          "Time": true,
                          "Time 1": true,
                          "Time 2": true,
                          "Time 3": true,
                          "Time 4": true
                        },
                        "renameByName": {
                          "groupname": "Process",
                          "Value #A": "Count",
                          "Value #B": "Threads",
                          "Value #C": "CPU %",
                          "Value #D": "Memory"
                        }
                      }
                    },
                    {
                      "id": "sortBy",
                      "options": {
                        "sort": [
                          {
                            "field": "Memory",
                            "desc": true
                          }
                        ]
                      }
                    }
                  ],
                  "fieldConfig": {
                    "defaults": {
                      "custom": {
                        "align": "auto",
                        "displayMode": "auto"
                      }
                    },
                    "overrides": [
                      {
                        "matcher": {
                          "id": "byName",
                          "options": "CPU %"
                        },
                        "properties": [
                          {
                            "id": "unit",
                            "value": "percent"
                          },
                          {
                            "id": "decimals",
                            "value": 1
                          },
                          {
                            "id": "custom.displayMode",
                            "value": "gradient-gauge"
                          }
                        ]
                      },
                      {
                        "matcher": {
                          "id": "byName",
                          "options": "Memory"
                        },
                        "properties": [
                          {
                            "id": "unit",
                            "value": "bytes"
                          },
                          {
                            "id": "custom.displayMode",
                            "value": "gradient-gauge"
                          }
                        ]
                      }
                    ]
                  }
                },
                {
                  "datasource": "Prometheus",
                  "gridPos": {"h": 8, "w": 12, "x": 0, "y": 40},
                  "id": 10,
                  "type": "graph",
                  "title": "Memory Types Comparison",
                  "targets": [
                    {
                      "expr": "topk(3, sum by (groupname) (namedprocess_namegroup_memory_bytes{memtype=\"resident\"}))",
                      "legendFormat": "{{ groupname }} - Resident"
                    },
                    {
                      "expr": "topk(3, sum by (groupname) (namedprocess_namegroup_memory_bytes{memtype=\"virtual\"}))",
                      "legendFormat": "{{ groupname }} - Virtual"
                    }
                  ],
                  "yaxes": [
                    {
                      "format": "bytes",
                      "label": "Memory",
                      "logBase": 1
                    },
                    {
                      "format": "short"
                    }
                  ],
                  "seriesOverrides": [
                    {
                      "alias": "/-Virtual/",
                      "dashes": true,
                      "lines": true
                    }
                  ]
                },
                {
                  "datasource": "Prometheus",
                  "gridPos": {"h": 8, "w": 12, "x": 12, "y": 40},
                  "id": 11,
                  "type": "graph",
                  "title": "Process States",
                  "targets": [
                    {
                      "expr": "sum(namedprocess_namegroup_states) by (state)",
                      "legendFormat": "{{ state }}"
                    }
                  ],
                  "yaxes": [
                    {
                      "format": "short",
                      "label": "Count"
                    },
                    {
                      "format": "short"
                    }
                  ]
                },
                {
                  "datasource": "Prometheus",
                  "gridPos": {"h": 8, "w": 24, "x": 0, "y": 48},
                  "id": 12,
                  "type": "timeseries",
                  "title": "CPU Usage Distribution (Stacked)",
                  "targets": [
                    {
                      "expr": "topk(10, sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m])) * 100)",
                      "legendFormat": "{{ groupname }}"
                    }
                  ],
                  "fieldConfig": {
                    "defaults": {
                      "unit": "percent",
                      "decimals": 1,
                      "min": 0,
                      "custom": {
                        "drawStyle": "line",
                        "lineWidth": 1,
                        "fillOpacity": 50,
                        "stacking": {
                          "mode": "normal",
                          "group": "A"
                        },
                        "showPoints": "never"
                      }
                    }
                  },
                  "options": {
                    "legend": {
                      "displayMode": "table",
                      "placement": "right",
                      "calcs": ["mean", "max"],
                      "showLegend": true
                    }
                  }
                }
              ]
            }
          }
  kind: ConfigMap
  metadata:
    creationTimestamp: "2025-05-30T02:36:28Z"
    name: host-process-dashboard-updated
    namespace: monitoring
    resourceVersion: "92892"
    uid: 4e69a509-cc3b-4883-8a11-a341c2800ece
- apiVersion: v1
  data:
    host-process-monitoring.json: |
      {
        "dashboard": {
          "id": null,
          "uid": "host-process-monitoring",
          "title": "Host Process Monitoring - Ubuntu 22.04",
          "tags": ["processes", "system", "razerblade", "host"],
          "timezone": "browser",
          "schemaVersion": 38,
          "version": 3,
          "refresh": "30s",
          "panels": [
            {
              "datasource": "Prometheus",
              "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0},
              "id": 1,
              "type": "timeseries",
              "title": "Top CPU Consuming Processes",
              "targets": [
                {
                  "expr": "topk(5, sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m])) * 100)",
                  "legendFormat": "{{ groupname }}"
                }
              ],
              "fieldConfig": {
                "defaults": {
                  "unit": "percent",
                  "decimals": 1,
                  "min": 0,
                  "max": 100
                }
              }
            },
            {
              "datasource": "Prometheus",
              "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0},
              "id": 2,
              "type": "table",
              "title": "Top Memory Consuming Processes (Resident Memory)",
              "targets": [
                {
                  "expr": "topk(10, sum by (groupname) (namedprocess_namegroup_memory_bytes{memtype=\"resident\"}))",
                  "format": "table",
                  "instant": true
                }
              ],
              "fieldConfig": {
                "defaults": {
                  "unit": "bytes",
                  "decimals": 0,
                  "custom": {
                    "align": "auto",
                    "displayMode": "color-background-solid"
                  }
                },
                "overrides": [
                  {
                    "matcher": {
                      "id": "byName",
                      "options": "groupname"
                    },
                    "properties": [
                      {
                        "id": "displayName",
                        "value": "Process Name"
                      },
                      {
                        "id": "custom.width",
                        "value": 200
                      }
                    ]
                  },
                  {
                    "matcher": {
                      "id": "byName",
                      "options": "Value"
                    },
                    "properties": [
                      {
                        "id": "displayName",
                        "value": "Memory"
                      },
                      {
                        "id": "custom.displayMode",
                        "value": "gradient-gauge"
                      }
                    ]
                  }
                ]
              },
              "transformations": [
                {
                  "id": "organize",
                  "options": {
                    "excludeByName": {
                      "Time": true
                    }
                  }
                }
              ]
            },
            {
              "datasource": "Prometheus",
              "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8},
              "id": 3,
              "type": "graph",
              "title": "Process CPU Usage Over Time",
              "targets": [
                {
                  "expr": "topk(5, sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m])) * 100)",
                  "legendFormat": "{{ groupname }}"
                }
              ],
              "yaxes": [
                {
                  "format": "percent",
                  "label": "CPU %",
                  "min": 0
                },
                {
                  "format": "short"
                }
              ]
            },
            {
              "datasource": "Prometheus",
              "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8},
              "id": 4,
              "type": "timeseries",
              "title": "Process Memory Usage Over Time (Resident)",
              "targets": [
                {
                  "expr": "topk(5, sum by (groupname) (namedprocess_namegroup_memory_bytes{memtype=\"resident\"}))",
                  "legendFormat": "{{ groupname }}"
                }
              ],
              "fieldConfig": {
                "defaults": {
                  "unit": "bytes",
                  "decimals": 0,
                  "min": 0,
                  "custom": {
                    "drawStyle": "line",
                    "lineInterpolation": "linear",
                    "lineWidth": 2,
                    "fillOpacity": 10,
                    "showPoints": "never"
                  }
                },
                "overrides": []
              },
              "options": {
                "legend": {
                  "displayMode": "table",
                  "placement": "right",
                  "calcs": ["mean", "max"],
                  "showLegend": true
                }
              }
            },
            {
              "datasource": "Prometheus",
              "gridPos": {"h": 8, "w": 12, "x": 0, "y": 16},
              "id": 5,
              "type": "stat",
              "title": "Total Processes",
              "targets": [
                {
                  "expr": "sum(namedprocess_namegroup_num_procs)"
                }
              ],
              "fieldConfig": {
                "defaults": {
                  "unit": "short",
                  "decimals": 0
                }
              }
            },
            {
              "datasource": "Prometheus",
              "gridPos": {"h": 8, "w": 12, "x": 12, "y": 16},
              "id": 6,
              "type": "stat",
              "title": "Total Threads",
              "targets": [
                {
                  "expr": "sum(namedprocess_namegroup_num_threads)"
                }
              ],
              "fieldConfig": {
                "defaults": {
                  "unit": "short",
                  "decimals": 0
                }
              }
            },
            {
              "datasource": "Prometheus",
              "gridPos": {"h": 8, "w": 12, "x": 0, "y": 24},
              "id": 7,
              "type": "piechart",
              "title": "CPU Usage by Process",
              "targets": [
                {
                  "expr": "topk(10, sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m])) * 100)",
                  "legendFormat": "{{ groupname }}"
                }
              ],
              "options": {
                "reduceOptions": {
                  "values": false,
                  "calcs": ["lastNotNull"]
                },
                "pieType": "donut",
                "displayLabels": ["name", "value"],
                "legendDisplayMode": "table",
                "legendPlacement": "right"
              },
              "fieldConfig": {
                "defaults": {
                  "unit": "percent",
                  "decimals": 1
                }
              }
            },
            {
              "datasource": "Prometheus",
              "gridPos": {"h": 8, "w": 12, "x": 12, "y": 24},
              "id": 8,
              "type": "piechart",
              "title": "Memory Usage by Process (Resident)",
              "targets": [
                {
                  "expr": "topk(10, sum by (groupname) (namedprocess_namegroup_memory_bytes{memtype=\"resident\"}))",
                  "legendFormat": "{{ groupname }}"
                }
              ],
              "options": {
                "reduceOptions": {
                  "values": false,
                  "calcs": ["lastNotNull"]
                },
                "pieType": "donut",
                "displayLabels": ["name", "value"],
                "legendDisplayMode": "table",
                "legendPlacement": "right"
              },
              "fieldConfig": {
                "defaults": {
                  "unit": "bytes",
                  "decimals": 1
                }
              }
            },
            {
              "datasource": "Prometheus",
              "gridPos": {"h": 8, "w": 24, "x": 0, "y": 32},
              "id": 9,
              "type": "table",
              "title": "Process Details",
              "targets": [
                {
                  "expr": "sum by (groupname) (namedprocess_namegroup_num_procs)",
                  "format": "table",
                  "instant": true
                },
                {
                  "expr": "sum by (groupname) (namedprocess_namegroup_num_threads)",
                  "format": "table",
                  "instant": true
                },
                {
                  "expr": "sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m])) * 100",
                  "format": "table",
                  "instant": true
                },
                {
                  "expr": "sum by (groupname) (namedprocess_namegroup_memory_bytes{memtype=\"resident\"})",
                  "format": "table",
                  "instant": true
                }
              ],
              "transformations": [
                {
                  "id": "merge"
                },
                {
                  "id": "organize",
                  "options": {
                    "excludeByName": {
                      "Time": true,
                      "Time 1": true,
                      "Time 2": true,
                      "Time 3": true,
                      "Time 4": true
                    },
                    "renameByName": {
                      "groupname": "Process",
                      "Value #A": "Count",
                      "Value #B": "Threads",
                      "Value #C": "CPU %",
                      "Value #D": "Memory"
                    }
                  }
                },
                {
                  "id": "sortBy",
                  "options": {
                    "sort": [
                      {
                        "field": "Memory",
                        "desc": true
                      }
                    ]
                  }
                }
              ],
              "fieldConfig": {
                "defaults": {
                  "custom": {
                    "align": "auto",
                    "displayMode": "auto"
                  }
                },
                "overrides": [
                  {
                    "matcher": {
                      "id": "byName",
                      "options": "CPU %"
                    },
                    "properties": [
                      {
                        "id": "unit",
                        "value": "percent"
                      },
                      {
                        "id": "decimals",
                        "value": 1
                      },
                      {
                        "id": "custom.displayMode",
                        "value": "gradient-gauge"
                      }
                    ]
                  },
                  {
                    "matcher": {
                      "id": "byName",
                      "options": "Memory"
                    },
                    "properties": [
                      {
                        "id": "unit",
                        "value": "bytes"
                      },
                      {
                        "id": "custom.displayMode",
                        "value": "gradient-gauge"
                      }
                    ]
                  }
                ]
              }
            },
            {
              "datasource": "Prometheus",
              "gridPos": {"h": 8, "w": 12, "x": 0, "y": 40},
              "id": 10,
              "type": "graph",
              "title": "Memory Types Comparison",
              "targets": [
                {
                  "expr": "topk(3, sum by (groupname) (namedprocess_namegroup_memory_bytes{memtype=\"resident\"}))",
                  "legendFormat": "{{ groupname }} - Resident"
                },
                {
                  "expr": "topk(3, sum by (groupname) (namedprocess_namegroup_memory_bytes{memtype=\"virtual\"}))",
                  "legendFormat": "{{ groupname }} - Virtual"
                }
              ],
              "yaxes": [
                {
                  "format": "bytes",
                  "label": "Memory",
                  "logBase": 1
                },
                {
                  "format": "short"
                }
              ],
              "seriesOverrides": [
                {
                  "alias": "/-Virtual/",
                  "dashes": true,
                  "lines": true
                }
              ]
            },
            {
              "datasource": "Prometheus",
              "gridPos": {"h": 8, "w": 12, "x": 12, "y": 40},
              "id": 11,
              "type": "graph",
              "title": "Process States",
              "targets": [
                {
                  "expr": "sum(namedprocess_namegroup_states) by (state)",
                  "legendFormat": "{{ state }}"
                }
              ],
              "yaxes": [
                {
                  "format": "short",
                  "label": "Count"
                },
                {
                  "format": "short"
                }
              ]
            },
            {
              "datasource": "Prometheus",
              "gridPos": {"h": 8, "w": 24, "x": 0, "y": 48},
              "id": 12,
              "type": "timeseries",
              "title": "CPU Usage Distribution (Stacked)",
              "targets": [
                {
                  "expr": "topk(10, sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m])) * 100)",
                  "legendFormat": "{{ groupname }}"
                }
              ],
              "fieldConfig": {
                "defaults": {
                  "unit": "percent",
                  "decimals": 1,
                  "min": 0,
                  "custom": {
                    "drawStyle": "line",
                    "lineWidth": 1,
                    "fillOpacity": 50,
                    "stacking": {
                      "mode": "normal",
                      "group": "A"
                    },
                    "showPoints": "never"
                  }
                }
              },
              "options": {
                "legend": {
                  "displayMode": "table",
                  "placement": "right",
                  "calcs": ["mean", "max"],
                  "showLegend": true
                }
              }
            }
          ]
        }
      }
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"host-process-monitoring.json":"{\n  \"dashboard\": {\n    \"id\": null,\n    \"uid\": \"host-process-monitoring\",\n    \"title\": \"Host Process Monitoring - Ubuntu 22.04\",\n    \"tags\": [\"processes\", \"system\", \"razerblade\", \"host\"],\n    \"timezone\": \"browser\",\n    \"schemaVersion\": 38,\n    \"version\": 3,\n    \"refresh\": \"30s\",\n    \"panels\": [\n      {\n        \"datasource\": \"Prometheus\",\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 0},\n        \"id\": 1,\n        \"type\": \"timeseries\",\n        \"title\": \"Top CPU Consuming Processes\",\n        \"targets\": [\n          {\n            \"expr\": \"topk(5, sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m])) * 100)\",\n            \"legendFormat\": \"{{ groupname }}\"\n          }\n        ],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"unit\": \"percent\",\n            \"decimals\": 1,\n            \"min\": 0,\n            \"max\": 100\n          }\n        }\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 0},\n        \"id\": 2,\n        \"type\": \"table\",\n        \"title\": \"Top Memory Consuming Processes (Resident Memory)\",\n        \"targets\": [\n          {\n            \"expr\": \"topk(10, sum by (groupname) (namedprocess_namegroup_memory_bytes{memtype=\\\"resident\\\"}))\",\n            \"format\": \"table\",\n            \"instant\": true\n          }\n        ],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"unit\": \"bytes\",\n            \"decimals\": 0,\n            \"custom\": {\n              \"align\": \"auto\",\n              \"displayMode\": \"color-background-solid\"\n            }\n          },\n          \"overrides\": [\n            {\n              \"matcher\": {\n                \"id\": \"byName\",\n                \"options\": \"groupname\"\n              },\n              \"properties\": [\n                {\n                  \"id\": \"displayName\",\n                  \"value\": \"Process Name\"\n                },\n                {\n                  \"id\": \"custom.width\",\n                  \"value\": 200\n                }\n              ]\n            },\n            {\n              \"matcher\": {\n                \"id\": \"byName\",\n                \"options\": \"Value\"\n              },\n              \"properties\": [\n                {\n                  \"id\": \"displayName\",\n                  \"value\": \"Memory\"\n                },\n                {\n                  \"id\": \"custom.displayMode\",\n                  \"value\": \"gradient-gauge\"\n                }\n              ]\n            }\n          ]\n        },\n        \"transformations\": [\n          {\n            \"id\": \"organize\",\n            \"options\": {\n              \"excludeByName\": {\n                \"Time\": true\n              }\n            }\n          }\n        ]\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 8},\n        \"id\": 3,\n        \"type\": \"graph\",\n        \"title\": \"Process CPU Usage Over Time\",\n        \"targets\": [\n          {\n            \"expr\": \"topk(5, sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m])) * 100)\",\n            \"legendFormat\": \"{{ groupname }}\"\n          }\n        ],\n        \"yaxes\": [\n          {\n            \"format\": \"percent\",\n            \"label\": \"CPU %\",\n            \"min\": 0\n          },\n          {\n            \"format\": \"short\"\n          }\n        ]\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 8},\n        \"id\": 4,\n        \"type\": \"timeseries\",\n        \"title\": \"Process Memory Usage Over Time (Resident)\",\n        \"targets\": [\n          {\n            \"expr\": \"topk(5, sum by (groupname) (namedprocess_namegroup_memory_bytes{memtype=\\\"resident\\\"}))\",\n            \"legendFormat\": \"{{ groupname }}\"\n          }\n        ],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"unit\": \"bytes\",\n            \"decimals\": 0,\n            \"min\": 0,\n            \"custom\": {\n              \"drawStyle\": \"line\",\n              \"lineInterpolation\": \"linear\",\n              \"lineWidth\": 2,\n              \"fillOpacity\": 10,\n              \"showPoints\": \"never\"\n            }\n          },\n          \"overrides\": []\n        },\n        \"options\": {\n          \"legend\": {\n            \"displayMode\": \"table\",\n            \"placement\": \"right\",\n            \"calcs\": [\"mean\", \"max\"],\n            \"showLegend\": true\n          }\n        }\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 16},\n        \"id\": 5,\n        \"type\": \"stat\",\n        \"title\": \"Total Processes\",\n        \"targets\": [\n          {\n            \"expr\": \"sum(namedprocess_namegroup_num_procs)\"\n          }\n        ],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"unit\": \"short\",\n            \"decimals\": 0\n          }\n        }\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 16},\n        \"id\": 6,\n        \"type\": \"stat\",\n        \"title\": \"Total Threads\",\n        \"targets\": [\n          {\n            \"expr\": \"sum(namedprocess_namegroup_num_threads)\"\n          }\n        ],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"unit\": \"short\",\n            \"decimals\": 0\n          }\n        }\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 24},\n        \"id\": 7,\n        \"type\": \"piechart\",\n        \"title\": \"CPU Usage by Process\",\n        \"targets\": [\n          {\n            \"expr\": \"topk(10, sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m])) * 100)\",\n            \"legendFormat\": \"{{ groupname }}\"\n          }\n        ],\n        \"options\": {\n          \"reduceOptions\": {\n            \"values\": false,\n            \"calcs\": [\"lastNotNull\"]\n          },\n          \"pieType\": \"donut\",\n          \"displayLabels\": [\"name\", \"value\"],\n          \"legendDisplayMode\": \"table\",\n          \"legendPlacement\": \"right\"\n        },\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"unit\": \"percent\",\n            \"decimals\": 1\n          }\n        }\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 24},\n        \"id\": 8,\n        \"type\": \"piechart\",\n        \"title\": \"Memory Usage by Process (Resident)\",\n        \"targets\": [\n          {\n            \"expr\": \"topk(10, sum by (groupname) (namedprocess_namegroup_memory_bytes{memtype=\\\"resident\\\"}))\",\n            \"legendFormat\": \"{{ groupname }}\"\n          }\n        ],\n        \"options\": {\n          \"reduceOptions\": {\n            \"values\": false,\n            \"calcs\": [\"lastNotNull\"]\n          },\n          \"pieType\": \"donut\",\n          \"displayLabels\": [\"name\", \"value\"],\n          \"legendDisplayMode\": \"table\",\n          \"legendPlacement\": \"right\"\n        },\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"unit\": \"bytes\",\n            \"decimals\": 1\n          }\n        }\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 32},\n        \"id\": 9,\n        \"type\": \"table\",\n        \"title\": \"Process Details\",\n        \"targets\": [\n          {\n            \"expr\": \"sum by (groupname) (namedprocess_namegroup_num_procs)\",\n            \"format\": \"table\",\n            \"instant\": true\n          },\n          {\n            \"expr\": \"sum by (groupname) (namedprocess_namegroup_num_threads)\",\n            \"format\": \"table\",\n            \"instant\": true\n          },\n          {\n            \"expr\": \"sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m])) * 100\",\n            \"format\": \"table\",\n            \"instant\": true\n          },\n          {\n            \"expr\": \"sum by (groupname) (namedprocess_namegroup_memory_bytes{memtype=\\\"resident\\\"})\",\n            \"format\": \"table\",\n            \"instant\": true\n          }\n        ],\n        \"transformations\": [\n          {\n            \"id\": \"merge\"\n          },\n          {\n            \"id\": \"organize\",\n            \"options\": {\n              \"excludeByName\": {\n                \"Time\": true,\n                \"Time 1\": true,\n                \"Time 2\": true,\n                \"Time 3\": true,\n                \"Time 4\": true\n              },\n              \"renameByName\": {\n                \"groupname\": \"Process\",\n                \"Value #A\": \"Count\",\n                \"Value #B\": \"Threads\",\n                \"Value #C\": \"CPU %\",\n                \"Value #D\": \"Memory\"\n              }\n            }\n          },\n          {\n            \"id\": \"sortBy\",\n            \"options\": {\n              \"sort\": [\n                {\n                  \"field\": \"Memory\",\n                  \"desc\": true\n                }\n              ]\n            }\n          }\n        ],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"custom\": {\n              \"align\": \"auto\",\n              \"displayMode\": \"auto\"\n            }\n          },\n          \"overrides\": [\n            {\n              \"matcher\": {\n                \"id\": \"byName\",\n                \"options\": \"CPU %\"\n              },\n              \"properties\": [\n                {\n                  \"id\": \"unit\",\n                  \"value\": \"percent\"\n                },\n                {\n                  \"id\": \"decimals\",\n                  \"value\": 1\n                },\n                {\n                  \"id\": \"custom.displayMode\",\n                  \"value\": \"gradient-gauge\"\n                }\n              ]\n            },\n            {\n              \"matcher\": {\n                \"id\": \"byName\",\n                \"options\": \"Memory\"\n              },\n              \"properties\": [\n                {\n                  \"id\": \"unit\",\n                  \"value\": \"bytes\"\n                },\n                {\n                  \"id\": \"custom.displayMode\",\n                  \"value\": \"gradient-gauge\"\n                }\n              ]\n            }\n          ]\n        }\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 40},\n        \"id\": 10,\n        \"type\": \"graph\",\n        \"title\": \"Memory Types Comparison\",\n        \"targets\": [\n          {\n            \"expr\": \"topk(3, sum by (groupname) (namedprocess_namegroup_memory_bytes{memtype=\\\"resident\\\"}))\",\n            \"legendFormat\": \"{{ groupname }} - Resident\"\n          },\n          {\n            \"expr\": \"topk(3, sum by (groupname) (namedprocess_namegroup_memory_bytes{memtype=\\\"virtual\\\"}))\",\n            \"legendFormat\": \"{{ groupname }} - Virtual\"\n          }\n        ],\n        \"yaxes\": [\n          {\n            \"format\": \"bytes\",\n            \"label\": \"Memory\",\n            \"logBase\": 1\n          },\n          {\n            \"format\": \"short\"\n          }\n        ],\n        \"seriesOverrides\": [\n          {\n            \"alias\": \"/-Virtual/\",\n            \"dashes\": true,\n            \"lines\": true\n          }\n        ]\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 40},\n        \"id\": 11,\n        \"type\": \"graph\",\n        \"title\": \"Process States\",\n        \"targets\": [\n          {\n            \"expr\": \"sum(namedprocess_namegroup_states) by (state)\",\n            \"legendFormat\": \"{{ state }}\"\n          }\n        ],\n        \"yaxes\": [\n          {\n            \"format\": \"short\",\n            \"label\": \"Count\"\n          },\n          {\n            \"format\": \"short\"\n          }\n        ]\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 48},\n        \"id\": 12,\n        \"type\": \"timeseries\",\n        \"title\": \"CPU Usage Distribution (Stacked)\",\n        \"targets\": [\n          {\n            \"expr\": \"topk(10, sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m])) * 100)\",\n            \"legendFormat\": \"{{ groupname }}\"\n          }\n        ],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"unit\": \"percent\",\n            \"decimals\": 1,\n            \"min\": 0,\n            \"custom\": {\n              \"drawStyle\": \"line\",\n              \"lineWidth\": 1,\n              \"fillOpacity\": 50,\n              \"stacking\": {\n                \"mode\": \"normal\",\n                \"group\": \"A\"\n              },\n              \"showPoints\": \"never\"\n            }\n          }\n        },\n        \"options\": {\n          \"legend\": {\n            \"displayMode\": \"table\",\n            \"placement\": \"right\",\n            \"calcs\": [\"mean\", \"max\"],\n            \"showLegend\": true\n          }\n        }\n      }\n    ]\n  }\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"host-process-dashboard-v2","namespace":"monitoring"}}
    creationTimestamp: "2025-05-30T02:32:03Z"
    name: host-process-dashboard-v2
    namespace: monitoring
    resourceVersion: "92360"
    uid: 7b429ac0-00a2-4534-879a-45e8eff1c77b
- apiVersion: v1
  data:
    k3s-alerts.yaml: "groups:\n- name: k3s_core_services\n  interval: 30s\n  rules:\n
      \ # NOTE: K3s API Server, Controller Manager, Scheduler, and etcd metrics \n
      \ # are not exposed by default in K3s. These alerts are commented out \n  #
      to prevent false positives. Enable them only if you have configured\n  # K3s
      to expose these metrics.\n  \n  # # K3s API Server (DISABLED - metrics not exposed
      in K3s)\n  # - alert: K3sAPIServerDown\n  #   expr: up{job=\"kubernetes-apiservers\"}
      == 0 or absent(up{job=\"kubernetes-apiservers\"})\n  #   for: 2m\n  #   labels:\n
      \ #     severity: critical\n  #     component: k3s\n  #     service: apiserver\n
      \ #   annotations:\n  #     summary: \"K3s API Server is down\"\n  #     description:
      \"K3s API Server has been unreachable for more than 2 minutes. This is critical
      for cluster operation.\"\n      \n  # K3s Service Process (this is what we can
      actually monitor)\n  - alert: K3sServiceDown\n    expr: up{job=\"node-exporter\"}
      == 1 and node_systemd_unit_state{name=\"k3s.service\",state=\"active\"} != 1\n
      \   for: 2m\n    labels:\n      severity: critical\n      component: k3s\n      service:
      k3s-service\n    annotations:\n      summary: \"K3s service is not active\"\n
      \     description: \"K3s systemd service is not in active state on {{ $labels.instance
      }}\"\n      \n  # Node conditions (these work with kube-state-metrics)\n  -
      alert: NodeNotReady\n    expr: kube_node_status_condition{condition=\"Ready\",status=\"true\"}
      == 0\n    for: 5m\n    labels:\n      severity: critical\n      component: k3s\n
      \   annotations:\n      summary: \"Kubernetes node not ready\"\n      description:
      \"Node {{ $labels.node }} has been not ready for more than 5 minutes\"\n      \n
      \ - alert: NodeMemoryPressure\n    expr: kube_node_status_condition{condition=\"MemoryPressure\",status=\"true\"}
      == 1\n    for: 2m\n    labels:\n      severity: critical\n      component: k3s\n
      \   annotations:\n      summary: \"Node has memory pressure\"\n      description:
      \"Node {{ $labels.node }} is experiencing memory pressure\"\n      \n  - alert:
      NodeDiskPressure\n    expr: kube_node_status_condition{condition=\"DiskPressure\",status=\"true\"}
      == 1\n    for: 2m\n    labels:\n      severity: critical\n      component: k3s\n
      \   annotations:\n      summary: \"Node has disk pressure\"\n      description:
      \"Node {{ $labels.node }} is experiencing disk pressure\"\n      \n  - alert:
      NodePIDPressure\n    expr: kube_node_status_condition{condition=\"PIDPressure\",status=\"true\"}
      == 1\n    for: 2m\n    labels:\n      severity: critical\n      component: k3s\n
      \   annotations:\n      summary: \"Node has PID pressure\"\n      description:
      \"Node {{ $labels.node }} is experiencing PID pressure (too many processes)\"\n
      \     \n  # Critical daemon pods\n  - alert: CoreDNSDown\n    expr: kube_deployment_status_replicas_available{namespace=\"kube-system\",deployment=\"coredns\"}
      == 0\n    for: 2m\n    labels:\n      severity: critical\n      component: k3s\n
      \     service: coredns\n    annotations:\n      summary: \"CoreDNS is down\"\n
      \     description: \"CoreDNS has no available replicas. DNS resolution in cluster
      will fail.\"\n      \n  - alert: TraefikDown\n    expr: kube_deployment_status_replicas_available{namespace=\"kube-system\",deployment=\"traefik\"}
      == 0\n    for: 5m\n    labels:\n      severity: warning\n      component: k3s\n
      \     service: traefik\n    annotations:\n      summary: \"Traefik ingress controller
      is down\"\n      description: \"Traefik has no available replicas. Ingress routing
      may be affected.\"\n      \n  # Certificate expiry (if cert-manager is installed)\n
      \ - alert: K3sCertificateExpiringSoon\n    expr: (kube_certificate_expiration_timestamp_seconds
      - time()) / 86400 < 30\n    for: 1h\n    labels:\n      severity: warning\n
      \     component: k3s\n    annotations:\n      summary: \"K3s certificate expiring
      soon\"\n      description: \"Certificate {{ $labels.name }} will expire in {{
      $value }} days\"\n      \n  - alert: K3sCertificateExpiringCritical\n    expr:
      (kube_certificate_expiration_timestamp_seconds - time()) / 86400 < 7\n    for:
      1h\n    labels:\n      severity: critical\n      component: k3s\n    annotations:\n
      \     summary: \"K3s certificate expiring critically soon\"\n      description:
      \"Certificate {{ $labels.name }} will expire in {{ $value }} days!\"\n      \n
      \ # Workload alerts\n  - alert: PodCrashLooping\n    expr: |\n      rate(kube_pod_container_status_restarts_total[15m])
      > 0.1\n      and \n      kube_pod_container_status_restarts_total > 5\n    for:
      5m\n    labels:\n      severity: critical\n      component: k3s\n    annotations:\n
      \     summary: \"Pod is crash looping\"\n      description: \"Pod {{ $labels.namespace
      }}/{{ $labels.pod }} has restarted {{ $value | humanize }} times recently (total
      restarts: {{ $labels.restarts_total }})\"\n      \n  - alert: DeploymentReplicasMismatch\n
      \   expr: |\n      kube_deployment_spec_replicas{namespace!~\"kube-system|odin-prime\"}\n
      \       != kube_deployment_status_replicas_available{namespace!~\"kube-system|odin-prime\"}\n
      \   for: 10m\n    labels:\n      severity: warning\n      component: k3s\n    annotations:\n
      \     summary: \"Deployment has replica mismatch\"\n      description: \"Deployment
      {{ $labels.namespace }}/{{ $labels.deployment }} has {{ $labels.replicas }}
      replicas defined but only {{ $labels.available_replicas }} available\"\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"k3s-alerts.yaml":"groups:\n- name: k3s_core_services\n  interval: 30s\n  rules:\n  # NOTE: K3s API Server, Controller Manager, Scheduler, and etcd metrics \n  # are not exposed by default in K3s. These alerts are commented out \n  # to prevent false positives. Enable them only if you have configured\n  # K3s to expose these metrics.\n  \n  # # K3s API Server (DISABLED - metrics not exposed in K3s)\n  # - alert: K3sAPIServerDown\n  #   expr: up{job=\"kubernetes-apiservers\"} == 0 or absent(up{job=\"kubernetes-apiservers\"})\n  #   for: 2m\n  #   labels:\n  #     severity: critical\n  #     component: k3s\n  #     service: apiserver\n  #   annotations:\n  #     summary: \"K3s API Server is down\"\n  #     description: \"K3s API Server has been unreachable for more than 2 minutes. This is critical for cluster operation.\"\n      \n  # K3s Service Process (this is what we can actually monitor)\n  - alert: K3sServiceDown\n    expr: up{job=\"node-exporter\"} == 1 and node_systemd_unit_state{name=\"k3s.service\",state=\"active\"} != 1\n    for: 2m\n    labels:\n      severity: critical\n      component: k3s\n      service: k3s-service\n    annotations:\n      summary: \"K3s service is not active\"\n      description: \"K3s systemd service is not in active state on {{ $labels.instance }}\"\n      \n  # Node conditions (these work with kube-state-metrics)\n  - alert: NodeNotReady\n    expr: kube_node_status_condition{condition=\"Ready\",status=\"true\"} == 0\n    for: 5m\n    labels:\n      severity: critical\n      component: k3s\n    annotations:\n      summary: \"Kubernetes node not ready\"\n      description: \"Node {{ $labels.node }} has been not ready for more than 5 minutes\"\n      \n  - alert: NodeMemoryPressure\n    expr: kube_node_status_condition{condition=\"MemoryPressure\",status=\"true\"} == 1\n    for: 2m\n    labels:\n      severity: critical\n      component: k3s\n    annotations:\n      summary: \"Node has memory pressure\"\n      description: \"Node {{ $labels.node }} is experiencing memory pressure\"\n      \n  - alert: NodeDiskPressure\n    expr: kube_node_status_condition{condition=\"DiskPressure\",status=\"true\"} == 1\n    for: 2m\n    labels:\n      severity: critical\n      component: k3s\n    annotations:\n      summary: \"Node has disk pressure\"\n      description: \"Node {{ $labels.node }} is experiencing disk pressure\"\n      \n  - alert: NodePIDPressure\n    expr: kube_node_status_condition{condition=\"PIDPressure\",status=\"true\"} == 1\n    for: 2m\n    labels:\n      severity: critical\n      component: k3s\n    annotations:\n      summary: \"Node has PID pressure\"\n      description: \"Node {{ $labels.node }} is experiencing PID pressure (too many processes)\"\n      \n  # Critical daemon pods\n  - alert: CoreDNSDown\n    expr: kube_deployment_status_replicas_available{namespace=\"kube-system\",deployment=\"coredns\"} == 0\n    for: 2m\n    labels:\n      severity: critical\n      component: k3s\n      service: coredns\n    annotations:\n      summary: \"CoreDNS is down\"\n      description: \"CoreDNS has no available replicas. DNS resolution in cluster will fail.\"\n      \n  - alert: TraefikDown\n    expr: kube_deployment_status_replicas_available{namespace=\"kube-system\",deployment=\"traefik\"} == 0\n    for: 5m\n    labels:\n      severity: warning\n      component: k3s\n      service: traefik\n    annotations:\n      summary: \"Traefik ingress controller is down\"\n      description: \"Traefik has no available replicas. Ingress routing may be affected.\"\n      \n  # Certificate expiry (if cert-manager is installed)\n  - alert: K3sCertificateExpiringSoon\n    expr: (kube_certificate_expiration_timestamp_seconds - time()) / 86400 \u003c 30\n    for: 1h\n    labels:\n      severity: warning\n      component: k3s\n    annotations:\n      summary: \"K3s certificate expiring soon\"\n      description: \"Certificate {{ $labels.name }} will expire in {{ $value }} days\"\n      \n  - alert: K3sCertificateExpiringCritical\n    expr: (kube_certificate_expiration_timestamp_seconds - time()) / 86400 \u003c 7\n    for: 1h\n    labels:\n      severity: critical\n      component: k3s\n    annotations:\n      summary: \"K3s certificate expiring critically soon\"\n      description: \"Certificate {{ $labels.name }} will expire in {{ $value }} days!\"\n      \n  # Workload alerts\n  - alert: PodCrashLooping\n    expr: |\n      rate(kube_pod_container_status_restarts_total[15m]) \u003e 0.1\n      and \n      kube_pod_container_status_restarts_total \u003e 5\n    for: 5m\n    labels:\n      severity: critical\n      component: k3s\n    annotations:\n      summary: \"Pod is crash looping\"\n      description: \"Pod {{ $labels.namespace }}/{{ $labels.pod }} has restarted {{ $value | humanize }} times recently (total restarts: {{ $labels.restarts_total }})\"\n      \n  - alert: DeploymentReplicasMismatch\n    expr: |\n      kube_deployment_spec_replicas{namespace!~\"kube-system|odin-prime\"}\n        != kube_deployment_status_replicas_available{namespace!~\"kube-system|odin-prime\"}\n    for: 10m\n    labels:\n      severity: warning\n      component: k3s\n    annotations:\n      summary: \"Deployment has replica mismatch\"\n      description: \"Deployment {{ $labels.namespace }}/{{ $labels.deployment }} has {{ $labels.replicas }} replicas defined but only {{ $labels.available_replicas }} available\"\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"k3s-alert-rules","namespace":"monitoring"}}
    creationTimestamp: "2025-05-29T23:07:31Z"
    name: k3s-alert-rules
    namespace: monitoring
    resourceVersion: "5304042"
    uid: ef29152a-1ee6-4a06-b14f-0f821d979fe2
- apiVersion: v1
  data:
    k8s-alerts.yaml: |
      groups:
      - name: kubernetes
        rules:
        - alert: KubeNodeNotReady
          expr: kube_node_status_condition{condition="Ready",status="true"} == 0
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "Node {{ $labels.node }} is not ready"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"k8s-alerts.yaml":"groups:\n- name: kubernetes\n  rules:\n  - alert: KubeNodeNotReady\n    expr: kube_node_status_condition{condition=\"Ready\",status=\"true\"} == 0\n    for: 5m\n    labels:\n      severity: critical\n    annotations:\n      summary: \"Node {{ $labels.node }} is not ready\"\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"k8s-alert-rules","namespace":"monitoring"}}
    creationTimestamp: "2025-06-04T14:47:34Z"
    name: k8s-alert-rules
    namespace: monitoring
    resourceVersion: "3018028"
    uid: 97ef2c03-7807-49ed-bd23-4f82c0852180
- apiVersion: v1
  data:
    k8s_pod_anomaly_detector.py: "#!/usr/bin/env python3\nimport time\nimport numpy
      as np\nimport pandas as pd\nfrom datetime import datetime, timedelta\nimport
      requests\nimport logging\nimport json\nimport os\nimport pickle\nimport threading\nfrom
      prometheus_client import start_http_server, Gauge, Counter, Histogram\nfrom
      sklearn.ensemble import IsolationForest\nfrom sklearn.preprocessing import StandardScaler\nfrom
      kubernetes import client, config\nfrom http.server import HTTPServer, BaseHTTPRequestHandler\nimport
      warnings\nwarnings.filterwarnings('ignore')\n\n# Configure logging\nlogging.basicConfig(\n
      \   level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s
      - %(message)s'\n)\nlogger = logging.getLogger('k8s-pod-anomaly-detector')\n\n#
      Prometheus metrics\npod_anomaly_score = Gauge('k8s_pod_anomaly_score', 'Pod
      anomaly score', ['namespace', 'pod', 'metric_type', 'algorithm'])\npod_restart_anomaly
      = Gauge('k8s_pod_restart_anomaly_score', 'Pod restart frequency anomaly', ['namespace',
      'pod'])\npod_resource_anomaly = Gauge('k8s_pod_resource_anomaly_score', 'Pod
      resource usage anomaly', ['namespace', 'pod', 'resource'])\npod_lifecycle_anomaly
      = Gauge('k8s_pod_lifecycle_anomaly_score', 'Pod lifecycle anomaly', ['namespace',
      'pod'])\nmodel_training_duration = Histogram('k8s_anomaly_model_training_duration_seconds',
      'Model training duration')\nmodel_updates = Counter('k8s_anomaly_model_updates_total',
      'Total model updates', ['metric_type'])\ndetection_errors = Counter('k8s_anomaly_detection_errors_total',
      'Total detection errors', ['metric_type'])\nhealth_status = Gauge('k8s_anomaly_detector_health',
      'Health status of K8s anomaly detector')\nmetrics_processed = Counter('k8s_anomaly_metrics_processed_total',
      'Total metrics processed', ['metric_type'])\n\n# Configuration\nPROMETHEUS_URL
      = os.getenv('PROMETHEUS_URL', 'http://prometheus:9090')\nMODEL_PATH = '/models'\nUPDATE_INTERVAL
      = int(os.getenv('UPDATE_INTERVAL', '60'))  # 1 minute\nTRAINING_WINDOW = os.getenv('TRAINING_WINDOW',
      '7d')\n\n# K8s Pod Metrics Configuration\nPOD_METRICS = [\n    {\n        'name':
      'cpu_usage',\n        'query': 'rate(container_cpu_usage_seconds_total{container!=\"\",container!=\"POD\"}[5m])',\n
      \       'algorithm': 'isolation_forest',\n        'sensitivity': 0.1,\n        'min_samples':
      50\n    },\n    {\n        'name': 'memory_usage',\n        'query': 'container_memory_working_set_bytes{container!=\"\",container!=\"POD\"}',\n
      \       'algorithm': 'isolation_forest', \n        'sensitivity': 0.1,\n        'min_samples':
      50\n    },\n    {\n        'name': 'restart_rate',\n        'query': 'increase(kube_pod_container_status_restarts_total[1h])',\n
      \       'algorithm': 'statistical',\n        'z_threshold': 2,\n        'min_samples':
      20\n    },\n    {\n        'name': 'pod_ready_time',\n        'query': 'time()
      - kube_pod_status_ready_time',\n        'algorithm': 'statistical',\n        'z_threshold':
      3,\n        'min_samples': 30\n    },\n    {\n        'name': 'container_oom_kills',\n
      \       'query': 'increase(container_oom_events_total[1h])',\n        'algorithm':
      'statistical', \n        'z_threshold': 1,\n        'min_samples': 10\n    },\n
      \   {\n        'name': 'network_rx_errors',\n        'query': 'rate(container_network_receive_errors_total[5m])',\n
      \       'algorithm': 'statistical',\n        'z_threshold': 2,\n        'min_samples':
      20\n    },\n    {\n        'name': 'network_tx_errors', \n        'query': 'rate(container_network_transmit_errors_total[5m])',\n
      \       'algorithm': 'statistical',\n        'z_threshold': 2,\n        'min_samples':
      20\n    }\n]\n\n# Global health status\nhealth_info = {\n    'healthy': True,\n
      \   'last_update': datetime.now(),\n    'errors': [],\n    'k8s_available':
      False,\n    'prometheus_available': False\n}\n\nclass HealthCheckHandler(BaseHTTPRequestHandler):\n
      \   \"\"\"HTTP handler for health checks\"\"\"\n    def do_GET(self):\n        if
      self.path == '/health':\n            self.send_health_response()\n        elif
      self.path == '/healthz':\n            self.send_healthz_response()\n        elif
      self.path == '/ready':\n            self.send_ready_response()\n        else:\n
      \           self.send_error(404)\n    \n    def send_health_response(self):\n
      \       \"\"\"Detailed health check response\"\"\"\n        status_code = 200
      if health_info['healthy'] else 503\n        response = {\n            'status':
      'healthy' if status_code == 200 else 'unhealthy',\n            'timestamp':
      datetime.now().isoformat(),\n            'k8s_available': health_info['k8s_available'],\n
      \           'prometheus_available': health_info['prometheus_available'],\n            'last_update':
      health_info['last_update'].isoformat()\n        }\n        \n        if health_info['errors']:\n
      \           response['recent_errors'] = health_info['errors'][-5:]\n            \n
      \       self.send_response(status_code)\n        self.send_header('Content-Type',
      'application/json')\n        self.end_headers()\n        import json\n        self.wfile.write(json.dumps(response).encode())\n
      \   \n    def send_healthz_response(self):\n        \"\"\"Simple health check
      for k8s\"\"\"\n        if health_info['healthy']:\n            self.send_response(200)\n
      \           self.end_headers()\n            self.wfile.write(b'OK')\n        else:\n
      \           self.send_response(503)\n            self.end_headers()\n            self.wfile.write(b'Unhealthy')\n
      \   \n    def send_ready_response(self):\n        \"\"\"Readiness check\"\"\"\n
      \       now = datetime.now()\n        if (now - health_info['last_update'] <
      timedelta(minutes=2) and \n            health_info['k8s_available'] and health_info['prometheus_available']):\n
      \           self.send_response(200)\n            self.end_headers()\n            self.wfile.write(b'Ready')\n
      \       else:\n            self.send_response(503)\n            self.end_headers()\n
      \           self.wfile.write(b'Not Ready')\n    \n    def log_message(self,
      format, *args):\n        # Suppress access logs\n        pass\n\ndef run_health_server():\n
      \   \"\"\"Run the health check HTTP server\"\"\"\n    server = HTTPServer(('',
      8080), HealthCheckHandler)\n    server.serve_forever()\n\nclass K8sPodAnomalyDetector:\n
      \   def __init__(self):\n        self.models = {}\n        self.scalers = {}\n
      \       self.thresholds = {}\n        self.k8s_client = None\n        os.makedirs(MODEL_PATH,
      exist_ok=True)\n        \n        # Initialize Kubernetes client\n        try:\n
      \           config.load_incluster_config()\n            self.k8s_client = client.CoreV1Api()\n
      \           health_info['k8s_available'] = True\n            logger.info(\"Kubernetes
      client initialized successfully\")\n        except Exception as e:\n            logger.error(f\"Failed
      to initialize Kubernetes client: {e}\")\n            health_info['k8s_available']
      = False\n            health_info['errors'].append(f\"K8s init error: {str(e)}\")\n
      \           \n        self.load_models()\n        \n    def load_models(self):\n
      \       \"\"\"Load saved models from disk\"\"\"\n        for metric in POD_METRICS:\n
      \           model_file = os.path.join(MODEL_PATH, f\"k8s_{metric['name'].replace('/',
      '_')}.pkl\")\n            if os.path.exists(model_file):\n                try:\n
      \                   with open(model_file, 'rb') as f:\n                        data
      = pickle.load(f)\n                        self.models[metric['name']] = data['model']\n
      \                       self.scalers[metric['name']] = data.get('scaler')\n
      \                       self.thresholds[metric['name']] = data.get('thresholds',
      {})\n                        logger.info(f\"Loaded K8s model for {metric['name']}\")\n
      \               except Exception as e:\n                    logger.error(f\"Failed
      to load K8s model for {metric['name']}: {e}\")\n                    \n    def
      save_model(self, metric_name):\n        \"\"\"Save model to disk\"\"\"\n        if
      metric_name in self.models:\n            model_file = os.path.join(MODEL_PATH,
      f\"k8s_{metric_name.replace('/', '_')}.pkl\")\n            try:\n                with
      open(model_file, 'wb') as f:\n                    pickle.dump({\n                        'model':
      self.models[metric_name],\n                        'scaler': self.scalers.get(metric_name),\n
      \                       'thresholds': self.thresholds.get(metric_name, {})\n
      \                   }, f)\n                logger.info(f\"Saved K8s model for
      {metric_name}\")\n            except Exception as e:\n                logger.error(f\"Failed
      to save K8s model for {metric_name}: {e}\")\n                \n    def query_prometheus(self,
      query, start_time=None, end_time=None, step='60s'):\n        \"\"\"Query Prometheus
      for metric data\"\"\"\n        if not start_time:\n            end_time = datetime.now()\n
      \           start_time = end_time - timedelta(days=7)\n            \n        params
      = {\n            'query': query,\n            'start': start_time.timestamp(),\n
      \           'end': end_time.timestamp(),\n            'step': step\n        }\n
      \       \n        try:\n            response = requests.get(f\"{PROMETHEUS_URL}/api/v1/query_range\",
      params=params, timeout=30)\n            response.raise_for_status()\n            data
      = response.json()\n            \n            health_info['prometheus_available']
      = True\n            \n            if data['status'] == 'success' and data['data']['result']:\n
      \               # Process multiple time series\n                all_data = []\n
      \               for result in data['data']['result']:\n                    for
      timestamp, value in result['values']:\n                        row = {'timestamp':
      float(timestamp), 'value': float(value)}\n                        # Add labels
      as additional features\n                        for label, label_value in result['metric'].items():\n
      \                           if label not in ['__name__', 'instance', 'job']:\n
      \                               row[label] = label_value\n                        all_data.append(row)\n
      \               \n                if all_data:\n                    return pd.DataFrame(all_data)\n
      \                   \n        except Exception as e:\n            logger.error(f\"Failed
      to query Prometheus: {e}\")\n            health_info['prometheus_available']
      = False\n            health_info['errors'].append(f\"Prometheus error: {str(e)}\")\n
      \           detection_errors.labels(metric_type=query).inc()\n            \n
      \       return pd.DataFrame()\n        \n    def query_instant(self, query):\n
      \       \"\"\"Query Prometheus for instant values\"\"\"\n        try:\n            response
      = requests.get(f\"{PROMETHEUS_URL}/api/v1/query\", params={'query': query},
      timeout=10)\n            response.raise_for_status()\n            data = response.json()\n
      \           \n            health_info['prometheus_available'] = True\n            \n
      \           if data['status'] == 'success' and data['data']['result']:\n                results
      = []\n                for result in data['data']['result']:\n                    row
      = {\n                        'value': float(result['value'][1]),\n                        'labels':
      result['metric']\n                    }\n                    results.append(row)\n
      \               return results\n                \n        except Exception as
      e:\n            logger.error(f\"Failed to query instant value: {e}\")\n            health_info['prometheus_available']
      = False\n            \n        return []\n        \n    def get_pod_info(self):\n
      \       \"\"\"Get current pod information from K8s API\"\"\"\n        if not
      self.k8s_client:\n            return []\n            \n        try:\n            pods
      = self.k8s_client.list_pod_for_all_namespaces()\n            pod_info = []\n
      \           \n            for pod in pods.items:\n                info = {\n
      \                   'name': pod.metadata.name,\n                    'namespace':
      pod.metadata.namespace,\n                    'phase': pod.status.phase,\n                    'creation_time':
      pod.metadata.creation_timestamp,\n                    'restart_count': sum([container.restart_count
      or 0 \n                                        for container in pod.status.container_statuses
      or []]),\n                    'ready': all([condition.status == \"True\" \n
      \                               for condition in pod.status.conditions or []
      \n                                if condition.type == \"Ready\"])\n                }\n
      \               pod_info.append(info)\n                \n            health_info['k8s_available']
      = True\n            return pod_info\n            \n        except Exception
      as e:\n            logger.error(f\"Failed to get pod info: {e}\")\n            health_info['k8s_available']
      = False\n            health_info['errors'].append(f\"K8s API error: {str(e)}\")\n
      \           return []\n        \n    def train_isolation_forest(self, metric_config,
      data):\n        \"\"\"Train Isolation Forest model for K8s metrics\"\"\"\n        if
      len(data) < metric_config['min_samples']:\n            logger.warning(f\"Insufficient
      data for K8s {metric_config['name']}: {len(data)} samples\")\n            return
      None, None\n            \n        # Prepare features - include pod metadata\n
      \       feature_cols = ['value']\n        if 'namespace' in data.columns:\n
      \           # Convert categorical to numeric\n            data['namespace_hash']
      = pd.Categorical(data['namespace']).codes\n            feature_cols.append('namespace_hash')\n
      \       if 'pod' in data.columns:\n            data['pod_hash'] = pd.Categorical(data['pod']).codes\n
      \           feature_cols.append('pod_hash')\n            \n        # Add time-based
      features\n        data['hour'] = pd.to_datetime(data['timestamp'], unit='s').dt.hour\n
      \       data['dayofweek'] = pd.to_datetime(data['timestamp'], unit='s').dt.dayofweek\n
      \       feature_cols.extend(['hour', 'dayofweek'])\n        \n        X = data[feature_cols].values\n
      \       \n        # Scale features\n        scaler = StandardScaler()\n        X_scaled
      = scaler.fit_transform(X)\n        \n        # Train model\n        model =
      IsolationForest(\n            contamination=metric_config['sensitivity'],\n
      \           random_state=42,\n            n_estimators=100\n        )\n        \n
      \       with model_training_duration.time():\n            model.fit(X_scaled)\n
      \           \n        model_updates.labels(metric_type=metric_config['name']).inc()\n
      \       \n        return model, scaler\n        \n    def train_statistical_model(self,
      metric_config, data):\n        \"\"\"Train statistical anomaly detection model\"\"\"\n
      \       if len(data) < metric_config['min_samples']:\n            logger.warning(f\"Insufficient
      data for K8s {metric_config['name']}: {len(data)} samples\")\n            return
      None\n            \n        values = data['value'].values\n        \n        #
      Calculate statistics per pod/namespace if available\n        thresholds = {\n
      \           'global': {\n                'mean': np.mean(values),\n                'std':
      np.std(values),\n                'p99': np.percentile(values, 99),\n                'p95':
      np.percentile(values, 95),\n                'p05': np.percentile(values, 5),\n
      \               'p01': np.percentile(values, 1)\n            }\n        }\n
      \       \n        # Per-namespace thresholds if namespace data available\n        if
      'namespace' in data.columns:\n            thresholds['per_namespace'] = {}\n
      \           for ns in data['namespace'].unique():\n                ns_data =
      data[data['namespace'] == ns]['value'].values\n                if len(ns_data)
      >= 10:  # Minimum samples per namespace\n                    thresholds['per_namespace'][ns]
      = {\n                        'mean': np.mean(ns_data),\n                        'std':
      np.std(ns_data),\n                        'p95': np.percentile(ns_data, 95)\n
      \                   }\n        \n        model_updates.labels(metric_type=metric_config['name']).inc()\n
      \       \n        return thresholds\n        \n    def detect_pod_anomalies(self,
      metric_config):\n        \"\"\"Detect anomalies for K8s pod metrics\"\"\"\n
      \       try:\n            # Query current values\n            current_results
      = self.query_instant(metric_config['query'])\n            \n            if not
      current_results:\n                logger.debug(f\"No data for K8s {metric_config['name']}\")\n
      \               return\n                \n            for result in current_results:\n
      \               current_value = result['value']\n                labels = result['labels']\n
      \               \n                # Extract pod and namespace from labels\n
      \               namespace = labels.get('namespace', 'unknown')\n                pod
      = labels.get('pod', labels.get('container', 'unknown'))\n                \n
      \               metrics_processed.labels(metric_type=metric_config['name']).inc()\n
      \               \n                if metric_config['algorithm'] == 'isolation_forest':\n
      \                   if metric_config['name'] in self.models:\n                        model
      = self.models[metric_config['name']]\n                        scaler = self.scalers[metric_config['name']]\n
      \                       \n                        # Prepare features\n                        now
      = datetime.now()\n                        hour = now.hour\n                        dayofweek
      = now.weekday()\n                        \n                        # Create
      feature vector matching training\n                        features = [current_value,
      hour, dayofweek]\n                        # Add namespace/pod hashes if model
      was trained with them\n                        X = np.array([features])\n                        X_scaled
      = scaler.transform(X)\n                        \n                        # Get
      anomaly score\n                        score = model.decision_function(X_scaled)[0]\n
      \                       normalized_score = 50 + (score * 50)\n                        normalized_score
      = max(0, min(100, normalized_score))\n                        \n                        pod_anomaly_score.labels(\n
      \                           namespace=namespace,\n                            pod=pod,\n
      \                           metric_type=metric_config['name'],\n                            algorithm='isolation_forest'\n
      \                       ).set(100 - normalized_score)\n                        \n
      \                       logger.debug(f\"K8s {metric_config['name']} [{namespace}/{pod}]:
      value={current_value}, score={100-normalized_score}\")\n                        \n
      \               elif metric_config['algorithm'] == 'statistical':\n                    if
      metric_config['name'] in self.thresholds:\n                        thresholds
      = self.thresholds[metric_config['name']]\n                        \n                        #
      Use namespace-specific thresholds if available\n                        threshold_data
      = thresholds['global']\n                        if ('per_namespace' in thresholds
      and \n                            namespace in thresholds['per_namespace']):\n
      \                           threshold_data = thresholds['per_namespace'][namespace]\n
      \                       \n                        # Calculate z-score\n                        z_score
      = abs((current_value - threshold_data['mean']) / (threshold_data['std'] + 1e-10))\n
      \                       \n                        # Convert to 0-100 scale\n
      \                       score = min(100, (z_score / metric_config['z_threshold'])
      * 100)\n                        \n                        pod_anomaly_score.labels(\n
      \                           namespace=namespace,\n                            pod=pod,\n
      \                           metric_type=metric_config['name'],\n                            algorithm='statistical'\n
      \                       ).set(score)\n                        \n                        logger.debug(f\"K8s
      {metric_config['name']} [{namespace}/{pod}]: value={current_value}, z-score={z_score},
      score={score}\")\n                    \n        except Exception as e:\n            logger.error(f\"Error
      detecting K8s anomalies for {metric_config['name']}: {e}\")\n            detection_errors.labels(metric_type=metric_config['name']).inc()\n
      \           \n    def update_models(self):\n        \"\"\"Update all K8s anomaly
      detection models\"\"\"\n        logger.info(\"Updating K8s anomaly detection
      models...\")\n        \n        for metric_config in POD_METRICS:\n            try:\n
      \               # Query training data\n                training_data = self.query_prometheus(metric_config['query'])\n
      \               \n                if training_data.empty:\n                    logger.warning(f\"No
      training data for K8s {metric_config['name']}\")\n                    continue\n
      \                   \n                if metric_config['algorithm'] == 'isolation_forest':\n
      \                   model, scaler = self.train_isolation_forest(metric_config,
      training_data)\n                    if model:\n                        self.models[metric_config['name']]
      = model\n                        self.scalers[metric_config['name']] = scaler\n
      \                       self.save_model(metric_config['name'])\n                        \n
      \               elif metric_config['algorithm'] == 'statistical':\n                    thresholds
      = self.train_statistical_model(metric_config, training_data)\n                    if
      thresholds:\n                        self.thresholds[metric_config['name']]
      = thresholds\n                        self.save_model(metric_config['name'])\n
      \                       \n                logger.info(f\"Updated K8s model for
      {metric_config['name']}\")\n                \n            except Exception as
      e:\n                logger.error(f\"Failed to update K8s model for {metric_config['name']}:
      {e}\")\n                health_info['errors'].append(f\"Model update error:
      {str(e)}\")\n                \n    def run(self):\n        \"\"\"Main K8s anomaly
      detection loop\"\"\"\n        # Initial model training\n        self.update_models()\n
      \       \n        last_model_update = time.time()\n        \n        while True:\n
      \           try:\n                # Detect anomalies for all metrics\n                for
      metric_config in POD_METRICS:\n                    self.detect_pod_anomalies(metric_config)\n
      \                   \n                # Update models periodically (every 6
      hours)\n                if time.time() - last_model_update > 21600:\n                    self.update_models()\n
      \                   last_model_update = time.time()\n                    \n
      \               # Update health status\n                health_info['healthy']
      = (health_info['k8s_available'] and \n                                        health_info['prometheus_available'])\n
      \               health_info['last_update'] = datetime.now()\n                health_status.set(1
      if health_info['healthy'] else 0)\n                \n                time.sleep(UPDATE_INTERVAL)\n
      \               \n            except Exception as e:\n                logger.error(f\"Error
      in K8s anomaly detection loop: {e}\")\n                health_info['healthy']
      = False\n                health_info['errors'].append(f\"Main loop error: {str(e)}\")\n
      \               health_status.set(0)\n                time.sleep(60)\n\ndef
      main():\n    # Start Prometheus metrics server\n    start_http_server(9406)\n
      \   logger.info(\"Started K8s anomaly detection metrics server on port 9406\")\n
      \   \n    # Start health check server in a separate thread\n    health_thread
      = threading.Thread(target=run_health_server, daemon=True)\n    health_thread.start()\n
      \   logger.info(\"Started health check server on port 8080\")\n    \n    # Start
      K8s anomaly detector\n    detector = K8sPodAnomalyDetector()\n    detector.run()\n\nif
      __name__ == '__main__':\n    main()\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"k8s_pod_anomaly_detector.py":"#!/usr/bin/env python3\nimport time\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta\nimport requests\nimport logging\nimport json\nimport os\nimport pickle\nimport threading\nfrom prometheus_client import start_http_server, Gauge, Counter, Histogram\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.preprocessing import StandardScaler\nfrom kubernetes import client, config\nfrom http.server import HTTPServer, BaseHTTPRequestHandler\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger('k8s-pod-anomaly-detector')\n\n# Prometheus metrics\npod_anomaly_score = Gauge('k8s_pod_anomaly_score', 'Pod anomaly score', ['namespace', 'pod', 'metric_type', 'algorithm'])\npod_restart_anomaly = Gauge('k8s_pod_restart_anomaly_score', 'Pod restart frequency anomaly', ['namespace', 'pod'])\npod_resource_anomaly = Gauge('k8s_pod_resource_anomaly_score', 'Pod resource usage anomaly', ['namespace', 'pod', 'resource'])\npod_lifecycle_anomaly = Gauge('k8s_pod_lifecycle_anomaly_score', 'Pod lifecycle anomaly', ['namespace', 'pod'])\nmodel_training_duration = Histogram('k8s_anomaly_model_training_duration_seconds', 'Model training duration')\nmodel_updates = Counter('k8s_anomaly_model_updates_total', 'Total model updates', ['metric_type'])\ndetection_errors = Counter('k8s_anomaly_detection_errors_total', 'Total detection errors', ['metric_type'])\nhealth_status = Gauge('k8s_anomaly_detector_health', 'Health status of K8s anomaly detector')\nmetrics_processed = Counter('k8s_anomaly_metrics_processed_total', 'Total metrics processed', ['metric_type'])\n\n# Configuration\nPROMETHEUS_URL = os.getenv('PROMETHEUS_URL', 'http://prometheus:9090')\nMODEL_PATH = '/models'\nUPDATE_INTERVAL = int(os.getenv('UPDATE_INTERVAL', '60'))  # 1 minute\nTRAINING_WINDOW = os.getenv('TRAINING_WINDOW', '7d')\n\n# K8s Pod Metrics Configuration\nPOD_METRICS = [\n    {\n        'name': 'cpu_usage',\n        'query': 'rate(container_cpu_usage_seconds_total{container!=\"\",container!=\"POD\"}[5m])',\n        'algorithm': 'isolation_forest',\n        'sensitivity': 0.1,\n        'min_samples': 50\n    },\n    {\n        'name': 'memory_usage',\n        'query': 'container_memory_working_set_bytes{container!=\"\",container!=\"POD\"}',\n        'algorithm': 'isolation_forest', \n        'sensitivity': 0.1,\n        'min_samples': 50\n    },\n    {\n        'name': 'restart_rate',\n        'query': 'increase(kube_pod_container_status_restarts_total[1h])',\n        'algorithm': 'statistical',\n        'z_threshold': 2,\n        'min_samples': 20\n    },\n    {\n        'name': 'pod_ready_time',\n        'query': 'time() - kube_pod_status_ready_time',\n        'algorithm': 'statistical',\n        'z_threshold': 3,\n        'min_samples': 30\n    },\n    {\n        'name': 'container_oom_kills',\n        'query': 'increase(container_oom_events_total[1h])',\n        'algorithm': 'statistical', \n        'z_threshold': 1,\n        'min_samples': 10\n    },\n    {\n        'name': 'network_rx_errors',\n        'query': 'rate(container_network_receive_errors_total[5m])',\n        'algorithm': 'statistical',\n        'z_threshold': 2,\n        'min_samples': 20\n    },\n    {\n        'name': 'network_tx_errors', \n        'query': 'rate(container_network_transmit_errors_total[5m])',\n        'algorithm': 'statistical',\n        'z_threshold': 2,\n        'min_samples': 20\n    }\n]\n\n# Global health status\nhealth_info = {\n    'healthy': True,\n    'last_update': datetime.now(),\n    'errors': [],\n    'k8s_available': False,\n    'prometheus_available': False\n}\n\nclass HealthCheckHandler(BaseHTTPRequestHandler):\n    \"\"\"HTTP handler for health checks\"\"\"\n    def do_GET(self):\n        if self.path == '/health':\n            self.send_health_response()\n        elif self.path == '/healthz':\n            self.send_healthz_response()\n        elif self.path == '/ready':\n            self.send_ready_response()\n        else:\n            self.send_error(404)\n    \n    def send_health_response(self):\n        \"\"\"Detailed health check response\"\"\"\n        status_code = 200 if health_info['healthy'] else 503\n        response = {\n            'status': 'healthy' if status_code == 200 else 'unhealthy',\n            'timestamp': datetime.now().isoformat(),\n            'k8s_available': health_info['k8s_available'],\n            'prometheus_available': health_info['prometheus_available'],\n            'last_update': health_info['last_update'].isoformat()\n        }\n        \n        if health_info['errors']:\n            response['recent_errors'] = health_info['errors'][-5:]\n            \n        self.send_response(status_code)\n        self.send_header('Content-Type', 'application/json')\n        self.end_headers()\n        import json\n        self.wfile.write(json.dumps(response).encode())\n    \n    def send_healthz_response(self):\n        \"\"\"Simple health check for k8s\"\"\"\n        if health_info['healthy']:\n            self.send_response(200)\n            self.end_headers()\n            self.wfile.write(b'OK')\n        else:\n            self.send_response(503)\n            self.end_headers()\n            self.wfile.write(b'Unhealthy')\n    \n    def send_ready_response(self):\n        \"\"\"Readiness check\"\"\"\n        now = datetime.now()\n        if (now - health_info['last_update'] \u003c timedelta(minutes=2) and \n            health_info['k8s_available'] and health_info['prometheus_available']):\n            self.send_response(200)\n            self.end_headers()\n            self.wfile.write(b'Ready')\n        else:\n            self.send_response(503)\n            self.end_headers()\n            self.wfile.write(b'Not Ready')\n    \n    def log_message(self, format, *args):\n        # Suppress access logs\n        pass\n\ndef run_health_server():\n    \"\"\"Run the health check HTTP server\"\"\"\n    server = HTTPServer(('', 8080), HealthCheckHandler)\n    server.serve_forever()\n\nclass K8sPodAnomalyDetector:\n    def __init__(self):\n        self.models = {}\n        self.scalers = {}\n        self.thresholds = {}\n        self.k8s_client = None\n        os.makedirs(MODEL_PATH, exist_ok=True)\n        \n        # Initialize Kubernetes client\n        try:\n            config.load_incluster_config()\n            self.k8s_client = client.CoreV1Api()\n            health_info['k8s_available'] = True\n            logger.info(\"Kubernetes client initialized successfully\")\n        except Exception as e:\n            logger.error(f\"Failed to initialize Kubernetes client: {e}\")\n            health_info['k8s_available'] = False\n            health_info['errors'].append(f\"K8s init error: {str(e)}\")\n            \n        self.load_models()\n        \n    def load_models(self):\n        \"\"\"Load saved models from disk\"\"\"\n        for metric in POD_METRICS:\n            model_file = os.path.join(MODEL_PATH, f\"k8s_{metric['name'].replace('/', '_')}.pkl\")\n            if os.path.exists(model_file):\n                try:\n                    with open(model_file, 'rb') as f:\n                        data = pickle.load(f)\n                        self.models[metric['name']] = data['model']\n                        self.scalers[metric['name']] = data.get('scaler')\n                        self.thresholds[metric['name']] = data.get('thresholds', {})\n                        logger.info(f\"Loaded K8s model for {metric['name']}\")\n                except Exception as e:\n                    logger.error(f\"Failed to load K8s model for {metric['name']}: {e}\")\n                    \n    def save_model(self, metric_name):\n        \"\"\"Save model to disk\"\"\"\n        if metric_name in self.models:\n            model_file = os.path.join(MODEL_PATH, f\"k8s_{metric_name.replace('/', '_')}.pkl\")\n            try:\n                with open(model_file, 'wb') as f:\n                    pickle.dump({\n                        'model': self.models[metric_name],\n                        'scaler': self.scalers.get(metric_name),\n                        'thresholds': self.thresholds.get(metric_name, {})\n                    }, f)\n                logger.info(f\"Saved K8s model for {metric_name}\")\n            except Exception as e:\n                logger.error(f\"Failed to save K8s model for {metric_name}: {e}\")\n                \n    def query_prometheus(self, query, start_time=None, end_time=None, step='60s'):\n        \"\"\"Query Prometheus for metric data\"\"\"\n        if not start_time:\n            end_time = datetime.now()\n            start_time = end_time - timedelta(days=7)\n            \n        params = {\n            'query': query,\n            'start': start_time.timestamp(),\n            'end': end_time.timestamp(),\n            'step': step\n        }\n        \n        try:\n            response = requests.get(f\"{PROMETHEUS_URL}/api/v1/query_range\", params=params, timeout=30)\n            response.raise_for_status()\n            data = response.json()\n            \n            health_info['prometheus_available'] = True\n            \n            if data['status'] == 'success' and data['data']['result']:\n                # Process multiple time series\n                all_data = []\n                for result in data['data']['result']:\n                    for timestamp, value in result['values']:\n                        row = {'timestamp': float(timestamp), 'value': float(value)}\n                        # Add labels as additional features\n                        for label, label_value in result['metric'].items():\n                            if label not in ['__name__', 'instance', 'job']:\n                                row[label] = label_value\n                        all_data.append(row)\n                \n                if all_data:\n                    return pd.DataFrame(all_data)\n                    \n        except Exception as e:\n            logger.error(f\"Failed to query Prometheus: {e}\")\n            health_info['prometheus_available'] = False\n            health_info['errors'].append(f\"Prometheus error: {str(e)}\")\n            detection_errors.labels(metric_type=query).inc()\n            \n        return pd.DataFrame()\n        \n    def query_instant(self, query):\n        \"\"\"Query Prometheus for instant values\"\"\"\n        try:\n            response = requests.get(f\"{PROMETHEUS_URL}/api/v1/query\", params={'query': query}, timeout=10)\n            response.raise_for_status()\n            data = response.json()\n            \n            health_info['prometheus_available'] = True\n            \n            if data['status'] == 'success' and data['data']['result']:\n                results = []\n                for result in data['data']['result']:\n                    row = {\n                        'value': float(result['value'][1]),\n                        'labels': result['metric']\n                    }\n                    results.append(row)\n                return results\n                \n        except Exception as e:\n            logger.error(f\"Failed to query instant value: {e}\")\n            health_info['prometheus_available'] = False\n            \n        return []\n        \n    def get_pod_info(self):\n        \"\"\"Get current pod information from K8s API\"\"\"\n        if not self.k8s_client:\n            return []\n            \n        try:\n            pods = self.k8s_client.list_pod_for_all_namespaces()\n            pod_info = []\n            \n            for pod in pods.items:\n                info = {\n                    'name': pod.metadata.name,\n                    'namespace': pod.metadata.namespace,\n                    'phase': pod.status.phase,\n                    'creation_time': pod.metadata.creation_timestamp,\n                    'restart_count': sum([container.restart_count or 0 \n                                        for container in pod.status.container_statuses or []]),\n                    'ready': all([condition.status == \"True\" \n                                for condition in pod.status.conditions or [] \n                                if condition.type == \"Ready\"])\n                }\n                pod_info.append(info)\n                \n            health_info['k8s_available'] = True\n            return pod_info\n            \n        except Exception as e:\n            logger.error(f\"Failed to get pod info: {e}\")\n            health_info['k8s_available'] = False\n            health_info['errors'].append(f\"K8s API error: {str(e)}\")\n            return []\n        \n    def train_isolation_forest(self, metric_config, data):\n        \"\"\"Train Isolation Forest model for K8s metrics\"\"\"\n        if len(data) \u003c metric_config['min_samples']:\n            logger.warning(f\"Insufficient data for K8s {metric_config['name']}: {len(data)} samples\")\n            return None, None\n            \n        # Prepare features - include pod metadata\n        feature_cols = ['value']\n        if 'namespace' in data.columns:\n            # Convert categorical to numeric\n            data['namespace_hash'] = pd.Categorical(data['namespace']).codes\n            feature_cols.append('namespace_hash')\n        if 'pod' in data.columns:\n            data['pod_hash'] = pd.Categorical(data['pod']).codes\n            feature_cols.append('pod_hash')\n            \n        # Add time-based features\n        data['hour'] = pd.to_datetime(data['timestamp'], unit='s').dt.hour\n        data['dayofweek'] = pd.to_datetime(data['timestamp'], unit='s').dt.dayofweek\n        feature_cols.extend(['hour', 'dayofweek'])\n        \n        X = data[feature_cols].values\n        \n        # Scale features\n        scaler = StandardScaler()\n        X_scaled = scaler.fit_transform(X)\n        \n        # Train model\n        model = IsolationForest(\n            contamination=metric_config['sensitivity'],\n            random_state=42,\n            n_estimators=100\n        )\n        \n        with model_training_duration.time():\n            model.fit(X_scaled)\n            \n        model_updates.labels(metric_type=metric_config['name']).inc()\n        \n        return model, scaler\n        \n    def train_statistical_model(self, metric_config, data):\n        \"\"\"Train statistical anomaly detection model\"\"\"\n        if len(data) \u003c metric_config['min_samples']:\n            logger.warning(f\"Insufficient data for K8s {metric_config['name']}: {len(data)} samples\")\n            return None\n            \n        values = data['value'].values\n        \n        # Calculate statistics per pod/namespace if available\n        thresholds = {\n            'global': {\n                'mean': np.mean(values),\n                'std': np.std(values),\n                'p99': np.percentile(values, 99),\n                'p95': np.percentile(values, 95),\n                'p05': np.percentile(values, 5),\n                'p01': np.percentile(values, 1)\n            }\n        }\n        \n        # Per-namespace thresholds if namespace data available\n        if 'namespace' in data.columns:\n            thresholds['per_namespace'] = {}\n            for ns in data['namespace'].unique():\n                ns_data = data[data['namespace'] == ns]['value'].values\n                if len(ns_data) \u003e= 10:  # Minimum samples per namespace\n                    thresholds['per_namespace'][ns] = {\n                        'mean': np.mean(ns_data),\n                        'std': np.std(ns_data),\n                        'p95': np.percentile(ns_data, 95)\n                    }\n        \n        model_updates.labels(metric_type=metric_config['name']).inc()\n        \n        return thresholds\n        \n    def detect_pod_anomalies(self, metric_config):\n        \"\"\"Detect anomalies for K8s pod metrics\"\"\"\n        try:\n            # Query current values\n            current_results = self.query_instant(metric_config['query'])\n            \n            if not current_results:\n                logger.debug(f\"No data for K8s {metric_config['name']}\")\n                return\n                \n            for result in current_results:\n                current_value = result['value']\n                labels = result['labels']\n                \n                # Extract pod and namespace from labels\n                namespace = labels.get('namespace', 'unknown')\n                pod = labels.get('pod', labels.get('container', 'unknown'))\n                \n                metrics_processed.labels(metric_type=metric_config['name']).inc()\n                \n                if metric_config['algorithm'] == 'isolation_forest':\n                    if metric_config['name'] in self.models:\n                        model = self.models[metric_config['name']]\n                        scaler = self.scalers[metric_config['name']]\n                        \n                        # Prepare features\n                        now = datetime.now()\n                        hour = now.hour\n                        dayofweek = now.weekday()\n                        \n                        # Create feature vector matching training\n                        features = [current_value, hour, dayofweek]\n                        # Add namespace/pod hashes if model was trained with them\n                        X = np.array([features])\n                        X_scaled = scaler.transform(X)\n                        \n                        # Get anomaly score\n                        score = model.decision_function(X_scaled)[0]\n                        normalized_score = 50 + (score * 50)\n                        normalized_score = max(0, min(100, normalized_score))\n                        \n                        pod_anomaly_score.labels(\n                            namespace=namespace,\n                            pod=pod,\n                            metric_type=metric_config['name'],\n                            algorithm='isolation_forest'\n                        ).set(100 - normalized_score)\n                        \n                        logger.debug(f\"K8s {metric_config['name']} [{namespace}/{pod}]: value={current_value}, score={100-normalized_score}\")\n                        \n                elif metric_config['algorithm'] == 'statistical':\n                    if metric_config['name'] in self.thresholds:\n                        thresholds = self.thresholds[metric_config['name']]\n                        \n                        # Use namespace-specific thresholds if available\n                        threshold_data = thresholds['global']\n                        if ('per_namespace' in thresholds and \n                            namespace in thresholds['per_namespace']):\n                            threshold_data = thresholds['per_namespace'][namespace]\n                        \n                        # Calculate z-score\n                        z_score = abs((current_value - threshold_data['mean']) / (threshold_data['std'] + 1e-10))\n                        \n                        # Convert to 0-100 scale\n                        score = min(100, (z_score / metric_config['z_threshold']) * 100)\n                        \n                        pod_anomaly_score.labels(\n                            namespace=namespace,\n                            pod=pod,\n                            metric_type=metric_config['name'],\n                            algorithm='statistical'\n                        ).set(score)\n                        \n                        logger.debug(f\"K8s {metric_config['name']} [{namespace}/{pod}]: value={current_value}, z-score={z_score}, score={score}\")\n                    \n        except Exception as e:\n            logger.error(f\"Error detecting K8s anomalies for {metric_config['name']}: {e}\")\n            detection_errors.labels(metric_type=metric_config['name']).inc()\n            \n    def update_models(self):\n        \"\"\"Update all K8s anomaly detection models\"\"\"\n        logger.info(\"Updating K8s anomaly detection models...\")\n        \n        for metric_config in POD_METRICS:\n            try:\n                # Query training data\n                training_data = self.query_prometheus(metric_config['query'])\n                \n                if training_data.empty:\n                    logger.warning(f\"No training data for K8s {metric_config['name']}\")\n                    continue\n                    \n                if metric_config['algorithm'] == 'isolation_forest':\n                    model, scaler = self.train_isolation_forest(metric_config, training_data)\n                    if model:\n                        self.models[metric_config['name']] = model\n                        self.scalers[metric_config['name']] = scaler\n                        self.save_model(metric_config['name'])\n                        \n                elif metric_config['algorithm'] == 'statistical':\n                    thresholds = self.train_statistical_model(metric_config, training_data)\n                    if thresholds:\n                        self.thresholds[metric_config['name']] = thresholds\n                        self.save_model(metric_config['name'])\n                        \n                logger.info(f\"Updated K8s model for {metric_config['name']}\")\n                \n            except Exception as e:\n                logger.error(f\"Failed to update K8s model for {metric_config['name']}: {e}\")\n                health_info['errors'].append(f\"Model update error: {str(e)}\")\n                \n    def run(self):\n        \"\"\"Main K8s anomaly detection loop\"\"\"\n        # Initial model training\n        self.update_models()\n        \n        last_model_update = time.time()\n        \n        while True:\n            try:\n                # Detect anomalies for all metrics\n                for metric_config in POD_METRICS:\n                    self.detect_pod_anomalies(metric_config)\n                    \n                # Update models periodically (every 6 hours)\n                if time.time() - last_model_update \u003e 21600:\n                    self.update_models()\n                    last_model_update = time.time()\n                    \n                # Update health status\n                health_info['healthy'] = (health_info['k8s_available'] and \n                                        health_info['prometheus_available'])\n                health_info['last_update'] = datetime.now()\n                health_status.set(1 if health_info['healthy'] else 0)\n                \n                time.sleep(UPDATE_INTERVAL)\n                \n            except Exception as e:\n                logger.error(f\"Error in K8s anomaly detection loop: {e}\")\n                health_info['healthy'] = False\n                health_info['errors'].append(f\"Main loop error: {str(e)}\")\n                health_status.set(0)\n                time.sleep(60)\n\ndef main():\n    # Start Prometheus metrics server\n    start_http_server(9406)\n    logger.info(\"Started K8s anomaly detection metrics server on port 9406\")\n    \n    # Start health check server in a separate thread\n    health_thread = threading.Thread(target=run_health_server, daemon=True)\n    health_thread.start()\n    logger.info(\"Started health check server on port 8080\")\n    \n    # Start K8s anomaly detector\n    detector = K8sPodAnomalyDetector()\n    detector.run()\n\nif __name__ == '__main__':\n    main()\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"k8s-pod-anomaly-detector-script","namespace":"monitoring"}}
    creationTimestamp: "2025-05-31T17:10:36Z"
    name: k8s-pod-anomaly-detector-script
    namespace: monitoring
    resourceVersion: "591400"
    uid: a4c4b777-1f93-4443-81e0-cf6e2d386d44
- apiVersion: v1
  data:
    ca.crt: |
      -----BEGIN CERTIFICATE-----
      MIIBdjCCAR2gAwIBAgIBADAKBggqhkjOPQQDAjAjMSEwHwYDVQQDDBhrM3Mtc2Vy
      dmVyLWNhQDE3NDgzODI5NjQwHhcNMjUwNTI3MjE1NjA0WhcNMzUwNTI1MjE1NjA0
      WjAjMSEwHwYDVQQDDBhrM3Mtc2VydmVyLWNhQDE3NDgzODI5NjQwWTATBgcqhkjO
      PQIBBggqhkjOPQMBBwNCAARW9rVvdGQQ7C3/6sEHoDuFx1x4thsXWzBvK6QqPiwC
      yLfiO7ySDAbJHieZcLEc1wqhvnWaJZd43+bFNWf8B/pzo0IwQDAOBgNVHQ8BAf8E
      BAMCAqQwDwYDVR0TAQH/BAUwAwEB/zAdBgNVHQ4EFgQU4pMcl/5+3lJs2IImuGnF
      CSpsyHYwCgYIKoZIzj0EAwIDRwAwRAIgUyrdIBpDBGnVGSBWGHcNtJNdEFtMlXc3
      e2XgEgo38i8CIAkdaSwLV22Knbnf4YWCiakj3OAvwK9+8dgnLu32cGFk
      -----END CERTIFICATE-----
  kind: ConfigMap
  metadata:
    annotations:
      kubernetes.io/description: Contains a CA bundle that can be used to verify the
        kube-apiserver when using internal endpoints such as the internal service
        IP or kubernetes.default.svc. No other usage is guaranteed across distributions
        of Kubernetes clusters.
    creationTimestamp: "2025-05-27T21:58:11Z"
    name: kube-root-ca.crt
    namespace: monitoring
    resourceVersion: "518"
    uid: 09aafa7b-bf34-46fe-a745-55a6bab9e1b9
- apiVersion: v1
  data:
    performance-logs.json: |
      {
        "id": null,
        "uid": "performance-logs",
        "title": "Performance & Resource Logs",
        "tags": ["logs", "performance", "resources"],
        "timezone": "browser",
        "schemaVersion": 30,
        "version": 1,
        "refresh": "30s",
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "panels": [
            {
              "id": 1,
              "gridPos": {"h": 8, "w": 24, "x": 0, "y": 0},
              "type": "logs",
              "title": "OOM Killer Events",
              "targets": [
                {
                  "expr": "{} |~ \"memory\"",
                  "legendFormat": "",
                  "refId": "A"
                }
              ],
              "options": {
                "showTime": true,
                "showLabels": false,
                "showCommonLabels": false,
                "wrapLogMessage": true,
                "prettifyLogMessage": false,
                "enableLogDetails": true,
                "sortOrder": "Descending",
                "dedupStrategy": "none"
              }
            },
            {
              "id": 2,
              "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8},
              "type": "logs",
              "title": "CPU Throttling Events",
              "targets": [
                {
                  "expr": "{} |~ \"thermal\"",
                  "legendFormat": "",
                  "refId": "A"
                }
              ],
              "options": {
                "showTime": true,
                "showLabels": false,
                "showCommonLabels": false,
                "wrapLogMessage": true,
                "prettifyLogMessage": false,
                "enableLogDetails": true,
                "sortOrder": "Descending",
                "dedupStrategy": "none"
              }
            },
            {
              "id": 3,
              "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8},
              "type": "logs",
              "title": "Disk I/O Errors",
              "targets": [
                {
                  "expr": "{} |~ \"disk|filesystem\"",
                  "legendFormat": "",
                  "refId": "A"
                }
              ],
              "options": {
                "showTime": true,
                "showLabels": false,
                "showCommonLabels": false,
                "wrapLogMessage": true,
                "prettifyLogMessage": false,
                "enableLogDetails": true,
                "sortOrder": "Descending",
                "dedupStrategy": "none"
              }
            },
            {
              "id": 4,
              "gridPos": {"h": 8, "w": 24, "x": 0, "y": 16},
              "type": "logs",
              "title": "Process Start/Stop Events",
              "targets": [
                {
                  "expr": "{}",
                  "legendFormat": "",
                  "refId": "A"
                }
              ],
              "options": {
                "showTime": true,
                "showLabels": false,
                "showCommonLabels": false,
                "wrapLogMessage": true,
                "prettifyLogMessage": false,
                "enableLogDetails": true,
                "sortOrder": "Descending",
                "dedupStrategy": "none"
              }
            }
          ]
      }
    system-logs-analysis.json: |
      {
        "id": null,
        "uid": "system-logs-analysis",
        "title": "System Logs Analysis",
        "tags": ["logs", "loki", "system"],
        "timezone": "browser",
        "schemaVersion": 30,
        "version": 1,
        "refresh": "30s",
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "panels": [
            {
              "id": 1,
              "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0},
              "type": "logs",
              "title": "Kernel Messages",
              "targets": [
                {
                  "expr": "{} |= \"kernel\"",
                  "legendFormat": "",
                  "refId": "A"
                }
              ],
              "options": {
                "showTime": true,
                "showLabels": false,
                "showCommonLabels": false,
                "wrapLogMessage": true,
                "prettifyLogMessage": false,
                "enableLogDetails": true,
                "sortOrder": "Descending",
                "dedupStrategy": "none"
              }
            },
            {
              "id": 2,
              "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0},
              "type": "logs",
              "title": "System Errors",
              "targets": [
                {
                  "expr": "{} |~ \"error|fail\"",
                  "legendFormat": "",
                  "refId": "A"
                }
              ],
              "options": {
                "showTime": true,
                "showLabels": true,
                "showCommonLabels": false,
                "wrapLogMessage": true,
                "prettifyLogMessage": false,
                "enableLogDetails": true,
                "sortOrder": "Descending",
                "dedupStrategy": "none"
              }
            },
            {
              "id": 3,
              "gridPos": {"h": 6, "w": 24, "x": 0, "y": 8},
              "type": "graph",
              "title": "Log Volume by Level",
              "targets": [
                {
                  "expr": "count_over_time({} |~ \"error\" [5m])",
                  "legendFormat": "Errors",
                  "refId": "A"
                }
              ],
              "fieldConfig": {
                "defaults": {
                  "unit": "logs/s",
                  "color": {"mode": "palette-classic"},
                  "custom": {
                    "lineInterpolation": "smooth",
                    "lineWidth": 2,
                    "fillOpacity": 10,
                    "showPoints": "never"
                  }
                }
              }
            },
            {
              "id": 4,
              "gridPos": {"h": 8, "w": 12, "x": 0, "y": 14},
              "type": "logs",
              "title": "Authentication Events",
              "targets": [
                {
                  "expr": "{} |~ \"auth|login\"",
                  "legendFormat": "",
                  "refId": "A"
                }
              ],
              "options": {
                "showTime": true,
                "showLabels": false,
                "showCommonLabels": false,
                "wrapLogMessage": true,
                "prettifyLogMessage": false,
                "enableLogDetails": true,
                "sortOrder": "Descending",
                "dedupStrategy": "none"
              }
            },
            {
              "id": 5,
              "gridPos": {"h": 8, "w": 12, "x": 12, "y": 14},
              "type": "table",
              "title": "Top Error Sources",
              "targets": [
                {
                  "expr": "{}",
                  "format": "table",
                  "instant": true,
                  "refId": "A"
                }
              ],
              "fieldConfig": {
                "defaults": {
                  "custom": {
                    "align": "auto",
                    "displayMode": "auto"
                  }
                },
                "overrides": [
                  {
                    "matcher": {"id": "byName", "options": "unit"},
                    "properties": [
                      {"id": "displayName", "value": "Service/Unit"},
                      {"id": "custom.width", "value": 200}
                    ]
                  },
                  {
                    "matcher": {"id": "byName", "options": "Value"},
                    "properties": [
                      {"id": "displayName", "value": "Errors/sec"},
                      {"id": "unit", "value": "ops"},
                      {"id": "decimals", "value": 3}
                    ]
                  }
                ]
              }
            },
            {
              "id": 6,
              "gridPos": {"h": 8, "w": 24, "x": 0, "y": 22},
              "type": "logs",
              "title": "Hardware Events",
              "targets": [
                {
                  "expr": "{} |~ \"nvidia|gpu\"",
                  "legendFormat": "",
                  "refId": "A"
                }
              ],
              "options": {
                "showTime": true,
                "showLabels": false,
                "showCommonLabels": false,
                "wrapLogMessage": true,
                "prettifyLogMessage": false,
                "enableLogDetails": true,
                "sortOrder": "Descending",
                "dedupStrategy": "none"
              }
            },
            {
              "id": 7,
              "gridPos": {"h": 8, "w": 12, "x": 0, "y": 30},
              "type": "logs",
              "title": "Network Events",
              "targets": [
                {
                  "expr": "{} |~ \"network\"",
                  "legendFormat": "",
                  "refId": "A"
                }
              ],
              "options": {
                "showTime": true,
                "showLabels": false,
                "showCommonLabels": false,
                "wrapLogMessage": true,
                "prettifyLogMessage": false,
                "enableLogDetails": true,
                "sortOrder": "Descending",
                "dedupStrategy": "none"
              }
            },
            {
              "id": 8,
              "gridPos": {"h": 8, "w": 12, "x": 12, "y": 30},
              "type": "logs",
              "title": "Application Crashes",
              "targets": [
                {
                  "expr": "{} |~ \"error\"",
                  "legendFormat": "",
                  "refId": "A"
                }
              ],
              "options": {
                "showTime": true,
                "showLabels": true,
                "showCommonLabels": false,
                "wrapLogMessage": true,
                "prettifyLogMessage": false,
                "enableLogDetails": true,
                "sortOrder": "Descending",
                "dedupStrategy": "none"
              }
            }
          ]
      }
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"performance-logs.json":"{\n  \"id\": null,\n  \"uid\": \"performance-logs\",\n  \"title\": \"Performance \u0026 Resource Logs\",\n  \"tags\": [\"logs\", \"performance\", \"resources\"],\n  \"timezone\": \"browser\",\n  \"schemaVersion\": 30,\n  \"version\": 1,\n  \"refresh\": \"30s\",\n  \"time\": {\n    \"from\": \"now-1h\",\n    \"to\": \"now\"\n  },\n  \"panels\": [\n      {\n        \"id\": 1,\n        \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 0},\n        \"type\": \"logs\",\n        \"title\": \"OOM Killer Events\",\n        \"targets\": [\n          {\n            \"expr\": \"{} |~ \\\"memory\\\"\",\n            \"legendFormat\": \"\",\n            \"refId\": \"A\"\n          }\n        ],\n        \"options\": {\n          \"showTime\": true,\n          \"showLabels\": false,\n          \"showCommonLabels\": false,\n          \"wrapLogMessage\": true,\n          \"prettifyLogMessage\": false,\n          \"enableLogDetails\": true,\n          \"sortOrder\": \"Descending\",\n          \"dedupStrategy\": \"none\"\n        }\n      },\n      {\n        \"id\": 2,\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 8},\n        \"type\": \"logs\",\n        \"title\": \"CPU Throttling Events\",\n        \"targets\": [\n          {\n            \"expr\": \"{} |~ \\\"thermal\\\"\",\n            \"legendFormat\": \"\",\n            \"refId\": \"A\"\n          }\n        ],\n        \"options\": {\n          \"showTime\": true,\n          \"showLabels\": false,\n          \"showCommonLabels\": false,\n          \"wrapLogMessage\": true,\n          \"prettifyLogMessage\": false,\n          \"enableLogDetails\": true,\n          \"sortOrder\": \"Descending\",\n          \"dedupStrategy\": \"none\"\n        }\n      },\n      {\n        \"id\": 3,\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 8},\n        \"type\": \"logs\",\n        \"title\": \"Disk I/O Errors\",\n        \"targets\": [\n          {\n            \"expr\": \"{} |~ \\\"disk|filesystem\\\"\",\n            \"legendFormat\": \"\",\n            \"refId\": \"A\"\n          }\n        ],\n        \"options\": {\n          \"showTime\": true,\n          \"showLabels\": false,\n          \"showCommonLabels\": false,\n          \"wrapLogMessage\": true,\n          \"prettifyLogMessage\": false,\n          \"enableLogDetails\": true,\n          \"sortOrder\": \"Descending\",\n          \"dedupStrategy\": \"none\"\n        }\n      },\n      {\n        \"id\": 4,\n        \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 16},\n        \"type\": \"logs\",\n        \"title\": \"Process Start/Stop Events\",\n        \"targets\": [\n          {\n            \"expr\": \"{}\",\n            \"legendFormat\": \"\",\n            \"refId\": \"A\"\n          }\n        ],\n        \"options\": {\n          \"showTime\": true,\n          \"showLabels\": false,\n          \"showCommonLabels\": false,\n          \"wrapLogMessage\": true,\n          \"prettifyLogMessage\": false,\n          \"enableLogDetails\": true,\n          \"sortOrder\": \"Descending\",\n          \"dedupStrategy\": \"none\"\n        }\n      }\n    ]\n}\n","system-logs-analysis.json":"{\n  \"id\": null,\n  \"uid\": \"system-logs-analysis\",\n  \"title\": \"System Logs Analysis\",\n  \"tags\": [\"logs\", \"loki\", \"system\"],\n  \"timezone\": \"browser\",\n  \"schemaVersion\": 30,\n  \"version\": 1,\n  \"refresh\": \"30s\",\n  \"time\": {\n    \"from\": \"now-1h\",\n    \"to\": \"now\"\n  },\n  \"panels\": [\n      {\n        \"id\": 1,\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 0},\n        \"type\": \"logs\",\n        \"title\": \"Kernel Messages\",\n        \"targets\": [\n          {\n            \"expr\": \"{} |= \\\"kernel\\\"\",\n            \"legendFormat\": \"\",\n            \"refId\": \"A\"\n          }\n        ],\n        \"options\": {\n          \"showTime\": true,\n          \"showLabels\": false,\n          \"showCommonLabels\": false,\n          \"wrapLogMessage\": true,\n          \"prettifyLogMessage\": false,\n          \"enableLogDetails\": true,\n          \"sortOrder\": \"Descending\",\n          \"dedupStrategy\": \"none\"\n        }\n      },\n      {\n        \"id\": 2,\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 0},\n        \"type\": \"logs\",\n        \"title\": \"System Errors\",\n        \"targets\": [\n          {\n            \"expr\": \"{} |~ \\\"error|fail\\\"\",\n            \"legendFormat\": \"\",\n            \"refId\": \"A\"\n          }\n        ],\n        \"options\": {\n          \"showTime\": true,\n          \"showLabels\": true,\n          \"showCommonLabels\": false,\n          \"wrapLogMessage\": true,\n          \"prettifyLogMessage\": false,\n          \"enableLogDetails\": true,\n          \"sortOrder\": \"Descending\",\n          \"dedupStrategy\": \"none\"\n        }\n      },\n      {\n        \"id\": 3,\n        \"gridPos\": {\"h\": 6, \"w\": 24, \"x\": 0, \"y\": 8},\n        \"type\": \"graph\",\n        \"title\": \"Log Volume by Level\",\n        \"targets\": [\n          {\n            \"expr\": \"count_over_time({} |~ \\\"error\\\" [5m])\",\n            \"legendFormat\": \"Errors\",\n            \"refId\": \"A\"\n          }\n        ],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"unit\": \"logs/s\",\n            \"color\": {\"mode\": \"palette-classic\"},\n            \"custom\": {\n              \"lineInterpolation\": \"smooth\",\n              \"lineWidth\": 2,\n              \"fillOpacity\": 10,\n              \"showPoints\": \"never\"\n            }\n          }\n        }\n      },\n      {\n        \"id\": 4,\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 14},\n        \"type\": \"logs\",\n        \"title\": \"Authentication Events\",\n        \"targets\": [\n          {\n            \"expr\": \"{} |~ \\\"auth|login\\\"\",\n            \"legendFormat\": \"\",\n            \"refId\": \"A\"\n          }\n        ],\n        \"options\": {\n          \"showTime\": true,\n          \"showLabels\": false,\n          \"showCommonLabels\": false,\n          \"wrapLogMessage\": true,\n          \"prettifyLogMessage\": false,\n          \"enableLogDetails\": true,\n          \"sortOrder\": \"Descending\",\n          \"dedupStrategy\": \"none\"\n        }\n      },\n      {\n        \"id\": 5,\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 14},\n        \"type\": \"table\",\n        \"title\": \"Top Error Sources\",\n        \"targets\": [\n          {\n            \"expr\": \"{}\",\n            \"format\": \"table\",\n            \"instant\": true,\n            \"refId\": \"A\"\n          }\n        ],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"custom\": {\n              \"align\": \"auto\",\n              \"displayMode\": \"auto\"\n            }\n          },\n          \"overrides\": [\n            {\n              \"matcher\": {\"id\": \"byName\", \"options\": \"unit\"},\n              \"properties\": [\n                {\"id\": \"displayName\", \"value\": \"Service/Unit\"},\n                {\"id\": \"custom.width\", \"value\": 200}\n              ]\n            },\n            {\n              \"matcher\": {\"id\": \"byName\", \"options\": \"Value\"},\n              \"properties\": [\n                {\"id\": \"displayName\", \"value\": \"Errors/sec\"},\n                {\"id\": \"unit\", \"value\": \"ops\"},\n                {\"id\": \"decimals\", \"value\": 3}\n              ]\n            }\n          ]\n        }\n      },\n      {\n        \"id\": 6,\n        \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 22},\n        \"type\": \"logs\",\n        \"title\": \"Hardware Events\",\n        \"targets\": [\n          {\n            \"expr\": \"{} |~ \\\"nvidia|gpu\\\"\",\n            \"legendFormat\": \"\",\n            \"refId\": \"A\"\n          }\n        ],\n        \"options\": {\n          \"showTime\": true,\n          \"showLabels\": false,\n          \"showCommonLabels\": false,\n          \"wrapLogMessage\": true,\n          \"prettifyLogMessage\": false,\n          \"enableLogDetails\": true,\n          \"sortOrder\": \"Descending\",\n          \"dedupStrategy\": \"none\"\n        }\n      },\n      {\n        \"id\": 7,\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 30},\n        \"type\": \"logs\",\n        \"title\": \"Network Events\",\n        \"targets\": [\n          {\n            \"expr\": \"{} |~ \\\"network\\\"\",\n            \"legendFormat\": \"\",\n            \"refId\": \"A\"\n          }\n        ],\n        \"options\": {\n          \"showTime\": true,\n          \"showLabels\": false,\n          \"showCommonLabels\": false,\n          \"wrapLogMessage\": true,\n          \"prettifyLogMessage\": false,\n          \"enableLogDetails\": true,\n          \"sortOrder\": \"Descending\",\n          \"dedupStrategy\": \"none\"\n        }\n      },\n      {\n        \"id\": 8,\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 30},\n        \"type\": \"logs\",\n        \"title\": \"Application Crashes\",\n        \"targets\": [\n          {\n            \"expr\": \"{} |~ \\\"error\\\"\",\n            \"legendFormat\": \"\",\n            \"refId\": \"A\"\n          }\n        ],\n        \"options\": {\n          \"showTime\": true,\n          \"showLabels\": true,\n          \"showCommonLabels\": false,\n          \"wrapLogMessage\": true,\n          \"prettifyLogMessage\": false,\n          \"enableLogDetails\": true,\n          \"sortOrder\": \"Descending\",\n          \"dedupStrategy\": \"none\"\n        }\n      }\n    ]\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"loki-analysis-dashboards","namespace":"monitoring"}}
    creationTimestamp: "2025-05-27T23:38:02Z"
    name: loki-analysis-dashboards
    namespace: monitoring
    resourceVersion: "10774"
    uid: 37add0e3-5fcf-4dc5-b2a9-6a3a14489d1a
- apiVersion: v1
  data:
    loki.yaml: |
      auth_enabled: false

      server:
        http_listen_port: 3100

      common:
        path_prefix: /tmp/loki
        storage:
          filesystem:
            chunks_directory: /tmp/loki/chunks
            rules_directory: /tmp/loki/rules
        replication_factor: 1
        ring:
          instance_addr: 127.0.0.1
          kvstore:
            store: inmemory

      ingester:
        wal:
          enabled: false
        lifecycler:
          address: 127.0.0.1
          ring:
            kvstore:
              store: inmemory
            replication_factor: 1
          final_sleep: 0s
        chunk_idle_period: 5m
        chunk_retain_period: 30s
        max_transfer_retries: 0

      schema_config:
        configs:
          - from: 2020-10-24
            store: boltdb-shipper
            object_store: filesystem
            schema: v11
            index:
              prefix: index_
              period: 24h

      storage_config:
        boltdb_shipper:
          active_index_directory: /tmp/loki/index
          shared_store: filesystem
          cache_location: /tmp/loki/index_cache
        filesystem:
          directory: /tmp/loki/chunks

      limits_config:
        enforce_metric_name: false
        retention_period: 720h  # 30 days retention (extended)
        max_query_length: 720h  # 30 days max query range
        max_query_series: 100000
        max_query_parallelism: 32
        max_streams_per_user: 0  # unlimited streams
        max_line_size: 256000    # 256KB max line size
        max_entries_limit_per_query: 5000
        max_global_streams_per_user: 5000
        ingestion_rate_mb: 6     # Increased to 6MB/s
        ingestion_burst_size_mb: 10 # Increased burst size
        split_queries_by_interval: 15m

      # Enhanced compactor for better performance
      compactor:
        working_directory: /tmp/loki/compactor
        shared_store: filesystem
        compaction_interval: 5m  # More frequent compaction
        retention_enabled: true
        retention_delete_delay: 1h  # Faster cleanup
        retention_delete_worker_count: 200  # More workers

      # Table manager for index cleanup
      table_manager:
        retention_deletes_enabled: true
        retention_period: 720h  # 30 days

      # Query scheduler for better performance
      query_scheduler:
        max_outstanding_requests_per_tenant: 512  # Increased capacity

      frontend:
        max_outstanding_per_tenant: 512

      query_range:
        align_queries_with_step: true
        max_retries: 5
        cache_results: true
        results_cache:
          cache:
            embedded_cache:
              enabled: true
              max_size_mb: 200  # Increased cache

      ruler:
        storage:
          type: local
          local:
            directory: /tmp/loki/rules
        rule_path: /tmp/loki/rules-temp
        alertmanager_url: http://alertmanager.monitoring.svc.cluster.local:9093
        ring:
          kvstore:
            store: inmemory
        enable_api: true
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"loki.yaml":"auth_enabled: false\n\nserver:\n  http_listen_port: 3100\n\ncommon:\n  path_prefix: /tmp/loki\n  storage:\n    filesystem:\n      chunks_directory: /tmp/loki/chunks\n      rules_directory: /tmp/loki/rules\n  replication_factor: 1\n  ring:\n    instance_addr: 127.0.0.1\n    kvstore:\n      store: inmemory\n\ningester:\n  wal:\n    enabled: false\n  lifecycler:\n    address: 127.0.0.1\n    ring:\n      kvstore:\n        store: inmemory\n      replication_factor: 1\n    final_sleep: 0s\n  chunk_idle_period: 5m\n  chunk_retain_period: 30s\n  max_transfer_retries: 0\n\nschema_config:\n  configs:\n    - from: 2020-10-24\n      store: boltdb-shipper\n      object_store: filesystem\n      schema: v11\n      index:\n        prefix: index_\n        period: 24h\n\nstorage_config:\n  boltdb_shipper:\n    active_index_directory: /tmp/loki/index\n    shared_store: filesystem\n    cache_location: /tmp/loki/index_cache\n  filesystem:\n    directory: /tmp/loki/chunks\n\nlimits_config:\n  enforce_metric_name: false\n  retention_period: 168h  # 7 days retention\n  max_query_length: 720h  # 30 days max query range\n  max_query_series: 100000\n  max_query_parallelism: 32\n  max_streams_per_user: 0  # unlimited streams\n  max_line_size: 256000    # 256KB max line size\n  max_entries_limit_per_query: 5000\n  max_global_streams_per_user: 5000\n  ingestion_rate_mb: 4     # 4MB/s ingestion rate limit\n  ingestion_burst_size_mb: 6 # 6MB burst size\n  split_queries_by_interval: 15m  # Split queries for better performance\n\n# Compactor for automated retention\ncompactor:\n  working_directory: /tmp/loki/compactor\n  shared_store: filesystem\n  compaction_interval: 10m\n  retention_enabled: true\n  retention_delete_delay: 2h\n  retention_delete_worker_count: 150\n\n# Table manager for index cleanup\ntable_manager:\n  retention_deletes_enabled: true\n  retention_period: 168h  # 7 days\n\n# Query scheduler for better performance\nquery_scheduler:\n  max_outstanding_requests_per_tenant: 256\n\nfrontend:\n  max_outstanding_per_tenant: 256\n\nquery_range:\n  align_queries_with_step: true\n  max_retries: 5\n  cache_results: true\n  results_cache:\n    cache:\n      embedded_cache:\n        enabled: true\n        max_size_mb: 100\n\nruler:\n  storage:\n    type: local\n    local:\n      directory: /tmp/loki/rules\n  rule_path: /tmp/loki/rules-temp\n  alertmanager_url: http://alertmanager.monitoring.svc.cluster.local:9093\n  ring:\n    kvstore:\n      store: inmemory\n  enable_api: true\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"loki-config","namespace":"monitoring"}}
    creationTimestamp: "2025-05-27T22:22:46Z"
    name: loki-config
    namespace: monitoring
    resourceVersion: "534683"
    uid: fb6fdf2a-7de3-46eb-ae80-a19999978612
- apiVersion: v1
  data:
    ml-anomaly-detection.json: |
      {
        "uid": "ml-anomaly-detection",
        "title": "ODIN ML Anomaly Detection",
        "tags": ["odin", "ml", "anomaly-detection"],
        "timezone": "America/Los_Angeles",
        "refresh": "30s",
        "panels": [
          {
            "gridPos": {"h": 1, "w": 24, "x": 0, "y": 0},
            "id": 1,
            "type": "row",
            "title": "Anomaly Detector Status",
            "collapsed": false
          },
          {
            "gridPos": {"h": 4, "w": 6, "x": 0, "y": 1},
            "id": 2,
            "type": "stat",
            "title": "GPU Anomaly Detector",
            "targets": [
              {
                "expr": "up{job=\"gpu-anomaly-detector\"}",
                "refId": "A"
              }
            ],
            "options": {
              "graphMode": "none",
              "colorMode": "background",
              "reduceOptions": {
                "values": false,
                "calcs": ["lastNotNull"]
              }
            },
            "fieldConfig": {
              "defaults": {
                "mappings": [
                  {"type": "value", "value": 1, "text": "UP", "color": "green"},
                  {"type": "value", "value": 0, "text": "DOWN", "color": "red"}
                ],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"value": 0, "color": "red"},
                    {"value": 1, "color": "green"}
                  ]
                }
              }
            }
          },
          {
            "gridPos": {"h": 4, "w": 6, "x": 6, "y": 1},
            "id": 3,
            "type": "stat",
            "title": "Process Anomaly Detector",
            "targets": [
              {
                "expr": "up{job=\"process-anomaly-detector\"}",
                "refId": "A"
              }
            ],
            "options": {
              "graphMode": "none",
              "colorMode": "background",
              "reduceOptions": {
                "values": false,
                "calcs": ["lastNotNull"]
              }
            },
            "fieldConfig": {
              "defaults": {
                "mappings": [
                  {"type": "value", "value": 1, "text": "UP", "color": "green"},
                  {"type": "value", "value": 0, "text": "DOWN", "color": "red"}
                ],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"value": 0, "color": "red"},
                    {"value": 1, "color": "green"}
                  ]
                }
              }
            }
          },
          {
            "gridPos": {"h": 4, "w": 6, "x": 12, "y": 1},
            "id": 4,
            "type": "stat",
            "title": "K8s Pod Anomaly Detector",
            "targets": [
              {
                "expr": "up{job=\"k8s-pod-anomaly-detector\"}",
                "refId": "A"
              }
            ],
            "options": {
              "graphMode": "none",
              "colorMode": "background",
              "reduceOptions": {
                "values": false,
                "calcs": ["lastNotNull"]
              }
            },
            "fieldConfig": {
              "defaults": {
                "mappings": [
                  {"type": "value", "value": 1, "text": "UP", "color": "green"},
                  {"type": "value", "value": 0, "text": "DOWN", "color": "red"}
                ],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"value": 0, "color": "red"},
                    {"value": 1, "color": "green"}
                  ]
                }
              }
            }
          },
          {
            "gridPos": {"h": 4, "w": 6, "x": 18, "y": 1},
            "id": 5,
            "type": "stat",
            "title": "Disk Anomaly Detector",
            "targets": [
              {
                "expr": "up{job=\"disk-anomaly-detector\"}",
                "refId": "A"
              }
            ],
            "options": {
              "graphMode": "none",
              "colorMode": "background",
              "reduceOptions": {
                "values": false,
                "calcs": ["lastNotNull"]
              }
            },
            "fieldConfig": {
              "defaults": {
                "mappings": [
                  {"type": "value", "value": 1, "text": "UP", "color": "green"},
                  {"type": "value", "value": 0, "text": "DOWN", "color": "red"}
                ],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"value": 0, "color": "red"},
                    {"value": 1, "color": "green"}
                  ]
                }
              }
            }
          },
          {
            "gridPos": {"h": 1, "w": 24, "x": 0, "y": 5},
            "id": 6,
            "type": "row",
            "title": "GPU Anomaly Scores",
            "collapsed": false
          },
          {
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 6},
            "id": 7,
            "type": "timeseries",
            "title": "GPU Temperature Anomaly Score",
            "targets": [
              {
                "expr": "gpu_anomaly_score{metric_name=\"nvidia_gpu_temperature_celsius\"}",
                "legendFormat": "GPU {{gpu}} Temperature",
                "refId": "A"
              }
            ],
            "options": {
              "tooltip": {"mode": "multi"},
              "legend": {"displayMode": "list", "placement": "bottom"}
            },
            "fieldConfig": {
              "defaults": {
                "unit": "percent",
                "min": 0,
                "max": 100,
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"value": 0, "color": "green"},
                    {"value": 50, "color": "yellow"},
                    {"value": 80, "color": "red"}
                  ]
                }
              }
            }
          },
          {
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 6},
            "id": 8,
            "type": "timeseries",
            "title": "GPU Power Anomaly Score",
            "targets": [
              {
                "expr": "gpu_anomaly_score{metric_name=\"node_gpu_power_watts\"}",
                "legendFormat": "GPU {{gpu}} Power",
                "refId": "A"
              }
            ],
            "options": {
              "tooltip": {"mode": "multi"},
              "legend": {"displayMode": "list", "placement": "bottom"}
            },
            "fieldConfig": {
              "defaults": {
                "unit": "percent",
                "min": 0,
                "max": 100,
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"value": 0, "color": "green"},
                    {"value": 50, "color": "yellow"},
                    {"value": 80, "color": "red"}
                  ]
                }
              }
            }
          },
          {
            "gridPos": {"h": 1, "w": 24, "x": 0, "y": 14},
            "id": 9,
            "type": "row",
            "title": "Process Anomaly Scores",
            "collapsed": false
          },
          {
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 15},
            "id": 10,
            "type": "timeseries",
            "title": "Process Anomaly Scores",
            "targets": [
              {
                "expr": "topk(10, process_anomaly_score)",
                "legendFormat": "{{process_name}} - {{metric_type}}",
                "refId": "A"
              }
            ],
            "options": {
              "tooltip": {"mode": "multi"},
              "legend": {"displayMode": "table", "placement": "right"}
            },
            "fieldConfig": {
              "defaults": {
                "unit": "percent",
                "min": 0,
                "max": 100,
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"value": 0, "color": "green"},
                    {"value": 50, "color": "yellow"},
                    {"value": 80, "color": "red"}
                  ]
                }
              }
            }
          },
          {
            "gridPos": {"h": 1, "w": 24, "x": 0, "y": 23},
            "id": 11,
            "type": "row",
            "title": "Disk Anomaly Scores",
            "collapsed": false
          },
          {
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 24},
            "id": 12,
            "type": "timeseries",
            "title": "Disk Space Anomaly Scores",
            "targets": [
              {
                "expr": "disk_anomaly_score",
                "legendFormat": "{{mountpoint}} - {{device}}",
                "refId": "A"
              }
            ],
            "options": {
              "tooltip": {"mode": "multi"},
              "legend": {"displayMode": "table", "placement": "right"}
            },
            "fieldConfig": {
              "defaults": {
                "unit": "percent",
                "min": 0,
                "max": 100,
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"value": 0, "color": "green"},
                    {"value": 50, "color": "yellow"},
                    {"value": 80, "color": "red"}
                  ]
                }
              }
            }
          },
          {
            "gridPos": {"h": 1, "w": 24, "x": 0, "y": 32},
            "id": 13,
            "type": "row",
            "title": "Pod Anomaly Scores",
            "collapsed": false
          },
          {
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 33},
            "id": 14,
            "type": "timeseries",
            "title": "K8s Pod Anomaly Scores",
            "targets": [
              {
                "expr": "topk(10, pod_anomaly_score)",
                "legendFormat": "{{namespace}}/{{pod}} - {{metric_type}}",
                "refId": "A"
              }
            ],
            "options": {
              "tooltip": {"mode": "multi"},
              "legend": {"displayMode": "table", "placement": "right"}
            },
            "fieldConfig": {
              "defaults": {
                "unit": "percent",
                "min": 0,
                "max": 100,
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"value": 0, "color": "green"},
                    {"value": 50, "color": "yellow"},
                    {"value": 80, "color": "red"}
                  ]
                }
              }
            }
          }
        ],
        "editable": true,
        "schemaVersion": 38,
        "version": 1
      }
    process-anomaly-detection.json: |
      {
        "id": null,
        "uid": "process-anomaly-detection",
        "title": "ODIN Process Anomaly Detection",
        "tags": ["anomaly", "process", "ml", "security", "odin"],
        "timezone": "America/Los_Angeles",
        "schemaVersion": 38,
        "version": 2,
        "refresh": "30s",
        "time": {
          "from": "now-3h",
          "to": "now"
        },
        "templating": {
          "list": [
            {
              "name": "groupname",
              "type": "query",
              "datasource": "Prometheus",
              "query": "label_values(process_cpu_anomaly_score, groupname)",
              "refresh": 1,
              "includeAll": true,
              "allValue": ".*",
              "multi": true
            },
            {
              "name": "instance",
              "type": "query",
              "datasource": "Prometheus",
              "query": "label_values(process_cpu_anomaly_score, instance)",
              "refresh": 1,
              "includeAll": true,
              "allValue": ".*",
              "multi": true
            },
            {
              "name": "top_n",
              "type": "custom",
              "current": {
                "text": "30",
                "value": "30"
              },
              "options": [
                {"text": "10", "value": "10"},
                {"text": "20", "value": "20"},
                {"text": "30", "value": "30"},
                {"text": "50", "value": "50"},
                {"text": "100", "value": "100"}
              ],
              "query": "10,20,30,50,100",
              "description": "Number of top anomalous processes to display"
            }
          ]
        },
        "panels": [
          {
            "gridPos": {"h": 6, "w": 24, "x": 0, "y": 0},
            "id": 1,
            "type": "text",
            "title": "Process Anomaly Detection Overview",
            "options": {
              "mode": "markdown",
              "content": "# ML-Based Process Anomaly Detection\\n\\nAdvanced process monitoring using **Isolation Forest** machine learning algorithms analyzing top CPU and memory consuming processes.\\n\\n## Detection Areas\\n- **CPU Usage Anomalies**: Unusual CPU consumption patterns\\n- **Memory Usage Anomalies**: Abnormal memory allocation behaviors\\n- **Process Count Anomalies**: Unexpected process scaling\\n- **New Process Detection**: Real-time alerts for unknown processes\\n- **Security Analysis**: Detection of suspicious process behaviors\\n\\n## Anomaly Scores\\n- **1.0** = Normal behavior (green)\\n- **0.5** = Moderate anomaly (yellow)\\n- **0.0** = Severe anomaly requiring investigation (red)\\n\\n## Tips\\n- Use the **top_n** variable to control how many processes to display\\n- Filter by specific process names using the **groupname** selector\\n- The improved dashboard at [Process Anomaly Detection (Improved)](/d/process-anomaly-improved) provides better visualization for large numbers of processes"
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 8, "w": 6, "x": 0, "y": 6},
            "id": 2,
            "type": "stat",
            "title": "Detection Status",
            "targets": [
              {
                "expr": "up{job=\"advanced-process-anomaly-detector\"}",
                "refId": "A"
              }
            ],
            "options": {
              "graphMode": "none",
              "colorMode": "background",
              "justifyMode": "center"
            },
            "fieldConfig": {
              "defaults": {
                "mappings": [
                  {"value": 1, "text": "ACTIVE", "color": "green"},
                  {"value": 0, "text": "DOWN", "color": "red"}
                ],
                "color": {"mode": "thresholds"},
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "green", "value": 1}
                  ]
                }
              }
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 8, "w": 6, "x": 6, "y": 6},
            "id": 3,
            "type": "stat",
            "title": "Processes Analyzed",
            "targets": [
              {
                "expr": "process_anomaly_processes_analyzed_total",
                "refId": "A"
              }
            ],
            "options": {
              "graphMode": "area",
              "colorMode": "value",
              "justifyMode": "center"
            },
            "fieldConfig": {
              "defaults": {
                "color": {"mode": "palette-classic"},
                "unit": "short"
              }
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 8, "w": 6, "x": 12, "y": 6},
            "id": 4,
            "type": "stat",
            "title": "Unique Processes",
            "targets": [
              {
                "expr": "count(count by (groupname) (process_cpu_anomaly_score))",
                "refId": "A"
              }
            ],
            "options": {
              "graphMode": "none",
              "colorMode": "value",
              "justifyMode": "center"
            },
            "fieldConfig": {
              "defaults": {
                "unit": "short",
                "color": {"mode": "palette-classic"}
              }
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 8, "w": 6, "x": 18, "y": 6},
            "id": 5,
            "type": "stat",
            "title": "Anomalous Processes",
            "targets": [
              {
                "expr": "count(process_cpu_anomaly_score < 0.7 or process_memory_anomaly_score < 0.7)",
                "refId": "A"
              }
            ],
            "options": {
              "graphMode": "none",
              "colorMode": "value",
              "justifyMode": "center"
            },
            "fieldConfig": {
              "defaults": {
                "unit": "short",
                "color": {"mode": "thresholds"},
                "thresholds": {
                  "steps": [
                    {"color": "green", "value": 0},
                    {"color": "yellow", "value": 10},
                    {"color": "red", "value": 50}
                  ]
                }
              }
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 12, "w": 24, "x": 0, "y": 14},
            "id": 6,
            "type": "barchart",
            "title": "Top $top_n Most Anomalous Processes (Lower = More Anomalous)",
            "targets": [
              {
                "expr": "bottomk($top_n, (process_cpu_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"} * 100)) and (process_cpu_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"} < 0.8)",
                "legendFormat": "CPU: {{groupname}}",
                "refId": "A"
              },
              {
                "expr": "bottomk($top_n, (process_memory_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"} * 100)) and (process_memory_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"} < 0.8)",
                "legendFormat": "Memory: {{groupname}}",
                "refId": "B"
              }
            ],
            "options": {
              "orientation": "horizontal",
              "displayMode": "gradient",
              "legend": {"displayMode": "table", "placement": "right", "calcs": ["lastNotNull"]},
              "tooltip": {"mode": "multi", "sort": "asc"}
            },
            "fieldConfig": {
              "defaults": {
                "color": {"mode": "continuous-GrYlRd"},
                "custom": {
                  "hideFrom": {"tooltip": false, "vis": false, "legend": false}
                },
                "unit": "percent",
                "min": 0,
                "max": 100,
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "yellow", "value": 30},
                    {"color": "green", "value": 70}
                  ]
                }
              }
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 10, "w": 12, "x": 0, "y": 26},
            "id": 7,
            "type": "timeseries",
            "title": "CPU Usage Anomaly Scores (Top $top_n Most Anomalous)",
            "targets": [
              {
                "expr": "bottomk($top_n, process_cpu_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"}) and (process_cpu_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"} < 0.8)",
                "legendFormat": "{{groupname}}",
                "refId": "A"
              }
            ],
            "options": {
              "legend": {"displayMode": "table", "placement": "right", "calcs": ["lastNotNull", "min"]},
              "tooltip": {"mode": "multi", "sort": "asc"}
            },
            "fieldConfig": {
              "defaults": {
                "color": {"mode": "palette-classic"},
                "custom": {
                  "drawStyle": "line",
                  "lineInterpolation": "smooth",
                  "lineWidth": 2,
                  "fillOpacity": 15,
                  "pointSize": 4
                },
                "unit": "percentunit",
                "min": 0,
                "max": 1,
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "yellow", "value": 0.3},
                    {"color": "green", "value": 0.7}
                  ]
                }
              }
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 10, "w": 12, "x": 12, "y": 26},
            "id": 8,
            "type": "timeseries",
            "title": "Memory Usage Anomaly Scores (Top $top_n Most Anomalous)",
            "targets": [
              {
                "expr": "bottomk($top_n, process_memory_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"}) and (process_memory_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"} < 0.8)",
                "legendFormat": "{{groupname}}",
                "refId": "A"
              }
            ],
            "options": {
              "legend": {"displayMode": "table", "placement": "right", "calcs": ["lastNotNull", "min"]},
              "tooltip": {"mode": "multi", "sort": "asc"}
            },
            "fieldConfig": {
              "defaults": {
                "color": {"mode": "palette-classic"},
                "custom": {
                  "drawStyle": "line",
                  "lineInterpolation": "smooth",
                  "lineWidth": 2,
                  "fillOpacity": 15,
                  "pointSize": 4
                },
                "unit": "percentunit",
                "min": 0,
                "max": 1,
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "yellow", "value": 0.3},
                    {"color": "green", "value": 0.7}
                  ]
                }
              }
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 10, "w": 24, "x": 0, "y": 36},
            "id": 9,
            "type": "state-timeline",
            "title": "Process Anomaly State Timeline (Top $top_n)",
            "targets": [
              {
                "expr": "bottomk($top_n, process_cpu_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"} < 0.8)",
                "format": "time_series",
                "refId": "A"
              }
            ],
            "options": {
              "legend": {
                "displayMode": "list",
                "placement": "bottom",
                "showLegend": true
              },
              "tooltip": {
                "mode": "single",
                "sort": "none"
              },
              "timezone": ["browser"],
              "rowHeight": 0.9
            },
            "fieldConfig": {
              "defaults": {
                "custom": {
                  "lineWidth": 0,
                  "fillOpacity": 70,
                  "spanNulls": false,
                  "insertNulls": false,
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  }
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "orange", "value": 0.3},
                    {"color": "yellow", "value": 0.5},
                    {"color": "green", "value": 0.7}
                  ]
                },
                "unit": "percentunit",
                "min": 0,
                "max": 1
              }
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 12, "w": 24, "x": 0, "y": 46},
            "id": 10,
            "type": "table",
            "title": "Detailed Anomalous Process Analysis (Top $top_n)",
            "targets": [
              {
                "expr": "bottomk($top_n, process_cpu_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"} < 0.8)",
                "format": "table",
                "instant": true,
                "refId": "A"
              },
              {
                "expr": "bottomk($top_n, process_memory_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"} < 0.8)",
                "format": "table",
                "instant": true,
                "refId": "B"
              },
              {
                "expr": "bottomk($top_n, process_count_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"} < 0.8)",
                "format": "table",
                "instant": true,
                "refId": "C"
              }
            ],
            "transformations": [
              {
                "id": "merge",
                "options": {}
              },
              {
                "id": "organize",
                "options": {
                  "excludeByName": {
                    "Time": true,
                    "__name__": true,
                    "job": true
                  },
                  "indexByName": {},
                  "renameByName": {
                    "Value #A": "CPU Anomaly Score",
                    "Value #B": "Memory Anomaly Score",
                    "Value #C": "Count Anomaly Score",
                    "groupname": "Process Group",
                    "instance": "Instance",
                    "type": "Alert Type"
                  }
                }
              }
            ],
            "fieldConfig": {
              "defaults": {
                "custom": {
                  "align": "center",
                  "filterable": true,
                  "sortBy": [{"desc": false, "displayName": "CPU Anomaly Score"}]
                },
                "unit": "percentunit",
                "min": 0,
                "max": 1,
                "color": {"mode": "thresholds"},
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "yellow", "value": 0.3},
                    {"color": "green", "value": 0.7}
                  ]
                }
              },
              "overrides": [
                {
                  "matcher": {"id": "byName", "options": "Alert Rate"},
                  "properties": [
                    {"id": "unit", "value": "reqps"},
                    {"id": "min", "value": 0},
                    {"id": "max"},
                    {"id": "color", "value": {"mode": "thresholds"}},
                    {
                      "id": "thresholds",
                      "value": {
                        "steps": [
                          {"color": "green", "value": 0},
                          {"color": "yellow", "value": 0.1},
                          {"color": "red", "value": 0.5}
                        ]
                      }
                    }
                  ]
                }
              ]
            },
            "options": {
              "showHeader": true,
              "sortBy": [{"desc": false, "displayName": "CPU Anomaly Score"}]
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 10, "w": 12, "x": 0, "y": 58},
            "id": 11,
            "type": "timeseries",
            "title": "New Process Detection Rate",
            "targets": [
              {
                "expr": "rate(process_new_process_detected_total{groupname=~\"$groupname\", instance=~\"$instance\"}[5m])",
                "legendFormat": "{{groupname}}",
                "refId": "A"
              }
            ],
            "options": {
              "legend": {"displayMode": "table", "placement": "right", "calcs": ["lastNotNull", "max"]},
              "tooltip": {"mode": "multi", "sort": "desc"}
            },
            "fieldConfig": {
              "defaults": {
                "color": {"mode": "palette-classic"},
                "custom": {
                  "drawStyle": "line",
                  "lineInterpolation": "smooth",
                  "lineWidth": 2,
                  "fillOpacity": 10,
                  "pointSize": 3
                },
                "unit": "reqps",
                "min": 0
              }
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 10, "w": 12, "x": 12, "y": 58},
            "id": 12,
            "type": "timeseries",
            "title": "Security Process Alerts (Suspicious Patterns)",
            "targets": [
              {
                "expr": "rate(process_anomaly_alerts_total{type=~\"cpu_anomaly|memory_anomaly\", groupname=~\".*crypto.*|.*miner.*|.*coin.*|.*hash.*|.*bash.*|.*sh.*|.*nc.*|.*netcat.*|.*wget.*|.*curl.*\"}[5m])",
                "legendFormat": "{{groupname}} - {{type}}",
                "refId": "A"
              }
            ],
            "options": {
              "legend": {"displayMode": "table", "placement": "right", "calcs": ["lastNotNull", "max"]},
              "tooltip": {"mode": "multi", "sort": "desc"}
            },
            "fieldConfig": {
              "defaults": {
                "color": {"mode": "palette-classic"},
                "custom": {
                  "drawStyle": "bars",
                  "lineInterpolation": "smooth",
                  "lineWidth": 2,
                  "fillOpacity": 50,
                  "pointSize": 5
                },
                "unit": "reqps",
                "min": 0
              }
            }
          }
        ]
      }
    process-anomaly-improved.json: |
      {
        "uid": "process-anomaly-improved",
        "title": "ODIN Process Anomaly Detection (Improved)",
        "tags": ["anomaly", "process", "ml", "security", "odin", "improved"],
        "timezone": "America/Los_Angeles",
        "schemaVersion": 38,
        "version": 1,
        "refresh": "30s",
        "editable": true,
        "time": {
          "from": "now-3h",
          "to": "now"
        },
        "templating": {
          "list": [
            {
              "name": "top_n",
              "type": "custom",
              "current": {
                "text": "30",
                "value": "30"
              },
              "options": [
                {"text": "10", "value": "10"},
                {"text": "20", "value": "20"},
                {"text": "30", "value": "30"},
                {"text": "50", "value": "50"},
                {"text": "100", "value": "100"}
              ],
              "query": "10,20,30,50,100",
              "description": "Number of top anomalous processes to show"
            }
          ]
        },
        "panels": [
          {
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 0},
            "id": 1,
            "type": "barchart",
            "title": "Top $top_n Most Anomalous Processes",
            "datasource": "Prometheus",
            "targets": [
              {
                "expr": "bottomk($top_n, min by (groupname) (process_cpu_anomaly_score < 0.8 or process_memory_anomaly_score < 0.8))",
                "legendFormat": "{{groupname}}",
                "refId": "A"
              }
            ],
            "options": {
              "orientation": "horizontal",
              "displayMode": "gradient",
              "showValue": "always",
              "legend": {
                "displayMode": "hidden"
              }
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "continuous-GrYlRd"
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "yellow", "value": 0.3},
                    {"color": "green", "value": 0.7}
                  ]
                },
                "unit": "percentunit",
                "min": 0,
                "max": 1
              }
            }
          },
          {
            "gridPos": {"h": 10, "w": 12, "x": 0, "y": 8},
            "id": 2,
            "type": "timeseries",
            "title": "CPU Anomaly Trends (Top $top_n)",
            "datasource": "Prometheus",
            "targets": [
              {
                "expr": "bottomk($top_n, process_cpu_anomaly_score < 0.8)",
                "legendFormat": "{{groupname}}",
                "refId": "A"
              }
            ],
            "options": {
              "tooltip": {"mode": "multi"},
              "legend": {"displayMode": "table", "placement": "right", "calcs": ["lastNotNull", "min"]}
            },
            "fieldConfig": {
              "defaults": {
                "color": {"mode": "palette-classic"},
                "custom": {
                  "drawStyle": "line",
                  "lineInterpolation": "smooth",
                  "lineWidth": 2,
                  "fillOpacity": 10,
                  "pointSize": 3
                },
                "unit": "percentunit",
                "min": 0,
                "max": 1,
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "yellow", "value": 0.3},
                    {"color": "green", "value": 0.7}
                  ]
                }
              }
            }
          },
          {
            "gridPos": {"h": 10, "w": 12, "x": 12, "y": 8},
            "id": 3,
            "type": "timeseries",
            "title": "Memory Anomaly Trends (Top $top_n)",
            "datasource": "Prometheus",
            "targets": [
              {
                "expr": "bottomk($top_n, process_memory_anomaly_score < 0.8)",
                "legendFormat": "{{groupname}}",
                "refId": "A"
              }
            ],
            "options": {
              "tooltip": {"mode": "multi"},
              "legend": {"displayMode": "table", "placement": "right", "calcs": ["lastNotNull", "min"]}
            },
            "fieldConfig": {
              "defaults": {
                "color": {"mode": "palette-classic"},
                "custom": {
                  "drawStyle": "line",
                  "lineInterpolation": "smooth",
                  "lineWidth": 2,
                  "fillOpacity": 10,
                  "pointSize": 3
                },
                "unit": "percentunit",
                "min": 0,
                "max": 1,
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "yellow", "value": 0.3},
                    {"color": "green", "value": 0.7}
                  ]
                }
              }
            }
          },
          {
            "gridPos": {"h": 10, "w": 24, "x": 0, "y": 18},
            "id": 4,
            "type": "state-timeline",
            "title": "Process Anomaly State Timeline (Top $top_n)",
            "datasource": "Prometheus",
            "targets": [
              {
                "expr": "bottomk($top_n, process_cpu_anomaly_score < 0.8)",
                "refId": "A"
              }
            ],
            "options": {
              "legend": {
                "displayMode": "list",
                "placement": "bottom",
                "showLegend": true
              },
              "tooltip": {
                "mode": "single"
              },
              "rowHeight": 0.9
            },
            "fieldConfig": {
              "defaults": {
                "custom": {
                  "lineWidth": 0,
                  "fillOpacity": 70,
                  "spanNulls": false
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "orange", "value": 0.3},
                    {"color": "yellow", "value": 0.5},
                    {"color": "green", "value": 0.7}
                  ]
                },
                "unit": "percentunit",
                "min": 0,
                "max": 1
              }
            }
          },
          {
            "gridPos": {"h": 10, "w": 24, "x": 0, "y": 28},
            "id": 5,
            "type": "table",
            "title": "Anomaly Score Details (Sortable)",
            "datasource": "Prometheus",
            "targets": [
              {
                "expr": "process_cpu_anomaly_score < 0.9",
                "format": "table",
                "instant": true,
                "refId": "A"
              },
              {
                "expr": "process_memory_anomaly_score < 0.9",
                "format": "table",
                "instant": true,
                "refId": "B"
              }
            ],
            "transformations": [
              {
                "id": "merge"
              },
              {
                "id": "organize",
                "options": {
                  "excludeByName": {
                    "Time": true,
                    "__name__": true,
                    "job": true
                  },
                  "renameByName": {
                    "Value #A": "CPU Score",
                    "Value #B": "Memory Score",
                    "groupname": "Process",
                    "instance": "Host"
                  }
                }
              }
            ],
            "options": {
              "showHeader": true,
              "sortBy": [{"desc": false, "displayName": "CPU Score"}]
            },
            "fieldConfig": {
              "defaults": {
                "custom": {
                  "align": "center",
                  "displayMode": "color-background-solid",
                  "filterable": true
                },
                "unit": "percentunit",
                "min": 0,
                "max": 1,
                "color": {"mode": "thresholds"},
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "yellow", "value": 0.3},
                    {"color": "green", "value": 0.7}
                  ]
                }
              }
            }
          }
        ]
      }
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"ml-anomaly-detection.json":"{\n  \"uid\": \"ml-anomaly-detection\",\n  \"title\": \"ODIN ML Anomaly Detection\",\n  \"tags\": [\"odin\", \"ml\", \"anomaly-detection\"],\n  \"timezone\": \"America/Los_Angeles\",\n  \"refresh\": \"30s\",\n  \"panels\": [\n    {\n      \"gridPos\": {\"h\": 1, \"w\": 24, \"x\": 0, \"y\": 0},\n      \"id\": 1,\n      \"type\": \"row\",\n      \"title\": \"Anomaly Detector Status\",\n      \"collapsed\": false\n    },\n    {\n      \"gridPos\": {\"h\": 4, \"w\": 6, \"x\": 0, \"y\": 1},\n      \"id\": 2,\n      \"type\": \"stat\",\n      \"title\": \"GPU Anomaly Detector\",\n      \"targets\": [\n        {\n          \"expr\": \"up{job=\\\"gpu-anomaly-detector\\\"}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"graphMode\": \"none\",\n        \"colorMode\": \"background\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"]\n        }\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"mappings\": [\n            {\"type\": \"value\", \"value\": 1, \"text\": \"UP\", \"color\": \"green\"},\n            {\"type\": \"value\", \"value\": 0, \"text\": \"DOWN\", \"color\": \"red\"}\n          ],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"value\": 0, \"color\": \"red\"},\n              {\"value\": 1, \"color\": \"green\"}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"gridPos\": {\"h\": 4, \"w\": 6, \"x\": 6, \"y\": 1},\n      \"id\": 3,\n      \"type\": \"stat\",\n      \"title\": \"Process Anomaly Detector\",\n      \"targets\": [\n        {\n          \"expr\": \"up{job=\\\"process-anomaly-detector\\\"}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"graphMode\": \"none\",\n        \"colorMode\": \"background\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"]\n        }\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"mappings\": [\n            {\"type\": \"value\", \"value\": 1, \"text\": \"UP\", \"color\": \"green\"},\n            {\"type\": \"value\", \"value\": 0, \"text\": \"DOWN\", \"color\": \"red\"}\n          ],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"value\": 0, \"color\": \"red\"},\n              {\"value\": 1, \"color\": \"green\"}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"gridPos\": {\"h\": 4, \"w\": 6, \"x\": 12, \"y\": 1},\n      \"id\": 4,\n      \"type\": \"stat\",\n      \"title\": \"K8s Pod Anomaly Detector\",\n      \"targets\": [\n        {\n          \"expr\": \"up{job=\\\"k8s-pod-anomaly-detector\\\"}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"graphMode\": \"none\",\n        \"colorMode\": \"background\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"]\n        }\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"mappings\": [\n            {\"type\": \"value\", \"value\": 1, \"text\": \"UP\", \"color\": \"green\"},\n            {\"type\": \"value\", \"value\": 0, \"text\": \"DOWN\", \"color\": \"red\"}\n          ],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"value\": 0, \"color\": \"red\"},\n              {\"value\": 1, \"color\": \"green\"}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"gridPos\": {\"h\": 4, \"w\": 6, \"x\": 18, \"y\": 1},\n      \"id\": 5,\n      \"type\": \"stat\",\n      \"title\": \"Disk Anomaly Detector\",\n      \"targets\": [\n        {\n          \"expr\": \"up{job=\\\"disk-anomaly-detector\\\"}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"graphMode\": \"none\",\n        \"colorMode\": \"background\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"]\n        }\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"mappings\": [\n            {\"type\": \"value\", \"value\": 1, \"text\": \"UP\", \"color\": \"green\"},\n            {\"type\": \"value\", \"value\": 0, \"text\": \"DOWN\", \"color\": \"red\"}\n          ],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"value\": 0, \"color\": \"red\"},\n              {\"value\": 1, \"color\": \"green\"}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"gridPos\": {\"h\": 1, \"w\": 24, \"x\": 0, \"y\": 5},\n      \"id\": 6,\n      \"type\": \"row\",\n      \"title\": \"GPU Anomaly Scores\",\n      \"collapsed\": false\n    },\n    {\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 6},\n      \"id\": 7,\n      \"type\": \"timeseries\",\n      \"title\": \"GPU Temperature Anomaly Score\",\n      \"targets\": [\n        {\n          \"expr\": \"gpu_anomaly_score{metric_name=\\\"nvidia_gpu_temperature_celsius\\\"}\",\n          \"legendFormat\": \"GPU {{gpu}} Temperature\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"tooltip\": {\"mode\": \"multi\"},\n        \"legend\": {\"displayMode\": \"list\", \"placement\": \"bottom\"}\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"percent\",\n          \"min\": 0,\n          \"max\": 100,\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"value\": 0, \"color\": \"green\"},\n              {\"value\": 50, \"color\": \"yellow\"},\n              {\"value\": 80, \"color\": \"red\"}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 6},\n      \"id\": 8,\n      \"type\": \"timeseries\",\n      \"title\": \"GPU Power Anomaly Score\",\n      \"targets\": [\n        {\n          \"expr\": \"gpu_anomaly_score{metric_name=\\\"node_gpu_power_watts\\\"}\",\n          \"legendFormat\": \"GPU {{gpu}} Power\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"tooltip\": {\"mode\": \"multi\"},\n        \"legend\": {\"displayMode\": \"list\", \"placement\": \"bottom\"}\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"percent\",\n          \"min\": 0,\n          \"max\": 100,\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"value\": 0, \"color\": \"green\"},\n              {\"value\": 50, \"color\": \"yellow\"},\n              {\"value\": 80, \"color\": \"red\"}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"gridPos\": {\"h\": 1, \"w\": 24, \"x\": 0, \"y\": 14},\n      \"id\": 9,\n      \"type\": \"row\",\n      \"title\": \"Process Anomaly Scores\",\n      \"collapsed\": false\n    },\n    {\n      \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 15},\n      \"id\": 10,\n      \"type\": \"timeseries\",\n      \"title\": \"Process Anomaly Scores\",\n      \"targets\": [\n        {\n          \"expr\": \"topk(10, process_anomaly_score)\",\n          \"legendFormat\": \"{{process_name}} - {{metric_type}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"tooltip\": {\"mode\": \"multi\"},\n        \"legend\": {\"displayMode\": \"table\", \"placement\": \"right\"}\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"percent\",\n          \"min\": 0,\n          \"max\": 100,\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"value\": 0, \"color\": \"green\"},\n              {\"value\": 50, \"color\": \"yellow\"},\n              {\"value\": 80, \"color\": \"red\"}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"gridPos\": {\"h\": 1, \"w\": 24, \"x\": 0, \"y\": 23},\n      \"id\": 11,\n      \"type\": \"row\",\n      \"title\": \"Disk Anomaly Scores\",\n      \"collapsed\": false\n    },\n    {\n      \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 24},\n      \"id\": 12,\n      \"type\": \"timeseries\",\n      \"title\": \"Disk Space Anomaly Scores\",\n      \"targets\": [\n        {\n          \"expr\": \"disk_anomaly_score\",\n          \"legendFormat\": \"{{mountpoint}} - {{device}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"tooltip\": {\"mode\": \"multi\"},\n        \"legend\": {\"displayMode\": \"table\", \"placement\": \"right\"}\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"percent\",\n          \"min\": 0,\n          \"max\": 100,\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"value\": 0, \"color\": \"green\"},\n              {\"value\": 50, \"color\": \"yellow\"},\n              {\"value\": 80, \"color\": \"red\"}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"gridPos\": {\"h\": 1, \"w\": 24, \"x\": 0, \"y\": 32},\n      \"id\": 13,\n      \"type\": \"row\",\n      \"title\": \"Pod Anomaly Scores\",\n      \"collapsed\": false\n    },\n    {\n      \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 33},\n      \"id\": 14,\n      \"type\": \"timeseries\",\n      \"title\": \"K8s Pod Anomaly Scores\",\n      \"targets\": [\n        {\n          \"expr\": \"topk(10, pod_anomaly_score)\",\n          \"legendFormat\": \"{{namespace}}/{{pod}} - {{metric_type}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"tooltip\": {\"mode\": \"multi\"},\n        \"legend\": {\"displayMode\": \"table\", \"placement\": \"right\"}\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"percent\",\n          \"min\": 0,\n          \"max\": 100,\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"value\": 0, \"color\": \"green\"},\n              {\"value\": 50, \"color\": \"yellow\"},\n              {\"value\": 80, \"color\": \"red\"}\n            ]\n          }\n        }\n      }\n    }\n  ],\n  \"editable\": true,\n  \"schemaVersion\": 38,\n  \"version\": 1\n}\n","process-anomaly-detection.json":"{\n  \"id\": null,\n  \"uid\": \"process-anomaly-detection\",\n  \"title\": \"ODIN Process Anomaly Detection\",\n  \"tags\": [\"anomaly\", \"process\", \"ml\", \"security\", \"odin\"],\n  \"timezone\": \"America/Los_Angeles\",\n  \"schemaVersion\": 38,\n  \"version\": 2,\n  \"refresh\": \"30s\",\n  \"time\": {\n    \"from\": \"now-3h\",\n    \"to\": \"now\"\n  },\n  \"templating\": {\n    \"list\": [\n      {\n        \"name\": \"groupname\",\n        \"type\": \"query\",\n        \"datasource\": \"Prometheus\",\n        \"query\": \"label_values(process_cpu_anomaly_score, groupname)\",\n        \"refresh\": 1,\n        \"includeAll\": true,\n        \"allValue\": \".*\",\n        \"multi\": true\n      },\n      {\n        \"name\": \"instance\",\n        \"type\": \"query\",\n        \"datasource\": \"Prometheus\",\n        \"query\": \"label_values(process_cpu_anomaly_score, instance)\",\n        \"refresh\": 1,\n        \"includeAll\": true,\n        \"allValue\": \".*\",\n        \"multi\": true\n      },\n      {\n        \"name\": \"top_n\",\n        \"type\": \"custom\",\n        \"current\": {\n          \"text\": \"30\",\n          \"value\": \"30\"\n        },\n        \"options\": [\n          {\"text\": \"10\", \"value\": \"10\"},\n          {\"text\": \"20\", \"value\": \"20\"},\n          {\"text\": \"30\", \"value\": \"30\"},\n          {\"text\": \"50\", \"value\": \"50\"},\n          {\"text\": \"100\", \"value\": \"100\"}\n        ],\n        \"query\": \"10,20,30,50,100\",\n        \"description\": \"Number of top anomalous processes to display\"\n      }\n    ]\n  },\n  \"panels\": [\n    {\n      \"gridPos\": {\"h\": 6, \"w\": 24, \"x\": 0, \"y\": 0},\n      \"id\": 1,\n      \"type\": \"text\",\n      \"title\": \"Process Anomaly Detection Overview\",\n      \"options\": {\n        \"mode\": \"markdown\",\n        \"content\": \"# ML-Based Process Anomaly Detection\\\\n\\\\nAdvanced process monitoring using **Isolation Forest** machine learning algorithms analyzing top CPU and memory consuming processes.\\\\n\\\\n## Detection Areas\\\\n- **CPU Usage Anomalies**: Unusual CPU consumption patterns\\\\n- **Memory Usage Anomalies**: Abnormal memory allocation behaviors\\\\n- **Process Count Anomalies**: Unexpected process scaling\\\\n- **New Process Detection**: Real-time alerts for unknown processes\\\\n- **Security Analysis**: Detection of suspicious process behaviors\\\\n\\\\n## Anomaly Scores\\\\n- **1.0** = Normal behavior (green)\\\\n- **0.5** = Moderate anomaly (yellow)\\\\n- **0.0** = Severe anomaly requiring investigation (red)\\\\n\\\\n## Tips\\\\n- Use the **top_n** variable to control how many processes to display\\\\n- Filter by specific process names using the **groupname** selector\\\\n- The improved dashboard at [Process Anomaly Detection (Improved)](/d/process-anomaly-improved) provides better visualization for large numbers of processes\"\n      }\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"gridPos\": {\"h\": 8, \"w\": 6, \"x\": 0, \"y\": 6},\n      \"id\": 2,\n      \"type\": \"stat\",\n      \"title\": \"Detection Status\",\n      \"targets\": [\n        {\n          \"expr\": \"up{job=\\\"advanced-process-anomaly-detector\\\"}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"graphMode\": \"none\",\n        \"colorMode\": \"background\",\n        \"justifyMode\": \"center\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"mappings\": [\n            {\"value\": 1, \"text\": \"ACTIVE\", \"color\": \"green\"},\n            {\"value\": 0, \"text\": \"DOWN\", \"color\": \"red\"}\n          ],\n          \"color\": {\"mode\": \"thresholds\"},\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"red\", \"value\": 0},\n              {\"color\": \"green\", \"value\": 1}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"gridPos\": {\"h\": 8, \"w\": 6, \"x\": 6, \"y\": 6},\n      \"id\": 3,\n      \"type\": \"stat\",\n      \"title\": \"Processes Analyzed\",\n      \"targets\": [\n        {\n          \"expr\": \"process_anomaly_processes_analyzed_total\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"graphMode\": \"area\",\n        \"colorMode\": \"value\",\n        \"justifyMode\": \"center\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"unit\": \"short\"\n        }\n      }\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"gridPos\": {\"h\": 8, \"w\": 6, \"x\": 12, \"y\": 6},\n      \"id\": 4,\n      \"type\": \"stat\",\n      \"title\": \"Unique Processes\",\n      \"targets\": [\n        {\n          \"expr\": \"count(count by (groupname) (process_cpu_anomaly_score))\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"graphMode\": \"none\",\n        \"colorMode\": \"value\",\n        \"justifyMode\": \"center\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"color\": {\"mode\": \"palette-classic\"}\n        }\n      }\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"gridPos\": {\"h\": 8, \"w\": 6, \"x\": 18, \"y\": 6},\n      \"id\": 5,\n      \"type\": \"stat\",\n      \"title\": \"Anomalous Processes\",\n      \"targets\": [\n        {\n          \"expr\": \"count(process_cpu_anomaly_score \u003c 0.7 or process_memory_anomaly_score \u003c 0.7)\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"graphMode\": \"none\",\n        \"colorMode\": \"value\",\n        \"justifyMode\": \"center\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"color\": {\"mode\": \"thresholds\"},\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"green\", \"value\": 0},\n              {\"color\": \"yellow\", \"value\": 10},\n              {\"color\": \"red\", \"value\": 50}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"gridPos\": {\"h\": 12, \"w\": 24, \"x\": 0, \"y\": 14},\n      \"id\": 6,\n      \"type\": \"barchart\",\n      \"title\": \"Top $top_n Most Anomalous Processes (Lower = More Anomalous)\",\n      \"targets\": [\n        {\n          \"expr\": \"bottomk($top_n, (process_cpu_anomaly_score{groupname=~\\\"$groupname\\\", instance=~\\\"$instance\\\"} * 100)) and (process_cpu_anomaly_score{groupname=~\\\"$groupname\\\", instance=~\\\"$instance\\\"} \u003c 0.8)\",\n          \"legendFormat\": \"CPU: {{groupname}}\",\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"bottomk($top_n, (process_memory_anomaly_score{groupname=~\\\"$groupname\\\", instance=~\\\"$instance\\\"} * 100)) and (process_memory_anomaly_score{groupname=~\\\"$groupname\\\", instance=~\\\"$instance\\\"} \u003c 0.8)\",\n          \"legendFormat\": \"Memory: {{groupname}}\",\n          \"refId\": \"B\"\n        }\n      ],\n      \"options\": {\n        \"orientation\": \"horizontal\",\n        \"displayMode\": \"gradient\",\n        \"legend\": {\"displayMode\": \"table\", \"placement\": \"right\", \"calcs\": [\"lastNotNull\"]},\n        \"tooltip\": {\"mode\": \"multi\", \"sort\": \"asc\"}\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\"mode\": \"continuous-GrYlRd\"},\n          \"custom\": {\n            \"hideFrom\": {\"tooltip\": false, \"vis\": false, \"legend\": false}\n          },\n          \"unit\": \"percent\",\n          \"min\": 0,\n          \"max\": 100,\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"color\": \"red\", \"value\": 0},\n              {\"color\": \"yellow\", \"value\": 30},\n              {\"color\": \"green\", \"value\": 70}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"gridPos\": {\"h\": 10, \"w\": 12, \"x\": 0, \"y\": 26},\n      \"id\": 7,\n      \"type\": \"timeseries\",\n      \"title\": \"CPU Usage Anomaly Scores (Top $top_n Most Anomalous)\",\n      \"targets\": [\n        {\n          \"expr\": \"bottomk($top_n, process_cpu_anomaly_score{groupname=~\\\"$groupname\\\", instance=~\\\"$instance\\\"}) and (process_cpu_anomaly_score{groupname=~\\\"$groupname\\\", instance=~\\\"$instance\\\"} \u003c 0.8)\",\n          \"legendFormat\": \"{{groupname}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"legend\": {\"displayMode\": \"table\", \"placement\": \"right\", \"calcs\": [\"lastNotNull\", \"min\"]},\n        \"tooltip\": {\"mode\": \"multi\", \"sort\": \"asc\"}\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"drawStyle\": \"line\",\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 15,\n            \"pointSize\": 4\n          },\n          \"unit\": \"percentunit\",\n          \"min\": 0,\n          \"max\": 1,\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"red\", \"value\": 0},\n              {\"color\": \"yellow\", \"value\": 0.3},\n              {\"color\": \"green\", \"value\": 0.7}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"gridPos\": {\"h\": 10, \"w\": 12, \"x\": 12, \"y\": 26},\n      \"id\": 8,\n      \"type\": \"timeseries\",\n      \"title\": \"Memory Usage Anomaly Scores (Top $top_n Most Anomalous)\",\n      \"targets\": [\n        {\n          \"expr\": \"bottomk($top_n, process_memory_anomaly_score{groupname=~\\\"$groupname\\\", instance=~\\\"$instance\\\"}) and (process_memory_anomaly_score{groupname=~\\\"$groupname\\\", instance=~\\\"$instance\\\"} \u003c 0.8)\",\n          \"legendFormat\": \"{{groupname}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"legend\": {\"displayMode\": \"table\", \"placement\": \"right\", \"calcs\": [\"lastNotNull\", \"min\"]},\n        \"tooltip\": {\"mode\": \"multi\", \"sort\": \"asc\"}\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"drawStyle\": \"line\",\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 15,\n            \"pointSize\": 4\n          },\n          \"unit\": \"percentunit\",\n          \"min\": 0,\n          \"max\": 1,\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"red\", \"value\": 0},\n              {\"color\": \"yellow\", \"value\": 0.3},\n              {\"color\": \"green\", \"value\": 0.7}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"gridPos\": {\"h\": 10, \"w\": 24, \"x\": 0, \"y\": 36},\n      \"id\": 9,\n      \"type\": \"state-timeline\",\n      \"title\": \"Process Anomaly State Timeline (Top $top_n)\",\n      \"targets\": [\n        {\n          \"expr\": \"bottomk($top_n, process_cpu_anomaly_score{groupname=~\\\"$groupname\\\", instance=~\\\"$instance\\\"} \u003c 0.8)\",\n          \"format\": \"time_series\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"legend\": {\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\",\n          \"showLegend\": true\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        },\n        \"timezone\": [\"browser\"],\n        \"rowHeight\": 0.9\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"custom\": {\n            \"lineWidth\": 0,\n            \"fillOpacity\": 70,\n            \"spanNulls\": false,\n            \"insertNulls\": false,\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"color\": \"red\", \"value\": 0},\n              {\"color\": \"orange\", \"value\": 0.3},\n              {\"color\": \"yellow\", \"value\": 0.5},\n              {\"color\": \"green\", \"value\": 0.7}\n            ]\n          },\n          \"unit\": \"percentunit\",\n          \"min\": 0,\n          \"max\": 1\n        }\n      }\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"gridPos\": {\"h\": 12, \"w\": 24, \"x\": 0, \"y\": 46},\n      \"id\": 10,\n      \"type\": \"table\",\n      \"title\": \"Detailed Anomalous Process Analysis (Top $top_n)\",\n      \"targets\": [\n        {\n          \"expr\": \"bottomk($top_n, process_cpu_anomaly_score{groupname=~\\\"$groupname\\\", instance=~\\\"$instance\\\"} \u003c 0.8)\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"bottomk($top_n, process_memory_anomaly_score{groupname=~\\\"$groupname\\\", instance=~\\\"$instance\\\"} \u003c 0.8)\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"B\"\n        },\n        {\n          \"expr\": \"bottomk($top_n, process_count_anomaly_score{groupname=~\\\"$groupname\\\", instance=~\\\"$instance\\\"} \u003c 0.8)\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"C\"\n        }\n      ],\n      \"transformations\": [\n        {\n          \"id\": \"merge\",\n          \"options\": {}\n        },\n        {\n          \"id\": \"organize\",\n          \"options\": {\n            \"excludeByName\": {\n              \"Time\": true,\n              \"__name__\": true,\n              \"job\": true\n            },\n            \"indexByName\": {},\n            \"renameByName\": {\n              \"Value #A\": \"CPU Anomaly Score\",\n              \"Value #B\": \"Memory Anomaly Score\",\n              \"Value #C\": \"Count Anomaly Score\",\n              \"groupname\": \"Process Group\",\n              \"instance\": \"Instance\",\n              \"type\": \"Alert Type\"\n            }\n          }\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"custom\": {\n            \"align\": \"center\",\n            \"filterable\": true,\n            \"sortBy\": [{\"desc\": false, \"displayName\": \"CPU Anomaly Score\"}]\n          },\n          \"unit\": \"percentunit\",\n          \"min\": 0,\n          \"max\": 1,\n          \"color\": {\"mode\": \"thresholds\"},\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"red\", \"value\": 0},\n              {\"color\": \"yellow\", \"value\": 0.3},\n              {\"color\": \"green\", \"value\": 0.7}\n            ]\n          }\n        },\n        \"overrides\": [\n          {\n            \"matcher\": {\"id\": \"byName\", \"options\": \"Alert Rate\"},\n            \"properties\": [\n              {\"id\": \"unit\", \"value\": \"reqps\"},\n              {\"id\": \"min\", \"value\": 0},\n              {\"id\": \"max\"},\n              {\"id\": \"color\", \"value\": {\"mode\": \"thresholds\"}},\n              {\n                \"id\": \"thresholds\",\n                \"value\": {\n                  \"steps\": [\n                    {\"color\": \"green\", \"value\": 0},\n                    {\"color\": \"yellow\", \"value\": 0.1},\n                    {\"color\": \"red\", \"value\": 0.5}\n                  ]\n                }\n              }\n            ]\n          }\n        ]\n      },\n      \"options\": {\n        \"showHeader\": true,\n        \"sortBy\": [{\"desc\": false, \"displayName\": \"CPU Anomaly Score\"}]\n      }\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"gridPos\": {\"h\": 10, \"w\": 12, \"x\": 0, \"y\": 58},\n      \"id\": 11,\n      \"type\": \"timeseries\",\n      \"title\": \"New Process Detection Rate\",\n      \"targets\": [\n        {\n          \"expr\": \"rate(process_new_process_detected_total{groupname=~\\\"$groupname\\\", instance=~\\\"$instance\\\"}[5m])\",\n          \"legendFormat\": \"{{groupname}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"legend\": {\"displayMode\": \"table\", \"placement\": \"right\", \"calcs\": [\"lastNotNull\", \"max\"]},\n        \"tooltip\": {\"mode\": \"multi\", \"sort\": \"desc\"}\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"drawStyle\": \"line\",\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 10,\n            \"pointSize\": 3\n          },\n          \"unit\": \"reqps\",\n          \"min\": 0\n        }\n      }\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"gridPos\": {\"h\": 10, \"w\": 12, \"x\": 12, \"y\": 58},\n      \"id\": 12,\n      \"type\": \"timeseries\",\n      \"title\": \"Security Process Alerts (Suspicious Patterns)\",\n      \"targets\": [\n        {\n          \"expr\": \"rate(process_anomaly_alerts_total{type=~\\\"cpu_anomaly|memory_anomaly\\\", groupname=~\\\".*crypto.*|.*miner.*|.*coin.*|.*hash.*|.*bash.*|.*sh.*|.*nc.*|.*netcat.*|.*wget.*|.*curl.*\\\"}[5m])\",\n          \"legendFormat\": \"{{groupname}} - {{type}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"legend\": {\"displayMode\": \"table\", \"placement\": \"right\", \"calcs\": [\"lastNotNull\", \"max\"]},\n        \"tooltip\": {\"mode\": \"multi\", \"sort\": \"desc\"}\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"drawStyle\": \"bars\",\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 50,\n            \"pointSize\": 5\n          },\n          \"unit\": \"reqps\",\n          \"min\": 0\n        }\n      }\n    }\n  ]\n}\n","process-anomaly-improved.json":"{\n  \"uid\": \"process-anomaly-improved\",\n  \"title\": \"ODIN Process Anomaly Detection (Improved)\",\n  \"tags\": [\"anomaly\", \"process\", \"ml\", \"security\", \"odin\", \"improved\"],\n  \"timezone\": \"America/Los_Angeles\",\n  \"schemaVersion\": 38,\n  \"version\": 1,\n  \"refresh\": \"30s\",\n  \"editable\": true,\n  \"time\": {\n    \"from\": \"now-3h\",\n    \"to\": \"now\"\n  },\n  \"templating\": {\n    \"list\": [\n      {\n        \"name\": \"top_n\",\n        \"type\": \"custom\",\n        \"current\": {\n          \"text\": \"30\",\n          \"value\": \"30\"\n        },\n        \"options\": [\n          {\"text\": \"10\", \"value\": \"10\"},\n          {\"text\": \"20\", \"value\": \"20\"},\n          {\"text\": \"30\", \"value\": \"30\"},\n          {\"text\": \"50\", \"value\": \"50\"},\n          {\"text\": \"100\", \"value\": \"100\"}\n        ],\n        \"query\": \"10,20,30,50,100\",\n        \"description\": \"Number of top anomalous processes to show\"\n      }\n    ]\n  },\n  \"panels\": [\n    {\n      \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 0},\n      \"id\": 1,\n      \"type\": \"barchart\",\n      \"title\": \"Top $top_n Most Anomalous Processes\",\n      \"datasource\": \"Prometheus\",\n      \"targets\": [\n        {\n          \"expr\": \"bottomk($top_n, min by (groupname) (process_cpu_anomaly_score \u003c 0.8 or process_memory_anomaly_score \u003c 0.8))\",\n          \"legendFormat\": \"{{groupname}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"orientation\": \"horizontal\",\n        \"displayMode\": \"gradient\",\n        \"showValue\": \"always\",\n        \"legend\": {\n          \"displayMode\": \"hidden\"\n        }\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"continuous-GrYlRd\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"color\": \"red\", \"value\": 0},\n              {\"color\": \"yellow\", \"value\": 0.3},\n              {\"color\": \"green\", \"value\": 0.7}\n            ]\n          },\n          \"unit\": \"percentunit\",\n          \"min\": 0,\n          \"max\": 1\n        }\n      }\n    },\n    {\n      \"gridPos\": {\"h\": 10, \"w\": 12, \"x\": 0, \"y\": 8},\n      \"id\": 2,\n      \"type\": \"timeseries\",\n      \"title\": \"CPU Anomaly Trends (Top $top_n)\",\n      \"datasource\": \"Prometheus\",\n      \"targets\": [\n        {\n          \"expr\": \"bottomk($top_n, process_cpu_anomaly_score \u003c 0.8)\",\n          \"legendFormat\": \"{{groupname}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"tooltip\": {\"mode\": \"multi\"},\n        \"legend\": {\"displayMode\": \"table\", \"placement\": \"right\", \"calcs\": [\"lastNotNull\", \"min\"]}\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"drawStyle\": \"line\",\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 10,\n            \"pointSize\": 3\n          },\n          \"unit\": \"percentunit\",\n          \"min\": 0,\n          \"max\": 1,\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"red\", \"value\": 0},\n              {\"color\": \"yellow\", \"value\": 0.3},\n              {\"color\": \"green\", \"value\": 0.7}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"gridPos\": {\"h\": 10, \"w\": 12, \"x\": 12, \"y\": 8},\n      \"id\": 3,\n      \"type\": \"timeseries\",\n      \"title\": \"Memory Anomaly Trends (Top $top_n)\",\n      \"datasource\": \"Prometheus\",\n      \"targets\": [\n        {\n          \"expr\": \"bottomk($top_n, process_memory_anomaly_score \u003c 0.8)\",\n          \"legendFormat\": \"{{groupname}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"tooltip\": {\"mode\": \"multi\"},\n        \"legend\": {\"displayMode\": \"table\", \"placement\": \"right\", \"calcs\": [\"lastNotNull\", \"min\"]}\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"drawStyle\": \"line\",\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 10,\n            \"pointSize\": 3\n          },\n          \"unit\": \"percentunit\",\n          \"min\": 0,\n          \"max\": 1,\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"red\", \"value\": 0},\n              {\"color\": \"yellow\", \"value\": 0.3},\n              {\"color\": \"green\", \"value\": 0.7}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"gridPos\": {\"h\": 10, \"w\": 24, \"x\": 0, \"y\": 18},\n      \"id\": 4,\n      \"type\": \"state-timeline\",\n      \"title\": \"Process Anomaly State Timeline (Top $top_n)\",\n      \"datasource\": \"Prometheus\",\n      \"targets\": [\n        {\n          \"expr\": \"bottomk($top_n, process_cpu_anomaly_score \u003c 0.8)\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"legend\": {\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\",\n          \"showLegend\": true\n        },\n        \"tooltip\": {\n          \"mode\": \"single\"\n        },\n        \"rowHeight\": 0.9\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"custom\": {\n            \"lineWidth\": 0,\n            \"fillOpacity\": 70,\n            \"spanNulls\": false\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"color\": \"red\", \"value\": 0},\n              {\"color\": \"orange\", \"value\": 0.3},\n              {\"color\": \"yellow\", \"value\": 0.5},\n              {\"color\": \"green\", \"value\": 0.7}\n            ]\n          },\n          \"unit\": \"percentunit\",\n          \"min\": 0,\n          \"max\": 1\n        }\n      }\n    },\n    {\n      \"gridPos\": {\"h\": 10, \"w\": 24, \"x\": 0, \"y\": 28},\n      \"id\": 5,\n      \"type\": \"table\",\n      \"title\": \"Anomaly Score Details (Sortable)\",\n      \"datasource\": \"Prometheus\",\n      \"targets\": [\n        {\n          \"expr\": \"process_cpu_anomaly_score \u003c 0.9\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"process_memory_anomaly_score \u003c 0.9\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"B\"\n        }\n      ],\n      \"transformations\": [\n        {\n          \"id\": \"merge\"\n        },\n        {\n          \"id\": \"organize\",\n          \"options\": {\n            \"excludeByName\": {\n              \"Time\": true,\n              \"__name__\": true,\n              \"job\": true\n            },\n            \"renameByName\": {\n              \"Value #A\": \"CPU Score\",\n              \"Value #B\": \"Memory Score\",\n              \"groupname\": \"Process\",\n              \"instance\": \"Host\"\n            }\n          }\n        }\n      ],\n      \"options\": {\n        \"showHeader\": true,\n        \"sortBy\": [{\"desc\": false, \"displayName\": \"CPU Score\"}]\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"custom\": {\n            \"align\": \"center\",\n            \"displayMode\": \"color-background-solid\",\n            \"filterable\": true\n          },\n          \"unit\": \"percentunit\",\n          \"min\": 0,\n          \"max\": 1,\n          \"color\": {\"mode\": \"thresholds\"},\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"red\", \"value\": 0},\n              {\"color\": \"yellow\", \"value\": 0.3},\n              {\"color\": \"green\", \"value\": 0.7}\n            ]\n          }\n        }\n      }\n    }\n  ]\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"creationTimestamp":"2025-06-07T02:37:11Z","name":"ml-anomaly-dashboards","namespace":"monitoring","resourceVersion":"4608817","uid":"dc7da10a-1842-4dda-87db-f06f8be92977"}}
    creationTimestamp: "2025-06-07T02:37:59Z"
    name: ml-anomaly-dashboards
    namespace: monitoring
    resourceVersion: "4609164"
    uid: fc0fb0ea-b7d9-4d67-9225-48215b0ae2f5
- apiVersion: v1
  data:
    ml-anomaly-detection.json: |
      {
        "uid": "ml-anomaly-detection",
        "title": "ODIN ML Anomaly Detection",
        "tags": ["odin", "ml", "anomaly-detection"],
        "timezone": "America/Los_Angeles",
        "refresh": "30s",
        "panels": [
          {
            "gridPos": {"h": 1, "w": 24, "x": 0, "y": 0},
            "id": 1,
            "type": "row",
            "title": "Anomaly Detector Status",
            "collapsed": false
          },
          {
            "gridPos": {"h": 4, "w": 6, "x": 0, "y": 1},
            "id": 2,
            "type": "stat",
            "title": "GPU Anomaly Detector",
            "targets": [
              {
                "expr": "up{job=\"gpu-anomaly-detector\"}",
                "refId": "A"
              }
            ],
            "options": {
              "graphMode": "none",
              "colorMode": "background",
              "reduceOptions": {
                "values": false,
                "calcs": ["lastNotNull"]
              }
            },
            "fieldConfig": {
              "defaults": {
                "mappings": [
                  {"type": "value", "value": 1, "text": "UP", "color": "green"},
                  {"type": "value", "value": 0, "text": "DOWN", "color": "red"}
                ],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"value": 0, "color": "red"},
                    {"value": 1, "color": "green"}
                  ]
                }
              }
            }
          },
          {
            "gridPos": {"h": 4, "w": 6, "x": 6, "y": 1},
            "id": 3,
            "type": "stat",
            "title": "Process Anomaly Detector",
            "targets": [
              {
                "expr": "up{job=\"process-anomaly-detector\"}",
                "refId": "A"
              }
            ],
            "options": {
              "graphMode": "none",
              "colorMode": "background",
              "reduceOptions": {
                "values": false,
                "calcs": ["lastNotNull"]
              }
            },
            "fieldConfig": {
              "defaults": {
                "mappings": [
                  {"type": "value", "value": 1, "text": "UP", "color": "green"},
                  {"type": "value", "value": 0, "text": "DOWN", "color": "red"}
                ],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"value": 0, "color": "red"},
                    {"value": 1, "color": "green"}
                  ]
                }
              }
            }
          },
          {
            "gridPos": {"h": 4, "w": 6, "x": 12, "y": 1},
            "id": 4,
            "type": "stat",
            "title": "K8s Pod Anomaly Detector",
            "targets": [
              {
                "expr": "up{job=\"k8s-pod-anomaly-detector\"}",
                "refId": "A"
              }
            ],
            "options": {
              "graphMode": "none",
              "colorMode": "background",
              "reduceOptions": {
                "values": false,
                "calcs": ["lastNotNull"]
              }
            },
            "fieldConfig": {
              "defaults": {
                "mappings": [
                  {"type": "value", "value": 1, "text": "UP", "color": "green"},
                  {"type": "value", "value": 0, "text": "DOWN", "color": "red"}
                ],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"value": 0, "color": "red"},
                    {"value": 1, "color": "green"}
                  ]
                }
              }
            }
          },
          {
            "gridPos": {"h": 4, "w": 6, "x": 18, "y": 1},
            "id": 5,
            "type": "stat",
            "title": "Disk Anomaly Detector",
            "targets": [
              {
                "expr": "up{job=\"disk-anomaly-detector\"}",
                "refId": "A"
              }
            ],
            "options": {
              "graphMode": "none",
              "colorMode": "background",
              "reduceOptions": {
                "values": false,
                "calcs": ["lastNotNull"]
              }
            },
            "fieldConfig": {
              "defaults": {
                "mappings": [
                  {"type": "value", "value": 1, "text": "UP", "color": "green"},
                  {"type": "value", "value": 0, "text": "DOWN", "color": "red"}
                ],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"value": 0, "color": "red"},
                    {"value": 1, "color": "green"}
                  ]
                }
              }
            }
          },
          {
            "gridPos": {"h": 1, "w": 24, "x": 0, "y": 5},
            "id": 6,
            "type": "row",
            "title": "GPU Anomaly Scores",
            "collapsed": false
          },
          {
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 6},
            "id": 7,
            "type": "timeseries",
            "title": "GPU Temperature Anomaly Score",
            "targets": [
              {
                "expr": "gpu_anomaly_score{metric_name=\"nvidia_gpu_temperature_celsius\"}",
                "legendFormat": "GPU {{gpu}} Temperature",
                "refId": "A"
              }
            ],
            "options": {
              "tooltip": {"mode": "multi"},
              "legend": {"displayMode": "list", "placement": "bottom"}
            },
            "fieldConfig": {
              "defaults": {
                "unit": "percent",
                "min": 0,
                "max": 100,
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"value": 0, "color": "green"},
                    {"value": 50, "color": "yellow"},
                    {"value": 80, "color": "red"}
                  ]
                }
              }
            }
          },
          {
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 6},
            "id": 8,
            "type": "timeseries",
            "title": "GPU Power Anomaly Score",
            "targets": [
              {
                "expr": "gpu_anomaly_score{metric_name=\"node_gpu_power_watts\"}",
                "legendFormat": "GPU {{gpu}} Power",
                "refId": "A"
              }
            ],
            "options": {
              "tooltip": {"mode": "multi"},
              "legend": {"displayMode": "list", "placement": "bottom"}
            },
            "fieldConfig": {
              "defaults": {
                "unit": "percent",
                "min": 0,
                "max": 100,
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"value": 0, "color": "green"},
                    {"value": 50, "color": "yellow"},
                    {"value": 80, "color": "red"}
                  ]
                }
              }
            }
          },
          {
            "gridPos": {"h": 1, "w": 24, "x": 0, "y": 14},
            "id": 9,
            "type": "row",
            "title": "Process Anomaly Scores",
            "collapsed": false
          },
          {
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 15},
            "id": 10,
            "type": "timeseries",
            "title": "Process Anomaly Scores",
            "targets": [
              {
                "expr": "topk(10, process_anomaly_score)",
                "legendFormat": "{{process_name}} - {{metric_type}}",
                "refId": "A"
              }
            ],
            "options": {
              "tooltip": {"mode": "multi"},
              "legend": {"displayMode": "table", "placement": "right"}
            },
            "fieldConfig": {
              "defaults": {
                "unit": "percent",
                "min": 0,
                "max": 100,
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"value": 0, "color": "green"},
                    {"value": 50, "color": "yellow"},
                    {"value": 80, "color": "red"}
                  ]
                }
              }
            }
          },
          {
            "gridPos": {"h": 1, "w": 24, "x": 0, "y": 23},
            "id": 11,
            "type": "row",
            "title": "Disk Anomaly Scores",
            "collapsed": false
          },
          {
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 24},
            "id": 12,
            "type": "timeseries",
            "title": "Disk Space Anomaly Scores",
            "targets": [
              {
                "expr": "disk_anomaly_score",
                "legendFormat": "{{mountpoint}} - {{device}}",
                "refId": "A"
              }
            ],
            "options": {
              "tooltip": {"mode": "multi"},
              "legend": {"displayMode": "table", "placement": "right"}
            },
            "fieldConfig": {
              "defaults": {
                "unit": "percent",
                "min": 0,
                "max": 100,
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"value": 0, "color": "green"},
                    {"value": 50, "color": "yellow"},
                    {"value": 80, "color": "red"}
                  ]
                }
              }
            }
          },
          {
            "gridPos": {"h": 1, "w": 24, "x": 0, "y": 32},
            "id": 13,
            "type": "row",
            "title": "Pod Anomaly Scores",
            "collapsed": false
          },
          {
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 33},
            "id": 14,
            "type": "timeseries",
            "title": "K8s Pod Anomaly Scores",
            "targets": [
              {
                "expr": "topk(10, pod_anomaly_score)",
                "legendFormat": "{{namespace}}/{{pod}} - {{metric_type}}",
                "refId": "A"
              }
            ],
            "options": {
              "tooltip": {"mode": "multi"},
              "legend": {"displayMode": "table", "placement": "right"}
            },
            "fieldConfig": {
              "defaults": {
                "unit": "percent",
                "min": 0,
                "max": 100,
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"value": 0, "color": "green"},
                    {"value": 50, "color": "yellow"},
                    {"value": 80, "color": "red"}
                  ]
                }
              }
            }
          }
        ],
        "editable": true,
        "schemaVersion": 38,
        "version": 1
      }
    process-anomaly-detection.json: |
      {
        "id": null,
        "uid": "process-anomaly-detection",
        "title": "ODIN Process Anomaly Detection",
        "tags": ["anomaly", "process", "ml", "security", "odin"],
        "timezone": "America/Los_Angeles",
        "schemaVersion": 38,
        "version": 2,
        "refresh": "30s",
        "time": {
          "from": "now-3h",
          "to": "now"
        },
        "templating": {
          "list": [
            {
              "name": "groupname",
              "type": "query",
              "datasource": "Prometheus",
              "query": "label_values(process_cpu_anomaly_score, groupname)",
              "refresh": 1,
              "includeAll": true,
              "allValue": ".*",
              "multi": true
            },
            {
              "name": "instance",
              "type": "query",
              "datasource": "Prometheus",
              "query": "label_values(process_cpu_anomaly_score, instance)",
              "refresh": 1,
              "includeAll": true,
              "allValue": ".*",
              "multi": true
            },
            {
              "name": "top_n",
              "type": "custom",
              "current": {
                "text": "30",
                "value": "30"
              },
              "options": [
                {"text": "10", "value": "10"},
                {"text": "20", "value": "20"},
                {"text": "30", "value": "30"},
                {"text": "50", "value": "50"},
                {"text": "100", "value": "100"}
              ],
              "query": "10,20,30,50,100",
              "description": "Number of top anomalous processes to display"
            }
          ]
        },
        "panels": [
          {
            "gridPos": {"h": 6, "w": 24, "x": 0, "y": 0},
            "id": 1,
            "type": "text",
            "title": "Process Anomaly Detection Overview",
            "options": {
              "mode": "markdown",
              "content": "# ML-Based Process Anomaly Detection\\n\\nAdvanced process monitoring using **Isolation Forest** machine learning algorithms analyzing top CPU and memory consuming processes.\\n\\n## Detection Areas\\n- **CPU Usage Anomalies**: Unusual CPU consumption patterns\\n- **Memory Usage Anomalies**: Abnormal memory allocation behaviors\\n- **Process Count Anomalies**: Unexpected process scaling\\n- **New Process Detection**: Real-time alerts for unknown processes\\n- **Security Analysis**: Detection of suspicious process behaviors\\n\\n## Anomaly Scores\\n- **1.0** = Normal behavior (green)\\n- **0.5** = Moderate anomaly (yellow)\\n- **0.0** = Severe anomaly requiring investigation (red)\\n\\n## Tips\\n- Use the **top_n** variable to control how many processes to display\\n- Filter by specific process names using the **groupname** selector\\n- The improved dashboard at [Process Anomaly Detection (Improved)](/d/process-anomaly-improved) provides better visualization for large numbers of processes"
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 8, "w": 6, "x": 0, "y": 6},
            "id": 2,
            "type": "stat",
            "title": "Detection Status",
            "targets": [
              {
                "expr": "up{job=\"advanced-process-anomaly-detector\"}",
                "refId": "A"
              }
            ],
            "options": {
              "graphMode": "none",
              "colorMode": "background",
              "justifyMode": "center"
            },
            "fieldConfig": {
              "defaults": {
                "mappings": [
                  {"value": 1, "text": "ACTIVE", "color": "green"},
                  {"value": 0, "text": "DOWN", "color": "red"}
                ],
                "color": {"mode": "thresholds"},
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "green", "value": 1}
                  ]
                }
              }
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 8, "w": 6, "x": 6, "y": 6},
            "id": 3,
            "type": "stat",
            "title": "Processes Analyzed",
            "targets": [
              {
                "expr": "process_anomaly_processes_analyzed_total",
                "refId": "A"
              }
            ],
            "options": {
              "graphMode": "area",
              "colorMode": "value",
              "justifyMode": "center"
            },
            "fieldConfig": {
              "defaults": {
                "color": {"mode": "palette-classic"},
                "unit": "short"
              }
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 8, "w": 6, "x": 12, "y": 6},
            "id": 4,
            "type": "stat",
            "title": "Unique Processes",
            "targets": [
              {
                "expr": "count(count by (groupname) (process_cpu_anomaly_score))",
                "refId": "A"
              }
            ],
            "options": {
              "graphMode": "none",
              "colorMode": "value",
              "justifyMode": "center"
            },
            "fieldConfig": {
              "defaults": {
                "unit": "short",
                "color": {"mode": "palette-classic"}
              }
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 8, "w": 6, "x": 18, "y": 6},
            "id": 5,
            "type": "stat",
            "title": "Anomalous Processes",
            "targets": [
              {
                "expr": "count(process_cpu_anomaly_score < 0.7 or process_memory_anomaly_score < 0.7)",
                "refId": "A"
              }
            ],
            "options": {
              "graphMode": "none",
              "colorMode": "value",
              "justifyMode": "center"
            },
            "fieldConfig": {
              "defaults": {
                "unit": "short",
                "color": {"mode": "thresholds"},
                "thresholds": {
                  "steps": [
                    {"color": "green", "value": 0},
                    {"color": "yellow", "value": 10},
                    {"color": "red", "value": 50}
                  ]
                }
              }
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 12, "w": 24, "x": 0, "y": 14},
            "id": 6,
            "type": "barchart",
            "title": "Top $top_n Most Anomalous Processes (Lower = More Anomalous)",
            "targets": [
              {
                "expr": "bottomk($top_n, (process_cpu_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"} * 100)) and (process_cpu_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"} < 0.8)",
                "legendFormat": "CPU: {{groupname}}",
                "refId": "A"
              },
              {
                "expr": "bottomk($top_n, (process_memory_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"} * 100)) and (process_memory_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"} < 0.8)",
                "legendFormat": "Memory: {{groupname}}",
                "refId": "B"
              }
            ],
            "options": {
              "orientation": "horizontal",
              "displayMode": "gradient",
              "legend": {"displayMode": "table", "placement": "right", "calcs": ["lastNotNull"]},
              "tooltip": {"mode": "multi", "sort": "asc"}
            },
            "fieldConfig": {
              "defaults": {
                "color": {"mode": "continuous-GrYlRd"},
                "custom": {
                  "hideFrom": {"tooltip": false, "vis": false, "legend": false}
                },
                "unit": "percent",
                "min": 0,
                "max": 100,
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "yellow", "value": 30},
                    {"color": "green", "value": 70}
                  ]
                }
              }
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 10, "w": 12, "x": 0, "y": 26},
            "id": 7,
            "type": "timeseries",
            "title": "CPU Usage Anomaly Scores (Top $top_n Most Anomalous)",
            "targets": [
              {
                "expr": "bottomk($top_n, process_cpu_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"}) and (process_cpu_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"} < 0.8)",
                "legendFormat": "{{groupname}}",
                "refId": "A"
              }
            ],
            "options": {
              "legend": {"displayMode": "table", "placement": "right", "calcs": ["lastNotNull", "min"]},
              "tooltip": {"mode": "multi", "sort": "asc"}
            },
            "fieldConfig": {
              "defaults": {
                "color": {"mode": "palette-classic"},
                "custom": {
                  "drawStyle": "line",
                  "lineInterpolation": "smooth",
                  "lineWidth": 2,
                  "fillOpacity": 15,
                  "pointSize": 4
                },
                "unit": "percentunit",
                "min": 0,
                "max": 1,
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "yellow", "value": 0.3},
                    {"color": "green", "value": 0.7}
                  ]
                }
              }
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 10, "w": 12, "x": 12, "y": 26},
            "id": 8,
            "type": "timeseries",
            "title": "Memory Usage Anomaly Scores (Top $top_n Most Anomalous)",
            "targets": [
              {
                "expr": "bottomk($top_n, process_memory_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"}) and (process_memory_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"} < 0.8)",
                "legendFormat": "{{groupname}}",
                "refId": "A"
              }
            ],
            "options": {
              "legend": {"displayMode": "table", "placement": "right", "calcs": ["lastNotNull", "min"]},
              "tooltip": {"mode": "multi", "sort": "asc"}
            },
            "fieldConfig": {
              "defaults": {
                "color": {"mode": "palette-classic"},
                "custom": {
                  "drawStyle": "line",
                  "lineInterpolation": "smooth",
                  "lineWidth": 2,
                  "fillOpacity": 15,
                  "pointSize": 4
                },
                "unit": "percentunit",
                "min": 0,
                "max": 1,
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "yellow", "value": 0.3},
                    {"color": "green", "value": 0.7}
                  ]
                }
              }
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 10, "w": 24, "x": 0, "y": 36},
            "id": 9,
            "type": "state-timeline",
            "title": "Process Anomaly State Timeline (Top $top_n)",
            "targets": [
              {
                "expr": "bottomk($top_n, process_cpu_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"} < 0.8)",
                "format": "time_series",
                "refId": "A"
              }
            ],
            "options": {
              "legend": {
                "displayMode": "list",
                "placement": "bottom",
                "showLegend": true
              },
              "tooltip": {
                "mode": "single",
                "sort": "none"
              },
              "timezone": ["browser"],
              "rowHeight": 0.9
            },
            "fieldConfig": {
              "defaults": {
                "custom": {
                  "lineWidth": 0,
                  "fillOpacity": 70,
                  "spanNulls": false,
                  "insertNulls": false,
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  }
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "orange", "value": 0.3},
                    {"color": "yellow", "value": 0.5},
                    {"color": "green", "value": 0.7}
                  ]
                },
                "unit": "percentunit",
                "min": 0,
                "max": 1
              }
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 12, "w": 24, "x": 0, "y": 46},
            "id": 10,
            "type": "table",
            "title": "Detailed Anomalous Process Analysis (Top $top_n)",
            "targets": [
              {
                "expr": "bottomk($top_n, process_cpu_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"} < 0.8)",
                "format": "table",
                "instant": true,
                "refId": "A"
              },
              {
                "expr": "bottomk($top_n, process_memory_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"} < 0.8)",
                "format": "table",
                "instant": true,
                "refId": "B"
              },
              {
                "expr": "bottomk($top_n, process_count_anomaly_score{groupname=~\"$groupname\", instance=~\"$instance\"} < 0.8)",
                "format": "table",
                "instant": true,
                "refId": "C"
              }
            ],
            "transformations": [
              {
                "id": "merge",
                "options": {}
              },
              {
                "id": "organize",
                "options": {
                  "excludeByName": {
                    "Time": true,
                    "__name__": true,
                    "job": true
                  },
                  "indexByName": {},
                  "renameByName": {
                    "Value #A": "CPU Anomaly Score",
                    "Value #B": "Memory Anomaly Score",
                    "Value #C": "Count Anomaly Score",
                    "groupname": "Process Group",
                    "instance": "Instance",
                    "type": "Alert Type"
                  }
                }
              }
            ],
            "fieldConfig": {
              "defaults": {
                "custom": {
                  "align": "center",
                  "filterable": true,
                  "sortBy": [{"desc": false, "displayName": "CPU Anomaly Score"}]
                },
                "unit": "percentunit",
                "min": 0,
                "max": 1,
                "color": {"mode": "thresholds"},
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "yellow", "value": 0.3},
                    {"color": "green", "value": 0.7}
                  ]
                }
              },
              "overrides": [
                {
                  "matcher": {"id": "byName", "options": "Alert Rate"},
                  "properties": [
                    {"id": "unit", "value": "reqps"},
                    {"id": "min", "value": 0},
                    {"id": "max"},
                    {"id": "color", "value": {"mode": "thresholds"}},
                    {
                      "id": "thresholds",
                      "value": {
                        "steps": [
                          {"color": "green", "value": 0},
                          {"color": "yellow", "value": 0.1},
                          {"color": "red", "value": 0.5}
                        ]
                      }
                    }
                  ]
                }
              ]
            },
            "options": {
              "showHeader": true,
              "sortBy": [{"desc": false, "displayName": "CPU Anomaly Score"}]
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 10, "w": 12, "x": 0, "y": 58},
            "id": 11,
            "type": "timeseries",
            "title": "New Process Detection Rate",
            "targets": [
              {
                "expr": "rate(process_new_process_detected_total{groupname=~\"$groupname\", instance=~\"$instance\"}[5m])",
                "legendFormat": "{{groupname}}",
                "refId": "A"
              }
            ],
            "options": {
              "legend": {"displayMode": "table", "placement": "right", "calcs": ["lastNotNull", "max"]},
              "tooltip": {"mode": "multi", "sort": "desc"}
            },
            "fieldConfig": {
              "defaults": {
                "color": {"mode": "palette-classic"},
                "custom": {
                  "drawStyle": "line",
                  "lineInterpolation": "smooth",
                  "lineWidth": 2,
                  "fillOpacity": 10,
                  "pointSize": 3
                },
                "unit": "reqps",
                "min": 0
              }
            }
          },
          {
            "datasource": "Prometheus",
            "gridPos": {"h": 10, "w": 12, "x": 12, "y": 58},
            "id": 12,
            "type": "timeseries",
            "title": "Security Process Alerts (Suspicious Patterns)",
            "targets": [
              {
                "expr": "rate(process_anomaly_alerts_total{type=~\"cpu_anomaly|memory_anomaly\", groupname=~\".*crypto.*|.*miner.*|.*coin.*|.*hash.*|.*bash.*|.*sh.*|.*nc.*|.*netcat.*|.*wget.*|.*curl.*\"}[5m])",
                "legendFormat": "{{groupname}} - {{type}}",
                "refId": "A"
              }
            ],
            "options": {
              "legend": {"displayMode": "table", "placement": "right", "calcs": ["lastNotNull", "max"]},
              "tooltip": {"mode": "multi", "sort": "desc"}
            },
            "fieldConfig": {
              "defaults": {
                "color": {"mode": "palette-classic"},
                "custom": {
                  "drawStyle": "bars",
                  "lineInterpolation": "smooth",
                  "lineWidth": 2,
                  "fillOpacity": 50,
                  "pointSize": 5
                },
                "unit": "reqps",
                "min": 0
              }
            }
          }
        ]
      }
    process-anomaly-improved.json: |
      {
        "uid": "process-anomaly-improved",
        "title": "ODIN Process Anomaly Detection (Improved)",
        "tags": ["anomaly", "process", "ml", "security", "odin", "improved"],
        "timezone": "America/Los_Angeles",
        "schemaVersion": 38,
        "version": 1,
        "refresh": "30s",
        "editable": true,
        "time": {
          "from": "now-3h",
          "to": "now"
        },
        "templating": {
          "list": [
            {
              "name": "top_n",
              "type": "custom",
              "current": {
                "text": "30",
                "value": "30"
              },
              "options": [
                {"text": "10", "value": "10"},
                {"text": "20", "value": "20"},
                {"text": "30", "value": "30"},
                {"text": "50", "value": "50"},
                {"text": "100", "value": "100"}
              ],
              "query": "10,20,30,50,100",
              "description": "Number of top anomalous processes to show"
            }
          ]
        },
        "panels": [
          {
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 0},
            "id": 1,
            "type": "barchart",
            "title": "Top $top_n Most Anomalous Processes",
            "datasource": "Prometheus",
            "targets": [
              {
                "expr": "bottomk($top_n, min by (groupname) (process_cpu_anomaly_score < 0.8 or process_memory_anomaly_score < 0.8))",
                "legendFormat": "{{groupname}}",
                "refId": "A"
              }
            ],
            "options": {
              "orientation": "horizontal",
              "displayMode": "gradient",
              "showValue": "always",
              "legend": {
                "displayMode": "hidden"
              }
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "continuous-GrYlRd"
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "yellow", "value": 0.3},
                    {"color": "green", "value": 0.7}
                  ]
                },
                "unit": "percentunit",
                "min": 0,
                "max": 1
              }
            }
          },
          {
            "gridPos": {"h": 10, "w": 12, "x": 0, "y": 8},
            "id": 2,
            "type": "timeseries",
            "title": "CPU Anomaly Trends (Top $top_n)",
            "datasource": "Prometheus",
            "targets": [
              {
                "expr": "bottomk($top_n, process_cpu_anomaly_score < 0.8)",
                "legendFormat": "{{groupname}}",
                "refId": "A"
              }
            ],
            "options": {
              "tooltip": {"mode": "multi"},
              "legend": {"displayMode": "table", "placement": "right", "calcs": ["lastNotNull", "min"]}
            },
            "fieldConfig": {
              "defaults": {
                "color": {"mode": "palette-classic"},
                "custom": {
                  "drawStyle": "line",
                  "lineInterpolation": "smooth",
                  "lineWidth": 2,
                  "fillOpacity": 10,
                  "pointSize": 3
                },
                "unit": "percentunit",
                "min": 0,
                "max": 1,
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "yellow", "value": 0.3},
                    {"color": "green", "value": 0.7}
                  ]
                }
              }
            }
          },
          {
            "gridPos": {"h": 10, "w": 12, "x": 12, "y": 8},
            "id": 3,
            "type": "timeseries",
            "title": "Memory Anomaly Trends (Top $top_n)",
            "datasource": "Prometheus",
            "targets": [
              {
                "expr": "bottomk($top_n, process_memory_anomaly_score < 0.8)",
                "legendFormat": "{{groupname}}",
                "refId": "A"
              }
            ],
            "options": {
              "tooltip": {"mode": "multi"},
              "legend": {"displayMode": "table", "placement": "right", "calcs": ["lastNotNull", "min"]}
            },
            "fieldConfig": {
              "defaults": {
                "color": {"mode": "palette-classic"},
                "custom": {
                  "drawStyle": "line",
                  "lineInterpolation": "smooth",
                  "lineWidth": 2,
                  "fillOpacity": 10,
                  "pointSize": 3
                },
                "unit": "percentunit",
                "min": 0,
                "max": 1,
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "yellow", "value": 0.3},
                    {"color": "green", "value": 0.7}
                  ]
                }
              }
            }
          },
          {
            "gridPos": {"h": 10, "w": 24, "x": 0, "y": 18},
            "id": 4,
            "type": "state-timeline",
            "title": "Process Anomaly State Timeline (Top $top_n)",
            "datasource": "Prometheus",
            "targets": [
              {
                "expr": "bottomk($top_n, process_cpu_anomaly_score < 0.8)",
                "refId": "A"
              }
            ],
            "options": {
              "legend": {
                "displayMode": "list",
                "placement": "bottom",
                "showLegend": true
              },
              "tooltip": {
                "mode": "single"
              },
              "rowHeight": 0.9
            },
            "fieldConfig": {
              "defaults": {
                "custom": {
                  "lineWidth": 0,
                  "fillOpacity": 70,
                  "spanNulls": false
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "orange", "value": 0.3},
                    {"color": "yellow", "value": 0.5},
                    {"color": "green", "value": 0.7}
                  ]
                },
                "unit": "percentunit",
                "min": 0,
                "max": 1
              }
            }
          },
          {
            "gridPos": {"h": 10, "w": 24, "x": 0, "y": 28},
            "id": 5,
            "type": "table",
            "title": "Anomaly Score Details (Sortable)",
            "datasource": "Prometheus",
            "targets": [
              {
                "expr": "process_cpu_anomaly_score < 0.9",
                "format": "table",
                "instant": true,
                "refId": "A"
              },
              {
                "expr": "process_memory_anomaly_score < 0.9",
                "format": "table",
                "instant": true,
                "refId": "B"
              }
            ],
            "transformations": [
              {
                "id": "merge"
              },
              {
                "id": "organize",
                "options": {
                  "excludeByName": {
                    "Time": true,
                    "__name__": true,
                    "job": true
                  },
                  "renameByName": {
                    "Value #A": "CPU Score",
                    "Value #B": "Memory Score",
                    "groupname": "Process",
                    "instance": "Host"
                  }
                }
              }
            ],
            "options": {
              "showHeader": true,
              "sortBy": [{"desc": false, "displayName": "CPU Score"}]
            },
            "fieldConfig": {
              "defaults": {
                "custom": {
                  "align": "center",
                  "displayMode": "color-background-solid",
                  "filterable": true
                },
                "unit": "percentunit",
                "min": 0,
                "max": 1,
                "color": {"mode": "thresholds"},
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "yellow", "value": 0.3},
                    {"color": "green", "value": 0.7}
                  ]
                }
              }
            }
          }
        ]
      }
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"ml-anomaly-detection.json":"{\n  \"uid\": \"ml-anomaly-detection\",\n  \"title\": \"ODIN ML Anomaly Detection\",\n  \"tags\": [\"odin\", \"ml\", \"anomaly-detection\"],\n  \"timezone\": \"America/Los_Angeles\",\n  \"refresh\": \"30s\",\n  \"panels\": [\n    {\n      \"gridPos\": {\"h\": 1, \"w\": 24, \"x\": 0, \"y\": 0},\n      \"id\": 1,\n      \"type\": \"row\",\n      \"title\": \"Anomaly Detector Status\",\n      \"collapsed\": false\n    },\n    {\n      \"gridPos\": {\"h\": 4, \"w\": 6, \"x\": 0, \"y\": 1},\n      \"id\": 2,\n      \"type\": \"stat\",\n      \"title\": \"GPU Anomaly Detector\",\n      \"targets\": [\n        {\n          \"expr\": \"up{job=\\\"gpu-anomaly-detector\\\"}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"graphMode\": \"none\",\n        \"colorMode\": \"background\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"]\n        }\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"mappings\": [\n            {\"type\": \"value\", \"value\": 1, \"text\": \"UP\", \"color\": \"green\"},\n            {\"type\": \"value\", \"value\": 0, \"text\": \"DOWN\", \"color\": \"red\"}\n          ],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"value\": 0, \"color\": \"red\"},\n              {\"value\": 1, \"color\": \"green\"}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"gridPos\": {\"h\": 4, \"w\": 6, \"x\": 6, \"y\": 1},\n      \"id\": 3,\n      \"type\": \"stat\",\n      \"title\": \"Process Anomaly Detector\",\n      \"targets\": [\n        {\n          \"expr\": \"up{job=\\\"process-anomaly-detector\\\"}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"graphMode\": \"none\",\n        \"colorMode\": \"background\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"]\n        }\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"mappings\": [\n            {\"type\": \"value\", \"value\": 1, \"text\": \"UP\", \"color\": \"green\"},\n            {\"type\": \"value\", \"value\": 0, \"text\": \"DOWN\", \"color\": \"red\"}\n          ],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"value\": 0, \"color\": \"red\"},\n              {\"value\": 1, \"color\": \"green\"}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"gridPos\": {\"h\": 4, \"w\": 6, \"x\": 12, \"y\": 1},\n      \"id\": 4,\n      \"type\": \"stat\",\n      \"title\": \"K8s Pod Anomaly Detector\",\n      \"targets\": [\n        {\n          \"expr\": \"up{job=\\\"k8s-pod-anomaly-detector\\\"}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"graphMode\": \"none\",\n        \"colorMode\": \"background\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"]\n        }\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"mappings\": [\n            {\"type\": \"value\", \"value\": 1, \"text\": \"UP\", \"color\": \"green\"},\n            {\"type\": \"value\", \"value\": 0, \"text\": \"DOWN\", \"color\": \"red\"}\n          ],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"value\": 0, \"color\": \"red\"},\n              {\"value\": 1, \"color\": \"green\"}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"gridPos\": {\"h\": 4, \"w\": 6, \"x\": 18, \"y\": 1},\n      \"id\": 5,\n      \"type\": \"stat\",\n      \"title\": \"Disk Anomaly Detector\",\n      \"targets\": [\n        {\n          \"expr\": \"up{job=\\\"disk-anomaly-detector\\\"}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"graphMode\": \"none\",\n        \"colorMode\": \"background\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"]\n        }\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"mappings\": [\n            {\"type\": \"value\", \"value\": 1, \"text\": \"UP\", \"color\": \"green\"},\n            {\"type\": \"value\", \"value\": 0, \"text\": \"DOWN\", \"color\": \"red\"}\n          ],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"value\": 0, \"color\": \"red\"},\n              {\"value\": 1, \"color\": \"green\"}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"gridPos\": {\"h\": 1, \"w\": 24, \"x\": 0, \"y\": 5},\n      \"id\": 6,\n      \"type\": \"row\",\n      \"title\": \"GPU Anomaly Scores\",\n      \"collapsed\": false\n    },\n    {\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 6},\n      \"id\": 7,\n      \"type\": \"timeseries\",\n      \"title\": \"GPU Temperature Anomaly Score\",\n      \"targets\": [\n        {\n          \"expr\": \"gpu_anomaly_score{metric_name=\\\"nvidia_gpu_temperature_celsius\\\"}\",\n          \"legendFormat\": \"GPU {{gpu}} Temperature\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"tooltip\": {\"mode\": \"multi\"},\n        \"legend\": {\"displayMode\": \"list\", \"placement\": \"bottom\"}\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"percent\",\n          \"min\": 0,\n          \"max\": 100,\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"value\": 0, \"color\": \"green\"},\n              {\"value\": 50, \"color\": \"yellow\"},\n              {\"value\": 80, \"color\": \"red\"}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 6},\n      \"id\": 8,\n      \"type\": \"timeseries\",\n      \"title\": \"GPU Power Anomaly Score\",\n      \"targets\": [\n        {\n          \"expr\": \"gpu_anomaly_score{metric_name=\\\"node_gpu_power_watts\\\"}\",\n          \"legendFormat\": \"GPU {{gpu}} Power\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"tooltip\": {\"mode\": \"multi\"},\n        \"legend\": {\"displayMode\": \"list\", \"placement\": \"bottom\"}\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"percent\",\n          \"min\": 0,\n          \"max\": 100,\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"value\": 0, \"color\": \"green\"},\n              {\"value\": 50, \"color\": \"yellow\"},\n              {\"value\": 80, \"color\": \"red\"}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"gridPos\": {\"h\": 1, \"w\": 24, \"x\": 0, \"y\": 14},\n      \"id\": 9,\n      \"type\": \"row\",\n      \"title\": \"Process Anomaly Scores\",\n      \"collapsed\": false\n    },\n    {\n      \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 15},\n      \"id\": 10,\n      \"type\": \"timeseries\",\n      \"title\": \"Process Anomaly Scores\",\n      \"targets\": [\n        {\n          \"expr\": \"topk(10, process_anomaly_score)\",\n          \"legendFormat\": \"{{process_name}} - {{metric_type}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"tooltip\": {\"mode\": \"multi\"},\n        \"legend\": {\"displayMode\": \"table\", \"placement\": \"right\"}\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"percent\",\n          \"min\": 0,\n          \"max\": 100,\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"value\": 0, \"color\": \"green\"},\n              {\"value\": 50, \"color\": \"yellow\"},\n              {\"value\": 80, \"color\": \"red\"}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"gridPos\": {\"h\": 1, \"w\": 24, \"x\": 0, \"y\": 23},\n      \"id\": 11,\n      \"type\": \"row\",\n      \"title\": \"Disk Anomaly Scores\",\n      \"collapsed\": false\n    },\n    {\n      \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 24},\n      \"id\": 12,\n      \"type\": \"timeseries\",\n      \"title\": \"Disk Space Anomaly Scores\",\n      \"targets\": [\n        {\n          \"expr\": \"disk_anomaly_score\",\n          \"legendFormat\": \"{{mountpoint}} - {{device}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"tooltip\": {\"mode\": \"multi\"},\n        \"legend\": {\"displayMode\": \"table\", \"placement\": \"right\"}\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"percent\",\n          \"min\": 0,\n          \"max\": 100,\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"value\": 0, \"color\": \"green\"},\n              {\"value\": 50, \"color\": \"yellow\"},\n              {\"value\": 80, \"color\": \"red\"}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"gridPos\": {\"h\": 1, \"w\": 24, \"x\": 0, \"y\": 32},\n      \"id\": 13,\n      \"type\": \"row\",\n      \"title\": \"Pod Anomaly Scores\",\n      \"collapsed\": false\n    },\n    {\n      \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 33},\n      \"id\": 14,\n      \"type\": \"timeseries\",\n      \"title\": \"K8s Pod Anomaly Scores\",\n      \"targets\": [\n        {\n          \"expr\": \"topk(10, pod_anomaly_score)\",\n          \"legendFormat\": \"{{namespace}}/{{pod}} - {{metric_type}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"tooltip\": {\"mode\": \"multi\"},\n        \"legend\": {\"displayMode\": \"table\", \"placement\": \"right\"}\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"percent\",\n          \"min\": 0,\n          \"max\": 100,\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"value\": 0, \"color\": \"green\"},\n              {\"value\": 50, \"color\": \"yellow\"},\n              {\"value\": 80, \"color\": \"red\"}\n            ]\n          }\n        }\n      }\n    }\n  ],\n  \"editable\": true,\n  \"schemaVersion\": 38,\n  \"version\": 1\n}\n","process-anomaly-detection.json":"{\n  \"id\": null,\n  \"uid\": \"process-anomaly-detection\",\n  \"title\": \"ODIN Process Anomaly Detection\",\n  \"tags\": [\"anomaly\", \"process\", \"ml\", \"security\", \"odin\"],\n  \"timezone\": \"America/Los_Angeles\",\n  \"schemaVersion\": 38,\n  \"version\": 2,\n  \"refresh\": \"30s\",\n  \"time\": {\n    \"from\": \"now-3h\",\n    \"to\": \"now\"\n  },\n  \"templating\": {\n    \"list\": [\n      {\n        \"name\": \"groupname\",\n        \"type\": \"query\",\n        \"datasource\": \"Prometheus\",\n        \"query\": \"label_values(process_cpu_anomaly_score, groupname)\",\n        \"refresh\": 1,\n        \"includeAll\": true,\n        \"allValue\": \".*\",\n        \"multi\": true\n      },\n      {\n        \"name\": \"instance\",\n        \"type\": \"query\",\n        \"datasource\": \"Prometheus\",\n        \"query\": \"label_values(process_cpu_anomaly_score, instance)\",\n        \"refresh\": 1,\n        \"includeAll\": true,\n        \"allValue\": \".*\",\n        \"multi\": true\n      },\n      {\n        \"name\": \"top_n\",\n        \"type\": \"custom\",\n        \"current\": {\n          \"text\": \"30\",\n          \"value\": \"30\"\n        },\n        \"options\": [\n          {\"text\": \"10\", \"value\": \"10\"},\n          {\"text\": \"20\", \"value\": \"20\"},\n          {\"text\": \"30\", \"value\": \"30\"},\n          {\"text\": \"50\", \"value\": \"50\"},\n          {\"text\": \"100\", \"value\": \"100\"}\n        ],\n        \"query\": \"10,20,30,50,100\",\n        \"description\": \"Number of top anomalous processes to display\"\n      }\n    ]\n  },\n  \"panels\": [\n    {\n      \"gridPos\": {\"h\": 6, \"w\": 24, \"x\": 0, \"y\": 0},\n      \"id\": 1,\n      \"type\": \"text\",\n      \"title\": \"Process Anomaly Detection Overview\",\n      \"options\": {\n        \"mode\": \"markdown\",\n        \"content\": \"# ML-Based Process Anomaly Detection\\\\n\\\\nAdvanced process monitoring using **Isolation Forest** machine learning algorithms analyzing top CPU and memory consuming processes.\\\\n\\\\n## Detection Areas\\\\n- **CPU Usage Anomalies**: Unusual CPU consumption patterns\\\\n- **Memory Usage Anomalies**: Abnormal memory allocation behaviors\\\\n- **Process Count Anomalies**: Unexpected process scaling\\\\n- **New Process Detection**: Real-time alerts for unknown processes\\\\n- **Security Analysis**: Detection of suspicious process behaviors\\\\n\\\\n## Anomaly Scores\\\\n- **1.0** = Normal behavior (green)\\\\n- **0.5** = Moderate anomaly (yellow)\\\\n- **0.0** = Severe anomaly requiring investigation (red)\\\\n\\\\n## Tips\\\\n- Use the **top_n** variable to control how many processes to display\\\\n- Filter by specific process names using the **groupname** selector\\\\n- The improved dashboard at [Process Anomaly Detection (Improved)](/d/process-anomaly-improved) provides better visualization for large numbers of processes\"\n      }\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"gridPos\": {\"h\": 8, \"w\": 6, \"x\": 0, \"y\": 6},\n      \"id\": 2,\n      \"type\": \"stat\",\n      \"title\": \"Detection Status\",\n      \"targets\": [\n        {\n          \"expr\": \"up{job=\\\"advanced-process-anomaly-detector\\\"}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"graphMode\": \"none\",\n        \"colorMode\": \"background\",\n        \"justifyMode\": \"center\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"mappings\": [\n            {\"value\": 1, \"text\": \"ACTIVE\", \"color\": \"green\"},\n            {\"value\": 0, \"text\": \"DOWN\", \"color\": \"red\"}\n          ],\n          \"color\": {\"mode\": \"thresholds\"},\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"red\", \"value\": 0},\n              {\"color\": \"green\", \"value\": 1}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"gridPos\": {\"h\": 8, \"w\": 6, \"x\": 6, \"y\": 6},\n      \"id\": 3,\n      \"type\": \"stat\",\n      \"title\": \"Processes Analyzed\",\n      \"targets\": [\n        {\n          \"expr\": \"process_anomaly_processes_analyzed_total\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"graphMode\": \"area\",\n        \"colorMode\": \"value\",\n        \"justifyMode\": \"center\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"unit\": \"short\"\n        }\n      }\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"gridPos\": {\"h\": 8, \"w\": 6, \"x\": 12, \"y\": 6},\n      \"id\": 4,\n      \"type\": \"stat\",\n      \"title\": \"Unique Processes\",\n      \"targets\": [\n        {\n          \"expr\": \"count(count by (groupname) (process_cpu_anomaly_score))\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"graphMode\": \"none\",\n        \"colorMode\": \"value\",\n        \"justifyMode\": \"center\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"color\": {\"mode\": \"palette-classic\"}\n        }\n      }\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"gridPos\": {\"h\": 8, \"w\": 6, \"x\": 18, \"y\": 6},\n      \"id\": 5,\n      \"type\": \"stat\",\n      \"title\": \"Anomalous Processes\",\n      \"targets\": [\n        {\n          \"expr\": \"count(process_cpu_anomaly_score \u003c 0.7 or process_memory_anomaly_score \u003c 0.7)\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"graphMode\": \"none\",\n        \"colorMode\": \"value\",\n        \"justifyMode\": \"center\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"color\": {\"mode\": \"thresholds\"},\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"green\", \"value\": 0},\n              {\"color\": \"yellow\", \"value\": 10},\n              {\"color\": \"red\", \"value\": 50}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"gridPos\": {\"h\": 12, \"w\": 24, \"x\": 0, \"y\": 14},\n      \"id\": 6,\n      \"type\": \"barchart\",\n      \"title\": \"Top $top_n Most Anomalous Processes (Lower = More Anomalous)\",\n      \"targets\": [\n        {\n          \"expr\": \"bottomk($top_n, (process_cpu_anomaly_score{groupname=~\\\"$groupname\\\", instance=~\\\"$instance\\\"} * 100)) and (process_cpu_anomaly_score{groupname=~\\\"$groupname\\\", instance=~\\\"$instance\\\"} \u003c 0.8)\",\n          \"legendFormat\": \"CPU: {{groupname}}\",\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"bottomk($top_n, (process_memory_anomaly_score{groupname=~\\\"$groupname\\\", instance=~\\\"$instance\\\"} * 100)) and (process_memory_anomaly_score{groupname=~\\\"$groupname\\\", instance=~\\\"$instance\\\"} \u003c 0.8)\",\n          \"legendFormat\": \"Memory: {{groupname}}\",\n          \"refId\": \"B\"\n        }\n      ],\n      \"options\": {\n        \"orientation\": \"horizontal\",\n        \"displayMode\": \"gradient\",\n        \"legend\": {\"displayMode\": \"table\", \"placement\": \"right\", \"calcs\": [\"lastNotNull\"]},\n        \"tooltip\": {\"mode\": \"multi\", \"sort\": \"asc\"}\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\"mode\": \"continuous-GrYlRd\"},\n          \"custom\": {\n            \"hideFrom\": {\"tooltip\": false, \"vis\": false, \"legend\": false}\n          },\n          \"unit\": \"percent\",\n          \"min\": 0,\n          \"max\": 100,\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"color\": \"red\", \"value\": 0},\n              {\"color\": \"yellow\", \"value\": 30},\n              {\"color\": \"green\", \"value\": 70}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"gridPos\": {\"h\": 10, \"w\": 12, \"x\": 0, \"y\": 26},\n      \"id\": 7,\n      \"type\": \"timeseries\",\n      \"title\": \"CPU Usage Anomaly Scores (Top $top_n Most Anomalous)\",\n      \"targets\": [\n        {\n          \"expr\": \"bottomk($top_n, process_cpu_anomaly_score{groupname=~\\\"$groupname\\\", instance=~\\\"$instance\\\"}) and (process_cpu_anomaly_score{groupname=~\\\"$groupname\\\", instance=~\\\"$instance\\\"} \u003c 0.8)\",\n          \"legendFormat\": \"{{groupname}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"legend\": {\"displayMode\": \"table\", \"placement\": \"right\", \"calcs\": [\"lastNotNull\", \"min\"]},\n        \"tooltip\": {\"mode\": \"multi\", \"sort\": \"asc\"}\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"drawStyle\": \"line\",\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 15,\n            \"pointSize\": 4\n          },\n          \"unit\": \"percentunit\",\n          \"min\": 0,\n          \"max\": 1,\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"red\", \"value\": 0},\n              {\"color\": \"yellow\", \"value\": 0.3},\n              {\"color\": \"green\", \"value\": 0.7}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"gridPos\": {\"h\": 10, \"w\": 12, \"x\": 12, \"y\": 26},\n      \"id\": 8,\n      \"type\": \"timeseries\",\n      \"title\": \"Memory Usage Anomaly Scores (Top $top_n Most Anomalous)\",\n      \"targets\": [\n        {\n          \"expr\": \"bottomk($top_n, process_memory_anomaly_score{groupname=~\\\"$groupname\\\", instance=~\\\"$instance\\\"}) and (process_memory_anomaly_score{groupname=~\\\"$groupname\\\", instance=~\\\"$instance\\\"} \u003c 0.8)\",\n          \"legendFormat\": \"{{groupname}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"legend\": {\"displayMode\": \"table\", \"placement\": \"right\", \"calcs\": [\"lastNotNull\", \"min\"]},\n        \"tooltip\": {\"mode\": \"multi\", \"sort\": \"asc\"}\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"drawStyle\": \"line\",\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 15,\n            \"pointSize\": 4\n          },\n          \"unit\": \"percentunit\",\n          \"min\": 0,\n          \"max\": 1,\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"red\", \"value\": 0},\n              {\"color\": \"yellow\", \"value\": 0.3},\n              {\"color\": \"green\", \"value\": 0.7}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"gridPos\": {\"h\": 10, \"w\": 24, \"x\": 0, \"y\": 36},\n      \"id\": 9,\n      \"type\": \"state-timeline\",\n      \"title\": \"Process Anomaly State Timeline (Top $top_n)\",\n      \"targets\": [\n        {\n          \"expr\": \"bottomk($top_n, process_cpu_anomaly_score{groupname=~\\\"$groupname\\\", instance=~\\\"$instance\\\"} \u003c 0.8)\",\n          \"format\": \"time_series\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"legend\": {\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\",\n          \"showLegend\": true\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        },\n        \"timezone\": [\"browser\"],\n        \"rowHeight\": 0.9\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"custom\": {\n            \"lineWidth\": 0,\n            \"fillOpacity\": 70,\n            \"spanNulls\": false,\n            \"insertNulls\": false,\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"color\": \"red\", \"value\": 0},\n              {\"color\": \"orange\", \"value\": 0.3},\n              {\"color\": \"yellow\", \"value\": 0.5},\n              {\"color\": \"green\", \"value\": 0.7}\n            ]\n          },\n          \"unit\": \"percentunit\",\n          \"min\": 0,\n          \"max\": 1\n        }\n      }\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"gridPos\": {\"h\": 12, \"w\": 24, \"x\": 0, \"y\": 46},\n      \"id\": 10,\n      \"type\": \"table\",\n      \"title\": \"Detailed Anomalous Process Analysis (Top $top_n)\",\n      \"targets\": [\n        {\n          \"expr\": \"bottomk($top_n, process_cpu_anomaly_score{groupname=~\\\"$groupname\\\", instance=~\\\"$instance\\\"} \u003c 0.8)\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"bottomk($top_n, process_memory_anomaly_score{groupname=~\\\"$groupname\\\", instance=~\\\"$instance\\\"} \u003c 0.8)\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"B\"\n        },\n        {\n          \"expr\": \"bottomk($top_n, process_count_anomaly_score{groupname=~\\\"$groupname\\\", instance=~\\\"$instance\\\"} \u003c 0.8)\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"C\"\n        }\n      ],\n      \"transformations\": [\n        {\n          \"id\": \"merge\",\n          \"options\": {}\n        },\n        {\n          \"id\": \"organize\",\n          \"options\": {\n            \"excludeByName\": {\n              \"Time\": true,\n              \"__name__\": true,\n              \"job\": true\n            },\n            \"indexByName\": {},\n            \"renameByName\": {\n              \"Value #A\": \"CPU Anomaly Score\",\n              \"Value #B\": \"Memory Anomaly Score\",\n              \"Value #C\": \"Count Anomaly Score\",\n              \"groupname\": \"Process Group\",\n              \"instance\": \"Instance\",\n              \"type\": \"Alert Type\"\n            }\n          }\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"custom\": {\n            \"align\": \"center\",\n            \"filterable\": true,\n            \"sortBy\": [{\"desc\": false, \"displayName\": \"CPU Anomaly Score\"}]\n          },\n          \"unit\": \"percentunit\",\n          \"min\": 0,\n          \"max\": 1,\n          \"color\": {\"mode\": \"thresholds\"},\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"red\", \"value\": 0},\n              {\"color\": \"yellow\", \"value\": 0.3},\n              {\"color\": \"green\", \"value\": 0.7}\n            ]\n          }\n        },\n        \"overrides\": [\n          {\n            \"matcher\": {\"id\": \"byName\", \"options\": \"Alert Rate\"},\n            \"properties\": [\n              {\"id\": \"unit\", \"value\": \"reqps\"},\n              {\"id\": \"min\", \"value\": 0},\n              {\"id\": \"max\"},\n              {\"id\": \"color\", \"value\": {\"mode\": \"thresholds\"}},\n              {\n                \"id\": \"thresholds\",\n                \"value\": {\n                  \"steps\": [\n                    {\"color\": \"green\", \"value\": 0},\n                    {\"color\": \"yellow\", \"value\": 0.1},\n                    {\"color\": \"red\", \"value\": 0.5}\n                  ]\n                }\n              }\n            ]\n          }\n        ]\n      },\n      \"options\": {\n        \"showHeader\": true,\n        \"sortBy\": [{\"desc\": false, \"displayName\": \"CPU Anomaly Score\"}]\n      }\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"gridPos\": {\"h\": 10, \"w\": 12, \"x\": 0, \"y\": 58},\n      \"id\": 11,\n      \"type\": \"timeseries\",\n      \"title\": \"New Process Detection Rate\",\n      \"targets\": [\n        {\n          \"expr\": \"rate(process_new_process_detected_total{groupname=~\\\"$groupname\\\", instance=~\\\"$instance\\\"}[5m])\",\n          \"legendFormat\": \"{{groupname}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"legend\": {\"displayMode\": \"table\", \"placement\": \"right\", \"calcs\": [\"lastNotNull\", \"max\"]},\n        \"tooltip\": {\"mode\": \"multi\", \"sort\": \"desc\"}\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"drawStyle\": \"line\",\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 10,\n            \"pointSize\": 3\n          },\n          \"unit\": \"reqps\",\n          \"min\": 0\n        }\n      }\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"gridPos\": {\"h\": 10, \"w\": 12, \"x\": 12, \"y\": 58},\n      \"id\": 12,\n      \"type\": \"timeseries\",\n      \"title\": \"Security Process Alerts (Suspicious Patterns)\",\n      \"targets\": [\n        {\n          \"expr\": \"rate(process_anomaly_alerts_total{type=~\\\"cpu_anomaly|memory_anomaly\\\", groupname=~\\\".*crypto.*|.*miner.*|.*coin.*|.*hash.*|.*bash.*|.*sh.*|.*nc.*|.*netcat.*|.*wget.*|.*curl.*\\\"}[5m])\",\n          \"legendFormat\": \"{{groupname}} - {{type}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"legend\": {\"displayMode\": \"table\", \"placement\": \"right\", \"calcs\": [\"lastNotNull\", \"max\"]},\n        \"tooltip\": {\"mode\": \"multi\", \"sort\": \"desc\"}\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"drawStyle\": \"bars\",\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 50,\n            \"pointSize\": 5\n          },\n          \"unit\": \"reqps\",\n          \"min\": 0\n        }\n      }\n    }\n  ]\n}\n","process-anomaly-improved.json":"{\n  \"uid\": \"process-anomaly-improved\",\n  \"title\": \"ODIN Process Anomaly Detection (Improved)\",\n  \"tags\": [\"anomaly\", \"process\", \"ml\", \"security\", \"odin\", \"improved\"],\n  \"timezone\": \"America/Los_Angeles\",\n  \"schemaVersion\": 38,\n  \"version\": 1,\n  \"refresh\": \"30s\",\n  \"editable\": true,\n  \"time\": {\n    \"from\": \"now-3h\",\n    \"to\": \"now\"\n  },\n  \"templating\": {\n    \"list\": [\n      {\n        \"name\": \"top_n\",\n        \"type\": \"custom\",\n        \"current\": {\n          \"text\": \"30\",\n          \"value\": \"30\"\n        },\n        \"options\": [\n          {\"text\": \"10\", \"value\": \"10\"},\n          {\"text\": \"20\", \"value\": \"20\"},\n          {\"text\": \"30\", \"value\": \"30\"},\n          {\"text\": \"50\", \"value\": \"50\"},\n          {\"text\": \"100\", \"value\": \"100\"}\n        ],\n        \"query\": \"10,20,30,50,100\",\n        \"description\": \"Number of top anomalous processes to show\"\n      }\n    ]\n  },\n  \"panels\": [\n    {\n      \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 0},\n      \"id\": 1,\n      \"type\": \"barchart\",\n      \"title\": \"Top $top_n Most Anomalous Processes\",\n      \"datasource\": \"Prometheus\",\n      \"targets\": [\n        {\n          \"expr\": \"bottomk($top_n, min by (groupname) (process_cpu_anomaly_score \u003c 0.8 or process_memory_anomaly_score \u003c 0.8))\",\n          \"legendFormat\": \"{{groupname}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"orientation\": \"horizontal\",\n        \"displayMode\": \"gradient\",\n        \"showValue\": \"always\",\n        \"legend\": {\n          \"displayMode\": \"hidden\"\n        }\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"continuous-GrYlRd\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"color\": \"red\", \"value\": 0},\n              {\"color\": \"yellow\", \"value\": 0.3},\n              {\"color\": \"green\", \"value\": 0.7}\n            ]\n          },\n          \"unit\": \"percentunit\",\n          \"min\": 0,\n          \"max\": 1\n        }\n      }\n    },\n    {\n      \"gridPos\": {\"h\": 10, \"w\": 12, \"x\": 0, \"y\": 8},\n      \"id\": 2,\n      \"type\": \"timeseries\",\n      \"title\": \"CPU Anomaly Trends (Top $top_n)\",\n      \"datasource\": \"Prometheus\",\n      \"targets\": [\n        {\n          \"expr\": \"bottomk($top_n, process_cpu_anomaly_score \u003c 0.8)\",\n          \"legendFormat\": \"{{groupname}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"tooltip\": {\"mode\": \"multi\"},\n        \"legend\": {\"displayMode\": \"table\", \"placement\": \"right\", \"calcs\": [\"lastNotNull\", \"min\"]}\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"drawStyle\": \"line\",\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 10,\n            \"pointSize\": 3\n          },\n          \"unit\": \"percentunit\",\n          \"min\": 0,\n          \"max\": 1,\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"red\", \"value\": 0},\n              {\"color\": \"yellow\", \"value\": 0.3},\n              {\"color\": \"green\", \"value\": 0.7}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"gridPos\": {\"h\": 10, \"w\": 12, \"x\": 12, \"y\": 8},\n      \"id\": 3,\n      \"type\": \"timeseries\",\n      \"title\": \"Memory Anomaly Trends (Top $top_n)\",\n      \"datasource\": \"Prometheus\",\n      \"targets\": [\n        {\n          \"expr\": \"bottomk($top_n, process_memory_anomaly_score \u003c 0.8)\",\n          \"legendFormat\": \"{{groupname}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"tooltip\": {\"mode\": \"multi\"},\n        \"legend\": {\"displayMode\": \"table\", \"placement\": \"right\", \"calcs\": [\"lastNotNull\", \"min\"]}\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"drawStyle\": \"line\",\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 10,\n            \"pointSize\": 3\n          },\n          \"unit\": \"percentunit\",\n          \"min\": 0,\n          \"max\": 1,\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"red\", \"value\": 0},\n              {\"color\": \"yellow\", \"value\": 0.3},\n              {\"color\": \"green\", \"value\": 0.7}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"gridPos\": {\"h\": 10, \"w\": 24, \"x\": 0, \"y\": 18},\n      \"id\": 4,\n      \"type\": \"state-timeline\",\n      \"title\": \"Process Anomaly State Timeline (Top $top_n)\",\n      \"datasource\": \"Prometheus\",\n      \"targets\": [\n        {\n          \"expr\": \"bottomk($top_n, process_cpu_anomaly_score \u003c 0.8)\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"legend\": {\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\",\n          \"showLegend\": true\n        },\n        \"tooltip\": {\n          \"mode\": \"single\"\n        },\n        \"rowHeight\": 0.9\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"custom\": {\n            \"lineWidth\": 0,\n            \"fillOpacity\": 70,\n            \"spanNulls\": false\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"color\": \"red\", \"value\": 0},\n              {\"color\": \"orange\", \"value\": 0.3},\n              {\"color\": \"yellow\", \"value\": 0.5},\n              {\"color\": \"green\", \"value\": 0.7}\n            ]\n          },\n          \"unit\": \"percentunit\",\n          \"min\": 0,\n          \"max\": 1\n        }\n      }\n    },\n    {\n      \"gridPos\": {\"h\": 10, \"w\": 24, \"x\": 0, \"y\": 28},\n      \"id\": 5,\n      \"type\": \"table\",\n      \"title\": \"Anomaly Score Details (Sortable)\",\n      \"datasource\": \"Prometheus\",\n      \"targets\": [\n        {\n          \"expr\": \"process_cpu_anomaly_score \u003c 0.9\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"process_memory_anomaly_score \u003c 0.9\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"B\"\n        }\n      ],\n      \"transformations\": [\n        {\n          \"id\": \"merge\"\n        },\n        {\n          \"id\": \"organize\",\n          \"options\": {\n            \"excludeByName\": {\n              \"Time\": true,\n              \"__name__\": true,\n              \"job\": true\n            },\n            \"renameByName\": {\n              \"Value #A\": \"CPU Score\",\n              \"Value #B\": \"Memory Score\",\n              \"groupname\": \"Process\",\n              \"instance\": \"Host\"\n            }\n          }\n        }\n      ],\n      \"options\": {\n        \"showHeader\": true,\n        \"sortBy\": [{\"desc\": false, \"displayName\": \"CPU Score\"}]\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"custom\": {\n            \"align\": \"center\",\n            \"displayMode\": \"color-background-solid\",\n            \"filterable\": true\n          },\n          \"unit\": \"percentunit\",\n          \"min\": 0,\n          \"max\": 1,\n          \"color\": {\"mode\": \"thresholds\"},\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"red\", \"value\": 0},\n              {\"color\": \"yellow\", \"value\": 0.3},\n              {\"color\": \"green\", \"value\": 0.7}\n            ]\n          }\n        }\n      }\n    }\n  ]\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"creationTimestamp":null,"name":"ml-anomaly-dashboards-updated","namespace":"monitoring"}}
    creationTimestamp: "2025-06-07T02:37:11Z"
    name: ml-anomaly-dashboards-updated
    namespace: monitoring
    resourceVersion: "4608817"
    uid: dc7da10a-1842-4dda-87db-f06f8be92977
- apiVersion: v1
  data:
    ml-provider.yaml: |
      apiVersion: 1
      providers:
      - name: 'odin-ml'
        orgId: 1
        folder: 'ODIN'
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards-ml
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"ml-provider.yaml":"apiVersion: 1\nproviders:\n- name: 'odin-ml'\n  orgId: 1\n  folder: 'ODIN'\n  type: file\n  disableDeletion: false\n  updateIntervalSeconds: 10\n  allowUiUpdates: true\n  options:\n    path: /var/lib/grafana/dashboards-ml\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"ml-dashboard-provider","namespace":"monitoring"}}
    creationTimestamp: "2025-05-30T02:18:45Z"
    name: ml-dashboard-provider
    namespace: monitoring
    resourceVersion: "91710"
    uid: 20429694-95ed-489a-826e-1a466d9f1bb2
- apiVersion: v1
  data:
    healthcheck.sh: |
      #!/bin/bash
      # Health check script for monitoring stack

      echo "=== ODIN Monitoring Stack Health Check ==="
      echo "Timestamp: $(date)"
      echo ""

      # Check Prometheus
      echo "Checking Prometheus..."
      if curl -s http://prometheus:9090/-/healthy > /dev/null; then
          echo "✓ Prometheus is healthy"
      else
          echo "✗ Prometheus is unhealthy"
          kubectl rollout restart deployment/prometheus -n monitoring
      fi

      # Check Grafana
      echo "Checking Grafana..."
      if curl -s http://grafana:3000/api/health > /dev/null; then
          echo "✓ Grafana is healthy"
      else
          echo "✗ Grafana is unhealthy"
          kubectl rollout restart deployment/grafana -n monitoring
      fi

      # Check Loki
      echo "Checking Loki..."
      if curl -s http://loki:3100/ready > /dev/null; then
          echo "✓ Loki is healthy"
      else
          echo "✗ Loki is unhealthy"
          kubectl rollout restart deployment/loki -n monitoring
      fi

      # Check AlertManager
      echo "Checking AlertManager..."
      if curl -s http://alertmanager:9093/-/healthy > /dev/null; then
          echo "✓ AlertManager is healthy"
      else
          echo "✗ AlertManager is unhealthy"
          kubectl rollout restart deployment/alertmanager -n monitoring
      fi

      echo ""
      echo "=== Pod Status ==="
      kubectl get pods -n monitoring

      echo ""
      echo "=== Resource Usage ==="
      kubectl top pods -n monitoring --no-headers | head -10
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"healthcheck.sh":"#!/bin/bash\n# Health check script for monitoring stack\n\necho \"=== ODIN Monitoring Stack Health Check ===\"\necho \"Timestamp: $(date)\"\necho \"\"\n\n# Check Prometheus\necho \"Checking Prometheus...\"\nif curl -s http://prometheus:9090/-/healthy \u003e /dev/null; then\n    echo \"✓ Prometheus is healthy\"\nelse\n    echo \"✗ Prometheus is unhealthy\"\n    kubectl rollout restart deployment/prometheus -n monitoring\nfi\n\n# Check Grafana\necho \"Checking Grafana...\"\nif curl -s http://grafana:3000/api/health \u003e /dev/null; then\n    echo \"✓ Grafana is healthy\"\nelse\n    echo \"✗ Grafana is unhealthy\"\n    kubectl rollout restart deployment/grafana -n monitoring\nfi\n\n# Check Loki\necho \"Checking Loki...\"\nif curl -s http://loki:3100/ready \u003e /dev/null; then\n    echo \"✓ Loki is healthy\"\nelse\n    echo \"✗ Loki is unhealthy\"\n    kubectl rollout restart deployment/loki -n monitoring\nfi\n\n# Check AlertManager\necho \"Checking AlertManager...\"\nif curl -s http://alertmanager:9093/-/healthy \u003e /dev/null; then\n    echo \"✓ AlertManager is healthy\"\nelse\n    echo \"✗ AlertManager is unhealthy\"\n    kubectl rollout restart deployment/alertmanager -n monitoring\nfi\n\necho \"\"\necho \"=== Pod Status ===\"\nkubectl get pods -n monitoring\n\necho \"\"\necho \"=== Resource Usage ===\"\nkubectl top pods -n monitoring --no-headers | head -10\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"monitoring-healthcheck","namespace":"monitoring"}}
    creationTimestamp: "2025-05-27T22:59:02Z"
    name: monitoring-healthcheck
    namespace: monitoring
    resourceVersion: "3167"
    uid: b7f0a322-1dd8-453c-af10-24b7fe17946f
- apiVersion: v1
  data:
    monitoring-health.json: |
      {
        "id": null,
        "title": "Monitoring Stack Health",
        "tags": ["monitoring", "health", "reliability"],
        "style": "dark",
        "timezone": "browser",
        "refresh": "30s",
        "schemaVersion": 27,
        "version": 1,
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "panels": [
          {
            "id": 1,
            "title": "Service Uptime",
            "type": "stat",
            "targets": [
              {
                "expr": "up{job=~\"prometheus|node-exporter|alertmanager|kube-state-metrics\"}",
                "legendFormat": "{{ job }}",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "short",
                "mappings": [
                  {"type": "value", "value": "0", "text": "DOWN"},
                  {"type": "value", "value": "1", "text": "UP"}
                ],
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": null},
                    {"color": "green", "value": 1}
                  ]
                }
              }
            },
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0}
          },
          {
            "id": 2,
            "title": "Pod Restart Count (Last 24h)",
            "type": "stat",
            "targets": [
              {
                "expr": "sum(increase(kube_pod_container_status_restarts_total{namespace=\"monitoring\"}[24h])) by (pod)",
                "legendFormat": "{{ pod }}",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "short",
                "thresholds": {
                  "steps": [
                    {"color": "green", "value": null},
                    {"color": "yellow", "value": 1},
                    {"color": "red", "value": 5}
                  ]
                }
              }
            },
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0}
          },
          {
            "id": 3,
            "title": "Prometheus Query Rate",
            "type": "timeseries",
            "targets": [
              {
                "expr": "rate(prometheus_http_requests_total{handler=\"/api/v1/query\"}[5m])",
                "legendFormat": "Query Rate",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "reqps"
              }
            },
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8}
          },
          {
            "id": 4,
            "title": "Prometheus Storage Usage",
            "type": "timeseries",
            "targets": [
              {
                "expr": "prometheus_tsdb_head_series",
                "legendFormat": "Active Series",
                "refId": "A"
              },
              {
                "expr": "rate(prometheus_tsdb_head_samples_appended_total[5m])",
                "legendFormat": "Sample Rate",
                "refId": "B"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "short"
              }
            },
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8}
          },
          {
            "id": 5,
            "title": "Resource Usage by Pod",
            "type": "table",
            "targets": [
              {
                "expr": "sum(rate(container_cpu_usage_seconds_total{namespace=\"monitoring\",container!=\"\",container!=\"POD\"}[5m])) by (pod) * 100",
                "format": "table",
                "instant": true,
                "refId": "A"
              }
            ],
            "transformations": [
              {
                "id": "organize",
                "options": {
                  "excludeByName": {
                    "Time": true,
                    "__name__": true
                  },
                  "renameByName": {
                    "Value": "CPU %"
                  }
                }
              }
            ],
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 16}
          },
          {
            "id": 6,
            "title": "Alert Firing Status",
            "type": "table",
            "targets": [
              {
                "expr": "ALERTS{alertstate=\"firing\"}",
                "format": "table",
                "instant": true,
                "refId": "A"
              }
            ],
            "transformations": [
              {
                "id": "organize",
                "options": {
                  "excludeByName": {
                    "Time": true,
                    "__name__": true,
                    "job": true,
                    "instance": true
                  }
                }
              }
            ],
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 24}
          }
        ]
      }
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"monitoring-health.json":"{\n  \"id\": null,\n  \"title\": \"Monitoring Stack Health\",\n  \"tags\": [\"monitoring\", \"health\", \"reliability\"],\n  \"style\": \"dark\",\n  \"timezone\": \"browser\",\n  \"refresh\": \"30s\",\n  \"schemaVersion\": 27,\n  \"version\": 1,\n  \"time\": {\n    \"from\": \"now-1h\",\n    \"to\": \"now\"\n  },\n  \"panels\": [\n    {\n      \"id\": 1,\n      \"title\": \"Service Uptime\",\n      \"type\": \"stat\",\n      \"targets\": [\n        {\n          \"expr\": \"up{job=~\\\"prometheus|node-exporter|alertmanager|kube-state-metrics\\\"}\",\n          \"legendFormat\": \"{{ job }}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"mappings\": [\n            {\"type\": \"value\", \"value\": \"0\", \"text\": \"DOWN\"},\n            {\"type\": \"value\", \"value\": \"1\", \"text\": \"UP\"}\n          ],\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"red\", \"value\": null},\n              {\"color\": \"green\", \"value\": 1}\n            ]\n          }\n        }\n      },\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 0}\n    },\n    {\n      \"id\": 2,\n      \"title\": \"Pod Restart Count (Last 24h)\",\n      \"type\": \"stat\",\n      \"targets\": [\n        {\n          \"expr\": \"sum(increase(kube_pod_container_status_restarts_total{namespace=\\\"monitoring\\\"}[24h])) by (pod)\",\n          \"legendFormat\": \"{{ pod }}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 1},\n              {\"color\": \"red\", \"value\": 5}\n            ]\n          }\n        }\n      },\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 0}\n    },\n    {\n      \"id\": 3,\n      \"title\": \"Prometheus Query Rate\",\n      \"type\": \"timeseries\",\n      \"targets\": [\n        {\n          \"expr\": \"rate(prometheus_http_requests_total{handler=\\\"/api/v1/query\\\"}[5m])\",\n          \"legendFormat\": \"Query Rate\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"reqps\"\n        }\n      },\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 8}\n    },\n    {\n      \"id\": 4,\n      \"title\": \"Prometheus Storage Usage\",\n      \"type\": \"timeseries\",\n      \"targets\": [\n        {\n          \"expr\": \"prometheus_tsdb_head_series\",\n          \"legendFormat\": \"Active Series\",\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"rate(prometheus_tsdb_head_samples_appended_total[5m])\",\n          \"legendFormat\": \"Sample Rate\",\n          \"refId\": \"B\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\"\n        }\n      },\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 8}\n    },\n    {\n      \"id\": 5,\n      \"title\": \"Resource Usage by Pod\",\n      \"type\": \"table\",\n      \"targets\": [\n        {\n          \"expr\": \"sum(rate(container_cpu_usage_seconds_total{namespace=\\\"monitoring\\\",container!=\\\"\\\",container!=\\\"POD\\\"}[5m])) by (pod) * 100\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"transformations\": [\n        {\n          \"id\": \"organize\",\n          \"options\": {\n            \"excludeByName\": {\n              \"Time\": true,\n              \"__name__\": true\n            },\n            \"renameByName\": {\n              \"Value\": \"CPU %\"\n            }\n          }\n        }\n      ],\n      \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 16}\n    },\n    {\n      \"id\": 6,\n      \"title\": \"Alert Firing Status\",\n      \"type\": \"table\",\n      \"targets\": [\n        {\n          \"expr\": \"ALERTS{alertstate=\\\"firing\\\"}\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"transformations\": [\n        {\n          \"id\": \"organize\",\n          \"options\": {\n            \"excludeByName\": {\n              \"Time\": true,\n              \"__name__\": true,\n              \"job\": true,\n              \"instance\": true\n            }\n          }\n        }\n      ],\n      \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 24}\n    }\n  ]\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"monitoring-self-dashboard","namespace":"monitoring"}}
    creationTimestamp: "2025-05-27T22:59:44Z"
    name: monitoring-self-dashboard
    namespace: monitoring
    resourceVersion: "3259"
    uid: 16e69605-f9bc-4f03-bd36-95112e489f66
- apiVersion: v1
  data:
    fluent-bit.conf: |
      [SERVICE]
          Flush         5
          Log_Level     info
          Daemon        off
          HTTP_Server   On
          HTTP_Listen   0.0.0.0
          HTTP_Port     2020

      [INPUT]
          Name              tail
          Path              /data/netflow/nfcapd.*
          Tag               netflow.udm
          Multiline         Off
          Parser            netflow_parser
          Refresh_Interval  5

      [FILTER]
          Name    modify
          Match   netflow.*
          Add     job udm-netflow
          Add     source_type netflow
          Add     device_ip 192.168.1.1

      [OUTPUT]
          Name            loki
          Match           netflow.*
          Host            loki.monitoring.svc.cluster.local
          Port            3100
          Labels          job=udm-netflow,source_type=netflow,device_ip=192.168.1.1
          Line_format     json
    nfcapd.conf: |
      # NetFlow collector configuration for UDM Pro
      # Listen on all interfaces, port 30514
      -P /var/run/nfcapd.pid
      -D
      -p 30514
      -l /data/netflow
      -S 2
      -T all
      -t 300
    parsers.conf: |
      [PARSER]
          Name        netflow_parser
          Format      regex
          Regex       ^(?<timestamp>\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2}\.\d{3})\s+(?<flows>\d+)\s+(?<duration>[\d.]+)\s+(?<proto>\w+)\s+(?<src_addr>[\d.]+):(?<src_port>\d+)\s+->\s+(?<dst_addr>[\d.]+):(?<dst_port>\d+)\s+(?<packets>\d+)\s+(?<bytes>\d+).*
          Time_Key    timestamp
          Time_Format %Y-%m-%d %H:%M:%S.%L
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"fluent-bit.conf":"[SERVICE]\n    Flush         5\n    Log_Level     info\n    Daemon        off\n    HTTP_Server   On\n    HTTP_Listen   0.0.0.0\n    HTTP_Port     2020\n\n[INPUT]\n    Name              tail\n    Path              /data/netflow/nfcapd.*\n    Tag               netflow.udm\n    Multiline         Off\n    Parser            netflow_parser\n    Refresh_Interval  5\n\n[FILTER]\n    Name    modify\n    Match   netflow.*\n    Add     job udm-netflow\n    Add     source_type netflow\n    Add     device_ip 192.168.1.1\n\n[OUTPUT]\n    Name            loki\n    Match           netflow.*\n    Host            loki.monitoring.svc.cluster.local\n    Port            3100\n    Labels          job=udm-netflow,source_type=netflow,device_ip=192.168.1.1\n    Line_format     json\n","nfcapd.conf":"# NetFlow collector configuration for UDM Pro\n# Listen on all interfaces, port 30514\n-P /var/run/nfcapd.pid\n-D\n-p 30514\n-l /data/netflow\n-S 2\n-T all\n-t 300\n","parsers.conf":"[PARSER]\n    Name        netflow_parser\n    Format      regex\n    Regex       ^(?\u003ctimestamp\u003e\\d{4}-\\d{2}-\\d{2}\\s+\\d{2}:\\d{2}:\\d{2}\\.\\d{3})\\s+(?\u003cflows\u003e\\d+)\\s+(?\u003cduration\u003e[\\d.]+)\\s+(?\u003cproto\u003e\\w+)\\s+(?\u003csrc_addr\u003e[\\d.]+):(?\u003csrc_port\u003e\\d+)\\s+-\u003e\\s+(?\u003cdst_addr\u003e[\\d.]+):(?\u003cdst_port\u003e\\d+)\\s+(?\u003cpackets\u003e\\d+)\\s+(?\u003cbytes\u003e\\d+).*\n    Time_Key    timestamp\n    Time_Format %Y-%m-%d %H:%M:%S.%L\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"netflow-collector-config","namespace":"monitoring"}}
    creationTimestamp: "2025-06-02T02:54:19Z"
    name: netflow-collector-config
    namespace: monitoring
    resourceVersion: "1770145"
    uid: 51b87b35-b501-4725-8067-45f9641c3de6
- apiVersion: v1
  data:
    netflow_exporter.py: "#!/usr/bin/env python3\nimport os\nimport time\nimport logging\nimport
      json\nimport subprocess\nfrom datetime import datetime\nfrom prometheus_client
      import start_http_server, Gauge, Counter\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO,
      format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger('netflow-exporter')\n\n#
      Configuration\nEXPORTER_PORT = int(os.getenv('EXPORTER_PORT', '9134'))\nNETFLOW_DATA_DIR
      = '/data/netflow'\n\n# Prometheus metrics\nnetflow_flows_total = Counter('netflow_flows_total',
      'Total number of NetFlow records', ['src_net', 'dst_net', 'protocol'])\nnetflow_bytes_total
      = Counter('netflow_bytes_total', 'Total bytes in NetFlow records', ['src_net',
      'dst_net', 'protocol'])\nnetflow_packets_total = Counter('netflow_packets_total',
      'Total packets in NetFlow records', ['src_net', 'dst_net', 'protocol'])\nnetflow_active_flows
      = Gauge('netflow_active_flows', 'Current active flows')\nnetflow_top_talkers_bytes
      = Gauge('netflow_top_talkers_bytes', 'Top talking hosts by bytes', ['src_ip',
      'dst_ip'])\nnetflow_top_protocols = Gauge('netflow_top_protocols', 'Top protocols
      by flow count', ['protocol'])\n\nclass NetFlowExporter:\n    def __init__(self):\n
      \       self.last_processed_file = None\n        \n    def process_netflow_data(self):\n
      \       \"\"\"Process NetFlow data and update metrics\"\"\"\n        try:\n
      \           # Find latest nfcapd file\n            files = []\n            for
      file in os.listdir(NETFLOW_DATA_DIR):\n                if file.startswith('nfcapd.'):\n
      \                   files.append(os.path.join(NETFLOW_DATA_DIR, file))\n            \n
      \           if not files:\n                logger.debug(\"No NetFlow files found\")\n
      \               return\n            \n            # Sort by modification time,
      get latest\n            latest_file = max(files, key=os.path.getmtime)\n            \n
      \           if latest_file == self.last_processed_file:\n                return
      \ # Already processed\n            \n            logger.info(f\"Processing NetFlow
      file: {latest_file}\")\n            \n            # Use nfdump to read the file\n
      \           result = subprocess.run([\n                'nfdump', '-r', latest_file,
      '-o', 'csv'\n            ], capture_output=True, text=True, timeout=30)\n            \n
      \           if result.returncode == 0:\n                self.parse_nfdump_output(result.stdout)\n
      \               self.last_processed_file = latest_file\n            else:\n
      \               logger.error(f\"nfdump failed: {result.stderr}\")\n                \n
      \       except Exception as e:\n            logger.error(f\"Error processing
      NetFlow data: {e}\")\n    \n    def parse_nfdump_output(self, csv_output):\n
      \       \"\"\"Parse nfdump CSV output and update metrics\"\"\"\n        try:\n
      \           lines = csv_output.strip().split('\\n')\n            for line in
      lines[1:]:  # Skip header\n                if line:\n                    self.process_flow_record(line)\n
      \                   \n        except Exception as e:\n            logger.error(f\"Error
      parsing nfdump output: {e}\")\n    \n    def process_flow_record(self, csv_line):\n
      \       \"\"\"Process individual flow record\"\"\"\n        try:\n            #
      CSV format from nfdump: ts,td,pr,sa,sp,da,dp,flg,fwd,stos,ipkt,ibyt,opkt,obyt\n
      \           fields = csv_line.split(',')\n            if len(fields) >= 13:\n
      \               src_addr = fields[3]\n                dst_addr = fields[5] \n
      \               protocol = fields[2]\n                packets = int(fields[10])
      if fields[10].isdigit() else 0\n                bytes_count = int(fields[11])
      if fields[11].isdigit() else 0\n                \n                # Classify
      networks\n                src_net = self.classify_network(src_addr)\n                dst_net
      = self.classify_network(dst_addr)\n                \n                # Update
      counters\n                netflow_flows_total.labels(src_net=src_net, dst_net=dst_net,
      protocol=protocol).inc()\n                netflow_bytes_total.labels(src_net=src_net,
      dst_net=dst_net, protocol=protocol).inc(bytes_count)\n                netflow_packets_total.labels(src_net=src_net,
      dst_net=dst_net, protocol=protocol).inc(packets)\n                \n        except
      Exception as e:\n            logger.error(f\"Error processing flow record: {e}\")\n
      \   \n    def classify_network(self, ip_addr):\n        \"\"\"Classify IP address
      into network categories\"\"\"\n        try:\n            parts = ip_addr.split('.')\n
      \           if len(parts) == 4:\n                if parts[0] == '192' and parts[1]
      == '168':\n                    return f\"lan_{parts[2]}\"  # 192.168.x.x ->
      lan_x\n                elif parts[0] == '10':\n                    return \"lan_10\"\n
      \               elif parts[0] == '172' and 16 <= int(parts[1]) <= 31:\n                    return
      \"lan_172\"\n                else:\n                    return \"wan\"\n            return
      \"unknown\"\n        except:\n            return \"unknown\"\n    \n    def
      collect_metrics(self):\n        \"\"\"Main metrics collection loop\"\"\"\n        logger.info(\"Processing
      NetFlow data...\")\n        self.process_netflow_data()\n        logger.info(\"NetFlow
      processing completed\")\n\ndef main():\n    \"\"\"Main function\"\"\"\n    logger.info(\"Starting
      NetFlow Exporter...\")\n    \n    # Ensure data directory exists\n    os.makedirs(NETFLOW_DATA_DIR,
      exist_ok=True)\n    \n    # Create exporter instance\n    exporter = NetFlowExporter()\n
      \   \n    # Start metrics server\n    start_http_server(EXPORTER_PORT)\n    logger.info(f\"Metrics
      server started on port {EXPORTER_PORT}\")\n    \n    # Main loop\n    while
      True:\n        try:\n            exporter.collect_metrics()\n            time.sleep(60)
      \ # Process every minute\n            \n        except KeyboardInterrupt:\n
      \           logger.info(\"Shutting down...\")\n            break\n        except
      Exception as e:\n            logger.error(f\"Error in main loop: {e}\")\n            time.sleep(60)\n\nif
      __name__ == \"__main__\":\n    main()\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"netflow_exporter.py":"#!/usr/bin/env python3\nimport os\nimport time\nimport logging\nimport json\nimport subprocess\nfrom datetime import datetime\nfrom prometheus_client import start_http_server, Gauge, Counter\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger('netflow-exporter')\n\n# Configuration\nEXPORTER_PORT = int(os.getenv('EXPORTER_PORT', '9134'))\nNETFLOW_DATA_DIR = '/data/netflow'\n\n# Prometheus metrics\nnetflow_flows_total = Counter('netflow_flows_total', 'Total number of NetFlow records', ['src_net', 'dst_net', 'protocol'])\nnetflow_bytes_total = Counter('netflow_bytes_total', 'Total bytes in NetFlow records', ['src_net', 'dst_net', 'protocol'])\nnetflow_packets_total = Counter('netflow_packets_total', 'Total packets in NetFlow records', ['src_net', 'dst_net', 'protocol'])\nnetflow_active_flows = Gauge('netflow_active_flows', 'Current active flows')\nnetflow_top_talkers_bytes = Gauge('netflow_top_talkers_bytes', 'Top talking hosts by bytes', ['src_ip', 'dst_ip'])\nnetflow_top_protocols = Gauge('netflow_top_protocols', 'Top protocols by flow count', ['protocol'])\n\nclass NetFlowExporter:\n    def __init__(self):\n        self.last_processed_file = None\n        \n    def process_netflow_data(self):\n        \"\"\"Process NetFlow data and update metrics\"\"\"\n        try:\n            # Find latest nfcapd file\n            files = []\n            for file in os.listdir(NETFLOW_DATA_DIR):\n                if file.startswith('nfcapd.'):\n                    files.append(os.path.join(NETFLOW_DATA_DIR, file))\n            \n            if not files:\n                logger.debug(\"No NetFlow files found\")\n                return\n            \n            # Sort by modification time, get latest\n            latest_file = max(files, key=os.path.getmtime)\n            \n            if latest_file == self.last_processed_file:\n                return  # Already processed\n            \n            logger.info(f\"Processing NetFlow file: {latest_file}\")\n            \n            # Use nfdump to read the file\n            result = subprocess.run([\n                'nfdump', '-r', latest_file, '-o', 'csv'\n            ], capture_output=True, text=True, timeout=30)\n            \n            if result.returncode == 0:\n                self.parse_nfdump_output(result.stdout)\n                self.last_processed_file = latest_file\n            else:\n                logger.error(f\"nfdump failed: {result.stderr}\")\n                \n        except Exception as e:\n            logger.error(f\"Error processing NetFlow data: {e}\")\n    \n    def parse_nfdump_output(self, csv_output):\n        \"\"\"Parse nfdump CSV output and update metrics\"\"\"\n        try:\n            lines = csv_output.strip().split('\\n')\n            for line in lines[1:]:  # Skip header\n                if line:\n                    self.process_flow_record(line)\n                    \n        except Exception as e:\n            logger.error(f\"Error parsing nfdump output: {e}\")\n    \n    def process_flow_record(self, csv_line):\n        \"\"\"Process individual flow record\"\"\"\n        try:\n            # CSV format from nfdump: ts,td,pr,sa,sp,da,dp,flg,fwd,stos,ipkt,ibyt,opkt,obyt\n            fields = csv_line.split(',')\n            if len(fields) \u003e= 13:\n                src_addr = fields[3]\n                dst_addr = fields[5] \n                protocol = fields[2]\n                packets = int(fields[10]) if fields[10].isdigit() else 0\n                bytes_count = int(fields[11]) if fields[11].isdigit() else 0\n                \n                # Classify networks\n                src_net = self.classify_network(src_addr)\n                dst_net = self.classify_network(dst_addr)\n                \n                # Update counters\n                netflow_flows_total.labels(src_net=src_net, dst_net=dst_net, protocol=protocol).inc()\n                netflow_bytes_total.labels(src_net=src_net, dst_net=dst_net, protocol=protocol).inc(bytes_count)\n                netflow_packets_total.labels(src_net=src_net, dst_net=dst_net, protocol=protocol).inc(packets)\n                \n        except Exception as e:\n            logger.error(f\"Error processing flow record: {e}\")\n    \n    def classify_network(self, ip_addr):\n        \"\"\"Classify IP address into network categories\"\"\"\n        try:\n            parts = ip_addr.split('.')\n            if len(parts) == 4:\n                if parts[0] == '192' and parts[1] == '168':\n                    return f\"lan_{parts[2]}\"  # 192.168.x.x -\u003e lan_x\n                elif parts[0] == '10':\n                    return \"lan_10\"\n                elif parts[0] == '172' and 16 \u003c= int(parts[1]) \u003c= 31:\n                    return \"lan_172\"\n                else:\n                    return \"wan\"\n            return \"unknown\"\n        except:\n            return \"unknown\"\n    \n    def collect_metrics(self):\n        \"\"\"Main metrics collection loop\"\"\"\n        logger.info(\"Processing NetFlow data...\")\n        self.process_netflow_data()\n        logger.info(\"NetFlow processing completed\")\n\ndef main():\n    \"\"\"Main function\"\"\"\n    logger.info(\"Starting NetFlow Exporter...\")\n    \n    # Ensure data directory exists\n    os.makedirs(NETFLOW_DATA_DIR, exist_ok=True)\n    \n    # Create exporter instance\n    exporter = NetFlowExporter()\n    \n    # Start metrics server\n    start_http_server(EXPORTER_PORT)\n    logger.info(f\"Metrics server started on port {EXPORTER_PORT}\")\n    \n    # Main loop\n    while True:\n        try:\n            exporter.collect_metrics()\n            time.sleep(60)  # Process every minute\n            \n        except KeyboardInterrupt:\n            logger.info(\"Shutting down...\")\n            break\n        except Exception as e:\n            logger.error(f\"Error in main loop: {e}\")\n            time.sleep(60)\n\nif __name__ == \"__main__\":\n    main()\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"netflow-exporter-script","namespace":"monitoring"}}
    creationTimestamp: "2025-06-02T02:54:19Z"
    name: netflow-exporter-script
    namespace: monitoring
    resourceVersion: "1462511"
    uid: 8d6c050f-4b06-4d23-bdb9-b1d5220fe130
- apiVersion: v1
  data:
    network-alerts.yml: "groups:\n- name: network_performance_alerts\n  rules:\n  #
      Internet connectivity and speed alerts\n  - alert: InternetSpeedDegraded\n    expr:
      network_speedtest_download_mbps < 100\n    for: 10m\n    labels:\n      severity:
      warning\n      component: internet\n    annotations:\n      summary: \"Internet
      download speed degraded\"\n      description: \"Internet download speed is {{
      $value }} Mbps, below expected 100 Mbps threshold\"\n      \n  - alert: InternetConnectivityDown\n
      \   expr: network_speedtest_download_mbps == 0\n    for: 5m\n    labels:\n      severity:
      critical\n      component: internet\n    annotations:\n      summary: \"Internet
      connectivity lost\"\n      description: \"Internet speed test is reporting 0
      Mbps - connectivity may be down\"\n      \n  - alert: HighInternetLatency\n
      \   expr: network_speedtest_ping_ms > 50\n    for: 5m\n    labels:\n      severity:
      warning\n      component: internet\n    annotations:\n      summary: \"High
      internet latency detected\"\n      description: \"Internet ping latency is {{
      $value }}ms, above 50ms threshold\"\n      \n  - alert: HighPacketLoss\n    expr:
      network_speedtest_packet_loss_percent > 1\n    for: 5m\n    labels:\n      severity:
      warning\n      component: internet\n    annotations:\n      summary: \"High
      packet loss detected\"\n      description: \"Internet packet loss is {{ $value
      }}%, above 1% threshold\"\n      \n  - alert: CriticalPacketLoss\n    expr:
      network_speedtest_packet_loss_percent > 5\n    for: 2m\n    labels:\n      severity:
      critical\n      component: internet\n    annotations:\n      summary: \"Critical
      packet loss detected\"\n      description: \"Internet packet loss is {{ $value
      }}%, above 5% critical threshold\"\n      \n  - alert: HighJitter\n    expr:
      network_speedtest_jitter_ms > 20\n    for: 10m\n    labels:\n      severity:
      warning\n      component: internet\n    annotations:\n      summary: \"High
      network jitter detected\"\n      description: \"Internet jitter is {{ $value
      }}ms, above 20ms threshold\"\n\n- name: network_device_alerts\n  rules:\n  #
      UniFi device health alerts\n  - alert: UniFiDeviceDown\n    expr: up{job=\"unifi-exporter\"}
      == 0\n    for: 2m\n    labels:\n      severity: critical\n      component: unifi\n
      \   annotations:\n      summary: \"UniFi monitoring is down\"\n      description:
      \"UniFi exporter is not responding - device monitoring unavailable\"\n      \n
      \ - alert: UniFiDeviceHighTemperature\n    expr: unifi_device_temperature_celsius
      > 70\n    for: 5m\n    labels:\n      severity: warning\n      component: unifi\n
      \   annotations:\n      summary: \"UniFi device high temperature\"\n      description:
      \"Device {{ $labels.device_name }} temperature is {{ $value }}°C, above 70°C
      threshold\"\n      \n  - alert: UniFiDeviceCriticalTemperature\n    expr: unifi_device_temperature_celsius
      > 85\n    for: 2m\n    labels:\n      severity: critical\n      component: unifi\n
      \   annotations:\n      summary: \"UniFi device critical temperature\"\n      description:
      \"Device {{ $labels.device_name }} temperature is {{ $value }}°C, above 85°C
      critical threshold\"\n      \n  - alert: UniFiDeviceHighCPU\n    expr: unifi_device_cpu_usage_percent
      > 80\n    for: 10m\n    labels:\n      severity: warning\n      component: unifi\n
      \   annotations:\n      summary: \"UniFi device high CPU usage\"\n      description:
      \"Device {{ $labels.device_name }} CPU usage is {{ $value }}%, above 80% for
      10 minutes\"\n      \n  - alert: UniFiDeviceHighMemory\n    expr: unifi_device_memory_usage_percent
      > 90\n    for: 5m\n    labels:\n      severity: warning\n      component: unifi\n
      \   annotations:\n      summary: \"UniFi device high memory usage\"\n      description:
      \"Device {{ $labels.device_name }} memory usage is {{ $value }}%, above 90%\"\n
      \     \n  - alert: UniFiDeviceOffline\n    expr: unifi_device_uptime_seconds
      == 0\n    for: 5m\n    labels:\n      severity: critical\n      component: unifi\n
      \   annotations:\n      summary: \"UniFi device offline\"\n      description:
      \"Device {{ $labels.device_name }} appears to be offline (uptime = 0)\"\n\n-
      name: network_interface_alerts\n  rules:\n  # Interface status and performance
      alerts\n  - alert: NetworkInterfaceDown\n    expr: unifi_interface_up == 0\n
      \   for: 2m\n    labels:\n      severity: warning\n      component: interface\n
      \   annotations:\n      summary: \"Network interface down\"\n      description:
      \"Interface {{ $labels.interface }} on device {{ $labels.device_name }} is down\"\n
      \     \n  - alert: HighInterfaceUtilization\n    expr: rate(unifi_interface_rx_bytes_total[5m])
      * 8 / 1000000 > (unifi_interface_speed_mbps * 0.8)\n    for: 10m\n    labels:\n
      \     severity: warning\n      component: interface\n    annotations:\n      summary:
      \"High interface utilization\"\n      description: \"Interface {{ $labels.interface
      }} on {{ $labels.device_name }} is {{ $value }} Mbps, above 80% of link capacity\"\n
      \     \n  - alert: InterfaceErrors\n    expr: rate(unifi_interface_rx_errors_total[5m])
      > 10\n    for: 5m\n    labels:\n      severity: warning\n      component: interface\n
      \   annotations:\n      summary: \"Network interface errors\"\n      description:
      \"Interface {{ $labels.interface }} on {{ $labels.device_name }} has {{ $value
      }} errors/second\"\n      \n  - alert: InterfaceFlapping\n    expr: changes(unifi_interface_up[10m])
      > 3\n    for: 5m\n    labels:\n      severity: warning\n      component: interface\n
      \   annotations:\n      summary: \"Network interface flapping\"\n      description:
      \"Interface {{ $labels.interface }} on {{ $labels.device_name }} has changed
      state {{ $value }} times in 10 minutes\"\n\n- name: network_connectivity_alerts\n
      \ rules:\n  # Internal network connectivity alerts\n  - alert: InternalNetworkLatencyHigh\n
      \   expr: network_ping_latency_ms{target_type=\"internal\"} > 10\n    for: 5m\n
      \   labels:\n      severity: warning\n      component: internal_network\n    annotations:\n
      \     summary: \"High internal network latency\"\n      description: \"Ping
      to internal target {{ $labels.target }} is {{ $value }}ms, above 10ms threshold\"\n
      \     \n  - alert: InternalNetworkUnreachable\n    expr: network_ping_packet_loss{target_type=\"internal\"}
      == 100\n    for: 2m\n    labels:\n      severity: critical\n      component:
      internal_network\n    annotations:\n      summary: \"Internal network target
      unreachable\"\n      description: \"Internal target {{ $labels.target }} is
      unreachable (100% packet loss)\"\n      \n  - alert: ExternalNetworkLatencyHigh\n
      \   expr: network_ping_latency_ms{target_type=\"external\"} > 100\n    for:
      10m\n    labels:\n      severity: warning\n      component: external_network\n
      \   annotations:\n      summary: \"High external network latency\"\n      description:
      \"Ping to external target {{ $labels.target }} is {{ $value }}ms, above 100ms
      threshold\"\n      \n  - alert: DNSResolutionSlow\n    expr: network_dns_resolution_time_ms
      > 1000\n    for: 5m\n    labels:\n      severity: warning\n      component:
      dns\n    annotations:\n      summary: \"Slow DNS resolution\"\n      description:
      \"DNS resolution for {{ $labels.hostname }} is {{ $value }}ms, above 1000ms
      threshold\"\n      \n  - alert: DNSResolutionFailed\n    expr: network_dns_resolution_time_ms
      == -1\n    for: 2m\n    labels:\n      severity: critical\n      component:
      dns\n    annotations:\n      summary: \"DNS resolution failed\"\n      description:
      \"DNS resolution for {{ $labels.hostname }} has failed\"\n\n- name: network_topology_alerts\n
      \ rules:\n  # Network topology and discovery alerts\n  - alert: NetworkTopologyDiscoveryDown\n
      \   expr: up{job=\"network-topology-exporter\"} == 0\n    for: 5m\n    labels:\n
      \     severity: warning\n      component: topology\n    annotations:\n      summary:
      \"Network topology discovery down\"\n      description: \"Network topology exporter
      is not responding - device discovery unavailable\"\n      \n  - alert: DeviceNeighborLost\n
      \   expr: absent_over_time(network_neighbor_info[30m])\n    for: 10m\n    labels:\n
      \     severity: warning\n      component: topology\n    annotations:\n      summary:
      \"Network neighbor relationship lost\"\n      description: \"Device neighbor
      relationship between {{ $labels.local_device }} and {{ $labels.remote_device
      }} has been lost\"\n      \n  - alert: ARPTableFull\n    expr: network_arp_entries_total
      > 1000\n    for: 10m\n    labels:\n      severity: warning\n      component:
      topology\n    annotations:\n      summary: \"ARP table getting full\"\n      description:
      \"Device {{ $labels.device }} ARP table has {{ $value }} entries, approaching
      limit\"\n\n- name: network_performance_monitoring_alerts\n  rules:\n  # Monitoring
      system health alerts\n  - alert: NetworkPerformanceMonitoringDown\n    expr:
      up{job=\"network-performance-exporter\"} == 0\n    for: 5m\n    labels:\n      severity:
      warning\n      component: monitoring\n    annotations:\n      summary: \"Network
      performance monitoring down\"\n      description: \"Network performance exporter
      is not responding - performance monitoring unavailable\"\n      \n  - alert:
      SpeedtestFailing\n    expr: absent_over_time(network_speedtest_download_mbps[30m])\n
      \   for: 15m\n    labels:\n      severity: warning\n      component: monitoring\n
      \   annotations:\n      summary: \"Internet speed tests failing\"\n      description:
      \"No successful speed test results in the last 30 minutes\"\n      \n  - alert:
      NetworkMonitoringDataStale\n    expr: time() - timestamp(network_speedtest_download_mbps)
      > 900\n    for: 5m\n    labels:\n      severity: warning\n      component: monitoring\n
      \   annotations:\n      summary: \"Network monitoring data is stale\"\n      description:
      \"Last speed test was {{ $value }} seconds ago, data may be stale\"\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"network-alerts.yml":"groups:\n- name: network_performance_alerts\n  rules:\n  # Internet connectivity and speed alerts\n  - alert: InternetSpeedDegraded\n    expr: network_speedtest_download_mbps \u003c 100\n    for: 10m\n    labels:\n      severity: warning\n      component: internet\n    annotations:\n      summary: \"Internet download speed degraded\"\n      description: \"Internet download speed is {{ $value }} Mbps, below expected 100 Mbps threshold\"\n      \n  - alert: InternetConnectivityDown\n    expr: network_speedtest_download_mbps == 0\n    for: 5m\n    labels:\n      severity: critical\n      component: internet\n    annotations:\n      summary: \"Internet connectivity lost\"\n      description: \"Internet speed test is reporting 0 Mbps - connectivity may be down\"\n      \n  - alert: HighInternetLatency\n    expr: network_speedtest_ping_ms \u003e 50\n    for: 5m\n    labels:\n      severity: warning\n      component: internet\n    annotations:\n      summary: \"High internet latency detected\"\n      description: \"Internet ping latency is {{ $value }}ms, above 50ms threshold\"\n      \n  - alert: HighPacketLoss\n    expr: network_speedtest_packet_loss_percent \u003e 1\n    for: 5m\n    labels:\n      severity: warning\n      component: internet\n    annotations:\n      summary: \"High packet loss detected\"\n      description: \"Internet packet loss is {{ $value }}%, above 1% threshold\"\n      \n  - alert: CriticalPacketLoss\n    expr: network_speedtest_packet_loss_percent \u003e 5\n    for: 2m\n    labels:\n      severity: critical\n      component: internet\n    annotations:\n      summary: \"Critical packet loss detected\"\n      description: \"Internet packet loss is {{ $value }}%, above 5% critical threshold\"\n      \n  - alert: HighJitter\n    expr: network_speedtest_jitter_ms \u003e 20\n    for: 10m\n    labels:\n      severity: warning\n      component: internet\n    annotations:\n      summary: \"High network jitter detected\"\n      description: \"Internet jitter is {{ $value }}ms, above 20ms threshold\"\n\n- name: network_device_alerts\n  rules:\n  # UniFi device health alerts\n  - alert: UniFiDeviceDown\n    expr: up{job=\"unifi-exporter\"} == 0\n    for: 2m\n    labels:\n      severity: critical\n      component: unifi\n    annotations:\n      summary: \"UniFi monitoring is down\"\n      description: \"UniFi exporter is not responding - device monitoring unavailable\"\n      \n  - alert: UniFiDeviceHighTemperature\n    expr: unifi_device_temperature_celsius \u003e 70\n    for: 5m\n    labels:\n      severity: warning\n      component: unifi\n    annotations:\n      summary: \"UniFi device high temperature\"\n      description: \"Device {{ $labels.device_name }} temperature is {{ $value }}°C, above 70°C threshold\"\n      \n  - alert: UniFiDeviceCriticalTemperature\n    expr: unifi_device_temperature_celsius \u003e 85\n    for: 2m\n    labels:\n      severity: critical\n      component: unifi\n    annotations:\n      summary: \"UniFi device critical temperature\"\n      description: \"Device {{ $labels.device_name }} temperature is {{ $value }}°C, above 85°C critical threshold\"\n      \n  - alert: UniFiDeviceHighCPU\n    expr: unifi_device_cpu_usage_percent \u003e 80\n    for: 10m\n    labels:\n      severity: warning\n      component: unifi\n    annotations:\n      summary: \"UniFi device high CPU usage\"\n      description: \"Device {{ $labels.device_name }} CPU usage is {{ $value }}%, above 80% for 10 minutes\"\n      \n  - alert: UniFiDeviceHighMemory\n    expr: unifi_device_memory_usage_percent \u003e 90\n    for: 5m\n    labels:\n      severity: warning\n      component: unifi\n    annotations:\n      summary: \"UniFi device high memory usage\"\n      description: \"Device {{ $labels.device_name }} memory usage is {{ $value }}%, above 90%\"\n      \n  - alert: UniFiDeviceOffline\n    expr: unifi_device_uptime_seconds == 0\n    for: 5m\n    labels:\n      severity: critical\n      component: unifi\n    annotations:\n      summary: \"UniFi device offline\"\n      description: \"Device {{ $labels.device_name }} appears to be offline (uptime = 0)\"\n\n- name: network_interface_alerts\n  rules:\n  # Interface status and performance alerts\n  - alert: NetworkInterfaceDown\n    expr: unifi_interface_up == 0\n    for: 2m\n    labels:\n      severity: warning\n      component: interface\n    annotations:\n      summary: \"Network interface down\"\n      description: \"Interface {{ $labels.interface }} on device {{ $labels.device_name }} is down\"\n      \n  - alert: HighInterfaceUtilization\n    expr: rate(unifi_interface_rx_bytes_total[5m]) * 8 / 1000000 \u003e (unifi_interface_speed_mbps * 0.8)\n    for: 10m\n    labels:\n      severity: warning\n      component: interface\n    annotations:\n      summary: \"High interface utilization\"\n      description: \"Interface {{ $labels.interface }} on {{ $labels.device_name }} is {{ $value }} Mbps, above 80% of link capacity\"\n      \n  - alert: InterfaceErrors\n    expr: rate(unifi_interface_rx_errors_total[5m]) \u003e 10\n    for: 5m\n    labels:\n      severity: warning\n      component: interface\n    annotations:\n      summary: \"Network interface errors\"\n      description: \"Interface {{ $labels.interface }} on {{ $labels.device_name }} has {{ $value }} errors/second\"\n      \n  - alert: InterfaceFlapping\n    expr: changes(unifi_interface_up[10m]) \u003e 3\n    for: 5m\n    labels:\n      severity: warning\n      component: interface\n    annotations:\n      summary: \"Network interface flapping\"\n      description: \"Interface {{ $labels.interface }} on {{ $labels.device_name }} has changed state {{ $value }} times in 10 minutes\"\n\n- name: network_connectivity_alerts\n  rules:\n  # Internal network connectivity alerts\n  - alert: InternalNetworkLatencyHigh\n    expr: network_ping_latency_ms{target_type=\"internal\"} \u003e 10\n    for: 5m\n    labels:\n      severity: warning\n      component: internal_network\n    annotations:\n      summary: \"High internal network latency\"\n      description: \"Ping to internal target {{ $labels.target }} is {{ $value }}ms, above 10ms threshold\"\n      \n  - alert: InternalNetworkUnreachable\n    expr: network_ping_packet_loss{target_type=\"internal\"} == 100\n    for: 2m\n    labels:\n      severity: critical\n      component: internal_network\n    annotations:\n      summary: \"Internal network target unreachable\"\n      description: \"Internal target {{ $labels.target }} is unreachable (100% packet loss)\"\n      \n  - alert: ExternalNetworkLatencyHigh\n    expr: network_ping_latency_ms{target_type=\"external\"} \u003e 100\n    for: 10m\n    labels:\n      severity: warning\n      component: external_network\n    annotations:\n      summary: \"High external network latency\"\n      description: \"Ping to external target {{ $labels.target }} is {{ $value }}ms, above 100ms threshold\"\n      \n  - alert: DNSResolutionSlow\n    expr: network_dns_resolution_time_ms \u003e 1000\n    for: 5m\n    labels:\n      severity: warning\n      component: dns\n    annotations:\n      summary: \"Slow DNS resolution\"\n      description: \"DNS resolution for {{ $labels.hostname }} is {{ $value }}ms, above 1000ms threshold\"\n      \n  - alert: DNSResolutionFailed\n    expr: network_dns_resolution_time_ms == -1\n    for: 2m\n    labels:\n      severity: critical\n      component: dns\n    annotations:\n      summary: \"DNS resolution failed\"\n      description: \"DNS resolution for {{ $labels.hostname }} has failed\"\n\n- name: network_topology_alerts\n  rules:\n  # Network topology and discovery alerts\n  - alert: NetworkTopologyDiscoveryDown\n    expr: up{job=\"network-topology-exporter\"} == 0\n    for: 5m\n    labels:\n      severity: warning\n      component: topology\n    annotations:\n      summary: \"Network topology discovery down\"\n      description: \"Network topology exporter is not responding - device discovery unavailable\"\n      \n  - alert: DeviceNeighborLost\n    expr: absent_over_time(network_neighbor_info[30m])\n    for: 10m\n    labels:\n      severity: warning\n      component: topology\n    annotations:\n      summary: \"Network neighbor relationship lost\"\n      description: \"Device neighbor relationship between {{ $labels.local_device }} and {{ $labels.remote_device }} has been lost\"\n      \n  - alert: ARPTableFull\n    expr: network_arp_entries_total \u003e 1000\n    for: 10m\n    labels:\n      severity: warning\n      component: topology\n    annotations:\n      summary: \"ARP table getting full\"\n      description: \"Device {{ $labels.device }} ARP table has {{ $value }} entries, approaching limit\"\n\n- name: network_performance_monitoring_alerts\n  rules:\n  # Monitoring system health alerts\n  - alert: NetworkPerformanceMonitoringDown\n    expr: up{job=\"network-performance-exporter\"} == 0\n    for: 5m\n    labels:\n      severity: warning\n      component: monitoring\n    annotations:\n      summary: \"Network performance monitoring down\"\n      description: \"Network performance exporter is not responding - performance monitoring unavailable\"\n      \n  - alert: SpeedtestFailing\n    expr: absent_over_time(network_speedtest_download_mbps[30m])\n    for: 15m\n    labels:\n      severity: warning\n      component: monitoring\n    annotations:\n      summary: \"Internet speed tests failing\"\n      description: \"No successful speed test results in the last 30 minutes\"\n      \n  - alert: NetworkMonitoringDataStale\n    expr: time() - timestamp(network_speedtest_download_mbps) \u003e 900\n    for: 5m\n    labels:\n      severity: warning\n      component: monitoring\n    annotations:\n      summary: \"Network monitoring data is stale\"\n      description: \"Last speed test was {{ $value }} seconds ago, data may be stale\"\n"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"app":"prometheus"},"name":"network-alert-rules","namespace":"monitoring"}}
    creationTimestamp: "2025-06-01T23:11:41Z"
    labels:
      app: prometheus
    name: network-alert-rules
    namespace: monitoring
    resourceVersion: "1364034"
    uid: e4ddf688-6862-422e-a5d7-6470e745046e
- apiVersion: v1
  data:
    network-analysis-dashboard.json: "{\n  \"uid\": \"network-analysis\",\n  \"title\":
      \"Network Traffic Analysis - Primary Interface (enp110s0)\",\n  \"tags\": [\"network\",
      \"traffic\", \"razerblade\"],\n  \"timezone\": \"browser\",\n  \"schemaVersion\":
      27,\n  \"version\": 3,\n  \"refresh\": \"30s\",\n  \"time\": {\n    \"from\":
      \"now-1h\",\n    \"to\": \"now\"\n  },\n  \"panels\": [\n    {\n      \"id\":
      1,\n      \"gridPos\": {\"h\": 4, \"w\": 6, \"x\": 0, \"y\": 0},\n      \"type\":
      \"stat\",\n      \"title\": \"Network Health Score\",\n      \"description\":
      \"Overall network health based on errors and retransmissions\",\n      \"targets\":
      [\n        {\n          \"expr\": \"100 - (100 * (sum(rate(node_network_receive_errs_total[5m]))
      + sum(rate(node_network_transmit_errs_total[5m])) + sum(rate(node_netstat_Tcp_RetransSegs[5m])))
      / (sum(rate(node_network_receive_packets_total[5m])) + sum(rate(node_network_transmit_packets_total[5m]))))\",\n
      \         \"legendFormat\": \"Health %\"\n        }\n      ],\n      \"fieldConfig\":
      {\n        \"defaults\": {\n          \"unit\": \"percent\",\n          \"decimals\":
      2,\n          \"color\": {\"mode\": \"thresholds\"},\n          \"thresholds\":
      {\n            \"steps\": [\n              {\"color\": \"red\", \"value\": null},\n
      \             {\"color\": \"orange\", \"value\": 95},\n              {\"color\":
      \"yellow\", \"value\": 98},\n              {\"color\": \"green\", \"value\":
      99.5}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"id\":
      2,\n      \"gridPos\": {\"h\": 4, \"w\": 6, \"x\": 6, \"y\": 0},\n      \"type\":
      \"stat\",\n      \"title\": \"TCP Retransmission Rate\",\n      \"targets\":
      [\n        {\n          \"expr\": \"100 * sum(rate(node_netstat_Tcp_RetransSegs[5m]))
      / sum(rate(node_netstat_Tcp_OutSegs[5m]))\",\n          \"legendFormat\": \"Retrans
      %\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n
      \         \"unit\": \"percent\",\n          \"decimals\": 3,\n          \"color\":
      {\"mode\": \"thresholds\"},\n          \"thresholds\": {\n            \"steps\":
      [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\":
      \"yellow\", \"value\": 0.1},\n              {\"color\": \"orange\", \"value\":
      1},\n              {\"color\": \"red\", \"value\": 5}\n            ]\n          }\n
      \       }\n      }\n    },\n    {\n      \"id\": 3,\n      \"gridPos\": {\"h\":
      4, \"w\": 6, \"x\": 12, \"y\": 0},\n      \"type\": \"stat\",\n      \"title\":
      \"Active TCP Connections\",\n      \"targets\": [\n        {\n          \"expr\":
      \"node_netstat_Tcp_CurrEstab\",\n          \"legendFormat\": \"Established\"\n
      \       },\n        {\n          \"expr\": \"node_sockstat_TCP_tw\",\n          \"legendFormat\":
      \"TIME_WAIT\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\":
      {\n          \"unit\": \"short\",\n          \"color\": {\"mode\": \"palette-classic\"}\n
      \       }\n      }\n    },\n    {\n      \"id\": 4,\n      \"gridPos\": {\"h\":
      4, \"w\": 6, \"x\": 18, \"y\": 0},\n      \"type\": \"stat\",\n      \"title\":
      \"Packet Drops\",\n      \"description\": \"Total packet drops across all interfaces\",\n
      \     \"targets\": [\n        {\n          \"expr\": \"sum(rate(node_network_receive_drop_total{device!=\\\"lo\\\"}[5m]))\",\n
      \         \"legendFormat\": \"RX Drops/s\"\n        },\n        {\n          \"expr\":
      \"sum(rate(node_network_transmit_drop_total{device!=\\\"lo\\\"}[5m]))\",\n          \"legendFormat\":
      \"TX Drops/s\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\":
      {\n          \"unit\": \"pps\",\n          \"decimals\": 3,\n          \"color\":
      {\"mode\": \"thresholds\"},\n          \"thresholds\": {\n            \"steps\":
      [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\":
      \"yellow\", \"value\": 1},\n              {\"color\": \"red\", \"value\": 10}\n
      \           ]\n          }\n        }\n      }\n    },\n    {\n      \"id\":
      5,\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 4},\n      \"type\":
      \"timeseries\",\n      \"title\": \"Network Interface Traffic\",\n      \"targets\":
      [\n        {\n          \"expr\": \"rate(node_network_receive_bytes_total{device=\\\"enp110s0\\\"}[5m])\",\n
      \         \"legendFormat\": \"RX: {{device}}\"\n        },\n        {\n          \"expr\":
      \"rate(node_network_transmit_bytes_total{device=\\\"enp110s0\\\"}[5m]) * -1\",\n
      \         \"legendFormat\": \"TX: {{device}}\"\n        }\n      ],\n      \"fieldConfig\":
      {\n        \"defaults\": {\n          \"unit\": \"binBps\",\n          \"decimals\":
      2,\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\":
      {\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\":
      2,\n            \"fillOpacity\": 10,\n            \"showPoints\": \"never\",\n
      \           \"spanNulls\": true\n          }\n        }\n      }\n    },\n    {\n
      \     \"id\": 6,\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\":
      4},\n      \"type\": \"timeseries\",\n      \"title\": \"TCP Retransmissions
      & Timeouts\",\n      \"targets\": [\n        {\n          \"expr\": \"rate(node_netstat_Tcp_RetransSegs[5m])\",\n
      \         \"legendFormat\": \"TCP Retrans/s\"\n        },\n        {\n          \"expr\":
      \"rate(node_netstat_TcpExt_TCPSynRetrans[5m])\",\n          \"legendFormat\":
      \"SYN Retrans/s\"\n        },\n        {\n          \"expr\": \"rate(node_netstat_TcpExt_TCPTimeouts[5m])\",\n
      \         \"legendFormat\": \"TCP Timeouts/s\"\n        }\n      ],\n      \"fieldConfig\":
      {\n        \"defaults\": {\n          \"unit\": \"ops\",\n          \"decimals\":
      2,\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\":
      {\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\":
      2,\n            \"fillOpacity\": 10,\n            \"showPoints\": \"never\",\n
      \           \"spanNulls\": true\n          }\n        }\n      }\n    },\n    {\n
      \     \"id\": 7,\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\":
      12},\n      \"type\": \"timeseries\",\n      \"title\": \"Network Errors & Drops
      (milli-packets/s)\",\n      \"description\": \"Shows errors and drops at millisecond
      precision\",\n      \"targets\": [\n        {\n          \"expr\": \"rate(node_network_receive_errs_total{device=\\\"enp110s0\\\"}[5m])
      * 1000\",\n          \"legendFormat\": \"RX Errors: {{device}}\"\n        },\n
      \       {\n          \"expr\": \"rate(node_network_transmit_errs_total{device=\\\"enp110s0\\\"}[5m])
      * 1000\",\n          \"legendFormat\": \"TX Errors: {{device}}\"\n        },\n
      \       {\n          \"expr\": \"rate(node_network_receive_drop_total{device=\\\"enp110s0\\\"}[5m])
      * 1000\",\n          \"legendFormat\": \"RX Drops: {{device}}\"\n        },\n
      \       {\n          \"expr\": \"rate(node_network_transmit_drop_total{device=\\\"enp110s0\\\"}[5m])
      * 1000\",\n          \"legendFormat\": \"TX Drops: {{device}}\"\n        }\n
      \     ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\":
      \"none\",\n          \"decimals\": 2,\n          \"color\": {\"mode\": \"palette-classic\"},\n
      \         \"custom\": {\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\":
      2,\n            \"fillOpacity\": 20,\n            \"showPoints\": \"auto\",\n
      \           \"spanNulls\": true,\n            \"drawStyle\": \"line\",\n            \"pointSize\":
      4,\n            \"stacking\": {\n              \"mode\": \"none\"\n            }\n
      \         }\n        },\n        \"overrides\": [\n          {\n            \"matcher\":
      {\"id\": \"byRegexp\", \"options\": \".*Drops.*\"},\n            \"properties\":
      [\n              {\"id\": \"color\", \"value\": {\"mode\": \"fixed\", \"fixedColor\":
      \"orange\"}}\n            ]\n          },\n          {\n            \"matcher\":
      {\"id\": \"byRegexp\", \"options\": \".*Errors.*\"},\n            \"properties\":
      [\n              {\"id\": \"color\", \"value\": {\"mode\": \"fixed\", \"fixedColor\":
      \"red\"}}\n            ]\n          }\n        ]\n      }\n    },\n    {\n      \"id\":
      8,\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 12},\n      \"type\":
      \"timeseries\",\n      \"title\": \"Drop Rate Percentage\",\n      \"description\":
      \"Packet drops as percentage of total packets\",\n      \"targets\": [\n        {\n
      \         \"expr\": \"100 * rate(node_network_receive_drop_total{device=\\\"enp110s0\\\"}[5m])
      / rate(node_network_receive_packets_total{device=\\\"enp110s0\\\"}[5m])\",\n
      \         \"legendFormat\": \"RX Drop %\"\n        },\n        {\n          \"expr\":
      \"100 * rate(node_network_transmit_drop_total{device=\\\"enp110s0\\\"}[5m])
      / rate(node_network_transmit_packets_total{device=\\\"enp110s0\\\"}[5m])\",\n
      \         \"legendFormat\": \"TX Drop %\"\n        }\n      ],\n      \"fieldConfig\":
      {\n        \"defaults\": {\n          \"unit\": \"percent\",\n          \"decimals\":
      4,\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\":
      {\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\":
      2,\n            \"fillOpacity\": 10,\n            \"showPoints\": \"auto\",\n
      \           \"spanNulls\": true\n          },\n          \"thresholds\": {\n
      \           \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n
      \             {\"color\": \"yellow\", \"value\": 0.01},\n              {\"color\":
      \"red\", \"value\": 0.1}\n            ]\n          }\n        }\n      }\n    },\n
      \   {\n      \"id\": 9,\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12,
      \"y\": 20},\n      \"type\": \"timeseries\",\n      \"title\": \"Socket & Connection
      Stats\",\n      \"targets\": [\n        {\n          \"expr\": \"node_sockstat_TCP_inuse\",\n
      \         \"legendFormat\": \"TCP In Use\"\n        },\n        {\n          \"expr\":
      \"node_sockstat_TCP_tw\",\n          \"legendFormat\": \"TCP TIME_WAIT\"\n        },\n
      \       {\n          \"expr\": \"node_sockstat_TCP_orphan\",\n          \"legendFormat\":
      \"TCP Orphaned\"\n        },\n        {\n          \"expr\": \"node_sockstat_UDP_inuse\",\n
      \         \"legendFormat\": \"UDP In Use\"\n        }\n      ],\n      \"fieldConfig\":
      {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"color\":
      {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"lineInterpolation\":
      \"smooth\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 10,\n
      \           \"showPoints\": \"never\",\n            \"spanNulls\": true\n          }\n
      \       }\n      }\n    },\n    {\n      \"id\": 10,\n      \"gridPos\": {\"h\":
      8, \"w\": 8, \"x\": 0, \"y\": 28},\n      \"type\": \"stat\",\n      \"title\":
      \"TCP Connection States\",\n      \"description\": \"System-wide TCP connection
      states\",\n      \"targets\": [\n        {\n          \"expr\": \"node_netstat_Tcp_CurrEstab\",\n
      \         \"legendFormat\": \"Established\"\n        },\n        {\n          \"expr\":
      \"node_sockstat_TCP_tw\",\n          \"legendFormat\": \"TIME_WAIT\"\n        },\n
      \       {\n          \"expr\": \"node_sockstat_TCP_orphan\",\n          \"legendFormat\":
      \"Orphaned\"\n        },\n        {\n          \"expr\": \"node_sockstat_TCP_inuse
      - node_netstat_Tcp_CurrEstab\",\n          \"legendFormat\": \"Other States\"\n
      \       }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\":
      \"short\",\n          \"color\": {\"mode\": \"palette-classic\"}\n        }\n
      \     },\n      \"options\": {\n        \"orientation\": \"horizontal\",\n        \"textMode\":
      \"auto\",\n        \"colorMode\": \"value\",\n        \"graphMode\": \"area\",\n
      \       \"justifyMode\": \"auto\"\n      }\n    },\n    {\n      \"id\": 10,\n
      \     \"gridPos\": {\"h\": 8, \"w\": 8, \"x\": 8, \"y\": 20},\n      \"type\":
      \"piechart\",\n      \"title\": \"Buffer Errors\",\n      \"targets\": [\n        {\n
      \         \"expr\": \"sum(increase(node_netstat_Udp_RcvbufErrors[1h]))\",\n
      \         \"legendFormat\": \"UDP RX Buffer\"\n        },\n        {\n          \"expr\":
      \"sum(increase(node_netstat_Udp_SndbufErrors[1h]))\",\n          \"legendFormat\":
      \"UDP TX Buffer\"\n        },\n        {\n          \"expr\": \"sum(increase(node_network_receive_fifo_total{device=\\\"enp110s0\\\"}[1h]))\",\n
      \         \"legendFormat\": \"RX FIFO\"\n        },\n        {\n          \"expr\":
      \"sum(increase(node_network_transmit_fifo_total{device=\\\"enp110s0\\\"}[1h]))\",\n
      \         \"legendFormat\": \"TX FIFO\"\n        }\n      ],\n      \"fieldConfig\":
      {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"decimals\":
      0\n        }\n      }\n    },\n    {\n      \"id\": 11,\n      \"gridPos\":
      {\"h\": 8, \"w\": 8, \"x\": 16, \"y\": 20},\n      \"type\": \"stat\",\n      \"title\":
      \"TCP Listen Queue Health\",\n      \"targets\": [\n        {\n          \"expr\":
      \"increase(node_netstat_TcpExt_ListenDrops[1h])\",\n          \"legendFormat\":
      \"Listen Drops (1h)\"\n        },\n        {\n          \"expr\": \"increase(node_netstat_TcpExt_ListenOverflows[1h])\",\n
      \         \"legendFormat\": \"Listen Overflows (1h)\"\n        }\n      ],\n
      \     \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n
      \         \"decimals\": 0,\n          \"color\": {\"mode\": \"thresholds\"},\n
      \         \"thresholds\": {\n            \"steps\": [\n              {\"color\":
      \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\":
      1},\n              {\"color\": \"red\", \"value\": 10}\n            ]\n          }\n
      \       }\n      }\n    },\n    {\n      \"id\": 12,\n      \"gridPos\": {\"h\":
      8, \"w\": 12, \"x\": 0, \"y\": 28},\n      \"type\": \"table\",\n      \"title\":
      \"Interface Statistics\",\n      \"targets\": [\n        {\n          \"expr\":
      \"node_network_up{device=\\\"enp110s0\\\"}\",\n          \"format\": \"table\",\n
      \         \"instant\": true,\n          \"refId\": \"A\"\n        },\n        {\n
      \         \"expr\": \"node_network_mtu_bytes{device=\\\"enp110s0\\\"}\",\n          \"format\":
      \"table\",\n          \"instant\": true,\n          \"refId\": \"B\"\n        },\n
      \       {\n          \"expr\": \"increase(node_network_carrier_changes_total{device=\\\"enp110s0\\\"}[1h])\",\n
      \         \"format\": \"table\", \n          \"instant\": true,\n          \"refId\":
      \"C\"\n        },\n        {\n          \"expr\": \"sum by (device) (rate(node_network_receive_packets_total{device=\\\"enp110s0\\\"}[5m]))\",\n
      \         \"format\": \"table\",\n          \"instant\": true,\n          \"refId\":
      \"D\"\n        },\n        {\n          \"expr\": \"sum by (device) (rate(node_network_transmit_packets_total{device=\\\"enp110s0\\\"}[5m]))\",\n
      \         \"format\": \"table\",\n          \"instant\": true,\n          \"refId\":
      \"E\"\n        }\n      ],\n      \"transformations\": [\n        {\n          \"id\":
      \"merge\"\n        },\n        {\n          \"id\": \"groupBy\",\n          \"options\":
      {\n            \"fields\": {\n              \"device\": {\n                \"aggregations\":
      [],\n                \"operation\": \"groupby\"\n              },\n              \"Value
      #A\": {\n                \"aggregations\": [\"lastNotNull\"],\n                \"operation\":
      \"aggregate\"\n              },\n              \"Value #B\": {\n                \"aggregations\":
      [\"lastNotNull\"],\n                \"operation\": \"aggregate\"\n              },\n
      \             \"Value #C\": {\n                \"aggregations\": [\"lastNotNull\"],\n
      \               \"operation\": \"aggregate\"\n              },\n              \"Value
      #D\": {\n                \"aggregations\": [\"lastNotNull\"],\n                \"operation\":
      \"aggregate\"\n              },\n              \"Value #E\": {\n                \"aggregations\":
      [\"lastNotNull\"],\n                \"operation\": \"aggregate\"\n              }\n
      \           }\n          }\n        },\n        {\n          \"id\": \"organize\",\n
      \         \"options\": {\n            \"excludeByName\": {\n              \"Time\":
      true,\n              \"job\": true,\n              \"instance\": true,\n              \"__name__\":
      true\n            },\n            \"renameByName\": {\n              \"device\":
      \"Interface\",\n              \"Value #A (lastNotNull)\": \"Link\",\n              \"Value
      #B (lastNotNull)\": \"MTU\",\n              \"Value #C (lastNotNull)\": \"Carrier
      Changes (1h)\",\n              \"Value #D (lastNotNull)\": \"RX pps\",\n              \"Value
      #E (lastNotNull)\": \"TX pps\"\n            }\n          }\n        }\n      ],\n
      \     \"fieldConfig\": {\n        \"defaults\": {\n          \"custom\": {\n
      \           \"align\": \"auto\"\n          }\n        },\n        \"overrides\":
      [\n          {\n            \"matcher\": {\"id\": \"byName\", \"options\": \"Link\"},\n
      \           \"properties\": [\n              {\n                \"id\": \"mappings\",\n
      \               \"value\": [\n                  {\"type\": \"value\", \"value\":
      \"0\", \"text\": \"DOWN\"},\n                  {\"type\": \"value\", \"value\":
      \"1\", \"text\": \"UP\"}\n                ]\n              },\n              {\n
      \               \"id\": \"custom.displayMode\",\n                \"value\":
      \"color-background\"\n              },\n              {\n                \"id\":
      \"thresholds\",\n                \"value\": {\n                  \"mode\": \"absolute\",\n
      \                 \"steps\": [\n                    {\"color\": \"red\", \"value\":
      null},\n                    {\"color\": \"green\", \"value\": 1}\n                  ]\n
      \               }\n              }\n            ]\n          },\n          {\n
      \           \"matcher\": {\"id\": \"byName\", \"options\": \"RX pps\"},\n            \"properties\":
      [\n              {\"id\": \"unit\", \"value\": \"pps\"},\n              {\"id\":
      \"decimals\", \"value\": 0}\n            ]\n          },\n          {\n            \"matcher\":
      {\"id\": \"byName\", \"options\": \"TX pps\"},\n            \"properties\":
      [\n              {\"id\": \"unit\", \"value\": \"pps\"},\n              {\"id\":
      \"decimals\", \"value\": 0}\n            ]\n          },\n          {\n            \"matcher\":
      {\"id\": \"byName\", \"options\": \"Carrier Changes (1h)\"},\n            \"properties\":
      [\n              {\"id\": \"color\", \"value\": {\"mode\": \"thresholds\"}},\n
      \             {\"id\": \"thresholds\", \"value\": {\n                \"mode\":
      \"absolute\",\n                \"steps\": [\n                  {\"color\": \"green\",
      \"value\": null},\n                  {\"color\": \"yellow\", \"value\": 1},\n
      \                 {\"color\": \"red\", \"value\": 5}\n                ]\n              }}\n
      \           ]\n          }\n        ]\n      }\n    },\n    {\n      \"id\":
      13,\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 28},\n      \"type\":
      \"timeseries\",\n      \"title\": \"Connection Tracking\",\n      \"targets\":
      [\n        {\n          \"expr\": \"node_nf_conntrack_entries\",\n          \"legendFormat\":
      \"Active Connections\"\n        },\n        {\n          \"expr\": \"node_nf_conntrack_entries_limit\",\n
      \         \"legendFormat\": \"Connection Limit\"\n        },\n        {\n          \"expr\":
      \"100 * node_nf_conntrack_entries / node_nf_conntrack_entries_limit\",\n          \"legendFormat\":
      \"Utilization %\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\":
      {\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\":
      {\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\":
      2,\n            \"fillOpacity\": 10,\n            \"showPoints\": \"never\",\n
      \           \"spanNulls\": true\n          }\n        },\n        \"overrides\":
      [\n          {\n            \"matcher\": {\"id\": \"byName\", \"options\": \"Utilization
      %\"},\n            \"properties\": [\n              {\"id\": \"unit\", \"value\":
      \"percent\"},\n              {\"id\": \"custom.axisPlacement\", \"value\": \"right\"}\n
      \           ]\n          }\n        ]\n      }\n    },\n    {\n      \"id\":
      14,\n      \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 36},\n      \"type\":
      \"table\",\n      \"title\": \"All Interface Drop Statistics\",\n      \"description\":
      \"Shows packet drops across all network interfaces\",\n      \"targets\": [\n
      \       {\n          \"expr\": \"rate(node_network_receive_drop_total[5m]) >
      0 or rate(node_network_transmit_drop_total[5m]) > 0\",\n          \"format\":
      \"table\",\n          \"instant\": true,\n          \"refId\": \"A\"\n        }\n
      \     ],\n      \"transformations\": [\n        {\n          \"id\": \"organize\",\n
      \         \"options\": {\n            \"excludeByName\": {\n              \"Time\":
      true,\n              \"job\": true,\n              \"instance\": true,\n              \"__name__\":
      true\n            },\n            \"renameByName\": {\n              \"device\":
      \"Interface\",\n              \"Value\": \"Drops/s\"\n            }\n          }\n
      \       }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\":
      \"pps\",\n          \"decimals\": 3,\n          \"custom\": {\n            \"align\":
      \"auto\",\n            \"displayMode\": \"gradient-gauge\"\n          },\n          \"thresholds\":
      {\n            \"steps\": [\n              {\"color\": \"green\", \"value\":
      null},\n              {\"color\": \"yellow\", \"value\": 0.1},\n              {\"color\":
      \"red\", \"value\": 1}\n            ]\n          }\n        }\n      }\n    },\n
      \   {\n      \"id\": 15,\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0,
      \"y\": 44},\n      \"type\": \"timeseries\",\n      \"title\": \"TCP Congestion
      & Performance\",\n      \"description\": \"TCP performance and congestion indicators\",\n
      \     \"targets\": [\n        {\n          \"expr\": \"rate(node_netstat_Tcp_RetransSegs[5m])\",\n
      \         \"legendFormat\": \"Total Retransmits/s\"\n        },\n        {\n
      \         \"expr\": \"rate(node_netstat_TcpExt_TCPSynRetrans[5m])\",\n          \"legendFormat\":
      \"SYN Retransmits/s\"\n        },\n        {\n          \"expr\": \"rate(node_netstat_TcpExt_TCPTimeouts[5m])\",\n
      \         \"legendFormat\": \"TCP Timeouts/s\"\n        },\n        {\n          \"expr\":
      \"rate(node_netstat_Tcp_InErrs[5m])\",\n          \"legendFormat\": \"TCP In
      Errors/s\"\n        },\n        {\n          \"expr\": \"rate(node_netstat_Tcp_OutRsts[5m])\",\n
      \         \"legendFormat\": \"TCP Resets Sent/s\"\n        }\n      ],\n      \"fieldConfig\":
      {\n        \"defaults\": {\n          \"unit\": \"ops\",\n          \"decimals\":
      3,\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\":
      {\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\":
      2,\n            \"fillOpacity\": 10,\n            \"showPoints\": \"never\",\n
      \           \"spanNulls\": true\n          }\n        }\n      }\n    },\n    {\n
      \     \"id\": 16,\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\":
      44},\n      \"type\": \"timeseries\",\n      \"title\": \"Link Quality Indicators\",\n
      \     \"description\": \"Network link stability and quality metrics\",\n      \"targets\":
      [\n        {\n          \"expr\": \"increase(node_network_carrier_changes_total{device=\\\"enp110s0\\\"}[5m])\",\n
      \         \"legendFormat\": \"Carrier Changes (5m)\"\n        },\n        {\n
      \         \"expr\": \"rate(node_network_receive_frame_total{device=\\\"enp110s0\\\"}[5m])
      * 1000\",\n          \"legendFormat\": \"Frame Errors (milli/s)\"\n        },\n
      \       {\n          \"expr\": \"rate(node_network_receive_fifo_total{device=\\\"enp110s0\\\"}[5m])
      * 1000\",\n          \"legendFormat\": \"RX FIFO Errors (milli/s)\"\n        },\n
      \       {\n          \"expr\": \"rate(node_network_transmit_fifo_total{device=\\\"enp110s0\\\"}[5m])
      * 1000\",\n          \"legendFormat\": \"TX FIFO Errors (milli/s)\"\n        },\n
      \       {\n          \"expr\": \"rate(node_network_transmit_colls_total{device=\\\"enp110s0\\\"}[5m])
      * 1000\",\n          \"legendFormat\": \"Collisions (milli/s)\"\n        }\n
      \     ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\":
      \"short\",\n          \"decimals\": 3,\n          \"color\": {\"mode\": \"palette-classic\"},\n
      \         \"custom\": {\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\":
      2,\n            \"fillOpacity\": 10,\n            \"showPoints\": \"auto\",\n
      \           \"spanNulls\": true,\n            \"drawStyle\": \"bars\"\n          },\n
      \         \"thresholds\": {\n            \"steps\": [\n              {\"color\":
      \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\":
      0.001},\n              {\"color\": \"red\", \"value\": 0.01}\n            ]\n
      \         }\n        }\n      }\n    },\n    {\n      \"id\": 17,\n      \"gridPos\":
      {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 52},\n      \"type\": \"timeseries\",
      \n      \"title\": \"DNS Performance Monitoring\",\n      \"description\": \"DNS
      query performance and reliability (requires DNS instrumentation)\",\n      \"targets\":
      [\n        {\n          \"expr\": \"rate(node_netstat_Udp_OutDatagrams[5m])\",\n
      \         \"legendFormat\": \"UDP Out (includes DNS)\"\n        },\n        {\n
      \         \"expr\": \"rate(node_netstat_Udp_InDatagrams[5m])\",\n          \"legendFormat\":
      \"UDP In (includes DNS)\"\n        },\n        {\n          \"expr\": \"rate(node_netstat_Udp_InErrors[5m])\",\n
      \         \"legendFormat\": \"UDP Errors\"\n        },\n        {\n          \"expr\":
      \"rate(node_netstat_Udp_NoPorts[5m])\",\n          \"legendFormat\": \"UDP No
      Ports\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\":
      {\n          \"unit\": \"pps\",\n          \"decimals\": 2,\n          \"color\":
      {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"lineInterpolation\":
      \"smooth\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 10,\n
      \           \"showPoints\": \"never\",\n            \"spanNulls\": true\n          }\n
      \       }\n      },\n      \"options\": {\n        \"legend\": {\n          \"displayMode\":
      \"table\",\n          \"placement\": \"right\",\n          \"calcs\": [\"mean\",
      \"max\"]\n        }\n      }\n    },\n    {\n      \"id\": 18,\n      \"gridPos\":
      {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 60},\n      \"type\": \"stat\",\n      \"title\":
      \"TCP Listen Queue Health\",\n      \"description\": \"TCP listen queue drops
      and overflows\",\n      \"targets\": [\n        {\n          \"expr\": \"increase(node_netstat_TcpExt_ListenDrops[1h])\",\n
      \         \"legendFormat\": \"Listen Drops (1h)\"\n        },\n        {\n          \"expr\":
      \"increase(node_netstat_TcpExt_ListenOverflows[1h])\",\n          \"legendFormat\":
      \"Listen Overflows (1h)\"\n        },\n        {\n          \"expr\": \"increase(node_netstat_TcpExt_SyncookiesSent[1h])\",\n
      \         \"legendFormat\": \"SYN Cookies Sent (1h)\"\n        },\n        {\n
      \         \"expr\": \"increase(node_netstat_TcpExt_SyncookiesRecv[1h])\",\n
      \         \"legendFormat\": \"SYN Cookies Recv (1h)\"\n        }\n      ],\n
      \     \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n
      \         \"decimals\": 0,\n          \"color\": {\"mode\": \"thresholds\"},\n
      \         \"thresholds\": {\n            \"steps\": [\n              {\"color\":
      \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\":
      10},\n              {\"color\": \"orange\", \"value\": 50},\n              {\"color\":
      \"red\", \"value\": 100}\n            ]\n          }\n        }\n      }\n    },\n
      \   {\n      \"id\": 19,\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12,
      \"y\": 60},\n      \"type\": \"gauge\",\n      \"title\": \"Link Quality Score\",\n
      \     \"description\": \"Overall link quality based on error rates\",\n      \"targets\":
      [\n        {\n          \"expr\": \"(node_network_up{device=\\\"enp110s0\\\"}
      == 1) * 100 - clamp_max((increase(node_network_receive_errs_total{device=\\\"enp110s0\\\"}[5m])
      + increase(node_network_transmit_errs_total{device=\\\"enp110s0\\\"}[5m]) +
      increase(node_network_receive_drop_total{device=\\\"enp110s0\\\"}[5m]) + increase(node_network_transmit_drop_total{device=\\\"enp110s0\\\"}[5m]))
      * 0.1, 5)\",\n          \"legendFormat\": \"Quality %\"\n        }\n      ],\n
      \     \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"percent\",\n
      \         \"decimals\": 4,\n          \"min\": 95,\n          \"max\": 100,\n
      \         \"thresholds\": {\n            \"steps\": [\n              {\"color\":
      \"red\", \"value\": 95},\n              {\"color\": \"orange\", \"value\": 99},\n
      \             {\"color\": \"yellow\", \"value\": 99.9},\n              {\"color\":
      \"green\", \"value\": 99.99}\n            ]\n          }\n        }\n      },\n
      \     \"options\": {\n        \"orientation\": \"horizontal\",\n        \"showThresholdLabels\":
      true,\n        \"showThresholdMarkers\": true\n      }\n    },\n    {\n      \"id\":
      20,\n      \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 68},\n      \"type\":
      \"timeseries\",\n      \"title\": \"TCP Connection Efficiency\",\n      \"description\":
      \"TCP connection establishment and efficiency metrics\",\n      \"targets\":
      [\n        {\n          \"expr\": \"rate(node_netstat_Tcp_ActiveOpens[5m])\",\n
      \         \"legendFormat\": \"Active Opens/s\"\n        },\n        {\n          \"expr\":
      \"rate(node_netstat_Tcp_PassiveOpens[5m])\",\n          \"legendFormat\": \"Passive
      Opens/s\"\n        },\n        {\n          \"expr\": \"rate(node_netstat_Tcp_AttemptFails[5m])\",\n
      \         \"legendFormat\": \"Connection Failures/s\"\n        },\n        {\n
      \         \"expr\": \"rate(node_netstat_Tcp_EstabResets[5m])\",\n          \"legendFormat\":
      \"Established Resets/s\"\n        },\n        {\n          \"expr\": \"100 *
      rate(node_netstat_Tcp_RetransSegs[5m]) / rate(node_netstat_Tcp_OutSegs[5m])\",\n
      \         \"legendFormat\": \"Retransmission Rate %\"\n        }\n      ],\n
      \     \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"ops\",\n
      \         \"decimals\": 3,\n          \"color\": {\"mode\": \"palette-classic\"},\n
      \         \"custom\": {\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\":
      2,\n            \"fillOpacity\": 10,\n            \"showPoints\": \"auto\",\n
      \           \"spanNulls\": true,\n            \"stacking\": {\n              \"mode\":
      \"none\"\n            }\n          }\n        }\n      }\n    }\n  ]\n}\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"network-analysis-dashboard.json":"{\n  \"uid\": \"network-analysis\",\n  \"title\": \"Network Traffic Analysis - Primary Interface (enp110s0)\",\n  \"tags\": [\"network\", \"traffic\", \"razerblade\"],\n  \"timezone\": \"browser\",\n  \"schemaVersion\": 27,\n  \"version\": 3,\n  \"refresh\": \"30s\",\n  \"time\": {\n    \"from\": \"now-1h\",\n    \"to\": \"now\"\n  },\n  \"panels\": [\n    {\n      \"id\": 1,\n      \"gridPos\": {\"h\": 4, \"w\": 6, \"x\": 0, \"y\": 0},\n      \"type\": \"stat\",\n      \"title\": \"Network Health Score\",\n      \"description\": \"Overall network health based on errors and retransmissions\",\n      \"targets\": [\n        {\n          \"expr\": \"100 - (100 * (sum(rate(node_network_receive_errs_total[5m])) + sum(rate(node_network_transmit_errs_total[5m])) + sum(rate(node_netstat_Tcp_RetransSegs[5m]))) / (sum(rate(node_network_receive_packets_total[5m])) + sum(rate(node_network_transmit_packets_total[5m]))))\",\n          \"legendFormat\": \"Health %\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"percent\",\n          \"decimals\": 2,\n          \"color\": {\"mode\": \"thresholds\"},\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"red\", \"value\": null},\n              {\"color\": \"orange\", \"value\": 95},\n              {\"color\": \"yellow\", \"value\": 98},\n              {\"color\": \"green\", \"value\": 99.5}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"id\": 2,\n      \"gridPos\": {\"h\": 4, \"w\": 6, \"x\": 6, \"y\": 0},\n      \"type\": \"stat\",\n      \"title\": \"TCP Retransmission Rate\",\n      \"targets\": [\n        {\n          \"expr\": \"100 * sum(rate(node_netstat_Tcp_RetransSegs[5m])) / sum(rate(node_netstat_Tcp_OutSegs[5m]))\",\n          \"legendFormat\": \"Retrans %\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"percent\",\n          \"decimals\": 3,\n          \"color\": {\"mode\": \"thresholds\"},\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 0.1},\n              {\"color\": \"orange\", \"value\": 1},\n              {\"color\": \"red\", \"value\": 5}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"id\": 3,\n      \"gridPos\": {\"h\": 4, \"w\": 6, \"x\": 12, \"y\": 0},\n      \"type\": \"stat\",\n      \"title\": \"Active TCP Connections\",\n      \"targets\": [\n        {\n          \"expr\": \"node_netstat_Tcp_CurrEstab\",\n          \"legendFormat\": \"Established\"\n        },\n        {\n          \"expr\": \"node_sockstat_TCP_tw\",\n          \"legendFormat\": \"TIME_WAIT\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"color\": {\"mode\": \"palette-classic\"}\n        }\n      }\n    },\n    {\n      \"id\": 4,\n      \"gridPos\": {\"h\": 4, \"w\": 6, \"x\": 18, \"y\": 0},\n      \"type\": \"stat\",\n      \"title\": \"Packet Drops\",\n      \"description\": \"Total packet drops across all interfaces\",\n      \"targets\": [\n        {\n          \"expr\": \"sum(rate(node_network_receive_drop_total{device!=\\\"lo\\\"}[5m]))\",\n          \"legendFormat\": \"RX Drops/s\"\n        },\n        {\n          \"expr\": \"sum(rate(node_network_transmit_drop_total{device!=\\\"lo\\\"}[5m]))\",\n          \"legendFormat\": \"TX Drops/s\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"pps\",\n          \"decimals\": 3,\n          \"color\": {\"mode\": \"thresholds\"},\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 1},\n              {\"color\": \"red\", \"value\": 10}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"id\": 5,\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 4},\n      \"type\": \"timeseries\",\n      \"title\": \"Network Interface Traffic\",\n      \"targets\": [\n        {\n          \"expr\": \"rate(node_network_receive_bytes_total{device=\\\"enp110s0\\\"}[5m])\",\n          \"legendFormat\": \"RX: {{device}}\"\n        },\n        {\n          \"expr\": \"rate(node_network_transmit_bytes_total{device=\\\"enp110s0\\\"}[5m]) * -1\",\n          \"legendFormat\": \"TX: {{device}}\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"binBps\",\n          \"decimals\": 2,\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 10,\n            \"showPoints\": \"never\",\n            \"spanNulls\": true\n          }\n        }\n      }\n    },\n    {\n      \"id\": 6,\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 4},\n      \"type\": \"timeseries\",\n      \"title\": \"TCP Retransmissions \u0026 Timeouts\",\n      \"targets\": [\n        {\n          \"expr\": \"rate(node_netstat_Tcp_RetransSegs[5m])\",\n          \"legendFormat\": \"TCP Retrans/s\"\n        },\n        {\n          \"expr\": \"rate(node_netstat_TcpExt_TCPSynRetrans[5m])\",\n          \"legendFormat\": \"SYN Retrans/s\"\n        },\n        {\n          \"expr\": \"rate(node_netstat_TcpExt_TCPTimeouts[5m])\",\n          \"legendFormat\": \"TCP Timeouts/s\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"ops\",\n          \"decimals\": 2,\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 10,\n            \"showPoints\": \"never\",\n            \"spanNulls\": true\n          }\n        }\n      }\n    },\n    {\n      \"id\": 7,\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 12},\n      \"type\": \"timeseries\",\n      \"title\": \"Network Errors \u0026 Drops (milli-packets/s)\",\n      \"description\": \"Shows errors and drops at millisecond precision\",\n      \"targets\": [\n        {\n          \"expr\": \"rate(node_network_receive_errs_total{device=\\\"enp110s0\\\"}[5m]) * 1000\",\n          \"legendFormat\": \"RX Errors: {{device}}\"\n        },\n        {\n          \"expr\": \"rate(node_network_transmit_errs_total{device=\\\"enp110s0\\\"}[5m]) * 1000\",\n          \"legendFormat\": \"TX Errors: {{device}}\"\n        },\n        {\n          \"expr\": \"rate(node_network_receive_drop_total{device=\\\"enp110s0\\\"}[5m]) * 1000\",\n          \"legendFormat\": \"RX Drops: {{device}}\"\n        },\n        {\n          \"expr\": \"rate(node_network_transmit_drop_total{device=\\\"enp110s0\\\"}[5m]) * 1000\",\n          \"legendFormat\": \"TX Drops: {{device}}\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"none\",\n          \"decimals\": 2,\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 20,\n            \"showPoints\": \"auto\",\n            \"spanNulls\": true,\n            \"drawStyle\": \"line\",\n            \"pointSize\": 4,\n            \"stacking\": {\n              \"mode\": \"none\"\n            }\n          }\n        },\n        \"overrides\": [\n          {\n            \"matcher\": {\"id\": \"byRegexp\", \"options\": \".*Drops.*\"},\n            \"properties\": [\n              {\"id\": \"color\", \"value\": {\"mode\": \"fixed\", \"fixedColor\": \"orange\"}}\n            ]\n          },\n          {\n            \"matcher\": {\"id\": \"byRegexp\", \"options\": \".*Errors.*\"},\n            \"properties\": [\n              {\"id\": \"color\", \"value\": {\"mode\": \"fixed\", \"fixedColor\": \"red\"}}\n            ]\n          }\n        ]\n      }\n    },\n    {\n      \"id\": 8,\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 12},\n      \"type\": \"timeseries\",\n      \"title\": \"Drop Rate Percentage\",\n      \"description\": \"Packet drops as percentage of total packets\",\n      \"targets\": [\n        {\n          \"expr\": \"100 * rate(node_network_receive_drop_total{device=\\\"enp110s0\\\"}[5m]) / rate(node_network_receive_packets_total{device=\\\"enp110s0\\\"}[5m])\",\n          \"legendFormat\": \"RX Drop %\"\n        },\n        {\n          \"expr\": \"100 * rate(node_network_transmit_drop_total{device=\\\"enp110s0\\\"}[5m]) / rate(node_network_transmit_packets_total{device=\\\"enp110s0\\\"}[5m])\",\n          \"legendFormat\": \"TX Drop %\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"percent\",\n          \"decimals\": 4,\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 10,\n            \"showPoints\": \"auto\",\n            \"spanNulls\": true\n          },\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 0.01},\n              {\"color\": \"red\", \"value\": 0.1}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"id\": 9,\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 20},\n      \"type\": \"timeseries\",\n      \"title\": \"Socket \u0026 Connection Stats\",\n      \"targets\": [\n        {\n          \"expr\": \"node_sockstat_TCP_inuse\",\n          \"legendFormat\": \"TCP In Use\"\n        },\n        {\n          \"expr\": \"node_sockstat_TCP_tw\",\n          \"legendFormat\": \"TCP TIME_WAIT\"\n        },\n        {\n          \"expr\": \"node_sockstat_TCP_orphan\",\n          \"legendFormat\": \"TCP Orphaned\"\n        },\n        {\n          \"expr\": \"node_sockstat_UDP_inuse\",\n          \"legendFormat\": \"UDP In Use\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 10,\n            \"showPoints\": \"never\",\n            \"spanNulls\": true\n          }\n        }\n      }\n    },\n    {\n      \"id\": 10,\n      \"gridPos\": {\"h\": 8, \"w\": 8, \"x\": 0, \"y\": 28},\n      \"type\": \"stat\",\n      \"title\": \"TCP Connection States\",\n      \"description\": \"System-wide TCP connection states\",\n      \"targets\": [\n        {\n          \"expr\": \"node_netstat_Tcp_CurrEstab\",\n          \"legendFormat\": \"Established\"\n        },\n        {\n          \"expr\": \"node_sockstat_TCP_tw\",\n          \"legendFormat\": \"TIME_WAIT\"\n        },\n        {\n          \"expr\": \"node_sockstat_TCP_orphan\",\n          \"legendFormat\": \"Orphaned\"\n        },\n        {\n          \"expr\": \"node_sockstat_TCP_inuse - node_netstat_Tcp_CurrEstab\",\n          \"legendFormat\": \"Other States\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"color\": {\"mode\": \"palette-classic\"}\n        }\n      },\n      \"options\": {\n        \"orientation\": \"horizontal\",\n        \"textMode\": \"auto\",\n        \"colorMode\": \"value\",\n        \"graphMode\": \"area\",\n        \"justifyMode\": \"auto\"\n      }\n    },\n    {\n      \"id\": 10,\n      \"gridPos\": {\"h\": 8, \"w\": 8, \"x\": 8, \"y\": 20},\n      \"type\": \"piechart\",\n      \"title\": \"Buffer Errors\",\n      \"targets\": [\n        {\n          \"expr\": \"sum(increase(node_netstat_Udp_RcvbufErrors[1h]))\",\n          \"legendFormat\": \"UDP RX Buffer\"\n        },\n        {\n          \"expr\": \"sum(increase(node_netstat_Udp_SndbufErrors[1h]))\",\n          \"legendFormat\": \"UDP TX Buffer\"\n        },\n        {\n          \"expr\": \"sum(increase(node_network_receive_fifo_total{device=\\\"enp110s0\\\"}[1h]))\",\n          \"legendFormat\": \"RX FIFO\"\n        },\n        {\n          \"expr\": \"sum(increase(node_network_transmit_fifo_total{device=\\\"enp110s0\\\"}[1h]))\",\n          \"legendFormat\": \"TX FIFO\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"decimals\": 0\n        }\n      }\n    },\n    {\n      \"id\": 11,\n      \"gridPos\": {\"h\": 8, \"w\": 8, \"x\": 16, \"y\": 20},\n      \"type\": \"stat\",\n      \"title\": \"TCP Listen Queue Health\",\n      \"targets\": [\n        {\n          \"expr\": \"increase(node_netstat_TcpExt_ListenDrops[1h])\",\n          \"legendFormat\": \"Listen Drops (1h)\"\n        },\n        {\n          \"expr\": \"increase(node_netstat_TcpExt_ListenOverflows[1h])\",\n          \"legendFormat\": \"Listen Overflows (1h)\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"decimals\": 0,\n          \"color\": {\"mode\": \"thresholds\"},\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 1},\n              {\"color\": \"red\", \"value\": 10}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"id\": 12,\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 28},\n      \"type\": \"table\",\n      \"title\": \"Interface Statistics\",\n      \"targets\": [\n        {\n          \"expr\": \"node_network_up{device=\\\"enp110s0\\\"}\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"node_network_mtu_bytes{device=\\\"enp110s0\\\"}\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"B\"\n        },\n        {\n          \"expr\": \"increase(node_network_carrier_changes_total{device=\\\"enp110s0\\\"}[1h])\",\n          \"format\": \"table\", \n          \"instant\": true,\n          \"refId\": \"C\"\n        },\n        {\n          \"expr\": \"sum by (device) (rate(node_network_receive_packets_total{device=\\\"enp110s0\\\"}[5m]))\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"D\"\n        },\n        {\n          \"expr\": \"sum by (device) (rate(node_network_transmit_packets_total{device=\\\"enp110s0\\\"}[5m]))\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"E\"\n        }\n      ],\n      \"transformations\": [\n        {\n          \"id\": \"merge\"\n        },\n        {\n          \"id\": \"groupBy\",\n          \"options\": {\n            \"fields\": {\n              \"device\": {\n                \"aggregations\": [],\n                \"operation\": \"groupby\"\n              },\n              \"Value #A\": {\n                \"aggregations\": [\"lastNotNull\"],\n                \"operation\": \"aggregate\"\n              },\n              \"Value #B\": {\n                \"aggregations\": [\"lastNotNull\"],\n                \"operation\": \"aggregate\"\n              },\n              \"Value #C\": {\n                \"aggregations\": [\"lastNotNull\"],\n                \"operation\": \"aggregate\"\n              },\n              \"Value #D\": {\n                \"aggregations\": [\"lastNotNull\"],\n                \"operation\": \"aggregate\"\n              },\n              \"Value #E\": {\n                \"aggregations\": [\"lastNotNull\"],\n                \"operation\": \"aggregate\"\n              }\n            }\n          }\n        },\n        {\n          \"id\": \"organize\",\n          \"options\": {\n            \"excludeByName\": {\n              \"Time\": true,\n              \"job\": true,\n              \"instance\": true,\n              \"__name__\": true\n            },\n            \"renameByName\": {\n              \"device\": \"Interface\",\n              \"Value #A (lastNotNull)\": \"Link\",\n              \"Value #B (lastNotNull)\": \"MTU\",\n              \"Value #C (lastNotNull)\": \"Carrier Changes (1h)\",\n              \"Value #D (lastNotNull)\": \"RX pps\",\n              \"Value #E (lastNotNull)\": \"TX pps\"\n            }\n          }\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"custom\": {\n            \"align\": \"auto\"\n          }\n        },\n        \"overrides\": [\n          {\n            \"matcher\": {\"id\": \"byName\", \"options\": \"Link\"},\n            \"properties\": [\n              {\n                \"id\": \"mappings\",\n                \"value\": [\n                  {\"type\": \"value\", \"value\": \"0\", \"text\": \"DOWN\"},\n                  {\"type\": \"value\", \"value\": \"1\", \"text\": \"UP\"}\n                ]\n              },\n              {\n                \"id\": \"custom.displayMode\",\n                \"value\": \"color-background\"\n              },\n              {\n                \"id\": \"thresholds\",\n                \"value\": {\n                  \"mode\": \"absolute\",\n                  \"steps\": [\n                    {\"color\": \"red\", \"value\": null},\n                    {\"color\": \"green\", \"value\": 1}\n                  ]\n                }\n              }\n            ]\n          },\n          {\n            \"matcher\": {\"id\": \"byName\", \"options\": \"RX pps\"},\n            \"properties\": [\n              {\"id\": \"unit\", \"value\": \"pps\"},\n              {\"id\": \"decimals\", \"value\": 0}\n            ]\n          },\n          {\n            \"matcher\": {\"id\": \"byName\", \"options\": \"TX pps\"},\n            \"properties\": [\n              {\"id\": \"unit\", \"value\": \"pps\"},\n              {\"id\": \"decimals\", \"value\": 0}\n            ]\n          },\n          {\n            \"matcher\": {\"id\": \"byName\", \"options\": \"Carrier Changes (1h)\"},\n            \"properties\": [\n              {\"id\": \"color\", \"value\": {\"mode\": \"thresholds\"}},\n              {\"id\": \"thresholds\", \"value\": {\n                \"mode\": \"absolute\",\n                \"steps\": [\n                  {\"color\": \"green\", \"value\": null},\n                  {\"color\": \"yellow\", \"value\": 1},\n                  {\"color\": \"red\", \"value\": 5}\n                ]\n              }}\n            ]\n          }\n        ]\n      }\n    },\n    {\n      \"id\": 13,\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 28},\n      \"type\": \"timeseries\",\n      \"title\": \"Connection Tracking\",\n      \"targets\": [\n        {\n          \"expr\": \"node_nf_conntrack_entries\",\n          \"legendFormat\": \"Active Connections\"\n        },\n        {\n          \"expr\": \"node_nf_conntrack_entries_limit\",\n          \"legendFormat\": \"Connection Limit\"\n        },\n        {\n          \"expr\": \"100 * node_nf_conntrack_entries / node_nf_conntrack_entries_limit\",\n          \"legendFormat\": \"Utilization %\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 10,\n            \"showPoints\": \"never\",\n            \"spanNulls\": true\n          }\n        },\n        \"overrides\": [\n          {\n            \"matcher\": {\"id\": \"byName\", \"options\": \"Utilization %\"},\n            \"properties\": [\n              {\"id\": \"unit\", \"value\": \"percent\"},\n              {\"id\": \"custom.axisPlacement\", \"value\": \"right\"}\n            ]\n          }\n        ]\n      }\n    },\n    {\n      \"id\": 14,\n      \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 36},\n      \"type\": \"table\",\n      \"title\": \"All Interface Drop Statistics\",\n      \"description\": \"Shows packet drops across all network interfaces\",\n      \"targets\": [\n        {\n          \"expr\": \"rate(node_network_receive_drop_total[5m]) \u003e 0 or rate(node_network_transmit_drop_total[5m]) \u003e 0\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"transformations\": [\n        {\n          \"id\": \"organize\",\n          \"options\": {\n            \"excludeByName\": {\n              \"Time\": true,\n              \"job\": true,\n              \"instance\": true,\n              \"__name__\": true\n            },\n            \"renameByName\": {\n              \"device\": \"Interface\",\n              \"Value\": \"Drops/s\"\n            }\n          }\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"pps\",\n          \"decimals\": 3,\n          \"custom\": {\n            \"align\": \"auto\",\n            \"displayMode\": \"gradient-gauge\"\n          },\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 0.1},\n              {\"color\": \"red\", \"value\": 1}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"id\": 15,\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 44},\n      \"type\": \"timeseries\",\n      \"title\": \"TCP Congestion \u0026 Performance\",\n      \"description\": \"TCP performance and congestion indicators\",\n      \"targets\": [\n        {\n          \"expr\": \"rate(node_netstat_Tcp_RetransSegs[5m])\",\n          \"legendFormat\": \"Total Retransmits/s\"\n        },\n        {\n          \"expr\": \"rate(node_netstat_TcpExt_TCPSynRetrans[5m])\",\n          \"legendFormat\": \"SYN Retransmits/s\"\n        },\n        {\n          \"expr\": \"rate(node_netstat_TcpExt_TCPTimeouts[5m])\",\n          \"legendFormat\": \"TCP Timeouts/s\"\n        },\n        {\n          \"expr\": \"rate(node_netstat_Tcp_InErrs[5m])\",\n          \"legendFormat\": \"TCP In Errors/s\"\n        },\n        {\n          \"expr\": \"rate(node_netstat_Tcp_OutRsts[5m])\",\n          \"legendFormat\": \"TCP Resets Sent/s\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"ops\",\n          \"decimals\": 3,\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 10,\n            \"showPoints\": \"never\",\n            \"spanNulls\": true\n          }\n        }\n      }\n    },\n    {\n      \"id\": 16,\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 44},\n      \"type\": \"timeseries\",\n      \"title\": \"Link Quality Indicators\",\n      \"description\": \"Network link stability and quality metrics\",\n      \"targets\": [\n        {\n          \"expr\": \"increase(node_network_carrier_changes_total{device=\\\"enp110s0\\\"}[5m])\",\n          \"legendFormat\": \"Carrier Changes (5m)\"\n        },\n        {\n          \"expr\": \"rate(node_network_receive_frame_total{device=\\\"enp110s0\\\"}[5m]) * 1000\",\n          \"legendFormat\": \"Frame Errors (milli/s)\"\n        },\n        {\n          \"expr\": \"rate(node_network_receive_fifo_total{device=\\\"enp110s0\\\"}[5m]) * 1000\",\n          \"legendFormat\": \"RX FIFO Errors (milli/s)\"\n        },\n        {\n          \"expr\": \"rate(node_network_transmit_fifo_total{device=\\\"enp110s0\\\"}[5m]) * 1000\",\n          \"legendFormat\": \"TX FIFO Errors (milli/s)\"\n        },\n        {\n          \"expr\": \"rate(node_network_transmit_colls_total{device=\\\"enp110s0\\\"}[5m]) * 1000\",\n          \"legendFormat\": \"Collisions (milli/s)\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"decimals\": 3,\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 10,\n            \"showPoints\": \"auto\",\n            \"spanNulls\": true,\n            \"drawStyle\": \"bars\"\n          },\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 0.001},\n              {\"color\": \"red\", \"value\": 0.01}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"id\": 17,\n      \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 52},\n      \"type\": \"timeseries\", \n      \"title\": \"DNS Performance Monitoring\",\n      \"description\": \"DNS query performance and reliability (requires DNS instrumentation)\",\n      \"targets\": [\n        {\n          \"expr\": \"rate(node_netstat_Udp_OutDatagrams[5m])\",\n          \"legendFormat\": \"UDP Out (includes DNS)\"\n        },\n        {\n          \"expr\": \"rate(node_netstat_Udp_InDatagrams[5m])\",\n          \"legendFormat\": \"UDP In (includes DNS)\"\n        },\n        {\n          \"expr\": \"rate(node_netstat_Udp_InErrors[5m])\",\n          \"legendFormat\": \"UDP Errors\"\n        },\n        {\n          \"expr\": \"rate(node_netstat_Udp_NoPorts[5m])\",\n          \"legendFormat\": \"UDP No Ports\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"pps\",\n          \"decimals\": 2,\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 10,\n            \"showPoints\": \"never\",\n            \"spanNulls\": true\n          }\n        }\n      },\n      \"options\": {\n        \"legend\": {\n          \"displayMode\": \"table\",\n          \"placement\": \"right\",\n          \"calcs\": [\"mean\", \"max\"]\n        }\n      }\n    },\n    {\n      \"id\": 18,\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 60},\n      \"type\": \"stat\",\n      \"title\": \"TCP Listen Queue Health\",\n      \"description\": \"TCP listen queue drops and overflows\",\n      \"targets\": [\n        {\n          \"expr\": \"increase(node_netstat_TcpExt_ListenDrops[1h])\",\n          \"legendFormat\": \"Listen Drops (1h)\"\n        },\n        {\n          \"expr\": \"increase(node_netstat_TcpExt_ListenOverflows[1h])\",\n          \"legendFormat\": \"Listen Overflows (1h)\"\n        },\n        {\n          \"expr\": \"increase(node_netstat_TcpExt_SyncookiesSent[1h])\",\n          \"legendFormat\": \"SYN Cookies Sent (1h)\"\n        },\n        {\n          \"expr\": \"increase(node_netstat_TcpExt_SyncookiesRecv[1h])\",\n          \"legendFormat\": \"SYN Cookies Recv (1h)\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"decimals\": 0,\n          \"color\": {\"mode\": \"thresholds\"},\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 10},\n              {\"color\": \"orange\", \"value\": 50},\n              {\"color\": \"red\", \"value\": 100}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"id\": 19,\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 60},\n      \"type\": \"gauge\",\n      \"title\": \"Link Quality Score\",\n      \"description\": \"Overall link quality based on error rates\",\n      \"targets\": [\n        {\n          \"expr\": \"(node_network_up{device=\\\"enp110s0\\\"} == 1) * 100 - clamp_max((increase(node_network_receive_errs_total{device=\\\"enp110s0\\\"}[5m]) + increase(node_network_transmit_errs_total{device=\\\"enp110s0\\\"}[5m]) + increase(node_network_receive_drop_total{device=\\\"enp110s0\\\"}[5m]) + increase(node_network_transmit_drop_total{device=\\\"enp110s0\\\"}[5m])) * 0.1, 5)\",\n          \"legendFormat\": \"Quality %\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"percent\",\n          \"decimals\": 4,\n          \"min\": 95,\n          \"max\": 100,\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"red\", \"value\": 95},\n              {\"color\": \"orange\", \"value\": 99},\n              {\"color\": \"yellow\", \"value\": 99.9},\n              {\"color\": \"green\", \"value\": 99.99}\n            ]\n          }\n        }\n      },\n      \"options\": {\n        \"orientation\": \"horizontal\",\n        \"showThresholdLabels\": true,\n        \"showThresholdMarkers\": true\n      }\n    },\n    {\n      \"id\": 20,\n      \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 68},\n      \"type\": \"timeseries\",\n      \"title\": \"TCP Connection Efficiency\",\n      \"description\": \"TCP connection establishment and efficiency metrics\",\n      \"targets\": [\n        {\n          \"expr\": \"rate(node_netstat_Tcp_ActiveOpens[5m])\",\n          \"legendFormat\": \"Active Opens/s\"\n        },\n        {\n          \"expr\": \"rate(node_netstat_Tcp_PassiveOpens[5m])\",\n          \"legendFormat\": \"Passive Opens/s\"\n        },\n        {\n          \"expr\": \"rate(node_netstat_Tcp_AttemptFails[5m])\",\n          \"legendFormat\": \"Connection Failures/s\"\n        },\n        {\n          \"expr\": \"rate(node_netstat_Tcp_EstabResets[5m])\",\n          \"legendFormat\": \"Established Resets/s\"\n        },\n        {\n          \"expr\": \"100 * rate(node_netstat_Tcp_RetransSegs[5m]) / rate(node_netstat_Tcp_OutSegs[5m])\",\n          \"legendFormat\": \"Retransmission Rate %\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"ops\",\n          \"decimals\": 3,\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 10,\n            \"showPoints\": \"auto\",\n            \"spanNulls\": true,\n            \"stacking\": {\n              \"mode\": \"none\"\n            }\n          }\n        }\n      }\n    }\n  ]\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"grafana_dashboard":"1"},"name":"network-analysis-dashboard","namespace":"monitoring"}}
    creationTimestamp: "2025-05-28T00:29:49Z"
    labels:
      grafana_dashboard: "1"
    name: network-analysis-dashboard
    namespace: monitoring
    resourceVersion: "82179"
    uid: fb6f0a15-0d63-4955-a39e-c4b983543d16
- apiVersion: v1
  data:
    network-exporter.py: "#!/usr/bin/env python3\nimport os\nimport time\nimport subprocess\nimport
      re\nfrom collections import defaultdict\nfrom prometheus_client import start_http_server,
      Gauge, Counter\n\n# Define Prometheus metrics\nprocess_network_rx_bytes = Counter('process_network_receive_bytes_total',
      'Network bytes received by process', ['process', 'pid'])\nprocess_network_tx_bytes
      = Counter('process_network_transmit_bytes_total', 'Network bytes transmitted
      by process', ['process', 'pid'])\nprocess_network_connections = Gauge('process_network_connections',
      'Number of network connections by process', ['process', 'pid', 'state'])\nprocess_network_rx_packets
      = Counter('process_network_receive_packets_total', 'Network packets received
      by process', ['process', 'pid'])\nprocess_network_tx_packets = Counter('process_network_transmit_packets_total',
      'Network packets transmitted by process', ['process', 'pid'])\n\ndef get_process_name(pid):\n
      \   \"\"\"Get process name from PID\"\"\"\n    try:\n        with open(f'/proc/{pid}/comm',
      'r') as f:\n            return f.read().strip()\n    except:\n        return
      \"unknown\"\n\ndef parse_ss_output():\n    \"\"\"Parse ss command output for
      network statistics per process\"\"\"\n    try:\n        # Get detailed socket
      statistics with process info\n        result = subprocess.run(['ss', '-tuanp'],
      capture_output=True, text=True)\n        if result.returncode != 0:\n            return
      {}\n        \n        connections = defaultdict(lambda: defaultdict(int))\n
      \       \n        for line in result.stdout.split('\\n')[1:]:  # Skip header\n
      \           if not line:\n                continue\n                \n            parts
      = line.split()\n            if len(parts) < 7:\n                continue\n            \n
      \           state = parts[1]\n            \n            # Extract process info
      from last column (e.g., \"users:((\"chrome\",pid=1234,fd=45))\")\n            process_match
      = re.search(r'users:\\(\\(\"([^\"]+)\",pid=(\\d+)', line)\n            if process_match:\n
      \               process_name = process_match.group(1)\n                pid =
      process_match.group(2)\n                \n                connections[(process_name,
      pid)][state] += 1\n        \n        return connections\n    except Exception
      as e:\n        print(f\"Error parsing ss output: {e}\")\n        return {}\n\ndef
      get_network_stats_from_nethogs():\n    \"\"\"Get per-process network bandwidth
      using nethogs in batch mode\"\"\"\n    try:\n        # Run nethogs in batch
      mode for 2 seconds\n        result = subprocess.run(['nethogs', '-t', '-c',
      '2'], capture_output=True, text=True)\n        if result.returncode != 0:\n
      \           return {}\n        \n        stats = {}\n        for line in result.stdout.split('\\n'):\n
      \           if not line or line.startswith('Refreshing'):\n                continue\n
      \           \n            parts = line.split('\\t')\n            if len(parts)
      >= 3:\n                process_path = parts[0]\n                sent_kb = float(parts[1])\n
      \               recv_kb = float(parts[2])\n                \n                #
      Extract process name from path\n                process_name = os.path.basename(process_path.split()[0])
      if process_path else \"unknown\"\n                \n                stats[process_name]
      = {\n                    'sent_bytes': sent_kb * 1024,\n                    'recv_bytes':
      recv_kb * 1024\n                }\n        \n        return stats\n    except
      Exception as e:\n        print(f\"Error getting nethogs stats: {e}\")\n        return
      {}\n\ndef collect_network_metrics():\n    \"\"\"Collect network metrics per
      process\"\"\"\n    # Get connection counts\n    connections = parse_ss_output()\n
      \   for (process, pid), states in connections.items():\n        for state, count
      in states.items():\n            process_network_connections.labels(process=process,
      pid=pid, state=state).set(count)\n    \n    # Try to get bandwidth stats (requires
      nethogs)\n    bandwidth_stats = get_network_stats_from_nethogs()\n    for process,
      stats in bandwidth_stats.items():\n        # For bandwidth stats, we don't have
      PID from nethogs\n        process_network_tx_bytes.labels(process=process, pid=\"0\").inc(stats['sent_bytes'])\n
      \       process_network_rx_bytes.labels(process=process, pid=\"0\").inc(stats['recv_bytes'])\n\nif
      __name__ == '__main__':\n    # Start Prometheus metrics server\n    start_http_server(9403)\n
      \   \n    print(\"Network exporter started on port 9403\")\n    \n    # Collect
      metrics every 10 seconds\n    while True:\n        try:\n            collect_network_metrics()\n
      \       except Exception as e:\n            print(f\"Error collecting metrics:
      {e}\")\n        time.sleep(10)\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"network-exporter.py":"#!/usr/bin/env python3\nimport os\nimport time\nimport subprocess\nimport re\nfrom collections import defaultdict\nfrom prometheus_client import start_http_server, Gauge, Counter\n\n# Define Prometheus metrics\nprocess_network_rx_bytes = Counter('process_network_receive_bytes_total', 'Network bytes received by process', ['process', 'pid'])\nprocess_network_tx_bytes = Counter('process_network_transmit_bytes_total', 'Network bytes transmitted by process', ['process', 'pid'])\nprocess_network_connections = Gauge('process_network_connections', 'Number of network connections by process', ['process', 'pid', 'state'])\nprocess_network_rx_packets = Counter('process_network_receive_packets_total', 'Network packets received by process', ['process', 'pid'])\nprocess_network_tx_packets = Counter('process_network_transmit_packets_total', 'Network packets transmitted by process', ['process', 'pid'])\n\ndef get_process_name(pid):\n    \"\"\"Get process name from PID\"\"\"\n    try:\n        with open(f'/proc/{pid}/comm', 'r') as f:\n            return f.read().strip()\n    except:\n        return \"unknown\"\n\ndef parse_ss_output():\n    \"\"\"Parse ss command output for network statistics per process\"\"\"\n    try:\n        # Get detailed socket statistics with process info\n        result = subprocess.run(['ss', '-tuanp'], capture_output=True, text=True)\n        if result.returncode != 0:\n            return {}\n        \n        connections = defaultdict(lambda: defaultdict(int))\n        \n        for line in result.stdout.split('\\n')[1:]:  # Skip header\n            if not line:\n                continue\n                \n            parts = line.split()\n            if len(parts) \u003c 7:\n                continue\n            \n            state = parts[1]\n            \n            # Extract process info from last column (e.g., \"users:((\"chrome\",pid=1234,fd=45))\")\n            process_match = re.search(r'users:\\(\\(\"([^\"]+)\",pid=(\\d+)', line)\n            if process_match:\n                process_name = process_match.group(1)\n                pid = process_match.group(2)\n                \n                connections[(process_name, pid)][state] += 1\n        \n        return connections\n    except Exception as e:\n        print(f\"Error parsing ss output: {e}\")\n        return {}\n\ndef get_network_stats_from_nethogs():\n    \"\"\"Get per-process network bandwidth using nethogs in batch mode\"\"\"\n    try:\n        # Run nethogs in batch mode for 2 seconds\n        result = subprocess.run(['nethogs', '-t', '-c', '2'], capture_output=True, text=True)\n        if result.returncode != 0:\n            return {}\n        \n        stats = {}\n        for line in result.stdout.split('\\n'):\n            if not line or line.startswith('Refreshing'):\n                continue\n            \n            parts = line.split('\\t')\n            if len(parts) \u003e= 3:\n                process_path = parts[0]\n                sent_kb = float(parts[1])\n                recv_kb = float(parts[2])\n                \n                # Extract process name from path\n                process_name = os.path.basename(process_path.split()[0]) if process_path else \"unknown\"\n                \n                stats[process_name] = {\n                    'sent_bytes': sent_kb * 1024,\n                    'recv_bytes': recv_kb * 1024\n                }\n        \n        return stats\n    except Exception as e:\n        print(f\"Error getting nethogs stats: {e}\")\n        return {}\n\ndef collect_network_metrics():\n    \"\"\"Collect network metrics per process\"\"\"\n    # Get connection counts\n    connections = parse_ss_output()\n    for (process, pid), states in connections.items():\n        for state, count in states.items():\n            process_network_connections.labels(process=process, pid=pid, state=state).set(count)\n    \n    # Try to get bandwidth stats (requires nethogs)\n    bandwidth_stats = get_network_stats_from_nethogs()\n    for process, stats in bandwidth_stats.items():\n        # For bandwidth stats, we don't have PID from nethogs\n        process_network_tx_bytes.labels(process=process, pid=\"0\").inc(stats['sent_bytes'])\n        process_network_rx_bytes.labels(process=process, pid=\"0\").inc(stats['recv_bytes'])\n\nif __name__ == '__main__':\n    # Start Prometheus metrics server\n    start_http_server(9403)\n    \n    print(\"Network exporter started on port 9403\")\n    \n    # Collect metrics every 10 seconds\n    while True:\n        try:\n            collect_network_metrics()\n        except Exception as e:\n            print(f\"Error collecting metrics: {e}\")\n        time.sleep(10)\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"network-exporter-script","namespace":"monitoring"}}
    creationTimestamp: "2025-05-28T00:28:37Z"
    name: network-exporter-script
    namespace: monitoring
    resourceVersion: "6999"
    uid: 94b0c458-5644-4ac4-82a4-1579ee85e522
- apiVersion: v1
  data:
    network-exporter.py: "#!/usr/bin/env python3\nimport os\nimport time\nimport subprocess\nimport
      re\nfrom collections import defaultdict\nfrom prometheus_client import start_http_server,
      Gauge, Counter\n\n# Define Prometheus metrics\nprocess_network_connections =
      Gauge('process_network_connections', 'Number of network connections by process',
      ['pid', 'state', 'protocol'])\nsystem_tcp_connections = Gauge('system_tcp_connections_total',
      'Total TCP connections by state', ['state'])\nsystem_udp_connections = Gauge('system_udp_connections_total',
      'Total UDP connections')\n\ndef get_process_name(pid):\n    \"\"\"Get process
      name from PID\"\"\"\n    try:\n        with open(f'/proc/{pid}/comm', 'r') as
      f:\n            return f.read().strip()\n    except:\n        return None\n\ndef
      parse_proc_net_tcp():\n    \"\"\"Parse /proc/net/tcp for TCP connections\"\"\"\n
      \   TCP_STATES = {\n        '01': 'ESTAB',\n        '02': 'SYN_SENT',\n        '03':
      'SYN_RECV',\n        '04': 'FIN_WAIT1',\n        '05': 'FIN_WAIT2',\n        '06':
      'TIME_WAIT',\n        '07': 'CLOSE',\n        '08': 'CLOSE_WAIT',\n        '09':
      'LAST_ACK',\n        '0A': 'LISTEN',\n        '0B': 'CLOSING'\n    }\n    \n
      \   connections = defaultdict(int)\n    \n    try:\n        with open('/proc/net/tcp',
      'r') as f:\n            lines = f.readlines()[1:]  # Skip header\n            \n
      \       for line in lines:\n            parts = line.split()\n            if
      len(parts) >= 10:\n                state = parts[3]\n                state_name
      = TCP_STATES.get(state, 'UNKNOWN')\n                connections[state_name]
      += 1\n                \n                # Try to get inode to match with process\n
      \               inode = parts[9]\n                if inode != '0':\n                    #
      Find process that owns this socket\n                    for pid in os.listdir('/proc'):\n
      \                       if not pid.isdigit():\n                            continue\n
      \                       try:\n                            fd_path = f'/proc/{pid}/fd'\n
      \                           if os.path.exists(fd_path):\n                                for
      fd in os.listdir(fd_path):\n                                    try:\n                                        link
      = os.readlink(f'{fd_path}/{fd}')\n                                        if
      f'socket:[{inode}]' in link:\n                                            process_network_connections.labels(\n
      \                                               pid=pid,\n                                                state=state_name,\n
      \                                               protocol='tcp'\n                                            ).set(1)\n
      \                                   except:\n                                        pass\n
      \                       except:\n                            pass\n        \n
      \       # Update system-wide metrics\n        for state, count in connections.items():\n
      \           system_tcp_connections.labels(state=state).set(count)\n            \n
      \   except Exception as e:\n        print(f\"Error parsing /proc/net/tcp: {e}\")\n\ndef
      parse_proc_net_udp():\n    \"\"\"Parse /proc/net/udp for UDP connections\"\"\"\n
      \   try:\n        with open('/proc/net/udp', 'r') as f:\n            lines =
      f.readlines()[1:]  # Skip header\n            \n        udp_count = len(lines)\n
      \       system_udp_connections.set(udp_count)\n        \n    except Exception
      as e:\n        print(f\"Error parsing /proc/net/udp: {e}\")\n\ndef collect_network_metrics():\n
      \   \"\"\"Collect network metrics from /proc/net\"\"\"\n    # Reset metrics\n
      \   process_network_connections._metrics.clear()\n    \n    # Collect TCP connections\n
      \   parse_proc_net_tcp()\n    \n    # Collect UDP connections\n    parse_proc_net_udp()\n\nif
      __name__ == '__main__':\n    # Start Prometheus metrics server\n    start_http_server(9404)\n
      \   \n    print(\"Network exporter v2 started on port 9404\")\n    \n    # Collect
      metrics every 10 seconds\n    while True:\n        try:\n            collect_network_metrics()\n
      \       except Exception as e:\n            print(f\"Error collecting metrics:
      {e}\")\n        time.sleep(10)\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"network-exporter.py":"#!/usr/bin/env python3\nimport os\nimport time\nimport subprocess\nimport re\nfrom collections import defaultdict\nfrom prometheus_client import start_http_server, Gauge, Counter\n\n# Define Prometheus metrics\nprocess_network_connections = Gauge('process_network_connections', 'Number of network connections by process', ['pid', 'state', 'protocol'])\nsystem_tcp_connections = Gauge('system_tcp_connections_total', 'Total TCP connections by state', ['state'])\nsystem_udp_connections = Gauge('system_udp_connections_total', 'Total UDP connections')\n\ndef get_process_name(pid):\n    \"\"\"Get process name from PID\"\"\"\n    try:\n        with open(f'/proc/{pid}/comm', 'r') as f:\n            return f.read().strip()\n    except:\n        return None\n\ndef parse_proc_net_tcp():\n    \"\"\"Parse /proc/net/tcp for TCP connections\"\"\"\n    TCP_STATES = {\n        '01': 'ESTAB',\n        '02': 'SYN_SENT',\n        '03': 'SYN_RECV',\n        '04': 'FIN_WAIT1',\n        '05': 'FIN_WAIT2',\n        '06': 'TIME_WAIT',\n        '07': 'CLOSE',\n        '08': 'CLOSE_WAIT',\n        '09': 'LAST_ACK',\n        '0A': 'LISTEN',\n        '0B': 'CLOSING'\n    }\n    \n    connections = defaultdict(int)\n    \n    try:\n        with open('/proc/net/tcp', 'r') as f:\n            lines = f.readlines()[1:]  # Skip header\n            \n        for line in lines:\n            parts = line.split()\n            if len(parts) \u003e= 10:\n                state = parts[3]\n                state_name = TCP_STATES.get(state, 'UNKNOWN')\n                connections[state_name] += 1\n                \n                # Try to get inode to match with process\n                inode = parts[9]\n                if inode != '0':\n                    # Find process that owns this socket\n                    for pid in os.listdir('/proc'):\n                        if not pid.isdigit():\n                            continue\n                        try:\n                            fd_path = f'/proc/{pid}/fd'\n                            if os.path.exists(fd_path):\n                                for fd in os.listdir(fd_path):\n                                    try:\n                                        link = os.readlink(f'{fd_path}/{fd}')\n                                        if f'socket:[{inode}]' in link:\n                                            process_network_connections.labels(\n                                                pid=pid,\n                                                state=state_name,\n                                                protocol='tcp'\n                                            ).set(1)\n                                    except:\n                                        pass\n                        except:\n                            pass\n        \n        # Update system-wide metrics\n        for state, count in connections.items():\n            system_tcp_connections.labels(state=state).set(count)\n            \n    except Exception as e:\n        print(f\"Error parsing /proc/net/tcp: {e}\")\n\ndef parse_proc_net_udp():\n    \"\"\"Parse /proc/net/udp for UDP connections\"\"\"\n    try:\n        with open('/proc/net/udp', 'r') as f:\n            lines = f.readlines()[1:]  # Skip header\n            \n        udp_count = len(lines)\n        system_udp_connections.set(udp_count)\n        \n    except Exception as e:\n        print(f\"Error parsing /proc/net/udp: {e}\")\n\ndef collect_network_metrics():\n    \"\"\"Collect network metrics from /proc/net\"\"\"\n    # Reset metrics\n    process_network_connections._metrics.clear()\n    \n    # Collect TCP connections\n    parse_proc_net_tcp()\n    \n    # Collect UDP connections\n    parse_proc_net_udp()\n\nif __name__ == '__main__':\n    # Start Prometheus metrics server\n    start_http_server(9404)\n    \n    print(\"Network exporter v2 started on port 9404\")\n    \n    # Collect metrics every 10 seconds\n    while True:\n        try:\n            collect_network_metrics()\n        except Exception as e:\n            print(f\"Error collecting metrics: {e}\")\n        time.sleep(10)\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"network-exporter-script-v2","namespace":"monitoring"}}
    creationTimestamp: "2025-05-29T19:16:52Z"
    name: network-exporter-script-v2
    namespace: monitoring
    resourceVersion: "78837"
    uid: dec35295-3ab0-449e-9388-f8eb79362482
- apiVersion: v1
  data:
    network-overview-dashboard.json: |
      {
        "annotations": {
          "list": [
            {
              "builtIn": 1,
              "datasource": {
                "type": "grafana",
                "uid": "-- Grafana --"
              },
              "enable": true,
              "hide": true,
              "iconColor": "rgba(0, 211, 255, 1)",
              "name": "Annotations & Alerts",
              "type": "dashboard"
            }
          ]
        },
        "editable": true,
        "fiscalYearStartMonth": 0,
        "graphTooltip": 0,
        "id": null,
        "links": [],
        "liveNow": false,
        "panels": [
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "hideFrom": {
                    "legend": false,
                    "tooltip": false,
                    "vis": false
                  }
                },
                "mappings": [],
                "unit": "short"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 0,
              "y": 0
            },
            "id": 1,
            "options": {
              "legend": {
                "displayMode": "visible",
                "placement": "bottom",
                "showLegend": true
              },
              "pieType": "pie",
              "reduceOptions": {
                "calcs": [
                  "lastNotNull"
                ],
                "fields": "",
                "values": false
              },
              "tooltip": {
                "mode": "single",
                "sort": "none"
              }
            },
            "title": "Internet Performance Overview",
            "type": "piechart",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "network_speedtest_download_mbps",
                "legendFormat": "Download ({{value}} Mbps)",
                "range": true,
                "refId": "A"
              },
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "network_speedtest_upload_mbps",
                "legendFormat": "Upload ({{value}} Mbps)",
                "range": true,
                "refId": "B"
              }
            ]
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "red",
                      "value": 80
                    }
                  ]
                },
                "unit": "ms"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 4,
              "w": 6,
              "x": 12,
              "y": 0
            },
            "id": 2,
            "options": {
              "colorMode": "value",
              "graphMode": "area",
              "justifyMode": "auto",
              "orientation": "auto",
              "reduceOptions": {
                "calcs": [
                  "lastNotNull"
                ],
                "fields": "",
                "values": false
              },
              "textMode": "auto"
            },
            "pluginVersion": "9.4.7",
            "title": "Internet Latency",
            "type": "stat",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "network_speedtest_ping_ms",
                "legendFormat": "Ping",
                "range": true,
                "refId": "A"
              }
            ]
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "yellow",
                      "value": 1
                    },
                    {
                      "color": "red",
                      "value": 5
                    }
                  ]
                },
                "unit": "percent"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 4,
              "w": 6,
              "x": 18,
              "y": 0
            },
            "id": 3,
            "options": {
              "colorMode": "value",
              "graphMode": "area",
              "justifyMode": "auto",
              "orientation": "auto",
              "reduceOptions": {
                "calcs": [
                  "lastNotNull"
                ],
                "fields": "",
                "values": false
              },
              "textMode": "auto"
            },
            "pluginVersion": "9.4.7",
            "title": "Packet Loss",
            "type": "stat",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "network_speedtest_packet_loss_percent",
                "legendFormat": "Loss",
                "range": true,
                "refId": "A"
              }
            ]
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "yellow",
                      "value": 10
                    },
                    {
                      "color": "red",
                      "value": 20
                    }
                  ]
                },
                "unit": "ms"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 4,
              "w": 6,
              "x": 12,
              "y": 4
            },
            "id": 4,
            "options": {
              "colorMode": "value",
              "graphMode": "area",
              "justifyMode": "auto",
              "orientation": "auto",
              "reduceOptions": {
                "calcs": [
                  "lastNotNull"
                ],
                "fields": "",
                "values": false
              },
              "textMode": "auto"
            },
            "pluginVersion": "9.4.7",
            "title": "Jitter",
            "type": "stat",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "network_speedtest_jitter_ms",
                "legendFormat": "Jitter",
                "range": true,
                "refId": "A"
              }
            ]
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 10,
                  "gradientMode": "none",
                  "hideFrom": {
                    "legend": false,
                    "tooltip": false,
                    "vis": false
                  },
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "never",
                  "spanNulls": false,
                  "stacking": {
                    "group": "A",
                    "mode": "none"
                  },
                  "thresholdsStyle": {
                    "mode": "off"
                  }
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "red",
                      "value": 80
                    }
                  ]
                },
                "unit": "celsius"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 6,
              "x": 18,
              "y": 4
            },
            "id": 5,
            "options": {
              "legend": {
                "calcs": [],
                "displayMode": "list",
                "placement": "bottom",
                "showLegend": true
              },
              "tooltip": {
                "mode": "single",
                "sort": "none"
              }
            },
            "title": "Device Temperatures",
            "type": "timeseries",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "unifi_device_temperature_celsius",
                "legendFormat": "{{device_name}} ({{sensor}})",
                "range": true,
                "refId": "A"
              }
            ]
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "custom": {
                  "align": "auto",
                  "displayMode": "auto",
                  "inspect": false
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "red",
                      "value": 80
                    }
                  ]
                }
              },
              "overrides": [
                {
                  "matcher": {
                    "id": "byName",
                    "options": "Status"
                  },
                  "properties": [
                    {
                      "id": "custom.displayMode",
                      "value": "color-background"
                    },
                    {
                      "id": "mappings",
                      "value": [
                        {
                          "options": {
                            "1": {
                              "color": "green",
                              "index": 0,
                              "text": "UP"
                            }
                          },
                          "type": "value"
                        },
                        {
                          "options": {
                            "0": {
                              "color": "red",
                              "index": 1,
                              "text": "DOWN"
                            }
                          },
                          "type": "value"
                        }
                      ]
                    }
                  ]
                }
              ]
            },
            "gridPos": {
              "h": 8,
              "w": 24,
              "x": 0,
              "y": 8
            },
            "id": 6,
            "options": {
              "showHeader": true,
              "sortBy": [
                {
                  "desc": false,
                  "displayName": "Source Device"
                }
              ]
            },
            "pluginVersion": "9.4.7",
            "title": "Device Connectivity Matrix",
            "type": "table",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "network_neighbor_info",
                "format": "table",
                "instant": true,
                "legendFormat": "__auto",
                "range": false,
                "refId": "A"
              }
            ],
            "transformations": [
              {
                "id": "organize",
                "options": {
                  "excludeByName": {
                    "Time": true,
                    "__name__": true,
                    "job": true,
                    "instance": true
                  },
                  "indexByName": {},
                  "renameByName": {
                    "local_device": "Source Device",
                    "local_interface": "Source Interface",
                    "remote_device": "Destination Device",
                    "remote_interface": "Destination Interface",
                    "Value": "Status"
                  }
                }
              }
            ]
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 10,
                  "gradientMode": "none",
                  "hideFrom": {
                    "legend": false,
                    "tooltip": false,
                    "vis": false
                  },
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "never",
                  "spanNulls": false,
                  "stacking": {
                    "group": "A",
                    "mode": "none"
                  },
                  "thresholdsStyle": {
                    "mode": "off"
                  }
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "red",
                      "value": 80
                    }
                  ]
                },
                "unit": "ms"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 0,
              "y": 16
            },
            "id": 7,
            "options": {
              "legend": {
                "calcs": [],
                "displayMode": "list",
                "placement": "bottom",
                "showLegend": true
              },
              "tooltip": {
                "mode": "single",
                "sort": "none"
              }
            },
            "title": "Network Latency by Target",
            "type": "timeseries",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "network_ping_latency_ms",
                "legendFormat": "{{target}} ({{target_type}})",
                "range": true,
                "refId": "A"
              }
            ]
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 10,
                  "gradientMode": "none",
                  "hideFrom": {
                    "legend": false,
                    "tooltip": false,
                    "vis": false
                  },
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "never",
                  "spanNulls": false,
                  "stacking": {
                    "group": "A",
                    "mode": "none"
                  },
                  "thresholdsStyle": {
                    "mode": "off"
                  }
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "red",
                      "value": 80
                    }
                  ]
                },
                "unit": "percent"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 12,
              "y": 16
            },
            "id": 8,
            "options": {
              "legend": {
                "calcs": [],
                "displayMode": "list",
                "placement": "bottom",
                "showLegend": true
              },
              "tooltip": {
                "mode": "single",
                "sort": "none"
              }
            },
            "title": "Device CPU & Memory Usage",
            "type": "timeseries",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "unifi_device_cpu_usage_percent",
                "legendFormat": "{{device_name}} CPU",
                "range": true,
                "refId": "A"
              },
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "unifi_device_memory_usage_percent",
                "legendFormat": "{{device_name}} Memory",
                "range": true,
                "refId": "B"
              }
            ]
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 10,
                  "gradientMode": "none",
                  "hideFrom": {
                    "legend": false,
                    "tooltip": false,
                    "vis": false
                  },
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "never",
                  "spanNulls": false,
                  "stacking": {
                    "group": "A",
                    "mode": "none"
                  },
                  "thresholdsStyle": {
                    "mode": "off"
                  }
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "red",
                      "value": 80
                    }
                  ]
                },
                "unit": "bps"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 24,
              "x": 0,
              "y": 24
            },
            "id": 9,
            "options": {
              "legend": {
                "calcs": [],
                "displayMode": "list",
                "placement": "bottom",
                "showLegend": true
              },
              "tooltip": {
                "mode": "single",
                "sort": "none"
              }
            },
            "title": "Interface Throughput",
            "type": "timeseries",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "rate(unifi_interface_rx_bytes_total[5m]) * 8",
                "legendFormat": "{{device_name}} {{interface}} RX",
                "range": true,
                "refId": "A"
              },
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "rate(unifi_interface_tx_bytes_total[5m]) * 8",
                "legendFormat": "{{device_name}} {{interface}} TX",
                "range": true,
                "refId": "B"
              }
            ]
          }
        ],
        "refresh": "30s",
        "schemaVersion": 38,
        "style": "dark",
        "tags": [
          "network",
          "odin",
          "ubiquiti"
        ],
        "templating": {
          "list": []
        },
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "timepicker": {},
        "timezone": "",
        "title": "ODIN Network Environment Overview",
        "uid": "odin-network-overview-v1",
        "version": 1,
        "weekStart": ""
      }
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"network-overview-dashboard.json":"{\n  \"annotations\": {\n    \"list\": [\n      {\n        \"builtIn\": 1,\n        \"datasource\": {\n          \"type\": \"grafana\",\n          \"uid\": \"-- Grafana --\"\n        },\n        \"enable\": true,\n        \"hide\": true,\n        \"iconColor\": \"rgba(0, 211, 255, 1)\",\n        \"name\": \"Annotations \u0026 Alerts\",\n        \"type\": \"dashboard\"\n      }\n    ]\n  },\n  \"editable\": true,\n  \"fiscalYearStartMonth\": 0,\n  \"graphTooltip\": 0,\n  \"id\": null,\n  \"links\": [],\n  \"liveNow\": false,\n  \"panels\": [\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"hideFrom\": {\n              \"legend\": false,\n              \"tooltip\": false,\n              \"vis\": false\n            }\n          },\n          \"mappings\": [],\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 0,\n        \"y\": 0\n      },\n      \"id\": 1,\n      \"options\": {\n        \"legend\": {\n          \"displayMode\": \"visible\",\n          \"placement\": \"bottom\",\n          \"showLegend\": true\n        },\n        \"pieType\": \"pie\",\n        \"reduceOptions\": {\n          \"calcs\": [\n            \"lastNotNull\"\n          ],\n          \"fields\": \"\",\n          \"values\": false\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        }\n      },\n      \"title\": \"Internet Performance Overview\",\n      \"type\": \"piechart\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"network_speedtest_download_mbps\",\n          \"legendFormat\": \"Download ({{value}} Mbps)\",\n          \"range\": true,\n          \"refId\": \"A\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"network_speedtest_upload_mbps\",\n          \"legendFormat\": \"Upload ({{value}} Mbps)\",\n          \"range\": true,\n          \"refId\": \"B\"\n        }\n      ]\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 80\n              }\n            ]\n          },\n          \"unit\": \"ms\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 4,\n        \"w\": 6,\n        \"x\": 12,\n        \"y\": 0\n      },\n      \"id\": 2,\n      \"options\": {\n        \"colorMode\": \"value\",\n        \"graphMode\": \"area\",\n        \"justifyMode\": \"auto\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"calcs\": [\n            \"lastNotNull\"\n          ],\n          \"fields\": \"\",\n          \"values\": false\n        },\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"9.4.7\",\n      \"title\": \"Internet Latency\",\n      \"type\": \"stat\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"network_speedtest_ping_ms\",\n          \"legendFormat\": \"Ping\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ]\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"yellow\",\n                \"value\": 1\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 5\n              }\n            ]\n          },\n          \"unit\": \"percent\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 4,\n        \"w\": 6,\n        \"x\": 18,\n        \"y\": 0\n      },\n      \"id\": 3,\n      \"options\": {\n        \"colorMode\": \"value\",\n        \"graphMode\": \"area\",\n        \"justifyMode\": \"auto\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"calcs\": [\n            \"lastNotNull\"\n          ],\n          \"fields\": \"\",\n          \"values\": false\n        },\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"9.4.7\",\n      \"title\": \"Packet Loss\",\n      \"type\": \"stat\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"network_speedtest_packet_loss_percent\",\n          \"legendFormat\": \"Loss\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ]\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"yellow\",\n                \"value\": 10\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 20\n              }\n            ]\n          },\n          \"unit\": \"ms\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 4,\n        \"w\": 6,\n        \"x\": 12,\n        \"y\": 4\n      },\n      \"id\": 4,\n      \"options\": {\n        \"colorMode\": \"value\",\n        \"graphMode\": \"area\",\n        \"justifyMode\": \"auto\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"calcs\": [\n            \"lastNotNull\"\n          ],\n          \"fields\": \"\",\n          \"values\": false\n        },\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"9.4.7\",\n      \"title\": \"Jitter\",\n      \"type\": \"stat\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"network_speedtest_jitter_ms\",\n          \"legendFormat\": \"Jitter\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ]\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 10,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"legend\": false,\n              \"tooltip\": false,\n              \"vis\": false\n            },\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"never\",\n            \"spanNulls\": false,\n            \"stacking\": {\n              \"group\": \"A\",\n              \"mode\": \"none\"\n            },\n            \"thresholdsStyle\": {\n              \"mode\": \"off\"\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 80\n              }\n            ]\n          },\n          \"unit\": \"celsius\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 6,\n        \"x\": 18,\n        \"y\": 4\n      },\n      \"id\": 5,\n      \"options\": {\n        \"legend\": {\n          \"calcs\": [],\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\",\n          \"showLegend\": true\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        }\n      },\n      \"title\": \"Device Temperatures\",\n      \"type\": \"timeseries\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"unifi_device_temperature_celsius\",\n          \"legendFormat\": \"{{device_name}} ({{sensor}})\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ]\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"custom\": {\n            \"align\": \"auto\",\n            \"displayMode\": \"auto\",\n            \"inspect\": false\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 80\n              }\n            ]\n          }\n        },\n        \"overrides\": [\n          {\n            \"matcher\": {\n              \"id\": \"byName\",\n              \"options\": \"Status\"\n            },\n            \"properties\": [\n              {\n                \"id\": \"custom.displayMode\",\n                \"value\": \"color-background\"\n              },\n              {\n                \"id\": \"mappings\",\n                \"value\": [\n                  {\n                    \"options\": {\n                      \"1\": {\n                        \"color\": \"green\",\n                        \"index\": 0,\n                        \"text\": \"UP\"\n                      }\n                    },\n                    \"type\": \"value\"\n                  },\n                  {\n                    \"options\": {\n                      \"0\": {\n                        \"color\": \"red\",\n                        \"index\": 1,\n                        \"text\": \"DOWN\"\n                      }\n                    },\n                    \"type\": \"value\"\n                  }\n                ]\n              }\n            ]\n          }\n        ]\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 24,\n        \"x\": 0,\n        \"y\": 8\n      },\n      \"id\": 6,\n      \"options\": {\n        \"showHeader\": true,\n        \"sortBy\": [\n          {\n            \"desc\": false,\n            \"displayName\": \"Source Device\"\n          }\n        ]\n      },\n      \"pluginVersion\": \"9.4.7\",\n      \"title\": \"Device Connectivity Matrix\",\n      \"type\": \"table\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"network_neighbor_info\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"legendFormat\": \"__auto\",\n          \"range\": false,\n          \"refId\": \"A\"\n        }\n      ],\n      \"transformations\": [\n        {\n          \"id\": \"organize\",\n          \"options\": {\n            \"excludeByName\": {\n              \"Time\": true,\n              \"__name__\": true,\n              \"job\": true,\n              \"instance\": true\n            },\n            \"indexByName\": {},\n            \"renameByName\": {\n              \"local_device\": \"Source Device\",\n              \"local_interface\": \"Source Interface\",\n              \"remote_device\": \"Destination Device\",\n              \"remote_interface\": \"Destination Interface\",\n              \"Value\": \"Status\"\n            }\n          }\n        }\n      ]\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 10,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"legend\": false,\n              \"tooltip\": false,\n              \"vis\": false\n            },\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"never\",\n            \"spanNulls\": false,\n            \"stacking\": {\n              \"group\": \"A\",\n              \"mode\": \"none\"\n            },\n            \"thresholdsStyle\": {\n              \"mode\": \"off\"\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 80\n              }\n            ]\n          },\n          \"unit\": \"ms\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 0,\n        \"y\": 16\n      },\n      \"id\": 7,\n      \"options\": {\n        \"legend\": {\n          \"calcs\": [],\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\",\n          \"showLegend\": true\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        }\n      },\n      \"title\": \"Network Latency by Target\",\n      \"type\": \"timeseries\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"network_ping_latency_ms\",\n          \"legendFormat\": \"{{target}} ({{target_type}})\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ]\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 10,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"legend\": false,\n              \"tooltip\": false,\n              \"vis\": false\n            },\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"never\",\n            \"spanNulls\": false,\n            \"stacking\": {\n              \"group\": \"A\",\n              \"mode\": \"none\"\n            },\n            \"thresholdsStyle\": {\n              \"mode\": \"off\"\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 80\n              }\n            ]\n          },\n          \"unit\": \"percent\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 16\n      },\n      \"id\": 8,\n      \"options\": {\n        \"legend\": {\n          \"calcs\": [],\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\",\n          \"showLegend\": true\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        }\n      },\n      \"title\": \"Device CPU \u0026 Memory Usage\",\n      \"type\": \"timeseries\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"unifi_device_cpu_usage_percent\",\n          \"legendFormat\": \"{{device_name}} CPU\",\n          \"range\": true,\n          \"refId\": \"A\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"unifi_device_memory_usage_percent\",\n          \"legendFormat\": \"{{device_name}} Memory\",\n          \"range\": true,\n          \"refId\": \"B\"\n        }\n      ]\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 10,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"legend\": false,\n              \"tooltip\": false,\n              \"vis\": false\n            },\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"never\",\n            \"spanNulls\": false,\n            \"stacking\": {\n              \"group\": \"A\",\n              \"mode\": \"none\"\n            },\n            \"thresholdsStyle\": {\n              \"mode\": \"off\"\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 80\n              }\n            ]\n          },\n          \"unit\": \"bps\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 24,\n        \"x\": 0,\n        \"y\": 24\n      },\n      \"id\": 9,\n      \"options\": {\n        \"legend\": {\n          \"calcs\": [],\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\",\n          \"showLegend\": true\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        }\n      },\n      \"title\": \"Interface Throughput\",\n      \"type\": \"timeseries\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"rate(unifi_interface_rx_bytes_total[5m]) * 8\",\n          \"legendFormat\": \"{{device_name}} {{interface}} RX\",\n          \"range\": true,\n          \"refId\": \"A\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"rate(unifi_interface_tx_bytes_total[5m]) * 8\",\n          \"legendFormat\": \"{{device_name}} {{interface}} TX\",\n          \"range\": true,\n          \"refId\": \"B\"\n        }\n      ]\n    }\n  ],\n  \"refresh\": \"30s\",\n  \"schemaVersion\": 38,\n  \"style\": \"dark\",\n  \"tags\": [\n    \"network\",\n    \"odin\",\n    \"ubiquiti\"\n  ],\n  \"templating\": {\n    \"list\": []\n  },\n  \"time\": {\n    \"from\": \"now-1h\",\n    \"to\": \"now\"\n  },\n  \"timepicker\": {},\n  \"timezone\": \"\",\n  \"title\": \"ODIN Network Environment Overview\",\n  \"uid\": \"odin-network-overview-v1\",\n  \"version\": 1,\n  \"weekStart\": \"\"\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"network-overview-dashboard","namespace":"monitoring"}}
    creationTimestamp: "2025-06-01T22:07:09Z"
    name: network-overview-dashboard
    namespace: monitoring
    resourceVersion: "1337008"
    uid: 565b8c98-a188-46aa-8044-0ae595a50e55
- apiVersion: v1
  data:
    network-overview-dashboard.json: |
      {
        "id": null,
        "uid": "odin-network-overview",
        "title": "ODIN Network Environment Overview",
        "tags": ["network", "odin", "ubiquiti"],
        "style": "dark",
        "timezone": "browser",
        "refresh": "30s",
        "schemaVersion": 27,
        "version": 1,
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "panels": [
          {
            "id": 1,
            "title": "Internet Speed Test",
            "type": "stat",
            "gridPos": {"h": 4, "w": 6, "x": 0, "y": 0},
            "targets": [
              {
                "expr": "network_speedtest_download_mbps",
                "legendFormat": "Download (Mbps)",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "Mbps",
                "color": {"mode": "thresholds"},
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": null},
                    {"color": "yellow", "value": 50},
                    {"color": "green", "value": 100}
                  ]
                }
              }
            }
          },
          {
            "id": 2,
            "title": "Upload Speed",
            "type": "stat",
            "gridPos": {"h": 4, "w": 6, "x": 6, "y": 0},
            "targets": [
              {
                "expr": "network_speedtest_upload_mbps",
                "legendFormat": "Upload (Mbps)",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "Mbps",
                "color": {"mode": "thresholds"},
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": null},
                    {"color": "yellow", "value": 25},
                    {"color": "green", "value": 50}
                  ]
                }
              }
            }
          },
          {
            "id": 3,
            "title": "Internet Latency",
            "type": "stat",
            "gridPos": {"h": 4, "w": 6, "x": 12, "y": 0},
            "targets": [
              {
                "expr": "network_speedtest_ping_ms",
                "legendFormat": "Ping (ms)",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "ms",
                "color": {"mode": "thresholds"},
                "thresholds": {
                  "steps": [
                    {"color": "green", "value": null},
                    {"color": "yellow", "value": 50},
                    {"color": "red", "value": 100}
                  ]
                }
              }
            }
          },
          {
            "id": 4,
            "title": "Packet Loss",
            "type": "stat",
            "gridPos": {"h": 4, "w": 6, "x": 18, "y": 0},
            "targets": [
              {
                "expr": "network_speedtest_packet_loss_percent",
                "legendFormat": "Loss (%)",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "percent",
                "color": {"mode": "thresholds"},
                "thresholds": {
                  "steps": [
                    {"color": "green", "value": null},
                    {"color": "yellow", "value": 1},
                    {"color": "red", "value": 5}
                  ]
                }
              }
            }
          },
          {
            "id": 5,
            "title": "UniFi Device Status",
            "type": "table",
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 4},
            "targets": [
              {
                "expr": "unifi_device_info",
                "format": "table",
                "instant": true,
                "refId": "A"
              }
            ]
          },
          {
            "id": 6,
            "title": "Device Temperatures",
            "type": "timeseries",
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 4},
            "targets": [
              {
                "expr": "unifi_device_temperature_celsius",
                "legendFormat": "{{device_name}} ({{sensor}})",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "celsius"
              }
            }
          },
          {
            "id": 7,
            "title": "Network Latency Monitoring",
            "type": "timeseries",
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 12},
            "targets": [
              {
                "expr": "network_ping_latency_ms",
                "legendFormat": "{{target}} ({{target_type}})",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "ms"
              }
            }
          },
          {
            "id": 8,
            "title": "Device CPU & Memory",
            "type": "timeseries",
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 12},
            "targets": [
              {
                "expr": "unifi_device_cpu_usage_percent",
                "legendFormat": "{{device_name}} CPU",
                "refId": "A"
              },
              {
                "expr": "unifi_device_memory_usage_percent",
                "legendFormat": "{{device_name}} Memory",
                "refId": "B"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "percent"
              }
            }
          }
        ]
      }
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"network-overview-dashboard.json":"{\n  \"id\": null,\n  \"uid\": \"odin-network-overview\",\n  \"title\": \"ODIN Network Environment Overview\",\n  \"tags\": [\"network\", \"odin\", \"ubiquiti\"],\n  \"style\": \"dark\",\n  \"timezone\": \"browser\",\n  \"refresh\": \"30s\",\n  \"schemaVersion\": 27,\n  \"version\": 1,\n  \"time\": {\n    \"from\": \"now-1h\",\n    \"to\": \"now\"\n  },\n  \"panels\": [\n    {\n      \"id\": 1,\n      \"title\": \"Internet Speed Test\",\n      \"type\": \"stat\",\n      \"gridPos\": {\"h\": 4, \"w\": 6, \"x\": 0, \"y\": 0},\n      \"targets\": [\n        {\n          \"expr\": \"network_speedtest_download_mbps\",\n          \"legendFormat\": \"Download (Mbps)\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"Mbps\",\n          \"color\": {\"mode\": \"thresholds\"},\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"red\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 50},\n              {\"color\": \"green\", \"value\": 100}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"id\": 2,\n      \"title\": \"Upload Speed\",\n      \"type\": \"stat\",\n      \"gridPos\": {\"h\": 4, \"w\": 6, \"x\": 6, \"y\": 0},\n      \"targets\": [\n        {\n          \"expr\": \"network_speedtest_upload_mbps\",\n          \"legendFormat\": \"Upload (Mbps)\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"Mbps\",\n          \"color\": {\"mode\": \"thresholds\"},\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"red\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 25},\n              {\"color\": \"green\", \"value\": 50}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"id\": 3,\n      \"title\": \"Internet Latency\",\n      \"type\": \"stat\",\n      \"gridPos\": {\"h\": 4, \"w\": 6, \"x\": 12, \"y\": 0},\n      \"targets\": [\n        {\n          \"expr\": \"network_speedtest_ping_ms\",\n          \"legendFormat\": \"Ping (ms)\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"ms\",\n          \"color\": {\"mode\": \"thresholds\"},\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 50},\n              {\"color\": \"red\", \"value\": 100}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"id\": 4,\n      \"title\": \"Packet Loss\",\n      \"type\": \"stat\",\n      \"gridPos\": {\"h\": 4, \"w\": 6, \"x\": 18, \"y\": 0},\n      \"targets\": [\n        {\n          \"expr\": \"network_speedtest_packet_loss_percent\",\n          \"legendFormat\": \"Loss (%)\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"percent\",\n          \"color\": {\"mode\": \"thresholds\"},\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 1},\n              {\"color\": \"red\", \"value\": 5}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"id\": 5,\n      \"title\": \"UniFi Device Status\",\n      \"type\": \"table\",\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 4},\n      \"targets\": [\n        {\n          \"expr\": \"unifi_device_info\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"A\"\n        }\n      ]\n    },\n    {\n      \"id\": 6,\n      \"title\": \"Device Temperatures\",\n      \"type\": \"timeseries\",\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 4},\n      \"targets\": [\n        {\n          \"expr\": \"unifi_device_temperature_celsius\",\n          \"legendFormat\": \"{{device_name}} ({{sensor}})\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"celsius\"\n        }\n      }\n    },\n    {\n      \"id\": 7,\n      \"title\": \"Network Latency Monitoring\",\n      \"type\": \"timeseries\",\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 12},\n      \"targets\": [\n        {\n          \"expr\": \"network_ping_latency_ms\",\n          \"legendFormat\": \"{{target}} ({{target_type}})\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"ms\"\n        }\n      }\n    },\n    {\n      \"id\": 8,\n      \"title\": \"Device CPU \u0026 Memory\",\n      \"type\": \"timeseries\",\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 12},\n      \"targets\": [\n        {\n          \"expr\": \"unifi_device_cpu_usage_percent\",\n          \"legendFormat\": \"{{device_name}} CPU\",\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"unifi_device_memory_usage_percent\",\n          \"legendFormat\": \"{{device_name}} Memory\",\n          \"refId\": \"B\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"percent\"\n        }\n      }\n    }\n  ]\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"network-overview-dashboard-simple","namespace":"monitoring"}}
    creationTimestamp: "2025-06-01T22:38:50Z"
    name: network-overview-dashboard-simple
    namespace: monitoring
    resourceVersion: "1349663"
    uid: 651c155a-e343-4916-a147-a9e5258f5f4c
- apiVersion: v1
  data:
    network_performance_exporter.py: "#!/usr/bin/env python3\nimport subprocess\nimport
      json\nimport time\nimport logging\nimport os\nimport re\nimport socket\nfrom
      datetime import datetime\nfrom prometheus_client import start_http_server, Gauge,
      Counter, Histogram\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO,
      format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger('network-performance-exporter')\n\n#
      Configuration\nEXPORTER_PORT = int(os.getenv('EXPORTER_PORT', '9131'))\nSPEEDTEST_INTERVAL
      = int(os.getenv('SPEEDTEST_INTERVAL', '300'))  # 5 minutes\nPING_TARGETS = os.getenv('PING_TARGETS',
      '8.8.8.8,1.1.1.1,google.com').split(',')\nINTERNAL_TARGETS = os.getenv('INTERNAL_TARGETS',
      '192.168.1.1,192.168.1.10').split(',')\n\n# Prometheus metrics\n# Internet speed
      test metrics\nspeedtest_download_mbps = Gauge('network_speedtest_download_mbps',
      'Internet download speed in Mbps')\nspeedtest_upload_mbps = Gauge('network_speedtest_upload_mbps',
      'Internet upload speed in Mbps')\nspeedtest_ping_ms = Gauge('network_speedtest_ping_ms',
      'Internet ping latency in milliseconds')\nspeedtest_jitter_ms = Gauge('network_speedtest_jitter_ms',
      'Internet jitter in milliseconds')\nspeedtest_packet_loss = Gauge('network_speedtest_packet_loss_percent',
      'Internet packet loss percentage')\nspeedtest_server_info = Gauge('network_speedtest_server_info',
      'Speedtest server information', ['server_name', 'server_location', 'server_country'])\n\n#
      Ping monitoring metrics\nping_latency_ms = Gauge('network_ping_latency_ms',
      'Ping latency in milliseconds', ['target', 'target_type'])\nping_packet_loss
      = Gauge('network_ping_packet_loss_percent', 'Ping packet loss percentage', ['target',
      'target_type'])\nping_jitter_ms = Gauge('network_ping_jitter_ms', 'Ping jitter
      in milliseconds', ['target', 'target_type'])\n\n# Traceroute metrics\ntraceroute_hops
      = Gauge('network_traceroute_hops_total', 'Number of hops to target', ['target'])\ntraceroute_hop_latency
      = Gauge('network_traceroute_hop_latency_ms', 'Latency to specific hop', ['target',
      'hop_number', 'hop_ip'])\n\n# Bandwidth testing metrics\nbandwidth_throughput_mbps
      = Gauge('network_bandwidth_throughput_mbps', 'Bandwidth test throughput in Mbps',
      ['source', 'destination', 'direction'])\n\n# DNS resolution metrics\ndns_resolution_time_ms
      = Gauge('network_dns_resolution_time_ms', 'DNS resolution time in milliseconds',
      ['hostname', 'resolver'])\n\nclass NetworkPerformanceExporter:\n    def __init__(self):\n
      \       self.last_speedtest = 0\n        \n    def run_speedtest(self):\n        \"\"\"Run
      internet speed test using speedtest-cli\"\"\"\n        try:\n            logger.info(\"Running
      internet speed test...\")\n            \n            # Run speedtest with JSON
      output\n            result = subprocess.run([\n                'speedtest-cli',
      \n                '--json'\n            ], capture_output=True, text=True, timeout=120)\n
      \           \n            if result.returncode == 0:\n                data =
      json.loads(result.stdout)\n                \n                # Extract metrics\n
      \               download_mbps = data.get('download', 0) / 1_000_000  # Convert
      to Mbps\n                upload_mbps = data.get('upload', 0) / 1_000_000      #
      Convert to Mbps\n                ping_ms = data.get('ping', 0)\n                \n
      \               # Set Prometheus metrics\n                speedtest_download_mbps.set(download_mbps)\n
      \               speedtest_upload_mbps.set(upload_mbps)\n                speedtest_ping_ms.set(ping_ms)\n
      \               \n                # Server information\n                server
      = data.get('server', {})\n                server_name = server.get('sponsor',
      'Unknown')\n                server_location = server.get('name', 'Unknown')\n
      \               server_country = server.get('country', 'Unknown')\n                \n
      \               speedtest_server_info.labels(\n                    server_name=server_name,\n
      \                   server_location=server_location,\n                    server_country=server_country\n
      \               ).set(1)\n                \n                logger.info(f\"Speedtest
      completed: {download_mbps:.1f} Mbps down, {upload_mbps:.1f} Mbps up, {ping_ms:.1f}ms
      ping\")\n                \n            else:\n                logger.error(f\"Speedtest
      failed: {result.stderr}\")\n                \n        except subprocess.TimeoutExpired:\n
      \           logger.error(\"Speedtest timed out\")\n        except json.JSONDecodeError
      as e:\n            logger.error(f\"Failed to parse speedtest JSON: {e}\")\n
      \       except Exception as e:\n            logger.error(f\"Speedtest error:
      {e}\")\n            \n    def run_speedtest_ookla(self):\n        \"\"\"Alternative
      speedtest using Ookla's official CLI\"\"\"\n        try:\n            logger.info(\"Running
      Ookla speed test...\")\n            \n            result = subprocess.run([\n
      \               'speedtest', \n                '--format=json',\n                '--accept-license'\n
      \           ], capture_output=True, text=True, timeout=120)\n            \n
      \           if result.returncode == 0:\n                data = json.loads(result.stdout)\n
      \               \n                # Extract metrics\n                download_mbps
      = data.get('download', {}).get('bandwidth', 0) * 8 / 1_000_000  # Convert to
      Mbps\n                upload_mbps = data.get('upload', {}).get('bandwidth',
      0) * 8 / 1_000_000      # Convert to Mbps\n                ping_ms = data.get('ping',
      {}).get('latency', 0)\n                jitter_ms = data.get('ping', {}).get('jitter',
      0)\n                packet_loss = data.get('packetLoss', 0)\n                \n
      \               # Set Prometheus metrics\n                speedtest_download_mbps.set(download_mbps)\n
      \               speedtest_upload_mbps.set(upload_mbps)\n                speedtest_ping_ms.set(ping_ms)\n
      \               speedtest_jitter_ms.set(jitter_ms)\n                speedtest_packet_loss.set(packet_loss)\n
      \               \n                logger.info(f\"Ookla speedtest completed:
      {download_mbps:.1f} Mbps down, {upload_mbps:.1f} Mbps up, {ping_ms:.1f}ms ping\")\n
      \               \n            else:\n                logger.error(f\"Ookla speedtest
      failed: {result.stderr}\")\n                \n        except Exception as e:\n
      \           logger.error(f\"Ookla speedtest error: {e}\")\n            \n    def
      ping_target(self, target, target_type='external', count=10):\n        \"\"\"Ping
      a target and collect latency/loss metrics\"\"\"\n        try:\n            logger.debug(f\"Pinging
      {target} ({target_type})\")\n            \n            result = subprocess.run([\n
      \               'ping', '-c', str(count), '-i', '0.2', target\n            ],
      capture_output=True, text=True, timeout=30)\n            \n            if result.returncode
      == 0:\n                output = result.stdout\n                \n                #
      Parse packet loss\n                loss_match = re.search(r'(\\d+)% packet loss',
      output)\n                packet_loss = float(loss_match.group(1)) if loss_match
      else 0\n                \n                # Parse latency statistics\n                latency_match
      = re.search(r'rtt min/avg/max/mdev = ([\\d.]+)/([\\d.]+)/([\\d.]+)/([\\d.]+)
      ms', output)\n                if latency_match:\n                    min_latency
      = float(latency_match.group(1))\n                    avg_latency = float(latency_match.group(2))\n
      \                   max_latency = float(latency_match.group(3))\n                    mdev_latency
      = float(latency_match.group(4))  # This is standard deviation, close to jitter\n
      \                   \n                    # Set metrics\n                    ping_latency_ms.labels(target=target,
      target_type=target_type).set(avg_latency)\n                    ping_packet_loss.labels(target=target,
      target_type=target_type).set(packet_loss)\n                    ping_jitter_ms.labels(target=target,
      target_type=target_type).set(mdev_latency)\n                    \n                    logger.debug(f\"Ping
      {target}: {avg_latency:.1f}ms avg, {packet_loss}% loss\")\n                    \n
      \           else:\n                logger.warning(f\"Ping to {target} failed\")\n
      \               ping_packet_loss.labels(target=target, target_type=target_type).set(100)\n
      \               \n        except subprocess.TimeoutExpired:\n            logger.warning(f\"Ping
      to {target} timed out\")\n            ping_packet_loss.labels(target=target,
      target_type=target_type).set(100)\n        except Exception as e:\n            logger.error(f\"Ping
      error for {target}: {e}\")\n            \n    def traceroute_target(self, target):\n
      \       \"\"\"Perform traceroute to target and collect hop metrics\"\"\"\n        try:\n
      \           logger.debug(f\"Traceroute to {target}\")\n            \n            result
      = subprocess.run([\n                'traceroute', '-n', '-m', '15', target\n
      \           ], capture_output=True, text=True, timeout=60)\n            \n            if
      result.returncode == 0:\n                lines = result.stdout.strip().split('\\n')[1:]
      \ # Skip header\n                hop_count = 0\n                \n                for
      line in lines:\n                    if line.strip():\n                        #
      Parse traceroute output\n                        parts = line.split()\n                        if
      len(parts) >= 4:\n                            hop_num = parts[0]\n                            hop_ip
      = parts[1] if parts[1] != '*' else 'timeout'\n                            \n
      \                           if hop_ip != 'timeout':\n                                hop_count
      += 1\n                                # Try to extract latency (simplified parsing)\n
      \                               latencies = []\n                                for
      part in parts[2:]:\n                                    if part.endswith('ms'):\n
      \                                       try:\n                                            latency
      = float(part[:-2])\n                                            latencies.append(latency)\n
      \                                       except ValueError:\n                                            pass\n
      \                               \n                                if latencies:\n
      \                                   avg_latency = sum(latencies) / len(latencies)\n
      \                                   traceroute_hop_latency.labels(\n                                        target=target,\n
      \                                       hop_number=hop_num,\n                                        hop_ip=hop_ip\n
      \                                   ).set(avg_latency)\n                                    \n
      \               traceroute_hops.labels(target=target).set(hop_count)\n                logger.debug(f\"Traceroute
      to {target}: {hop_count} hops\")\n                \n        except subprocess.TimeoutExpired:\n
      \           logger.warning(f\"Traceroute to {target} timed out\")\n        except
      Exception as e:\n            logger.error(f\"Traceroute error for {target}:
      {e}\")\n            \n    def test_dns_resolution(self, hostname, resolver='system'):\n
      \       \"\"\"Test DNS resolution time\"\"\"\n        try:\n            start_time
      = time.time()\n            socket.gethostbyname(hostname)\n            resolution_time
      = (time.time() - start_time) * 1000  # Convert to milliseconds\n            \n
      \           dns_resolution_time_ms.labels(hostname=hostname, resolver=resolver).set(resolution_time)\n
      \           logger.debug(f\"DNS resolution for {hostname}: {resolution_time:.1f}ms\")\n
      \           \n        except Exception as e:\n            logger.error(f\"DNS
      resolution error for {hostname}: {e}\")\n            dns_resolution_time_ms.labels(hostname=hostname,
      resolver=resolver).set(-1)\n            \n    def collect_all_metrics(self):\n
      \       \"\"\"Collect all network performance metrics\"\"\"\n        logger.info(\"Collecting
      network performance metrics...\")\n        \n        try:\n            # Run
      speedtest periodically\n            current_time = time.time()\n            if
      current_time - self.last_speedtest > SPEEDTEST_INTERVAL:\n                #
      Use speedtest-cli (works reliably)\n                self.run_speedtest()\n                self.last_speedtest
      = current_time\n            \n            # Ping external targets\n            for
      target in PING_TARGETS:\n                if target.strip():\n                    self.ping_target(target.strip(),
      'external')\n                    \n            # Ping internal targets\n            for
      target in INTERNAL_TARGETS:\n                if target.strip():\n                    self.ping_target(target.strip(),
      'internal')\n                    \n            # Traceroute to key external
      targets (less frequently)\n            if int(current_time) % 120 == 0:  # Every
      2 minutes\n                for target in ['8.8.8.8', 'google.com']:\n                    self.traceroute_target(target)\n
      \                   \n            # DNS resolution tests\n            for hostname
      in ['google.com', 'cloudflare.com', 'github.com']:\n                self.test_dns_resolution(hostname)\n
      \               \n            logger.info(\"Network performance metrics collection
      completed\")\n            \n        except Exception as e:\n            logger.error(f\"Error
      collecting network performance metrics: {e}\")\n            \n    def health_check(self):\n
      \       \"\"\"Health check endpoint\"\"\"\n        return True\n        \ndef
      install_dependencies():\n    \"\"\"Install required packages\"\"\"\n    try:\n
      \       subprocess.run(['apt-get', 'update'], check=True)\n        subprocess.run([\n
      \           'apt-get', 'install', '-y', \n            'speedtest-cli', 'iputils-ping',
      'traceroute', 'dnsutils'\n        ], check=True)\n        \n        # Try to
      install Ookla speedtest\n        subprocess.run([\n            'curl', '-s',
      \n            'https://packagecloud.io/install/repositories/ookla/speedtest-cli/script.deb.sh'\n
      \       ], check=False)  # May fail, that's ok\n        \n        logger.info(\"Dependencies
      installed successfully\")\n        \n    except Exception as e:\n        logger.warning(f\"Failed
      to install some dependencies: {e}\")\n        \ndef main():\n    logger.info(f\"Starting
      Network Performance Exporter on port {EXPORTER_PORT}\")\n    \n    # Install
      dependencies\n    install_dependencies()\n    \n    exporter = NetworkPerformanceExporter()\n
      \   \n    # Start Prometheus metrics server\n    start_http_server(EXPORTER_PORT)\n
      \   logger.info(f\"Metrics server started on port {EXPORTER_PORT}\")\n    \n
      \   # Main collection loop\n    while True:\n        try:\n            exporter.collect_all_metrics()\n
      \           time.sleep(30)  # Collect metrics every 30 seconds\n            \n
      \       except KeyboardInterrupt:\n            logger.info(\"Received interrupt
      signal, shutting down...\")\n            break\n        except Exception as
      e:\n            logger.error(f\"Unexpected error: {e}\")\n            time.sleep(60)
      \ # Wait before retrying\n            \nif __name__ == '__main__':\n    main()\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"network_performance_exporter.py":"#!/usr/bin/env python3\nimport subprocess\nimport json\nimport time\nimport logging\nimport os\nimport re\nimport socket\nfrom datetime import datetime\nfrom prometheus_client import start_http_server, Gauge, Counter, Histogram\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger('network-performance-exporter')\n\n# Configuration\nEXPORTER_PORT = int(os.getenv('EXPORTER_PORT', '9131'))\nSPEEDTEST_INTERVAL = int(os.getenv('SPEEDTEST_INTERVAL', '300'))  # 5 minutes\nPING_TARGETS = os.getenv('PING_TARGETS', '8.8.8.8,1.1.1.1,google.com').split(',')\nINTERNAL_TARGETS = os.getenv('INTERNAL_TARGETS', '192.168.1.1,192.168.1.10').split(',')\n\n# Prometheus metrics\n# Internet speed test metrics\nspeedtest_download_mbps = Gauge('network_speedtest_download_mbps', 'Internet download speed in Mbps')\nspeedtest_upload_mbps = Gauge('network_speedtest_upload_mbps', 'Internet upload speed in Mbps')\nspeedtest_ping_ms = Gauge('network_speedtest_ping_ms', 'Internet ping latency in milliseconds')\nspeedtest_jitter_ms = Gauge('network_speedtest_jitter_ms', 'Internet jitter in milliseconds')\nspeedtest_packet_loss = Gauge('network_speedtest_packet_loss_percent', 'Internet packet loss percentage')\nspeedtest_server_info = Gauge('network_speedtest_server_info', 'Speedtest server information', ['server_name', 'server_location', 'server_country'])\n\n# Ping monitoring metrics\nping_latency_ms = Gauge('network_ping_latency_ms', 'Ping latency in milliseconds', ['target', 'target_type'])\nping_packet_loss = Gauge('network_ping_packet_loss_percent', 'Ping packet loss percentage', ['target', 'target_type'])\nping_jitter_ms = Gauge('network_ping_jitter_ms', 'Ping jitter in milliseconds', ['target', 'target_type'])\n\n# Traceroute metrics\ntraceroute_hops = Gauge('network_traceroute_hops_total', 'Number of hops to target', ['target'])\ntraceroute_hop_latency = Gauge('network_traceroute_hop_latency_ms', 'Latency to specific hop', ['target', 'hop_number', 'hop_ip'])\n\n# Bandwidth testing metrics\nbandwidth_throughput_mbps = Gauge('network_bandwidth_throughput_mbps', 'Bandwidth test throughput in Mbps', ['source', 'destination', 'direction'])\n\n# DNS resolution metrics\ndns_resolution_time_ms = Gauge('network_dns_resolution_time_ms', 'DNS resolution time in milliseconds', ['hostname', 'resolver'])\n\nclass NetworkPerformanceExporter:\n    def __init__(self):\n        self.last_speedtest = 0\n        \n    def run_speedtest(self):\n        \"\"\"Run internet speed test using speedtest-cli\"\"\"\n        try:\n            logger.info(\"Running internet speed test...\")\n            \n            # Run speedtest with JSON output\n            result = subprocess.run([\n                'speedtest-cli', \n                '--json'\n            ], capture_output=True, text=True, timeout=120)\n            \n            if result.returncode == 0:\n                data = json.loads(result.stdout)\n                \n                # Extract metrics\n                download_mbps = data.get('download', 0) / 1_000_000  # Convert to Mbps\n                upload_mbps = data.get('upload', 0) / 1_000_000      # Convert to Mbps\n                ping_ms = data.get('ping', 0)\n                \n                # Set Prometheus metrics\n                speedtest_download_mbps.set(download_mbps)\n                speedtest_upload_mbps.set(upload_mbps)\n                speedtest_ping_ms.set(ping_ms)\n                \n                # Server information\n                server = data.get('server', {})\n                server_name = server.get('sponsor', 'Unknown')\n                server_location = server.get('name', 'Unknown')\n                server_country = server.get('country', 'Unknown')\n                \n                speedtest_server_info.labels(\n                    server_name=server_name,\n                    server_location=server_location,\n                    server_country=server_country\n                ).set(1)\n                \n                logger.info(f\"Speedtest completed: {download_mbps:.1f} Mbps down, {upload_mbps:.1f} Mbps up, {ping_ms:.1f}ms ping\")\n                \n            else:\n                logger.error(f\"Speedtest failed: {result.stderr}\")\n                \n        except subprocess.TimeoutExpired:\n            logger.error(\"Speedtest timed out\")\n        except json.JSONDecodeError as e:\n            logger.error(f\"Failed to parse speedtest JSON: {e}\")\n        except Exception as e:\n            logger.error(f\"Speedtest error: {e}\")\n            \n    def run_speedtest_ookla(self):\n        \"\"\"Alternative speedtest using Ookla's official CLI\"\"\"\n        try:\n            logger.info(\"Running Ookla speed test...\")\n            \n            result = subprocess.run([\n                'speedtest', \n                '--format=json',\n                '--accept-license'\n            ], capture_output=True, text=True, timeout=120)\n            \n            if result.returncode == 0:\n                data = json.loads(result.stdout)\n                \n                # Extract metrics\n                download_mbps = data.get('download', {}).get('bandwidth', 0) * 8 / 1_000_000  # Convert to Mbps\n                upload_mbps = data.get('upload', {}).get('bandwidth', 0) * 8 / 1_000_000      # Convert to Mbps\n                ping_ms = data.get('ping', {}).get('latency', 0)\n                jitter_ms = data.get('ping', {}).get('jitter', 0)\n                packet_loss = data.get('packetLoss', 0)\n                \n                # Set Prometheus metrics\n                speedtest_download_mbps.set(download_mbps)\n                speedtest_upload_mbps.set(upload_mbps)\n                speedtest_ping_ms.set(ping_ms)\n                speedtest_jitter_ms.set(jitter_ms)\n                speedtest_packet_loss.set(packet_loss)\n                \n                logger.info(f\"Ookla speedtest completed: {download_mbps:.1f} Mbps down, {upload_mbps:.1f} Mbps up, {ping_ms:.1f}ms ping\")\n                \n            else:\n                logger.error(f\"Ookla speedtest failed: {result.stderr}\")\n                \n        except Exception as e:\n            logger.error(f\"Ookla speedtest error: {e}\")\n            \n    def ping_target(self, target, target_type='external', count=10):\n        \"\"\"Ping a target and collect latency/loss metrics\"\"\"\n        try:\n            logger.debug(f\"Pinging {target} ({target_type})\")\n            \n            result = subprocess.run([\n                'ping', '-c', str(count), '-i', '0.2', target\n            ], capture_output=True, text=True, timeout=30)\n            \n            if result.returncode == 0:\n                output = result.stdout\n                \n                # Parse packet loss\n                loss_match = re.search(r'(\\d+)% packet loss', output)\n                packet_loss = float(loss_match.group(1)) if loss_match else 0\n                \n                # Parse latency statistics\n                latency_match = re.search(r'rtt min/avg/max/mdev = ([\\d.]+)/([\\d.]+)/([\\d.]+)/([\\d.]+) ms', output)\n                if latency_match:\n                    min_latency = float(latency_match.group(1))\n                    avg_latency = float(latency_match.group(2))\n                    max_latency = float(latency_match.group(3))\n                    mdev_latency = float(latency_match.group(4))  # This is standard deviation, close to jitter\n                    \n                    # Set metrics\n                    ping_latency_ms.labels(target=target, target_type=target_type).set(avg_latency)\n                    ping_packet_loss.labels(target=target, target_type=target_type).set(packet_loss)\n                    ping_jitter_ms.labels(target=target, target_type=target_type).set(mdev_latency)\n                    \n                    logger.debug(f\"Ping {target}: {avg_latency:.1f}ms avg, {packet_loss}% loss\")\n                    \n            else:\n                logger.warning(f\"Ping to {target} failed\")\n                ping_packet_loss.labels(target=target, target_type=target_type).set(100)\n                \n        except subprocess.TimeoutExpired:\n            logger.warning(f\"Ping to {target} timed out\")\n            ping_packet_loss.labels(target=target, target_type=target_type).set(100)\n        except Exception as e:\n            logger.error(f\"Ping error for {target}: {e}\")\n            \n    def traceroute_target(self, target):\n        \"\"\"Perform traceroute to target and collect hop metrics\"\"\"\n        try:\n            logger.debug(f\"Traceroute to {target}\")\n            \n            result = subprocess.run([\n                'traceroute', '-n', '-m', '15', target\n            ], capture_output=True, text=True, timeout=60)\n            \n            if result.returncode == 0:\n                lines = result.stdout.strip().split('\\n')[1:]  # Skip header\n                hop_count = 0\n                \n                for line in lines:\n                    if line.strip():\n                        # Parse traceroute output\n                        parts = line.split()\n                        if len(parts) \u003e= 4:\n                            hop_num = parts[0]\n                            hop_ip = parts[1] if parts[1] != '*' else 'timeout'\n                            \n                            if hop_ip != 'timeout':\n                                hop_count += 1\n                                # Try to extract latency (simplified parsing)\n                                latencies = []\n                                for part in parts[2:]:\n                                    if part.endswith('ms'):\n                                        try:\n                                            latency = float(part[:-2])\n                                            latencies.append(latency)\n                                        except ValueError:\n                                            pass\n                                \n                                if latencies:\n                                    avg_latency = sum(latencies) / len(latencies)\n                                    traceroute_hop_latency.labels(\n                                        target=target,\n                                        hop_number=hop_num,\n                                        hop_ip=hop_ip\n                                    ).set(avg_latency)\n                                    \n                traceroute_hops.labels(target=target).set(hop_count)\n                logger.debug(f\"Traceroute to {target}: {hop_count} hops\")\n                \n        except subprocess.TimeoutExpired:\n            logger.warning(f\"Traceroute to {target} timed out\")\n        except Exception as e:\n            logger.error(f\"Traceroute error for {target}: {e}\")\n            \n    def test_dns_resolution(self, hostname, resolver='system'):\n        \"\"\"Test DNS resolution time\"\"\"\n        try:\n            start_time = time.time()\n            socket.gethostbyname(hostname)\n            resolution_time = (time.time() - start_time) * 1000  # Convert to milliseconds\n            \n            dns_resolution_time_ms.labels(hostname=hostname, resolver=resolver).set(resolution_time)\n            logger.debug(f\"DNS resolution for {hostname}: {resolution_time:.1f}ms\")\n            \n        except Exception as e:\n            logger.error(f\"DNS resolution error for {hostname}: {e}\")\n            dns_resolution_time_ms.labels(hostname=hostname, resolver=resolver).set(-1)\n            \n    def collect_all_metrics(self):\n        \"\"\"Collect all network performance metrics\"\"\"\n        logger.info(\"Collecting network performance metrics...\")\n        \n        try:\n            # Run speedtest periodically\n            current_time = time.time()\n            if current_time - self.last_speedtest \u003e SPEEDTEST_INTERVAL:\n                # Use speedtest-cli (works reliably)\n                self.run_speedtest()\n                self.last_speedtest = current_time\n            \n            # Ping external targets\n            for target in PING_TARGETS:\n                if target.strip():\n                    self.ping_target(target.strip(), 'external')\n                    \n            # Ping internal targets\n            for target in INTERNAL_TARGETS:\n                if target.strip():\n                    self.ping_target(target.strip(), 'internal')\n                    \n            # Traceroute to key external targets (less frequently)\n            if int(current_time) % 120 == 0:  # Every 2 minutes\n                for target in ['8.8.8.8', 'google.com']:\n                    self.traceroute_target(target)\n                    \n            # DNS resolution tests\n            for hostname in ['google.com', 'cloudflare.com', 'github.com']:\n                self.test_dns_resolution(hostname)\n                \n            logger.info(\"Network performance metrics collection completed\")\n            \n        except Exception as e:\n            logger.error(f\"Error collecting network performance metrics: {e}\")\n            \n    def health_check(self):\n        \"\"\"Health check endpoint\"\"\"\n        return True\n        \ndef install_dependencies():\n    \"\"\"Install required packages\"\"\"\n    try:\n        subprocess.run(['apt-get', 'update'], check=True)\n        subprocess.run([\n            'apt-get', 'install', '-y', \n            'speedtest-cli', 'iputils-ping', 'traceroute', 'dnsutils'\n        ], check=True)\n        \n        # Try to install Ookla speedtest\n        subprocess.run([\n            'curl', '-s', \n            'https://packagecloud.io/install/repositories/ookla/speedtest-cli/script.deb.sh'\n        ], check=False)  # May fail, that's ok\n        \n        logger.info(\"Dependencies installed successfully\")\n        \n    except Exception as e:\n        logger.warning(f\"Failed to install some dependencies: {e}\")\n        \ndef main():\n    logger.info(f\"Starting Network Performance Exporter on port {EXPORTER_PORT}\")\n    \n    # Install dependencies\n    install_dependencies()\n    \n    exporter = NetworkPerformanceExporter()\n    \n    # Start Prometheus metrics server\n    start_http_server(EXPORTER_PORT)\n    logger.info(f\"Metrics server started on port {EXPORTER_PORT}\")\n    \n    # Main collection loop\n    while True:\n        try:\n            exporter.collect_all_metrics()\n            time.sleep(30)  # Collect metrics every 30 seconds\n            \n        except KeyboardInterrupt:\n            logger.info(\"Received interrupt signal, shutting down...\")\n            break\n        except Exception as e:\n            logger.error(f\"Unexpected error: {e}\")\n            time.sleep(60)  # Wait before retrying\n            \nif __name__ == '__main__':\n    main()\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"network-performance-script","namespace":"monitoring"}}
    creationTimestamp: "2025-06-01T22:34:25Z"
    name: network-performance-script
    namespace: monitoring
    resourceVersion: "1380261"
    uid: 3c1a267c-fe83-44e3-a35d-6971e8c75fd3
- apiVersion: v1
  data:
    network_topology_exporter.py: "#!/usr/bin/env python3\nimport subprocess\nimport
      json\nimport time\nimport logging\nimport os\nimport re\nimport socket\nfrom
      datetime import datetime\nfrom prometheus_client import start_http_server, Gauge,
      Info\nfrom pysnmp.hlapi import *\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO,
      format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger('network-topology-exporter')\n\n#
      Configuration\nEXPORTER_PORT = int(os.getenv('EXPORTER_PORT', '9132'))\nSNMP_COMMUNITY
      = os.getenv('SNMP_COMMUNITY', 'public')\nNETWORK_DEVICES = os.getenv('NETWORK_DEVICES',
      '192.168.1.1,192.168.1.10').split(',')\n\n# Prometheus metrics\n# Device connectivity
      metrics\ndevice_connection_info = Info('network_device_connection', 'Device
      connection information', \n                              ['source_device', 'source_interface',
      'dest_device', 'dest_interface'])\ndevice_interface_status = Gauge('network_interface_status',
      'Interface operational status', \n                               ['device',
      'interface', 'interface_type'])\ndevice_interface_speed = Gauge('network_interface_speed_mbps',
      'Interface speed in Mbps', \n                              ['device', 'interface'])\ndevice_interface_mtu
      = Gauge('network_interface_mtu_bytes', 'Interface MTU in bytes', \n                            ['device',
      'interface'])\n\n# LLDP/CDP neighbor information\nneighbor_info = Info('network_neighbor_info',
      'Network neighbor discovery information',\n                     ['local_device',
      'local_interface', 'remote_device', 'remote_interface'])\n\n# VLAN information\nvlan_info
      = Info('network_vlan_info', 'VLAN information', ['device', 'vlan_id', 'vlan_name'])\nvlan_port_membership
      = Gauge('network_vlan_port_member', 'VLAN port membership', \n                            ['device',
      'interface', 'vlan_id'])\n\n# ARP table metrics\narp_table_entries = Gauge('network_arp_entries_total',
      'Total ARP table entries', ['device'])\n\n# Device information\ndevice_info
      = Info('network_device_info', 'Network device information', \n                   ['device',
      'hostname', 'model', 'vendor', 'os_version'])\n\nclass NetworkTopologyExporter:\n
      \   def __init__(self):\n        self.device_cache = {}\n        self.topology_map
      = {}\n        \n    def snmp_get(self, device, oid, community=None):\n        \"\"\"Perform
      SNMP GET operation\"\"\"\n        if community is None:\n            community
      = SNMP_COMMUNITY\n            \n        try:\n            iterator = getCmd(\n
      \               SnmpEngine(),\n                CommunityData(community),\n                UdpTransportTarget((device,
      161)),\n                ContextData(),\n                ObjectType(ObjectIdentity(oid)),\n
      \               lexicographicMode=False\n            )\n            \n            errorIndication,
      errorStatus, errorIndex, varBinds = next(iterator)\n            \n            if
      errorIndication:\n                logger.error(f\"SNMP error for {device}: {errorIndication}\")\n
      \               return None\n            elif errorStatus:\n                logger.error(f\"SNMP
      error for {device}: {errorStatus.prettyPrint()}\")\n                return None\n
      \           else:\n                for varBind in varBinds:\n                    return
      varBind[1]\n                    \n        except Exception as e:\n            logger.error(f\"SNMP
      GET error for {device}: {e}\")\n            return None\n            \n    def
      snmp_walk(self, device, oid, community=None):\n        \"\"\"Perform SNMP WALK
      operation\"\"\"\n        if community is None:\n            community = SNMP_COMMUNITY\n
      \           \n        results = []\n        try:\n            iterator = nextCmd(\n
      \               SnmpEngine(),\n                CommunityData(community),\n                UdpTransportTarget((device,
      161)),\n                ContextData(),\n                ObjectType(ObjectIdentity(oid)),\n
      \               lexicographicMode=False\n            )\n            \n            for
      errorIndication, errorStatus, errorIndex, varBinds in iterator:\n                if
      errorIndication:\n                    logger.error(f\"SNMP walk error for {device}:
      {errorIndication}\")\n                    break\n                elif errorStatus:\n
      \                   logger.error(f\"SNMP walk error for {device}: {errorStatus.prettyPrint()}\")\n
      \                   break\n                else:\n                    for varBind
      in varBinds:\n                        results.append((str(varBind[0]), varBind[1]))\n
      \                       \n        except Exception as e:\n            logger.error(f\"SNMP
      WALK error for {device}: {e}\")\n            \n        return results\n        \n
      \   def get_device_info(self, device):\n        \"\"\"Get basic device information
      via SNMP\"\"\"\n        try:\n            logger.debug(f\"Getting device info
      for {device}\")\n            \n            # System information\n            hostname
      = self.snmp_get(device, '1.3.6.1.2.1.1.5.0')  # sysName\n            description
      = self.snmp_get(device, '1.3.6.1.2.1.1.1.0')  # sysDescr\n            \n            #
      Parse description for vendor/model info\n            vendor = \"Unknown\"\n
      \           model = \"Unknown\"\n            os_version = \"Unknown\"\n            \n
      \           if description:\n                desc_str = str(description)\n                if
      \"Ubiquiti\" in desc_str or \"UniFi\" in desc_str:\n                    vendor
      = \"Ubiquiti\"\n                    # Try to extract model from description\n
      \                   model_match = re.search(r'(US-\\w+|USW-\\w+|UDM-\\w+)',
      desc_str)\n                    if model_match:\n                        model
      = model_match.group(1)\n                        \n            device_info.labels(\n
      \               device=device,\n                hostname=str(hostname) if hostname
      else device,\n                model=model,\n                vendor=vendor,\n
      \               os_version=os_version\n            ).info({\n                'description':
      str(description) if description else '',\n                'location': str(self.snmp_get(device,
      '1.3.6.1.2.1.1.6.0') or ''),\n                'contact': str(self.snmp_get(device,
      '1.3.6.1.2.1.1.4.0') or '')\n            })\n            \n            return
      {\n                'hostname': str(hostname) if hostname else device,\n                'description':
      str(description) if description else '',\n                'vendor': vendor,\n
      \               'model': model\n            }\n            \n        except
      Exception as e:\n            logger.error(f\"Error getting device info for {device}:
      {e}\")\n            return None\n            \n    def get_interface_info(self,
      device):\n        \"\"\"Get interface information via SNMP\"\"\"\n        try:\n
      \           logger.debug(f\"Getting interface info for {device}\")\n            \n
      \           # Interface names and indices\n            interface_names = self.snmp_walk(device,
      '1.3.6.1.2.1.2.2.1.2')  # ifDescr\n            interface_status = self.snmp_walk(device,
      '1.3.6.1.2.1.2.2.1.8')  # ifOperStatus\n            interface_admin_status =
      self.snmp_walk(device, '1.3.6.1.2.1.2.2.1.7')  # ifAdminStatus\n            interface_speed
      = self.snmp_walk(device, '1.3.6.1.2.1.2.2.1.5')  # ifSpeed\n            interface_mtu
      = self.snmp_walk(device, '1.3.6.1.2.1.2.2.1.4')  # ifMtu\n            interface_type
      = self.snmp_walk(device, '1.3.6.1.2.1.2.2.1.3')  # ifType\n            \n            #
      Create interface mapping\n            interfaces = {}\n            for oid,
      name in interface_names:\n                index = oid.split('.')[-1]\n                interfaces[index]
      = {'name': str(name)}\n                \n            # Add status information\n
      \           for oid, status in interface_status:\n                index = oid.split('.')[-1]\n
      \               if index in interfaces:\n                    interfaces[index]['oper_status']
      = int(status)\n                    \n            for oid, admin_status in interface_admin_status:\n
      \               index = oid.split('.')[-1]\n                if index in interfaces:\n
      \                   interfaces[index]['admin_status'] = int(admin_status)\n
      \                   \n            for oid, speed in interface_speed:\n                index
      = oid.split('.')[-1]\n                if index in interfaces:\n                    interfaces[index]['speed']
      = int(speed)\n                    \n            for oid, mtu in interface_mtu:\n
      \               index = oid.split('.')[-1]\n                if index in interfaces:\n
      \                   interfaces[index]['mtu'] = int(mtu)\n                    \n
      \           for oid, if_type in interface_type:\n                index = oid.split('.')[-1]\n
      \               if index in interfaces:\n                    interfaces[index]['type']
      = int(if_type)\n                    \n            # Set Prometheus metrics\n
      \           for index, interface in interfaces.items():\n                interface_name
      = interface.get('name', f'interface-{index}')\n                \n                #
      Interface status (1 = up, 2 = down)\n                status_value = 1 if interface.get('oper_status',
      2) == 1 else 0\n                device_interface_status.labels(\n                    device=device,\n
      \                   interface=interface_name,\n                    interface_type=self.get_interface_type_name(interface.get('type',
      0))\n                ).set(status_value)\n                \n                #
      Interface speed (convert to Mbps)\n                speed_mbps = interface.get('speed',
      0) / 1_000_000\n                device_interface_speed.labels(\n                    device=device,\n
      \                   interface=interface_name\n                ).set(speed_mbps)\n
      \               \n                # Interface MTU\n                device_interface_mtu.labels(\n
      \                   device=device,\n                    interface=interface_name\n
      \               ).set(interface.get('mtu', 0))\n                \n            return
      interfaces\n            \n        except Exception as e:\n            logger.error(f\"Error
      getting interface info for {device}: {e}\")\n            return {}\n            \n
      \   def get_interface_type_name(self, if_type):\n        \"\"\"Convert interface
      type number to name\"\"\"\n        type_map = {\n            6: 'ethernet',\n
      \           24: 'loopback',\n            131: 'tunnel',\n            161: 'ieee8023adLag',\n
      \           117: 'gigabitEthernet'\n        }\n        return type_map.get(if_type,
      f'type-{if_type}')\n        \n    def discover_lldp_neighbors(self, device):\n
      \       \"\"\"Discover LLDP neighbors\"\"\"\n        try:\n            logger.debug(f\"Discovering
      LLDP neighbors for {device}\")\n            \n            # LLDP Remote System
      Name (1.0.8802.1.1.2.1.4.1.1.9)\n            remote_names = self.snmp_walk(device,
      '1.0.8802.1.1.2.1.4.1.1.9')\n            # LLDP Remote Port Description (1.0.8802.1.1.2.1.4.1.1.8)\n
      \           remote_ports = self.snmp_walk(device, '1.0.8802.1.1.2.1.4.1.1.8')\n
      \           # LLDP Local Port Number (1.0.8802.1.1.2.1.4.1.1.2)\n            local_ports
      = self.snmp_walk(device, '1.0.8802.1.1.2.1.4.1.1.2')\n            \n            neighbors
      = {}\n            \n            # Process LLDP data\n            for oid, remote_name
      in remote_names:\n                # Extract indices from OID\n                indices
      = oid.split('.')[-3:]  # Last 3 parts are the indices\n                key =
      '.'.join(indices)\n                \n                if key not in neighbors:\n
      \                   neighbors[key] = {}\n                neighbors[key]['remote_name']
      = str(remote_name)\n                \n            for oid, remote_port in remote_ports:\n
      \               indices = oid.split('.')[-3:]\n                key = '.'.join(indices)\n
      \               \n                if key not in neighbors:\n                    neighbors[key]
      = {}\n                neighbors[key]['remote_port'] = str(remote_port)\n                \n
      \           for oid, local_port in local_ports:\n                indices = oid.split('.')[-3:]\n
      \               key = '.'.join(indices)\n                \n                if
      key not in neighbors:\n                    neighbors[key] = {}\n                neighbors[key]['local_port']
      = str(local_port)\n                \n            # Set neighbor info metrics\n
      \           for key, neighbor in neighbors.items():\n                local_port
      = neighbor.get('local_port', 'unknown')\n                remote_name = neighbor.get('remote_name',
      'unknown')\n                remote_port = neighbor.get('remote_port', 'unknown')\n
      \               \n                neighbor_info.labels(\n                    local_device=device,\n
      \                   local_interface=local_port,\n                    remote_device=remote_name,\n
      \                   remote_interface=remote_port\n                ).info({\n
      \                   'discovery_protocol': 'LLDP',\n                    'last_update':
      datetime.now().isoformat()\n                })\n                \n            return
      neighbors\n            \n        except Exception as e:\n            logger.error(f\"Error
      discovering LLDP neighbors for {device}: {e}\")\n            return {}\n            \n
      \   def discover_cdp_neighbors(self, device):\n        \"\"\"Discover CDP neighbors
      (Cisco Discovery Protocol)\"\"\"\n        try:\n            logger.debug(f\"Discovering
      CDP neighbors for {device}\")\n            \n            # CDP is less common
      on Ubiquiti, but we'll try\n            # CDP Remote Device ID (1.3.6.1.4.1.9.9.23.1.2.1.1.6)\n
      \           cdp_devices = self.snmp_walk(device, '1.3.6.1.4.1.9.9.23.1.2.1.1.6')\n
      \           \n            # Process CDP data if available\n            neighbors
      = {}\n            for oid, device_id in cdp_devices:\n                # Process
      CDP neighbor data\n                pass\n                \n            return
      neighbors\n            \n        except Exception as e:\n            logger.debug(f\"CDP
      not available or error for {device}: {e}\")\n            return {}\n            \n
      \   def get_arp_table(self, device):\n        \"\"\"Get ARP table from device\"\"\"\n
      \       try:\n            logger.debug(f\"Getting ARP table for {device}\")\n
      \           \n            # ARP table (1.3.6.1.2.1.4.22.1.2)\n            arp_entries
      = self.snmp_walk(device, '1.3.6.1.2.1.4.22.1.2')\n            \n            arp_count
      = len(arp_entries)\n            arp_table_entries.labels(device=device).set(arp_count)\n
      \           \n            logger.debug(f\"Found {arp_count} ARP entries for
      {device}\")\n            return arp_entries\n            \n        except Exception
      as e:\n            logger.error(f\"Error getting ARP table for {device}: {e}\")\n
      \           return []\n            \n    def discover_network_topology(self):\n
      \       \"\"\"Discover complete network topology\"\"\"\n        logger.info(\"Discovering
      network topology...\")\n        \n        topology = {\n            'devices':
      {},\n            'connections': [],\n            'vlans': {}\n        }\n        \n
      \       for device_ip in NETWORK_DEVICES:\n            device_ip = device_ip.strip()\n
      \           if not device_ip:\n                continue\n                \n
      \           logger.info(f\"Scanning device: {device_ip}\")\n            \n            try:\n
      \               # Get device information\n                device_info = self.get_device_info(device_ip)\n
      \               if device_info:\n                    topology['devices'][device_ip]
      = device_info\n                    \n                # Get interface information\n
      \               interfaces = self.get_interface_info(device_ip)\n                if
      interfaces:\n                    topology['devices'][device_ip]['interfaces']
      = interfaces\n                    \n                # Discover neighbors\n                lldp_neighbors
      = self.discover_lldp_neighbors(device_ip)\n                cdp_neighbors = self.discover_cdp_neighbors(device_ip)\n
      \               \n                # Get ARP table\n                arp_entries
      = self.get_arp_table(device_ip)\n                \n                # Store neighbor
      information\n                all_neighbors = {**lldp_neighbors, **cdp_neighbors}\n
      \               if all_neighbors:\n                    topology['devices'][device_ip]['neighbors']
      = all_neighbors\n                    \n            except Exception as e:\n
      \               logger.error(f\"Error scanning device {device_ip}: {e}\")\n
      \               \n        self.topology_map = topology\n        logger.info(f\"Topology
      discovery completed. Found {len(topology['devices'])} devices\")\n        \n
      \   def collect_all_metrics(self):\n        \"\"\"Collect all topology and connectivity
      metrics\"\"\"\n        logger.info(\"Collecting network topology metrics...\")\n
      \       \n        try:\n            self.discover_network_topology()\n            logger.info(\"Network
      topology metrics collection completed\")\n            \n        except Exception
      as e:\n            logger.error(f\"Error collecting topology metrics: {e}\")\n
      \           \n    def health_check(self):\n        \"\"\"Health check endpoint\"\"\"\n
      \       return True\n        \ndef install_dependencies():\n    \"\"\"Install
      required packages\"\"\"\n    try:\n        subprocess.run(['apt-get', 'update'],
      check=True)\n        subprocess.run([\n            'apt-get', 'install', '-y',
      \n            'python3-pip', 'snmp'\n        ], check=True)\n        subprocess.run([\n
      \           'pip3', 'install', 'pysnmp'\n        ], check=True)\n        \n
      \       logger.info(\"SNMP dependencies installed successfully\")\n        \n
      \   except Exception as e:\n        logger.error(f\"Failed to install dependencies:
      {e}\")\n        \ndef main():\n    logger.info(f\"Starting Network Topology
      Exporter on port {EXPORTER_PORT}\")\n    \n    # Install dependencies\n    install_dependencies()\n
      \   \n    exporter = NetworkTopologyExporter()\n    \n    # Start Prometheus
      metrics server\n    start_http_server(EXPORTER_PORT)\n    logger.info(f\"Metrics
      server started on port {EXPORTER_PORT}\")\n    \n    # Main collection loop\n
      \   while True:\n        try:\n            exporter.collect_all_metrics()\n
      \           time.sleep(60)  # Collect topology every minute\n            \n
      \       except KeyboardInterrupt:\n            logger.info(\"Received interrupt
      signal, shutting down...\")\n            break\n        except Exception as
      e:\n            logger.error(f\"Unexpected error: {e}\")\n            time.sleep(120)
      \ # Wait before retrying\n            \nif __name__ == '__main__':\n    main()\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"network_topology_exporter.py":"#!/usr/bin/env python3\nimport subprocess\nimport json\nimport time\nimport logging\nimport os\nimport re\nimport socket\nfrom datetime import datetime\nfrom prometheus_client import start_http_server, Gauge, Info\nfrom pysnmp.hlapi import *\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger('network-topology-exporter')\n\n# Configuration\nEXPORTER_PORT = int(os.getenv('EXPORTER_PORT', '9132'))\nSNMP_COMMUNITY = os.getenv('SNMP_COMMUNITY', 'public')\nNETWORK_DEVICES = os.getenv('NETWORK_DEVICES', '192.168.1.1,192.168.1.10').split(',')\n\n# Prometheus metrics\n# Device connectivity metrics\ndevice_connection_info = Info('network_device_connection', 'Device connection information', \n                              ['source_device', 'source_interface', 'dest_device', 'dest_interface'])\ndevice_interface_status = Gauge('network_interface_status', 'Interface operational status', \n                               ['device', 'interface', 'interface_type'])\ndevice_interface_speed = Gauge('network_interface_speed_mbps', 'Interface speed in Mbps', \n                              ['device', 'interface'])\ndevice_interface_mtu = Gauge('network_interface_mtu_bytes', 'Interface MTU in bytes', \n                            ['device', 'interface'])\n\n# LLDP/CDP neighbor information\nneighbor_info = Info('network_neighbor_info', 'Network neighbor discovery information',\n                     ['local_device', 'local_interface', 'remote_device', 'remote_interface'])\n\n# VLAN information\nvlan_info = Info('network_vlan_info', 'VLAN information', ['device', 'vlan_id', 'vlan_name'])\nvlan_port_membership = Gauge('network_vlan_port_member', 'VLAN port membership', \n                            ['device', 'interface', 'vlan_id'])\n\n# ARP table metrics\narp_table_entries = Gauge('network_arp_entries_total', 'Total ARP table entries', ['device'])\n\n# Device information\ndevice_info = Info('network_device_info', 'Network device information', \n                   ['device', 'hostname', 'model', 'vendor', 'os_version'])\n\nclass NetworkTopologyExporter:\n    def __init__(self):\n        self.device_cache = {}\n        self.topology_map = {}\n        \n    def snmp_get(self, device, oid, community=None):\n        \"\"\"Perform SNMP GET operation\"\"\"\n        if community is None:\n            community = SNMP_COMMUNITY\n            \n        try:\n            iterator = getCmd(\n                SnmpEngine(),\n                CommunityData(community),\n                UdpTransportTarget((device, 161)),\n                ContextData(),\n                ObjectType(ObjectIdentity(oid)),\n                lexicographicMode=False\n            )\n            \n            errorIndication, errorStatus, errorIndex, varBinds = next(iterator)\n            \n            if errorIndication:\n                logger.error(f\"SNMP error for {device}: {errorIndication}\")\n                return None\n            elif errorStatus:\n                logger.error(f\"SNMP error for {device}: {errorStatus.prettyPrint()}\")\n                return None\n            else:\n                for varBind in varBinds:\n                    return varBind[1]\n                    \n        except Exception as e:\n            logger.error(f\"SNMP GET error for {device}: {e}\")\n            return None\n            \n    def snmp_walk(self, device, oid, community=None):\n        \"\"\"Perform SNMP WALK operation\"\"\"\n        if community is None:\n            community = SNMP_COMMUNITY\n            \n        results = []\n        try:\n            iterator = nextCmd(\n                SnmpEngine(),\n                CommunityData(community),\n                UdpTransportTarget((device, 161)),\n                ContextData(),\n                ObjectType(ObjectIdentity(oid)),\n                lexicographicMode=False\n            )\n            \n            for errorIndication, errorStatus, errorIndex, varBinds in iterator:\n                if errorIndication:\n                    logger.error(f\"SNMP walk error for {device}: {errorIndication}\")\n                    break\n                elif errorStatus:\n                    logger.error(f\"SNMP walk error for {device}: {errorStatus.prettyPrint()}\")\n                    break\n                else:\n                    for varBind in varBinds:\n                        results.append((str(varBind[0]), varBind[1]))\n                        \n        except Exception as e:\n            logger.error(f\"SNMP WALK error for {device}: {e}\")\n            \n        return results\n        \n    def get_device_info(self, device):\n        \"\"\"Get basic device information via SNMP\"\"\"\n        try:\n            logger.debug(f\"Getting device info for {device}\")\n            \n            # System information\n            hostname = self.snmp_get(device, '1.3.6.1.2.1.1.5.0')  # sysName\n            description = self.snmp_get(device, '1.3.6.1.2.1.1.1.0')  # sysDescr\n            \n            # Parse description for vendor/model info\n            vendor = \"Unknown\"\n            model = \"Unknown\"\n            os_version = \"Unknown\"\n            \n            if description:\n                desc_str = str(description)\n                if \"Ubiquiti\" in desc_str or \"UniFi\" in desc_str:\n                    vendor = \"Ubiquiti\"\n                    # Try to extract model from description\n                    model_match = re.search(r'(US-\\w+|USW-\\w+|UDM-\\w+)', desc_str)\n                    if model_match:\n                        model = model_match.group(1)\n                        \n            device_info.labels(\n                device=device,\n                hostname=str(hostname) if hostname else device,\n                model=model,\n                vendor=vendor,\n                os_version=os_version\n            ).info({\n                'description': str(description) if description else '',\n                'location': str(self.snmp_get(device, '1.3.6.1.2.1.1.6.0') or ''),\n                'contact': str(self.snmp_get(device, '1.3.6.1.2.1.1.4.0') or '')\n            })\n            \n            return {\n                'hostname': str(hostname) if hostname else device,\n                'description': str(description) if description else '',\n                'vendor': vendor,\n                'model': model\n            }\n            \n        except Exception as e:\n            logger.error(f\"Error getting device info for {device}: {e}\")\n            return None\n            \n    def get_interface_info(self, device):\n        \"\"\"Get interface information via SNMP\"\"\"\n        try:\n            logger.debug(f\"Getting interface info for {device}\")\n            \n            # Interface names and indices\n            interface_names = self.snmp_walk(device, '1.3.6.1.2.1.2.2.1.2')  # ifDescr\n            interface_status = self.snmp_walk(device, '1.3.6.1.2.1.2.2.1.8')  # ifOperStatus\n            interface_admin_status = self.snmp_walk(device, '1.3.6.1.2.1.2.2.1.7')  # ifAdminStatus\n            interface_speed = self.snmp_walk(device, '1.3.6.1.2.1.2.2.1.5')  # ifSpeed\n            interface_mtu = self.snmp_walk(device, '1.3.6.1.2.1.2.2.1.4')  # ifMtu\n            interface_type = self.snmp_walk(device, '1.3.6.1.2.1.2.2.1.3')  # ifType\n            \n            # Create interface mapping\n            interfaces = {}\n            for oid, name in interface_names:\n                index = oid.split('.')[-1]\n                interfaces[index] = {'name': str(name)}\n                \n            # Add status information\n            for oid, status in interface_status:\n                index = oid.split('.')[-1]\n                if index in interfaces:\n                    interfaces[index]['oper_status'] = int(status)\n                    \n            for oid, admin_status in interface_admin_status:\n                index = oid.split('.')[-1]\n                if index in interfaces:\n                    interfaces[index]['admin_status'] = int(admin_status)\n                    \n            for oid, speed in interface_speed:\n                index = oid.split('.')[-1]\n                if index in interfaces:\n                    interfaces[index]['speed'] = int(speed)\n                    \n            for oid, mtu in interface_mtu:\n                index = oid.split('.')[-1]\n                if index in interfaces:\n                    interfaces[index]['mtu'] = int(mtu)\n                    \n            for oid, if_type in interface_type:\n                index = oid.split('.')[-1]\n                if index in interfaces:\n                    interfaces[index]['type'] = int(if_type)\n                    \n            # Set Prometheus metrics\n            for index, interface in interfaces.items():\n                interface_name = interface.get('name', f'interface-{index}')\n                \n                # Interface status (1 = up, 2 = down)\n                status_value = 1 if interface.get('oper_status', 2) == 1 else 0\n                device_interface_status.labels(\n                    device=device,\n                    interface=interface_name,\n                    interface_type=self.get_interface_type_name(interface.get('type', 0))\n                ).set(status_value)\n                \n                # Interface speed (convert to Mbps)\n                speed_mbps = interface.get('speed', 0) / 1_000_000\n                device_interface_speed.labels(\n                    device=device,\n                    interface=interface_name\n                ).set(speed_mbps)\n                \n                # Interface MTU\n                device_interface_mtu.labels(\n                    device=device,\n                    interface=interface_name\n                ).set(interface.get('mtu', 0))\n                \n            return interfaces\n            \n        except Exception as e:\n            logger.error(f\"Error getting interface info for {device}: {e}\")\n            return {}\n            \n    def get_interface_type_name(self, if_type):\n        \"\"\"Convert interface type number to name\"\"\"\n        type_map = {\n            6: 'ethernet',\n            24: 'loopback',\n            131: 'tunnel',\n            161: 'ieee8023adLag',\n            117: 'gigabitEthernet'\n        }\n        return type_map.get(if_type, f'type-{if_type}')\n        \n    def discover_lldp_neighbors(self, device):\n        \"\"\"Discover LLDP neighbors\"\"\"\n        try:\n            logger.debug(f\"Discovering LLDP neighbors for {device}\")\n            \n            # LLDP Remote System Name (1.0.8802.1.1.2.1.4.1.1.9)\n            remote_names = self.snmp_walk(device, '1.0.8802.1.1.2.1.4.1.1.9')\n            # LLDP Remote Port Description (1.0.8802.1.1.2.1.4.1.1.8)\n            remote_ports = self.snmp_walk(device, '1.0.8802.1.1.2.1.4.1.1.8')\n            # LLDP Local Port Number (1.0.8802.1.1.2.1.4.1.1.2)\n            local_ports = self.snmp_walk(device, '1.0.8802.1.1.2.1.4.1.1.2')\n            \n            neighbors = {}\n            \n            # Process LLDP data\n            for oid, remote_name in remote_names:\n                # Extract indices from OID\n                indices = oid.split('.')[-3:]  # Last 3 parts are the indices\n                key = '.'.join(indices)\n                \n                if key not in neighbors:\n                    neighbors[key] = {}\n                neighbors[key]['remote_name'] = str(remote_name)\n                \n            for oid, remote_port in remote_ports:\n                indices = oid.split('.')[-3:]\n                key = '.'.join(indices)\n                \n                if key not in neighbors:\n                    neighbors[key] = {}\n                neighbors[key]['remote_port'] = str(remote_port)\n                \n            for oid, local_port in local_ports:\n                indices = oid.split('.')[-3:]\n                key = '.'.join(indices)\n                \n                if key not in neighbors:\n                    neighbors[key] = {}\n                neighbors[key]['local_port'] = str(local_port)\n                \n            # Set neighbor info metrics\n            for key, neighbor in neighbors.items():\n                local_port = neighbor.get('local_port', 'unknown')\n                remote_name = neighbor.get('remote_name', 'unknown')\n                remote_port = neighbor.get('remote_port', 'unknown')\n                \n                neighbor_info.labels(\n                    local_device=device,\n                    local_interface=local_port,\n                    remote_device=remote_name,\n                    remote_interface=remote_port\n                ).info({\n                    'discovery_protocol': 'LLDP',\n                    'last_update': datetime.now().isoformat()\n                })\n                \n            return neighbors\n            \n        except Exception as e:\n            logger.error(f\"Error discovering LLDP neighbors for {device}: {e}\")\n            return {}\n            \n    def discover_cdp_neighbors(self, device):\n        \"\"\"Discover CDP neighbors (Cisco Discovery Protocol)\"\"\"\n        try:\n            logger.debug(f\"Discovering CDP neighbors for {device}\")\n            \n            # CDP is less common on Ubiquiti, but we'll try\n            # CDP Remote Device ID (1.3.6.1.4.1.9.9.23.1.2.1.1.6)\n            cdp_devices = self.snmp_walk(device, '1.3.6.1.4.1.9.9.23.1.2.1.1.6')\n            \n            # Process CDP data if available\n            neighbors = {}\n            for oid, device_id in cdp_devices:\n                # Process CDP neighbor data\n                pass\n                \n            return neighbors\n            \n        except Exception as e:\n            logger.debug(f\"CDP not available or error for {device}: {e}\")\n            return {}\n            \n    def get_arp_table(self, device):\n        \"\"\"Get ARP table from device\"\"\"\n        try:\n            logger.debug(f\"Getting ARP table for {device}\")\n            \n            # ARP table (1.3.6.1.2.1.4.22.1.2)\n            arp_entries = self.snmp_walk(device, '1.3.6.1.2.1.4.22.1.2')\n            \n            arp_count = len(arp_entries)\n            arp_table_entries.labels(device=device).set(arp_count)\n            \n            logger.debug(f\"Found {arp_count} ARP entries for {device}\")\n            return arp_entries\n            \n        except Exception as e:\n            logger.error(f\"Error getting ARP table for {device}: {e}\")\n            return []\n            \n    def discover_network_topology(self):\n        \"\"\"Discover complete network topology\"\"\"\n        logger.info(\"Discovering network topology...\")\n        \n        topology = {\n            'devices': {},\n            'connections': [],\n            'vlans': {}\n        }\n        \n        for device_ip in NETWORK_DEVICES:\n            device_ip = device_ip.strip()\n            if not device_ip:\n                continue\n                \n            logger.info(f\"Scanning device: {device_ip}\")\n            \n            try:\n                # Get device information\n                device_info = self.get_device_info(device_ip)\n                if device_info:\n                    topology['devices'][device_ip] = device_info\n                    \n                # Get interface information\n                interfaces = self.get_interface_info(device_ip)\n                if interfaces:\n                    topology['devices'][device_ip]['interfaces'] = interfaces\n                    \n                # Discover neighbors\n                lldp_neighbors = self.discover_lldp_neighbors(device_ip)\n                cdp_neighbors = self.discover_cdp_neighbors(device_ip)\n                \n                # Get ARP table\n                arp_entries = self.get_arp_table(device_ip)\n                \n                # Store neighbor information\n                all_neighbors = {**lldp_neighbors, **cdp_neighbors}\n                if all_neighbors:\n                    topology['devices'][device_ip]['neighbors'] = all_neighbors\n                    \n            except Exception as e:\n                logger.error(f\"Error scanning device {device_ip}: {e}\")\n                \n        self.topology_map = topology\n        logger.info(f\"Topology discovery completed. Found {len(topology['devices'])} devices\")\n        \n    def collect_all_metrics(self):\n        \"\"\"Collect all topology and connectivity metrics\"\"\"\n        logger.info(\"Collecting network topology metrics...\")\n        \n        try:\n            self.discover_network_topology()\n            logger.info(\"Network topology metrics collection completed\")\n            \n        except Exception as e:\n            logger.error(f\"Error collecting topology metrics: {e}\")\n            \n    def health_check(self):\n        \"\"\"Health check endpoint\"\"\"\n        return True\n        \ndef install_dependencies():\n    \"\"\"Install required packages\"\"\"\n    try:\n        subprocess.run(['apt-get', 'update'], check=True)\n        subprocess.run([\n            'apt-get', 'install', '-y', \n            'python3-pip', 'snmp'\n        ], check=True)\n        subprocess.run([\n            'pip3', 'install', 'pysnmp'\n        ], check=True)\n        \n        logger.info(\"SNMP dependencies installed successfully\")\n        \n    except Exception as e:\n        logger.error(f\"Failed to install dependencies: {e}\")\n        \ndef main():\n    logger.info(f\"Starting Network Topology Exporter on port {EXPORTER_PORT}\")\n    \n    # Install dependencies\n    install_dependencies()\n    \n    exporter = NetworkTopologyExporter()\n    \n    # Start Prometheus metrics server\n    start_http_server(EXPORTER_PORT)\n    logger.info(f\"Metrics server started on port {EXPORTER_PORT}\")\n    \n    # Main collection loop\n    while True:\n        try:\n            exporter.collect_all_metrics()\n            time.sleep(60)  # Collect topology every minute\n            \n        except KeyboardInterrupt:\n            logger.info(\"Received interrupt signal, shutting down...\")\n            break\n        except Exception as e:\n            logger.error(f\"Unexpected error: {e}\")\n            time.sleep(120)  # Wait before retrying\n            \nif __name__ == '__main__':\n    main()\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"network-topology-script","namespace":"monitoring"}}
    creationTimestamp: "2025-06-01T22:34:37Z"
    name: network-topology-script
    namespace: monitoring
    resourceVersion: "1347727"
    uid: 02ccab84-5449-4ba3-b132-b8494eeb865d
- apiVersion: v1
  data:
    gpu-exporter.py: "#!/usr/bin/env python3\nimport subprocess\nimport time\nimport
      re\nfrom prometheus_client import start_http_server, Gauge\n\n# Define metrics\ngpu_temp
      = Gauge('nvidia_gpu_temperature_celsius', 'GPU Temperature in Celsius', ['gpu',
      'name'])\ngpu_power = Gauge('nvidia_gpu_power_watts', 'GPU Power Usage in Watts',
      ['gpu', 'name'])\ngpu_memory_used = Gauge('nvidia_gpu_memory_used_mb', 'GPU
      Memory Used in MB', ['gpu', 'name'])\ngpu_memory_total = Gauge('nvidia_gpu_memory_total_mb',
      'GPU Memory Total in MB', ['gpu', 'name'])\ngpu_utilization = Gauge('nvidia_gpu_utilization_percent',
      'GPU Utilization Percentage', ['gpu', 'name'])\ngpu_memory_utilization = Gauge('nvidia_gpu_memory_utilization_percent',
      'GPU Memory Utilization', ['gpu', 'name'])\ngpu_fan_speed = Gauge('nvidia_gpu_fan_speed_percent',
      'GPU Fan Speed Percentage', ['gpu', 'name'])\ngpu_encoder_util = Gauge('nvidia_gpu_encoder_utilization_percent',
      'GPU Encoder Utilization', ['gpu', 'name'])\ngpu_decoder_util = Gauge('nvidia_gpu_decoder_utilization_percent',
      'GPU Decoder Utilization', ['gpu', 'name'])\n\ndef get_gpu_metrics():\n    \"\"\"Get
      GPU metrics using nvidia-smi\"\"\"\n    try:\n        # Get basic metrics\n
      \       cmd = [\n            '/host/usr/bin/nvidia-smi',\n            '--query-gpu=index,name,temperature.gpu,power.draw,memory.used,memory.total,utilization.gpu,utilization.memory,fan.speed,utilization.encoder,utilization.decoder',\n
      \           '--format=csv,noheader,nounits'\n        ]\n        \n        result
      = subprocess.run(cmd, capture_output=True, text=True)\n        if result.returncode
      != 0:\n            print(f\"nvidia-smi error: {result.stderr}\")\n            return\n
      \       \n        for line in result.stdout.strip().split('\\n'):\n            if
      not line:\n                continue\n                \n            parts = [p.strip()
      for p in line.split(',')]\n            if len(parts) >= 11:\n                idx
      = parts[0]\n                name = parts[1]\n                \n                #
      Temperature\n                try:\n                    gpu_temp.labels(gpu=idx,
      name=name).set(float(parts[2]))\n                except:\n                    pass\n
      \               \n                # Power\n                try:\n                    gpu_power.labels(gpu=idx,
      name=name).set(float(parts[3]))\n                except:\n                    pass\n
      \               \n                # Memory\n                try:\n                    mem_used
      = float(parts[4])\n                    mem_total = float(parts[5])\n                    gpu_memory_used.labels(gpu=idx,
      name=name).set(mem_used)\n                    gpu_memory_total.labels(gpu=idx,
      name=name).set(mem_total)\n                except:\n                    pass\n
      \               \n                # Utilization\n                try:\n                    gpu_utilization.labels(gpu=idx,
      name=name).set(float(parts[6]))\n                    gpu_memory_utilization.labels(gpu=idx,
      name=name).set(float(parts[7]))\n                except:\n                    pass\n
      \               \n                # Fan speed\n                try:\n                    if
      parts[8] != '[N/A]':\n                        gpu_fan_speed.labels(gpu=idx,
      name=name).set(float(parts[8]))\n                except:\n                    pass\n
      \               \n                # Encoder/Decoder\n                try:\n
      \                   gpu_encoder_util.labels(gpu=idx, name=name).set(float(parts[9]))\n
      \                   gpu_decoder_util.labels(gpu=idx, name=name).set(float(parts[10]))\n
      \               except:\n                    pass\n                    \n    except
      Exception as e:\n        print(f\"Error collecting GPU metrics: {e}\")\n\nif
      __name__ == '__main__':\n    # Start HTTP server\n    start_http_server(9400)\n
      \   print(\"NVIDIA GPU Exporter started on port 9400\")\n    \n    # Collect
      metrics every 5 seconds\n    while True:\n        get_gpu_metrics()\n        time.sleep(5)\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"gpu-exporter.py":"#!/usr/bin/env python3\nimport subprocess\nimport time\nimport re\nfrom prometheus_client import start_http_server, Gauge\n\n# Define metrics\ngpu_temp = Gauge('nvidia_gpu_temperature_celsius', 'GPU Temperature in Celsius', ['gpu', 'name'])\ngpu_power = Gauge('nvidia_gpu_power_watts', 'GPU Power Usage in Watts', ['gpu', 'name'])\ngpu_memory_used = Gauge('nvidia_gpu_memory_used_mb', 'GPU Memory Used in MB', ['gpu', 'name'])\ngpu_memory_total = Gauge('nvidia_gpu_memory_total_mb', 'GPU Memory Total in MB', ['gpu', 'name'])\ngpu_utilization = Gauge('nvidia_gpu_utilization_percent', 'GPU Utilization Percentage', ['gpu', 'name'])\ngpu_memory_utilization = Gauge('nvidia_gpu_memory_utilization_percent', 'GPU Memory Utilization', ['gpu', 'name'])\ngpu_fan_speed = Gauge('nvidia_gpu_fan_speed_percent', 'GPU Fan Speed Percentage', ['gpu', 'name'])\ngpu_encoder_util = Gauge('nvidia_gpu_encoder_utilization_percent', 'GPU Encoder Utilization', ['gpu', 'name'])\ngpu_decoder_util = Gauge('nvidia_gpu_decoder_utilization_percent', 'GPU Decoder Utilization', ['gpu', 'name'])\n\ndef get_gpu_metrics():\n    \"\"\"Get GPU metrics using nvidia-smi\"\"\"\n    try:\n        # Get basic metrics\n        cmd = [\n            '/host/usr/bin/nvidia-smi',\n            '--query-gpu=index,name,temperature.gpu,power.draw,memory.used,memory.total,utilization.gpu,utilization.memory,fan.speed,utilization.encoder,utilization.decoder',\n            '--format=csv,noheader,nounits'\n        ]\n        \n        result = subprocess.run(cmd, capture_output=True, text=True)\n        if result.returncode != 0:\n            print(f\"nvidia-smi error: {result.stderr}\")\n            return\n        \n        for line in result.stdout.strip().split('\\n'):\n            if not line:\n                continue\n                \n            parts = [p.strip() for p in line.split(',')]\n            if len(parts) \u003e= 11:\n                idx = parts[0]\n                name = parts[1]\n                \n                # Temperature\n                try:\n                    gpu_temp.labels(gpu=idx, name=name).set(float(parts[2]))\n                except:\n                    pass\n                \n                # Power\n                try:\n                    gpu_power.labels(gpu=idx, name=name).set(float(parts[3]))\n                except:\n                    pass\n                \n                # Memory\n                try:\n                    mem_used = float(parts[4])\n                    mem_total = float(parts[5])\n                    gpu_memory_used.labels(gpu=idx, name=name).set(mem_used)\n                    gpu_memory_total.labels(gpu=idx, name=name).set(mem_total)\n                except:\n                    pass\n                \n                # Utilization\n                try:\n                    gpu_utilization.labels(gpu=idx, name=name).set(float(parts[6]))\n                    gpu_memory_utilization.labels(gpu=idx, name=name).set(float(parts[7]))\n                except:\n                    pass\n                \n                # Fan speed\n                try:\n                    if parts[8] != '[N/A]':\n                        gpu_fan_speed.labels(gpu=idx, name=name).set(float(parts[8]))\n                except:\n                    pass\n                \n                # Encoder/Decoder\n                try:\n                    gpu_encoder_util.labels(gpu=idx, name=name).set(float(parts[9]))\n                    gpu_decoder_util.labels(gpu=idx, name=name).set(float(parts[10]))\n                except:\n                    pass\n                    \n    except Exception as e:\n        print(f\"Error collecting GPU metrics: {e}\")\n\nif __name__ == '__main__':\n    # Start HTTP server\n    start_http_server(9400)\n    print(\"NVIDIA GPU Exporter started on port 9400\")\n    \n    # Collect metrics every 5 seconds\n    while True:\n        get_gpu_metrics()\n        time.sleep(5)\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"nvidia-gpu-exporter-script","namespace":"monitoring"}}
    creationTimestamp: "2025-05-28T01:02:13Z"
    name: nvidia-gpu-exporter-script
    namespace: monitoring
    resourceVersion: "8617"
    uid: 7dbe9aee-897c-471c-8a1d-e49d0702b8fa
- apiVersion: v1
  data:
    nvidia-rtx-comprehensive-dashboard.json: |
      {
        "annotations": {
          "list": [
            {
              "builtIn": 1,
              "datasource": {
                "type": "grafana",
                "uid": "-- Grafana --"
              },
              "enable": true,
              "hide": true,
              "iconColor": "rgba(0, 211, 255, 1)",
              "name": "Annotations & Alerts",
              "type": "dashboard"
            }
          ]
        },
        "editable": true,
        "fiscalYearStartMonth": 0,
        "graphTooltip": 0,
        "id": null,
        "links": [],
        "liveNow": false,
        "panels": [
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "yellow",
                      "value": 70
                    },
                    {
                      "color": "orange",
                      "value": 80
                    },
                    {
                      "color": "red",
                      "value": 85
                    }
                  ]
                },
                "unit": "celsius"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 6,
              "x": 0,
              "y": 0
            },
            "id": 1,
            "options": {
              "orientation": "auto",
              "reduceOptions": {
                "calcs": [
                  "lastNotNull"
                ],
                "fields": "",
                "values": false
              },
              "showThresholdLabels": false,
              "showThresholdMarkers": true
            },
            "pluginVersion": "10.0.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "expr": "nvidia_gpu_temperature_celsius",
                "refId": "A"
              }
            ],
            "title": "GPU Temperature",
            "type": "gauge"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "yellow",
                      "value": 200
                    },
                    {
                      "color": "orange",
                      "value": 300
                    },
                    {
                      "color": "red",
                      "value": 350
                    }
                  ]
                },
                "unit": "watt"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 6,
              "x": 6,
              "y": 0
            },
            "id": 2,
            "options": {
              "orientation": "auto",
              "reduceOptions": {
                "calcs": [
                  "lastNotNull"
                ],
                "fields": "",
                "values": false
              },
              "showThresholdLabels": false,
              "showThresholdMarkers": true
            },
            "pluginVersion": "10.0.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "expr": "nvidia_gpu_power_draw_watts",
                "refId": "A"
              }
            ],
            "title": "GPU Power Draw",
            "type": "gauge"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "yellow",
                      "value": 70
                    },
                    {
                      "color": "orange",
                      "value": 85
                    },
                    {
                      "color": "red",
                      "value": 95
                    }
                  ]
                },
                "unit": "percent"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 6,
              "x": 12,
              "y": 0
            },
            "id": 3,
            "options": {
              "orientation": "auto",
              "reduceOptions": {
                "calcs": [
                  "lastNotNull"
                ],
                "fields": "",
                "values": false
              },
              "showThresholdLabels": false,
              "showThresholdMarkers": true
            },
            "pluginVersion": "10.0.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "expr": "nvidia_gpu_utilization_percent",
                "refId": "A"
              }
            ],
            "title": "GPU Utilization",
            "type": "gauge"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "yellow",
                      "value": 60
                    },
                    {
                      "color": "orange",
                      "value": 80
                    },
                    {
                      "color": "red",
                      "value": 90
                    }
                  ]
                },
                "unit": "percent"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 6,
              "x": 18,
              "y": 0
            },
            "id": 4,
            "options": {
              "orientation": "auto",
              "reduceOptions": {
                "calcs": [
                  "lastNotNull"
                ],
                "fields": "",
                "values": false
              },
              "showThresholdLabels": false,
              "showThresholdMarkers": true
            },
            "pluginVersion": "10.0.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "expr": "(nvidia_gpu_memory_used_mb / nvidia_gpu_memory_total_mb) * 100",
                "refId": "A"
              }
            ],
            "title": "GPU Memory Usage",
            "type": "gauge"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisCenteredZero": false,
                  "axisColorMode": "text",
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 10,
                  "gradientMode": "none",
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  },
                  "insertNulls": false,
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "never",
                  "spanNulls": false,
                  "stacking": {
                    "group": "A",
                    "mode": "none"
                  },
                  "thresholdsStyle": {
                    "mode": "off"
                  }
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    }
                  ]
                },
                "unit": "celsius"
              },
              "overrides": [
                {
                  "matcher": {
                    "id": "byName",
                    "options": "Temperature"
                  },
                  "properties": [
                    {
                      "id": "color",
                      "value": {
                        "fixedColor": "red",
                        "mode": "fixed"
                      }
                    }
                  ]
                }
              ]
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 0,
              "y": 8
            },
            "id": 5,
            "options": {
              "legend": {
                "calcs": [],
                "displayMode": "list",
                "placement": "bottom",
                "showLegend": true
              },
              "tooltip": {
                "mode": "single",
                "sort": "none"
              }
            },
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "expr": "nvidia_gpu_temperature_celsius",
                "legendFormat": "Temperature",
                "refId": "A"
              }
            ],
            "title": "GPU Temperature History",
            "type": "timeseries"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisCenteredZero": false,
                  "axisColorMode": "text",
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 10,
                  "gradientMode": "none",
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  },
                  "insertNulls": false,
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "never",
                  "spanNulls": false,
                  "stacking": {
                    "group": "A",
                    "mode": "none"
                  },
                  "thresholdsStyle": {
                    "mode": "off"
                  }
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    }
                  ]
                },
                "unit": "watt"
              },
              "overrides": [
                {
                  "matcher": {
                    "id": "byName",
                    "options": "Power Draw"
                  },
                  "properties": [
                    {
                      "id": "color",
                      "value": {
                        "fixedColor": "yellow",
                        "mode": "fixed"
                      }
                    }
                  ]
                }
              ]
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 12,
              "y": 8
            },
            "id": 6,
            "options": {
              "legend": {
                "calcs": [],
                "displayMode": "list",
                "placement": "bottom",
                "showLegend": true
              },
              "tooltip": {
                "mode": "single",
                "sort": "none"
              }
            },
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "expr": "node_gpu_power_watts",
                "legendFormat": "Power Draw",
                "refId": "A"
              }
            ],
            "title": "GPU Power History",
            "type": "timeseries"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisCenteredZero": false,
                  "axisColorMode": "text",
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 10,
                  "gradientMode": "none",
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  },
                  "insertNulls": false,
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "never",
                  "spanNulls": false,
                  "stacking": {
                    "group": "A",
                    "mode": "none"
                  },
                  "thresholdsStyle": {
                    "mode": "off"
                  }
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    }
                  ]
                },
                "unit": "percent"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 0,
              "y": 16
            },
            "id": 7,
            "options": {
              "legend": {
                "calcs": [],
                "displayMode": "list",
                "placement": "bottom",
                "showLegend": true
              },
              "tooltip": {
                "mode": "single",
                "sort": "none"
              }
            },
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "expr": "nvidia_gpu_utilization_percent",
                "legendFormat": "GPU Utilization",
                "refId": "A"
              },
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "expr": "nvidia_gpu_memory_utilization_percent",
                "legendFormat": "Memory Utilization",
                "refId": "B"
              }
            ],
            "title": "GPU & Memory Utilization",
            "type": "timeseries"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisCenteredZero": false,
                  "axisColorMode": "text",
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 10,
                  "gradientMode": "none",
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  },
                  "insertNulls": false,
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "never",
                  "spanNulls": false,
                  "stacking": {
                    "group": "A",
                    "mode": "normal"
                  },
                  "thresholdsStyle": {
                    "mode": "off"
                  }
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    }
                  ]
                },
                "unit": "decmbytes"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 12,
              "y": 16
            },
            "id": 8,
            "options": {
              "legend": {
                "calcs": [],
                "displayMode": "list",
                "placement": "bottom",
                "showLegend": true
              },
              "tooltip": {
                "mode": "single",
                "sort": "none"
              }
            },
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "expr": "nvidia_gpu_memory_used_mb",
                "legendFormat": "Used",
                "refId": "A"
              },
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "expr": "nvidia_gpu_memory_total_mb - nvidia_gpu_memory_used_mb",
                "legendFormat": "Free",
                "refId": "B"
              }
            ],
            "title": "GPU Memory Usage",
            "type": "timeseries"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisCenteredZero": false,
                  "axisColorMode": "text",
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 10,
                  "gradientMode": "none",
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  },
                  "insertNulls": false,
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "never",
                  "spanNulls": false,
                  "stacking": {
                    "group": "A",
                    "mode": "none"
                  },
                  "thresholdsStyle": {
                    "mode": "off"
                  }
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    }
                  ]
                },
                "unit": "megahertz"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 0,
              "y": 24
            },
            "id": 9,
            "options": {
              "legend": {
                "calcs": [],
                "displayMode": "list",
                "placement": "bottom",
                "showLegend": true
              },
              "tooltip": {
                "mode": "single",
                "sort": "none"
              }
            },
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "expr": "nvidia_gpu_clock_graphics_mhz",
                "legendFormat": "Graphics Clock",
                "refId": "A"
              },
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "expr": "nvidia_gpu_clock_sm_mhz",
                "legendFormat": "SM Clock",
                "refId": "B"
              },
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "expr": "nvidia_gpu_clock_memory_mhz",
                "legendFormat": "Memory Clock",
                "refId": "C"
              }
            ],
            "title": "GPU Clock Speeds",
            "type": "timeseries"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    }
                  ]
                },
                "unit": "short"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 12,
              "y": 24
            },
            "id": 10,
            "options": {
              "colorMode": "value",
              "graphMode": "area",
              "justifyMode": "auto",
              "orientation": "auto",
              "reduceOptions": {
                "calcs": [
                  "lastNotNull"
                ],
                "fields": "",
                "values": false
              },
              "textMode": "auto"
            },
            "pluginVersion": "10.0.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "expr": "nvidia_gpu_performance_state",
                "legendFormat": "P-State",
                "refId": "A"
              }
            ],
            "title": "GPU Performance State",
            "type": "stat"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "description": "Thermal throttling and power limit indicators",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [
                  {
                    "options": {
                      "0": {
                        "color": "green",
                        "index": 0,
                        "text": "No Throttling"
                      },
                      "1": {
                        "color": "red",
                        "index": 1,
                        "text": "Throttling Active"
                      }
                    },
                    "type": "value"
                  }
                ],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "red",
                      "value": 1
                    }
                  ]
                }
              },
              "overrides": []
            },
            "gridPos": {
              "h": 4,
              "w": 12,
              "x": 0,
              "y": 32
            },
            "id": 11,
            "options": {
              "colorMode": "background",
              "graphMode": "none",
              "justifyMode": "auto",
              "orientation": "horizontal",
              "reduceOptions": {
                "calcs": [
                  "lastNotNull"
                ],
                "fields": "",
                "values": false
              },
              "textMode": "auto"
            },
            "pluginVersion": "10.0.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "expr": "nvidia_gpu_throttle_hw_thermal",
                "legendFormat": "Thermal Throttle",
                "refId": "A"
              },
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "expr": "nvidia_gpu_throttle_sw_power_cap",
                "legendFormat": "Power Cap",
                "refId": "B"
              },
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "expr": "nvidia_gpu_throttle_hw_slowdown",
                "legendFormat": "HW Slowdown",
                "refId": "C"
              }
            ],
            "title": "GPU Throttle Status",
            "type": "stat"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "custom": {
                  "align": "auto",
                  "cellOptions": {
                    "type": "auto"
                  },
                  "inspect": false
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    }
                  ]
                }
              },
              "overrides": [
                {
                  "matcher": {
                    "id": "byName",
                    "options": "GPU"
                  },
                  "properties": [
                    {
                      "id": "custom.width",
                      "value": 50
                    }
                  ]
                },
                {
                  "matcher": {
                    "id": "byName",
                    "options": "Name"
                  },
                  "properties": [
                    {
                      "id": "custom.width",
                      "value": 300
                    }
                  ]
                },
                {
                  "matcher": {
                    "id": "byName",
                    "options": "Temp (°C)"
                  },
                  "properties": [
                    {
                      "id": "unit",
                      "value": "celsius"
                    },
                    {
                      "id": "custom.width",
                      "value": 100
                    },
                    {
                      "id": "thresholds",
                      "value": {
                        "mode": "absolute",
                        "steps": [
                          {
                            "color": "green",
                            "value": null
                          },
                          {
                            "color": "yellow",
                            "value": 70
                          },
                          {
                            "color": "orange",
                            "value": 80
                          },
                          {
                            "color": "red",
                            "value": 85
                          }
                        ]
                      }
                    },
                    {
                      "id": "custom.cellOptions",
                      "value": {
                        "type": "color-background"
                      }
                    }
                  ]
                },
                {
                  "matcher": {
                    "id": "byName",
                    "options": "Power (W)"
                  },
                  "properties": [
                    {
                      "id": "unit",
                      "value": "watt"
                    },
                    {
                      "id": "custom.width",
                      "value": 100
                    }
                  ]
                },
                {
                  "matcher": {
                    "id": "byName",
                    "options": "Util (%)"
                  },
                  "properties": [
                    {
                      "id": "unit",
                      "value": "percent"
                    },
                    {
                      "id": "custom.width",
                      "value": 100
                    },
                    {
                      "id": "thresholds",
                      "value": {
                        "mode": "absolute",
                        "steps": [
                          {
                            "color": "green",
                            "value": null
                          },
                          {
                            "color": "yellow",
                            "value": 70
                          },
                          {
                            "color": "orange",
                            "value": 85
                          },
                          {
                            "color": "red",
                            "value": 95
                          }
                        ]
                      }
                    },
                    {
                      "id": "custom.cellOptions",
                      "value": {
                        "type": "color-background"
                      }
                    }
                  ]
                },
                {
                  "matcher": {
                    "id": "byName",
                    "options": "Memory"
                  },
                  "properties": [
                    {
                      "id": "unit",
                      "value": "percentunit"
                    },
                    {
                      "id": "custom.width",
                      "value": 150
                    },
                    {
                      "id": "custom.cellOptions",
                      "value": {
                        "type": "lcd-gauge"
                      }
                    }
                  ]
                }
              ]
            },
            "gridPos": {
              "h": 4,
              "w": 12,
              "x": 12,
              "y": 32
            },
            "id": 12,
            "options": {
              "cellHeight": "sm",
              "footer": {
                "countRows": false,
                "fields": "",
                "reducer": [
                  "sum"
                ],
                "show": false
              },
              "showHeader": true
            },
            "pluginVersion": "10.0.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "expr": "nvidia_gpu_temperature_celsius",
                "format": "table",
                "instant": true,
                "refId": "A"
              },
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "expr": "node_gpu_power_watts",
                "format": "table",
                "instant": true,
                "refId": "B"
              },
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "expr": "nvidia_gpu_utilization_percent",
                "format": "table",
                "instant": true,
                "refId": "C"
              },
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "expr": "nvidia_gpu_memory_used_mb / nvidia_gpu_memory_total_mb",
                "format": "table",
                "instant": true,
                "refId": "D"
              }
            ],
            "title": "GPU Summary",
            "transformations": [
              {
                "id": "merge",
                "options": {}
              },
              {
                "id": "organize",
                "options": {
                  "excludeByName": {
                    "Time": true,
                    "__name__": true,
                    "job": true,
                    "instance": true
                  },
                  "indexByName": {},
                  "renameByName": {
                    "gpu": "GPU",
                    "name": "Name",
                    "Value #A": "Temp (°C)",
                    "Value #B": "Power (W)",
                    "Value #C": "Util (%)",
                    "Value #D": "Memory"
                  }
                }
              }
            ],
            "type": "table"
          }
        ],
        "refresh": "5s",
        "schemaVersion": 38,
        "style": "dark",
        "tags": ["gpu", "nvidia", "rtx", "performance"],
        "templating": {
          "list": []
        },
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "timepicker": {},
        "timezone": "",
        "title": "NVIDIA RTX Comprehensive Monitoring",
        "uid": "nvidia-rtx-comprehensive",
        "version": 1,
        "weekStart": ""
      }
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"nvidia-rtx-comprehensive-dashboard.json":"{\n  \"annotations\": {\n    \"list\": [\n      {\n        \"builtIn\": 1,\n        \"datasource\": {\n          \"type\": \"grafana\",\n          \"uid\": \"-- Grafana --\"\n        },\n        \"enable\": true,\n        \"hide\": true,\n        \"iconColor\": \"rgba(0, 211, 255, 1)\",\n        \"name\": \"Annotations \u0026 Alerts\",\n        \"type\": \"dashboard\"\n      }\n    ]\n  },\n  \"editable\": true,\n  \"fiscalYearStartMonth\": 0,\n  \"graphTooltip\": 0,\n  \"id\": null,\n  \"links\": [],\n  \"liveNow\": false,\n  \"panels\": [\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"yellow\",\n                \"value\": 70\n              },\n              {\n                \"color\": \"orange\",\n                \"value\": 80\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 85\n              }\n            ]\n          },\n          \"unit\": \"celsius\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 6,\n        \"x\": 0,\n        \"y\": 0\n      },\n      \"id\": 1,\n      \"options\": {\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"calcs\": [\n            \"lastNotNull\"\n          ],\n          \"fields\": \"\",\n          \"values\": false\n        },\n        \"showThresholdLabels\": false,\n        \"showThresholdMarkers\": true\n      },\n      \"pluginVersion\": \"10.0.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"expr\": \"nvidia_gpu_temperature_celsius\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"GPU Temperature\",\n      \"type\": \"gauge\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"yellow\",\n                \"value\": 200\n              },\n              {\n                \"color\": \"orange\",\n                \"value\": 300\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 350\n              }\n            ]\n          },\n          \"unit\": \"watt\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 6,\n        \"x\": 6,\n        \"y\": 0\n      },\n      \"id\": 2,\n      \"options\": {\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"calcs\": [\n            \"lastNotNull\"\n          ],\n          \"fields\": \"\",\n          \"values\": false\n        },\n        \"showThresholdLabels\": false,\n        \"showThresholdMarkers\": true\n      },\n      \"pluginVersion\": \"10.0.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"expr\": \"nvidia_gpu_power_draw_watts\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"GPU Power Draw\",\n      \"type\": \"gauge\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"yellow\",\n                \"value\": 70\n              },\n              {\n                \"color\": \"orange\",\n                \"value\": 85\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 95\n              }\n            ]\n          },\n          \"unit\": \"percent\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 6,\n        \"x\": 12,\n        \"y\": 0\n      },\n      \"id\": 3,\n      \"options\": {\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"calcs\": [\n            \"lastNotNull\"\n          ],\n          \"fields\": \"\",\n          \"values\": false\n        },\n        \"showThresholdLabels\": false,\n        \"showThresholdMarkers\": true\n      },\n      \"pluginVersion\": \"10.0.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"expr\": \"nvidia_gpu_utilization_percent\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"GPU Utilization\",\n      \"type\": \"gauge\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"yellow\",\n                \"value\": 60\n              },\n              {\n                \"color\": \"orange\",\n                \"value\": 80\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 90\n              }\n            ]\n          },\n          \"unit\": \"percent\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 6,\n        \"x\": 18,\n        \"y\": 0\n      },\n      \"id\": 4,\n      \"options\": {\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"calcs\": [\n            \"lastNotNull\"\n          ],\n          \"fields\": \"\",\n          \"values\": false\n        },\n        \"showThresholdLabels\": false,\n        \"showThresholdMarkers\": true\n      },\n      \"pluginVersion\": \"10.0.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"expr\": \"(nvidia_gpu_memory_used_mb / nvidia_gpu_memory_total_mb) * 100\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"GPU Memory Usage\",\n      \"type\": \"gauge\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisCenteredZero\": false,\n            \"axisColorMode\": \"text\",\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 10,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            },\n            \"insertNulls\": false,\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"never\",\n            \"spanNulls\": false,\n            \"stacking\": {\n              \"group\": \"A\",\n              \"mode\": \"none\"\n            },\n            \"thresholdsStyle\": {\n              \"mode\": \"off\"\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          },\n          \"unit\": \"celsius\"\n        },\n        \"overrides\": [\n          {\n            \"matcher\": {\n              \"id\": \"byName\",\n              \"options\": \"Temperature\"\n            },\n            \"properties\": [\n              {\n                \"id\": \"color\",\n                \"value\": {\n                  \"fixedColor\": \"red\",\n                  \"mode\": \"fixed\"\n                }\n              }\n            ]\n          }\n        ]\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 0,\n        \"y\": 8\n      },\n      \"id\": 5,\n      \"options\": {\n        \"legend\": {\n          \"calcs\": [],\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\",\n          \"showLegend\": true\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        }\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"expr\": \"nvidia_gpu_temperature_celsius\",\n          \"legendFormat\": \"Temperature\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"GPU Temperature History\",\n      \"type\": \"timeseries\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisCenteredZero\": false,\n            \"axisColorMode\": \"text\",\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 10,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            },\n            \"insertNulls\": false,\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"never\",\n            \"spanNulls\": false,\n            \"stacking\": {\n              \"group\": \"A\",\n              \"mode\": \"none\"\n            },\n            \"thresholdsStyle\": {\n              \"mode\": \"off\"\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          },\n          \"unit\": \"watt\"\n        },\n        \"overrides\": [\n          {\n            \"matcher\": {\n              \"id\": \"byName\",\n              \"options\": \"Power Draw\"\n            },\n            \"properties\": [\n              {\n                \"id\": \"color\",\n                \"value\": {\n                  \"fixedColor\": \"yellow\",\n                  \"mode\": \"fixed\"\n                }\n              }\n            ]\n          }\n        ]\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 8\n      },\n      \"id\": 6,\n      \"options\": {\n        \"legend\": {\n          \"calcs\": [],\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\",\n          \"showLegend\": true\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        }\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"expr\": \"node_gpu_power_watts\",\n          \"legendFormat\": \"Power Draw\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"GPU Power History\",\n      \"type\": \"timeseries\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisCenteredZero\": false,\n            \"axisColorMode\": \"text\",\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 10,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            },\n            \"insertNulls\": false,\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"never\",\n            \"spanNulls\": false,\n            \"stacking\": {\n              \"group\": \"A\",\n              \"mode\": \"none\"\n            },\n            \"thresholdsStyle\": {\n              \"mode\": \"off\"\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          },\n          \"unit\": \"percent\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 0,\n        \"y\": 16\n      },\n      \"id\": 7,\n      \"options\": {\n        \"legend\": {\n          \"calcs\": [],\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\",\n          \"showLegend\": true\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        }\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"expr\": \"nvidia_gpu_utilization_percent\",\n          \"legendFormat\": \"GPU Utilization\",\n          \"refId\": \"A\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"expr\": \"nvidia_gpu_memory_utilization_percent\",\n          \"legendFormat\": \"Memory Utilization\",\n          \"refId\": \"B\"\n        }\n      ],\n      \"title\": \"GPU \u0026 Memory Utilization\",\n      \"type\": \"timeseries\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisCenteredZero\": false,\n            \"axisColorMode\": \"text\",\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 10,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            },\n            \"insertNulls\": false,\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"never\",\n            \"spanNulls\": false,\n            \"stacking\": {\n              \"group\": \"A\",\n              \"mode\": \"normal\"\n            },\n            \"thresholdsStyle\": {\n              \"mode\": \"off\"\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          },\n          \"unit\": \"decmbytes\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 16\n      },\n      \"id\": 8,\n      \"options\": {\n        \"legend\": {\n          \"calcs\": [],\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\",\n          \"showLegend\": true\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        }\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"expr\": \"nvidia_gpu_memory_used_mb\",\n          \"legendFormat\": \"Used\",\n          \"refId\": \"A\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"expr\": \"nvidia_gpu_memory_total_mb - nvidia_gpu_memory_used_mb\",\n          \"legendFormat\": \"Free\",\n          \"refId\": \"B\"\n        }\n      ],\n      \"title\": \"GPU Memory Usage\",\n      \"type\": \"timeseries\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisCenteredZero\": false,\n            \"axisColorMode\": \"text\",\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 10,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            },\n            \"insertNulls\": false,\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"never\",\n            \"spanNulls\": false,\n            \"stacking\": {\n              \"group\": \"A\",\n              \"mode\": \"none\"\n            },\n            \"thresholdsStyle\": {\n              \"mode\": \"off\"\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          },\n          \"unit\": \"megahertz\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 0,\n        \"y\": 24\n      },\n      \"id\": 9,\n      \"options\": {\n        \"legend\": {\n          \"calcs\": [],\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\",\n          \"showLegend\": true\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        }\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"expr\": \"nvidia_gpu_clock_graphics_mhz\",\n          \"legendFormat\": \"Graphics Clock\",\n          \"refId\": \"A\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"expr\": \"nvidia_gpu_clock_sm_mhz\",\n          \"legendFormat\": \"SM Clock\",\n          \"refId\": \"B\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"expr\": \"nvidia_gpu_clock_memory_mhz\",\n          \"legendFormat\": \"Memory Clock\",\n          \"refId\": \"C\"\n        }\n      ],\n      \"title\": \"GPU Clock Speeds\",\n      \"type\": \"timeseries\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          },\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 24\n      },\n      \"id\": 10,\n      \"options\": {\n        \"colorMode\": \"value\",\n        \"graphMode\": \"area\",\n        \"justifyMode\": \"auto\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"calcs\": [\n            \"lastNotNull\"\n          ],\n          \"fields\": \"\",\n          \"values\": false\n        },\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"10.0.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"expr\": \"nvidia_gpu_performance_state\",\n          \"legendFormat\": \"P-State\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"GPU Performance State\",\n      \"type\": \"stat\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"description\": \"Thermal throttling and power limit indicators\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [\n            {\n              \"options\": {\n                \"0\": {\n                  \"color\": \"green\",\n                  \"index\": 0,\n                  \"text\": \"No Throttling\"\n                },\n                \"1\": {\n                  \"color\": \"red\",\n                  \"index\": 1,\n                  \"text\": \"Throttling Active\"\n                }\n              },\n              \"type\": \"value\"\n            }\n          ],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 1\n              }\n            ]\n          }\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 4,\n        \"w\": 12,\n        \"x\": 0,\n        \"y\": 32\n      },\n      \"id\": 11,\n      \"options\": {\n        \"colorMode\": \"background\",\n        \"graphMode\": \"none\",\n        \"justifyMode\": \"auto\",\n        \"orientation\": \"horizontal\",\n        \"reduceOptions\": {\n          \"calcs\": [\n            \"lastNotNull\"\n          ],\n          \"fields\": \"\",\n          \"values\": false\n        },\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"10.0.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"expr\": \"nvidia_gpu_throttle_hw_thermal\",\n          \"legendFormat\": \"Thermal Throttle\",\n          \"refId\": \"A\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"expr\": \"nvidia_gpu_throttle_sw_power_cap\",\n          \"legendFormat\": \"Power Cap\",\n          \"refId\": \"B\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"expr\": \"nvidia_gpu_throttle_hw_slowdown\",\n          \"legendFormat\": \"HW Slowdown\",\n          \"refId\": \"C\"\n        }\n      ],\n      \"title\": \"GPU Throttle Status\",\n      \"type\": \"stat\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"custom\": {\n            \"align\": \"auto\",\n            \"cellOptions\": {\n              \"type\": \"auto\"\n            },\n            \"inspect\": false\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          }\n        },\n        \"overrides\": [\n          {\n            \"matcher\": {\n              \"id\": \"byName\",\n              \"options\": \"GPU\"\n            },\n            \"properties\": [\n              {\n                \"id\": \"custom.width\",\n                \"value\": 50\n              }\n            ]\n          },\n          {\n            \"matcher\": {\n              \"id\": \"byName\",\n              \"options\": \"Name\"\n            },\n            \"properties\": [\n              {\n                \"id\": \"custom.width\",\n                \"value\": 300\n              }\n            ]\n          },\n          {\n            \"matcher\": {\n              \"id\": \"byName\",\n              \"options\": \"Temp (°C)\"\n            },\n            \"properties\": [\n              {\n                \"id\": \"unit\",\n                \"value\": \"celsius\"\n              },\n              {\n                \"id\": \"custom.width\",\n                \"value\": 100\n              },\n              {\n                \"id\": \"thresholds\",\n                \"value\": {\n                  \"mode\": \"absolute\",\n                  \"steps\": [\n                    {\n                      \"color\": \"green\",\n                      \"value\": null\n                    },\n                    {\n                      \"color\": \"yellow\",\n                      \"value\": 70\n                    },\n                    {\n                      \"color\": \"orange\",\n                      \"value\": 80\n                    },\n                    {\n                      \"color\": \"red\",\n                      \"value\": 85\n                    }\n                  ]\n                }\n              },\n              {\n                \"id\": \"custom.cellOptions\",\n                \"value\": {\n                  \"type\": \"color-background\"\n                }\n              }\n            ]\n          },\n          {\n            \"matcher\": {\n              \"id\": \"byName\",\n              \"options\": \"Power (W)\"\n            },\n            \"properties\": [\n              {\n                \"id\": \"unit\",\n                \"value\": \"watt\"\n              },\n              {\n                \"id\": \"custom.width\",\n                \"value\": 100\n              }\n            ]\n          },\n          {\n            \"matcher\": {\n              \"id\": \"byName\",\n              \"options\": \"Util (%)\"\n            },\n            \"properties\": [\n              {\n                \"id\": \"unit\",\n                \"value\": \"percent\"\n              },\n              {\n                \"id\": \"custom.width\",\n                \"value\": 100\n              },\n              {\n                \"id\": \"thresholds\",\n                \"value\": {\n                  \"mode\": \"absolute\",\n                  \"steps\": [\n                    {\n                      \"color\": \"green\",\n                      \"value\": null\n                    },\n                    {\n                      \"color\": \"yellow\",\n                      \"value\": 70\n                    },\n                    {\n                      \"color\": \"orange\",\n                      \"value\": 85\n                    },\n                    {\n                      \"color\": \"red\",\n                      \"value\": 95\n                    }\n                  ]\n                }\n              },\n              {\n                \"id\": \"custom.cellOptions\",\n                \"value\": {\n                  \"type\": \"color-background\"\n                }\n              }\n            ]\n          },\n          {\n            \"matcher\": {\n              \"id\": \"byName\",\n              \"options\": \"Memory\"\n            },\n            \"properties\": [\n              {\n                \"id\": \"unit\",\n                \"value\": \"percentunit\"\n              },\n              {\n                \"id\": \"custom.width\",\n                \"value\": 150\n              },\n              {\n                \"id\": \"custom.cellOptions\",\n                \"value\": {\n                  \"type\": \"lcd-gauge\"\n                }\n              }\n            ]\n          }\n        ]\n      },\n      \"gridPos\": {\n        \"h\": 4,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 32\n      },\n      \"id\": 12,\n      \"options\": {\n        \"cellHeight\": \"sm\",\n        \"footer\": {\n          \"countRows\": false,\n          \"fields\": \"\",\n          \"reducer\": [\n            \"sum\"\n          ],\n          \"show\": false\n        },\n        \"showHeader\": true\n      },\n      \"pluginVersion\": \"10.0.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"expr\": \"nvidia_gpu_temperature_celsius\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"A\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"expr\": \"node_gpu_power_watts\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"B\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"expr\": \"nvidia_gpu_utilization_percent\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"C\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"expr\": \"nvidia_gpu_memory_used_mb / nvidia_gpu_memory_total_mb\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"D\"\n        }\n      ],\n      \"title\": \"GPU Summary\",\n      \"transformations\": [\n        {\n          \"id\": \"merge\",\n          \"options\": {}\n        },\n        {\n          \"id\": \"organize\",\n          \"options\": {\n            \"excludeByName\": {\n              \"Time\": true,\n              \"__name__\": true,\n              \"job\": true,\n              \"instance\": true\n            },\n            \"indexByName\": {},\n            \"renameByName\": {\n              \"gpu\": \"GPU\",\n              \"name\": \"Name\",\n              \"Value #A\": \"Temp (°C)\",\n              \"Value #B\": \"Power (W)\",\n              \"Value #C\": \"Util (%)\",\n              \"Value #D\": \"Memory\"\n            }\n          }\n        }\n      ],\n      \"type\": \"table\"\n    }\n  ],\n  \"refresh\": \"5s\",\n  \"schemaVersion\": 38,\n  \"style\": \"dark\",\n  \"tags\": [\"gpu\", \"nvidia\", \"rtx\", \"performance\"],\n  \"templating\": {\n    \"list\": []\n  },\n  \"time\": {\n    \"from\": \"now-1h\",\n    \"to\": \"now\"\n  },\n  \"timepicker\": {},\n  \"timezone\": \"\",\n  \"title\": \"NVIDIA RTX Comprehensive Monitoring\",\n  \"uid\": \"nvidia-rtx-comprehensive\",\n  \"version\": 1,\n  \"weekStart\": \"\"\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"nvidia-rtx-comprehensive-dashboard","namespace":"monitoring"}}
    creationTimestamp: "2025-06-03T16:27:35Z"
    name: nvidia-rtx-comprehensive-dashboard
    namespace: monitoring
    resourceVersion: "2438727"
    uid: 8032e735-59c2-48e7-a182-61351e4fc095
- apiVersion: v1
  data:
    provider.yaml: |
      apiVersion: 1
      providers:
      - name: 'nvidia-rtx-dashboards'
        orgId: 1
        folder: 'GPU'
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /etc/grafana/provisioning/dashboards/nvidia-rtx
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"provider.yaml":"apiVersion: 1\nproviders:\n- name: 'nvidia-rtx-dashboards'\n  orgId: 1\n  folder: 'GPU'\n  type: file\n  disableDeletion: false\n  updateIntervalSeconds: 10\n  allowUiUpdates: true\n  options:\n    path: /etc/grafana/provisioning/dashboards/nvidia-rtx\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"nvidia-rtx-dashboard-provider","namespace":"monitoring"}}
    creationTimestamp: "2025-06-03T16:27:35Z"
    name: nvidia-rtx-dashboard-provider
    namespace: monitoring
    resourceVersion: "2438728"
    uid: 941dd744-bd20-4426-ad0f-c9731314e0dc
- apiVersion: v1
  data:
    nvidia_rtx_exporter.py: "#!/usr/bin/env python3\n\"\"\"\nNVIDIA RTX GPU Exporter
      for Prometheus\nSimplified version that works with mounted nvidia-smi\n\"\"\"\n\nimport
      subprocess\nimport time\nimport re\nfrom prometheus_client import start_http_server,
      Gauge, Info, Counter\nimport logging\nimport os\n\nlogging.basicConfig(level=logging.INFO,
      format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)\n\n#
      GPU Information metrics\ngpu_info = Info('nvidia_gpu_info', 'GPU information')\n\n#
      Temperature metrics\ntemp_gpu = Gauge('nvidia_gpu_temperature_celsius', 'GPU
      temperature in Celsius', ['gpu', 'name'])\ntemp_memory = Gauge('nvidia_gpu_memory_temperature_celsius',
      'Memory temperature in Celsius', ['gpu', 'name'])\n\n# Power metrics\npower_draw
      = Gauge('nvidia_gpu_power_draw_watts', 'Current power draw in watts', ['gpu',
      'name'])\npower_limit = Gauge('nvidia_gpu_power_limit_watts', 'Current power
      limit in watts', ['gpu', 'name'])\npower_max_limit = Gauge('nvidia_gpu_power_max_limit_watts',
      'Maximum power limit in watts', ['gpu', 'name'])\n\n# Clock metrics\nclock_graphics
      = Gauge('nvidia_gpu_clock_graphics_mhz', 'Current graphics clock in MHz', ['gpu',
      'name'])\nclock_sm = Gauge('nvidia_gpu_clock_sm_mhz', 'Current SM clock in MHz',
      ['gpu', 'name'])\nclock_memory = Gauge('nvidia_gpu_clock_memory_mhz', 'Current
      memory clock in MHz', ['gpu', 'name'])\n\n# Memory metrics\nmemory_total = Gauge('nvidia_gpu_memory_total_mb',
      'Total memory in MB', ['gpu', 'name'])\nmemory_used = Gauge('nvidia_gpu_memory_used_mb',
      'Used memory in MB', ['gpu', 'name'])\nmemory_free = Gauge('nvidia_gpu_memory_free_mb',
      'Free memory in MB', ['gpu', 'name'])\n\n# Utilization metrics\nutil_gpu = Gauge('nvidia_gpu_utilization_percent',
      'GPU utilization percentage', ['gpu', 'name'])\nutil_memory = Gauge('nvidia_gpu_memory_utilization_percent',
      'Memory utilization percentage', ['gpu', 'name'])\nutil_encoder = Gauge('nvidia_gpu_encoder_utilization_percent',
      'Encoder utilization percentage', ['gpu', 'name'])\nutil_decoder = Gauge('nvidia_gpu_decoder_utilization_percent',
      'Decoder utilization percentage', ['gpu', 'name'])\n\n# Performance state\npstate
      = Gauge('nvidia_gpu_performance_state', 'Current performance state (P0-P12)',
      ['gpu', 'name'])\n\n# Fan metrics\nfan_speed = Gauge('nvidia_gpu_fan_speed_percent',
      'Fan speed percentage', ['gpu', 'name'])\n\n# Throttling metrics\nthrottle_thermal
      = Gauge('nvidia_gpu_throttle_thermal', 'Thermal throttle active', ['gpu', 'name'])\nthrottle_power
      = Gauge('nvidia_gpu_throttle_power', 'Power throttle active', ['gpu', 'name'])\n\n#
      Health metrics\nscrape_errors = Counter('nvidia_gpu_scrape_errors_total', 'Total
      number of scrape errors')\nscrape_success = Gauge('nvidia_gpu_scrape_success',
      'Whether the last scrape was successful')\n\ndef parse_value(value):\n    \"\"\"Parse
      nvidia-smi output values\"\"\"\n    if value in ['N/A', '[N/A]', 'Not Active',
      'Default', 'ERR!']:\n        return None\n    \n    # Remove units and convert
      to float\n    value = value.strip()\n    \n    # Handle percentage\n    if value.endswith('
      %'):\n        return float(value[:-2])\n    \n    # Handle power in watts\n
      \   if value.endswith(' W'):\n        return float(value[:-2])\n    \n    #
      Handle memory in MiB\n    if value.endswith(' MiB'):\n        return float(value[:-4])\n
      \   \n    # Handle frequency in MHz\n    if value.endswith(' MHz'):\n        return
      float(value[:-4])\n    \n    # Handle temperature\n    if value.isdigit():\n
      \       return float(value)\n    \n    # Handle performance state (P0-P12)\n
      \   if value.startswith('P') and len(value) <= 3:\n        return float(value[1:])\n
      \   \n    # Handle Active/Not Active for throttle reasons\n    if value == 'Active':\n
      \       return 1.0\n    elif value == 'Not Active':\n        return 0.0\n    \n
      \   try:\n        return float(value)\n    except ValueError:\n        return
      None\n\ndef get_gpu_metrics():\n    \"\"\"Query GPU metrics using nvidia-smi\"\"\"\n
      \   try:\n        # Test if nvidia-smi is accessible\n        nvidia_smi_path
      = '/usr/bin/nvidia-smi'\n        if not os.path.exists(nvidia_smi_path):\n            logger.error(f\"nvidia-smi
      not found at {nvidia_smi_path}\")\n            return None\n        \n        #
      Basic query for all metrics we can get\n        query_string = \",\".join([\n
      \           \"index\",\n            \"name\",\n            \"temperature.gpu\",\n
      \           \"temperature.memory\",\n            \"power.draw\",\n            \"power.limit\",\n
      \           \"power.max_limit\",\n            \"clocks.current.graphics\",\n
      \           \"clocks.current.sm\",\n            \"clocks.current.memory\",\n
      \           \"memory.total\",\n            \"memory.used\",\n            \"memory.free\",\n
      \           \"utilization.gpu\",\n            \"utilization.memory\",\n            \"utilization.encoder\",\n
      \           \"utilization.decoder\",\n            \"pstate\",\n            \"fan.speed\",\n
      \           \"clocks_throttle_reasons.gpu_idle\",\n            \"clocks_throttle_reasons.hw_thermal_slowdown\",\n
      \           \"clocks_throttle_reasons.sw_power_cap\"\n        ])\n        \n
      \       cmd = [nvidia_smi_path, f\"--query-gpu={query_string}\", \"--format=csv,noheader,nounits\"]\n
      \       \n        logger.info(f\"Running command: {' '.join(cmd)}\")\n        result
      = subprocess.run(cmd, capture_output=True, text=True, timeout=10)\n        \n
      \       if result.returncode != 0:\n            logger.error(f\"nvidia-smi failed
      with return code {result.returncode}\")\n            logger.error(f\"stderr:
      {result.stderr}\")\n            return None\n        \n        logger.info(f\"nvidia-smi
      output: {result.stdout}\")\n        \n        # Parse output\n        gpu_data
      = []\n        for line in result.stdout.strip().split('\\n'):\n            if
      not line:\n                continue\n                \n            values =
      [v.strip() for v in line.split(',')]\n            if len(values) >= 22:  # We
      expect at least 22 values\n                gpu_data.append(values)\n            else:\n
      \               logger.warning(f\"Incomplete data line: {line}\")\n        \n
      \       return gpu_data\n        \n    except subprocess.TimeoutExpired:\n        logger.error(\"nvidia-smi
      command timed out\")\n        return None\n    except Exception as e:\n        logger.error(f\"Error
      querying GPU metrics: {e}\")\n        return None\n\ndef update_metrics():\n
      \   \"\"\"Update Prometheus metrics\"\"\"\n    try:\n        gpu_data = get_gpu_metrics()\n
      \       \n        if not gpu_data:\n            logger.warning(\"No GPU data
      available\")\n            scrape_success.set(0)\n            scrape_errors.inc()\n
      \           return\n        \n        scrape_success.set(1)\n        \n        for
      values in gpu_data:\n            try:\n                idx = 0\n                gpu_idx
      = values[idx]\n                idx += 1\n                \n                gpu_name
      = values[idx]\n                idx += 1\n                \n                #
      Update GPU info\n                gpu_info.info({\n                    'index':
      gpu_idx,\n                    'name': gpu_name\n                })\n                \n
      \               # Temperature\n                val = parse_value(values[idx])\n
      \               if val is not None:\n                    temp_gpu.labels(gpu=gpu_idx,
      name=gpu_name).set(val)\n                idx += 1\n                \n                val
      = parse_value(values[idx])\n                if val is not None:\n                    temp_memory.labels(gpu=gpu_idx,
      name=gpu_name).set(val)\n                idx += 1\n                \n                #
      Power\n                val = parse_value(values[idx])\n                if val
      is not None:\n                    power_draw.labels(gpu=gpu_idx, name=gpu_name).set(val)\n
      \               idx += 1\n                \n                val = parse_value(values[idx])\n
      \               if val is not None:\n                    power_limit.labels(gpu=gpu_idx,
      name=gpu_name).set(val)\n                idx += 1\n                \n                val
      = parse_value(values[idx])\n                if val is not None:\n                    power_max_limit.labels(gpu=gpu_idx,
      name=gpu_name).set(val)\n                idx += 1\n                \n                #
      Clocks\n                val = parse_value(values[idx])\n                if val
      is not None:\n                    clock_graphics.labels(gpu=gpu_idx, name=gpu_name).set(val)\n
      \               idx += 1\n                \n                val = parse_value(values[idx])\n
      \               if val is not None:\n                    clock_sm.labels(gpu=gpu_idx,
      name=gpu_name).set(val)\n                idx += 1\n                \n                val
      = parse_value(values[idx])\n                if val is not None:\n                    clock_memory.labels(gpu=gpu_idx,
      name=gpu_name).set(val)\n                idx += 1\n                \n                #
      Memory\n                val = parse_value(values[idx])\n                if val
      is not None:\n                    memory_total.labels(gpu=gpu_idx, name=gpu_name).set(val)\n
      \               idx += 1\n                \n                val = parse_value(values[idx])\n
      \               if val is not None:\n                    memory_used.labels(gpu=gpu_idx,
      name=gpu_name).set(val)\n                idx += 1\n                \n                val
      = parse_value(values[idx])\n                if val is not None:\n                    memory_free.labels(gpu=gpu_idx,
      name=gpu_name).set(val)\n                idx += 1\n                \n                #
      Utilization\n                val = parse_value(values[idx])\n                if
      val is not None:\n                    util_gpu.labels(gpu=gpu_idx, name=gpu_name).set(val)\n
      \               idx += 1\n                \n                val = parse_value(values[idx])\n
      \               if val is not None:\n                    util_memory.labels(gpu=gpu_idx,
      name=gpu_name).set(val)\n                idx += 1\n                \n                val
      = parse_value(values[idx])\n                if val is not None:\n                    util_encoder.labels(gpu=gpu_idx,
      name=gpu_name).set(val)\n                idx += 1\n                \n                val
      = parse_value(values[idx])\n                if val is not None:\n                    util_decoder.labels(gpu=gpu_idx,
      name=gpu_name).set(val)\n                idx += 1\n                \n                #
      Performance state\n                val = parse_value(values[idx])\n                if
      val is not None:\n                    pstate.labels(gpu=gpu_idx, name=gpu_name).set(val)\n
      \               idx += 1\n                \n                # Fan speed\n                val
      = parse_value(values[idx])\n                if val is not None:\n                    fan_speed.labels(gpu=gpu_idx,
      name=gpu_name).set(val)\n                idx += 1\n                \n                #
      Skip idle throttle reason\n                idx += 1\n                \n                #
      Thermal throttle\n                val = parse_value(values[idx])\n                if
      val is not None:\n                    throttle_thermal.labels(gpu=gpu_idx, name=gpu_name).set(val)\n
      \               idx += 1\n                \n                # Power throttle\n
      \               val = parse_value(values[idx])\n                if val is not
      None:\n                    throttle_power.labels(gpu=gpu_idx, name=gpu_name).set(val)\n
      \               idx += 1\n                \n            except Exception as
      e:\n                logger.error(f\"Error parsing GPU {gpu_idx} metrics: {e}\")\n
      \               scrape_errors.inc()\n                \n    except Exception
      as e:\n        logger.error(f\"Error updating metrics: {e}\")\n        scrape_success.set(0)\n
      \       scrape_errors.inc()\n\ndef main():\n    \"\"\"Main exporter loop\"\"\"\n
      \   # Start Prometheus metrics server\n    start_http_server(9410)\n    logger.info(\"NVIDIA
      RTX Exporter started on port 9410\")\n    \n    # Initial test\n    logger.info(\"Testing
      nvidia-smi access...\")\n    test_result = subprocess.run(['/usr/bin/nvidia-smi',
      '--list-gpus'], capture_output=True, text=True)\n    if test_result.returncode
      == 0:\n        logger.info(f\"GPUs found: {test_result.stdout}\")\n    else:\n
      \       logger.error(f\"Failed to list GPUs: {test_result.stderr}\")\n    \n
      \   # Main loop\n    while True:\n        try:\n            update_metrics()\n
      \       except Exception as e:\n            logger.error(f\"Error in main loop:
      {e}\")\n        \n        time.sleep(5)  # Update every 5 seconds\n\nif __name__
      == \"__main__\":\n    main()\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"nvidia_rtx_exporter.py":"#!/usr/bin/env python3\n\"\"\"\nNVIDIA RTX GPU Exporter for Prometheus\nSimplified version that works with mounted nvidia-smi\n\"\"\"\n\nimport subprocess\nimport time\nimport re\nfrom prometheus_client import start_http_server, Gauge, Info, Counter\nimport logging\nimport os\n\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)\n\n# GPU Information metrics\ngpu_info = Info('nvidia_gpu_info', 'GPU information')\n\n# Temperature metrics\ntemp_gpu = Gauge('nvidia_gpu_temperature_celsius', 'GPU temperature in Celsius', ['gpu', 'name'])\ntemp_memory = Gauge('nvidia_gpu_memory_temperature_celsius', 'Memory temperature in Celsius', ['gpu', 'name'])\n\n# Power metrics\npower_draw = Gauge('nvidia_gpu_power_draw_watts', 'Current power draw in watts', ['gpu', 'name'])\npower_limit = Gauge('nvidia_gpu_power_limit_watts', 'Current power limit in watts', ['gpu', 'name'])\npower_max_limit = Gauge('nvidia_gpu_power_max_limit_watts', 'Maximum power limit in watts', ['gpu', 'name'])\n\n# Clock metrics\nclock_graphics = Gauge('nvidia_gpu_clock_graphics_mhz', 'Current graphics clock in MHz', ['gpu', 'name'])\nclock_sm = Gauge('nvidia_gpu_clock_sm_mhz', 'Current SM clock in MHz', ['gpu', 'name'])\nclock_memory = Gauge('nvidia_gpu_clock_memory_mhz', 'Current memory clock in MHz', ['gpu', 'name'])\n\n# Memory metrics\nmemory_total = Gauge('nvidia_gpu_memory_total_mb', 'Total memory in MB', ['gpu', 'name'])\nmemory_used = Gauge('nvidia_gpu_memory_used_mb', 'Used memory in MB', ['gpu', 'name'])\nmemory_free = Gauge('nvidia_gpu_memory_free_mb', 'Free memory in MB', ['gpu', 'name'])\n\n# Utilization metrics\nutil_gpu = Gauge('nvidia_gpu_utilization_percent', 'GPU utilization percentage', ['gpu', 'name'])\nutil_memory = Gauge('nvidia_gpu_memory_utilization_percent', 'Memory utilization percentage', ['gpu', 'name'])\nutil_encoder = Gauge('nvidia_gpu_encoder_utilization_percent', 'Encoder utilization percentage', ['gpu', 'name'])\nutil_decoder = Gauge('nvidia_gpu_decoder_utilization_percent', 'Decoder utilization percentage', ['gpu', 'name'])\n\n# Performance state\npstate = Gauge('nvidia_gpu_performance_state', 'Current performance state (P0-P12)', ['gpu', 'name'])\n\n# Fan metrics\nfan_speed = Gauge('nvidia_gpu_fan_speed_percent', 'Fan speed percentage', ['gpu', 'name'])\n\n# Throttling metrics\nthrottle_thermal = Gauge('nvidia_gpu_throttle_thermal', 'Thermal throttle active', ['gpu', 'name'])\nthrottle_power = Gauge('nvidia_gpu_throttle_power', 'Power throttle active', ['gpu', 'name'])\n\n# Health metrics\nscrape_errors = Counter('nvidia_gpu_scrape_errors_total', 'Total number of scrape errors')\nscrape_success = Gauge('nvidia_gpu_scrape_success', 'Whether the last scrape was successful')\n\ndef parse_value(value):\n    \"\"\"Parse nvidia-smi output values\"\"\"\n    if value in ['N/A', '[N/A]', 'Not Active', 'Default', 'ERR!']:\n        return None\n    \n    # Remove units and convert to float\n    value = value.strip()\n    \n    # Handle percentage\n    if value.endswith(' %'):\n        return float(value[:-2])\n    \n    # Handle power in watts\n    if value.endswith(' W'):\n        return float(value[:-2])\n    \n    # Handle memory in MiB\n    if value.endswith(' MiB'):\n        return float(value[:-4])\n    \n    # Handle frequency in MHz\n    if value.endswith(' MHz'):\n        return float(value[:-4])\n    \n    # Handle temperature\n    if value.isdigit():\n        return float(value)\n    \n    # Handle performance state (P0-P12)\n    if value.startswith('P') and len(value) \u003c= 3:\n        return float(value[1:])\n    \n    # Handle Active/Not Active for throttle reasons\n    if value == 'Active':\n        return 1.0\n    elif value == 'Not Active':\n        return 0.0\n    \n    try:\n        return float(value)\n    except ValueError:\n        return None\n\ndef get_gpu_metrics():\n    \"\"\"Query GPU metrics using nvidia-smi\"\"\"\n    try:\n        # Test if nvidia-smi is accessible\n        nvidia_smi_path = '/usr/bin/nvidia-smi'\n        if not os.path.exists(nvidia_smi_path):\n            logger.error(f\"nvidia-smi not found at {nvidia_smi_path}\")\n            return None\n        \n        # Basic query for all metrics we can get\n        query_string = \",\".join([\n            \"index\",\n            \"name\",\n            \"temperature.gpu\",\n            \"temperature.memory\",\n            \"power.draw\",\n            \"power.limit\",\n            \"power.max_limit\",\n            \"clocks.current.graphics\",\n            \"clocks.current.sm\",\n            \"clocks.current.memory\",\n            \"memory.total\",\n            \"memory.used\",\n            \"memory.free\",\n            \"utilization.gpu\",\n            \"utilization.memory\",\n            \"utilization.encoder\",\n            \"utilization.decoder\",\n            \"pstate\",\n            \"fan.speed\",\n            \"clocks_throttle_reasons.gpu_idle\",\n            \"clocks_throttle_reasons.hw_thermal_slowdown\",\n            \"clocks_throttle_reasons.sw_power_cap\"\n        ])\n        \n        cmd = [nvidia_smi_path, f\"--query-gpu={query_string}\", \"--format=csv,noheader,nounits\"]\n        \n        logger.info(f\"Running command: {' '.join(cmd)}\")\n        result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)\n        \n        if result.returncode != 0:\n            logger.error(f\"nvidia-smi failed with return code {result.returncode}\")\n            logger.error(f\"stderr: {result.stderr}\")\n            return None\n        \n        logger.info(f\"nvidia-smi output: {result.stdout}\")\n        \n        # Parse output\n        gpu_data = []\n        for line in result.stdout.strip().split('\\n'):\n            if not line:\n                continue\n                \n            values = [v.strip() for v in line.split(',')]\n            if len(values) \u003e= 22:  # We expect at least 22 values\n                gpu_data.append(values)\n            else:\n                logger.warning(f\"Incomplete data line: {line}\")\n        \n        return gpu_data\n        \n    except subprocess.TimeoutExpired:\n        logger.error(\"nvidia-smi command timed out\")\n        return None\n    except Exception as e:\n        logger.error(f\"Error querying GPU metrics: {e}\")\n        return None\n\ndef update_metrics():\n    \"\"\"Update Prometheus metrics\"\"\"\n    try:\n        gpu_data = get_gpu_metrics()\n        \n        if not gpu_data:\n            logger.warning(\"No GPU data available\")\n            scrape_success.set(0)\n            scrape_errors.inc()\n            return\n        \n        scrape_success.set(1)\n        \n        for values in gpu_data:\n            try:\n                idx = 0\n                gpu_idx = values[idx]\n                idx += 1\n                \n                gpu_name = values[idx]\n                idx += 1\n                \n                # Update GPU info\n                gpu_info.info({\n                    'index': gpu_idx,\n                    'name': gpu_name\n                })\n                \n                # Temperature\n                val = parse_value(values[idx])\n                if val is not None:\n                    temp_gpu.labels(gpu=gpu_idx, name=gpu_name).set(val)\n                idx += 1\n                \n                val = parse_value(values[idx])\n                if val is not None:\n                    temp_memory.labels(gpu=gpu_idx, name=gpu_name).set(val)\n                idx += 1\n                \n                # Power\n                val = parse_value(values[idx])\n                if val is not None:\n                    power_draw.labels(gpu=gpu_idx, name=gpu_name).set(val)\n                idx += 1\n                \n                val = parse_value(values[idx])\n                if val is not None:\n                    power_limit.labels(gpu=gpu_idx, name=gpu_name).set(val)\n                idx += 1\n                \n                val = parse_value(values[idx])\n                if val is not None:\n                    power_max_limit.labels(gpu=gpu_idx, name=gpu_name).set(val)\n                idx += 1\n                \n                # Clocks\n                val = parse_value(values[idx])\n                if val is not None:\n                    clock_graphics.labels(gpu=gpu_idx, name=gpu_name).set(val)\n                idx += 1\n                \n                val = parse_value(values[idx])\n                if val is not None:\n                    clock_sm.labels(gpu=gpu_idx, name=gpu_name).set(val)\n                idx += 1\n                \n                val = parse_value(values[idx])\n                if val is not None:\n                    clock_memory.labels(gpu=gpu_idx, name=gpu_name).set(val)\n                idx += 1\n                \n                # Memory\n                val = parse_value(values[idx])\n                if val is not None:\n                    memory_total.labels(gpu=gpu_idx, name=gpu_name).set(val)\n                idx += 1\n                \n                val = parse_value(values[idx])\n                if val is not None:\n                    memory_used.labels(gpu=gpu_idx, name=gpu_name).set(val)\n                idx += 1\n                \n                val = parse_value(values[idx])\n                if val is not None:\n                    memory_free.labels(gpu=gpu_idx, name=gpu_name).set(val)\n                idx += 1\n                \n                # Utilization\n                val = parse_value(values[idx])\n                if val is not None:\n                    util_gpu.labels(gpu=gpu_idx, name=gpu_name).set(val)\n                idx += 1\n                \n                val = parse_value(values[idx])\n                if val is not None:\n                    util_memory.labels(gpu=gpu_idx, name=gpu_name).set(val)\n                idx += 1\n                \n                val = parse_value(values[idx])\n                if val is not None:\n                    util_encoder.labels(gpu=gpu_idx, name=gpu_name).set(val)\n                idx += 1\n                \n                val = parse_value(values[idx])\n                if val is not None:\n                    util_decoder.labels(gpu=gpu_idx, name=gpu_name).set(val)\n                idx += 1\n                \n                # Performance state\n                val = parse_value(values[idx])\n                if val is not None:\n                    pstate.labels(gpu=gpu_idx, name=gpu_name).set(val)\n                idx += 1\n                \n                # Fan speed\n                val = parse_value(values[idx])\n                if val is not None:\n                    fan_speed.labels(gpu=gpu_idx, name=gpu_name).set(val)\n                idx += 1\n                \n                # Skip idle throttle reason\n                idx += 1\n                \n                # Thermal throttle\n                val = parse_value(values[idx])\n                if val is not None:\n                    throttle_thermal.labels(gpu=gpu_idx, name=gpu_name).set(val)\n                idx += 1\n                \n                # Power throttle\n                val = parse_value(values[idx])\n                if val is not None:\n                    throttle_power.labels(gpu=gpu_idx, name=gpu_name).set(val)\n                idx += 1\n                \n            except Exception as e:\n                logger.error(f\"Error parsing GPU {gpu_idx} metrics: {e}\")\n                scrape_errors.inc()\n                \n    except Exception as e:\n        logger.error(f\"Error updating metrics: {e}\")\n        scrape_success.set(0)\n        scrape_errors.inc()\n\ndef main():\n    \"\"\"Main exporter loop\"\"\"\n    # Start Prometheus metrics server\n    start_http_server(9410)\n    logger.info(\"NVIDIA RTX Exporter started on port 9410\")\n    \n    # Initial test\n    logger.info(\"Testing nvidia-smi access...\")\n    test_result = subprocess.run(['/usr/bin/nvidia-smi', '--list-gpus'], capture_output=True, text=True)\n    if test_result.returncode == 0:\n        logger.info(f\"GPUs found: {test_result.stdout}\")\n    else:\n        logger.error(f\"Failed to list GPUs: {test_result.stderr}\")\n    \n    # Main loop\n    while True:\n        try:\n            update_metrics()\n        except Exception as e:\n            logger.error(f\"Error in main loop: {e}\")\n        \n        time.sleep(5)  # Update every 5 seconds\n\nif __name__ == \"__main__\":\n    main()\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"nvidia-rtx-exporter-script","namespace":"monitoring"}}
    creationTimestamp: "2025-06-03T16:46:43Z"
    name: nvidia-rtx-exporter-script
    namespace: monitoring
    resourceVersion: "2449980"
    uid: a25589a9-cd17-4885-975d-fb4b3614c0e4
- apiVersion: v1
  data:
    odin-gpu-monitoring.json: |
      {
        "annotations": {
          "list": [
            {
              "builtIn": 1,
              "datasource": {
                "type": "grafana",
                "uid": "-- Grafana --"
              },
              "enable": true,
              "hide": true,
              "iconColor": "rgba(0, 211, 255, 1)",
              "name": "Annotations & Alerts",
              "type": "dashboard"
            }
          ]
        },
        "editable": true,
        "fiscalYearStartMonth": 0,
        "graphTooltip": 0,
        "id": null,
        "links": [],
        "liveNow": false,
        "panels": [
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisCenteredZero": false,
                  "axisColorMode": "text",
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 10,
                  "gradientMode": "none",
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  },
                  "insertNulls": false,
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "never",
                  "spanNulls": false,
                  "stacking": {
                    "group": "A",
                    "mode": "none"
                  },
                  "thresholdsStyle": {
                    "mode": "off"
                  }
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "red",
                      "value": 80
                    }
                  ]
                },
                "unit": "celsius"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 0,
              "y": 0
            },
            "id": 1,
            "options": {
              "legend": {
                "calcs": ["lastNotNull", "max"],
                "displayMode": "table",
                "placement": "right",
                "showLegend": true
              },
              "tooltip": {
                "mode": "single",
                "sort": "none"
              }
            },
            "pluginVersion": "10.2.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "power_gpu_temperature_celsius",
                "legendFormat": "GPU {{gpu_index}} Temperature",
                "range": true,
                "refId": "A"
              }
            ],
            "title": "GPU Temperature",
            "type": "timeseries"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisCenteredZero": false,
                  "axisColorMode": "text",
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 10,
                  "gradientMode": "none",
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  },
                  "insertNulls": false,
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "never",
                  "spanNulls": false,
                  "stacking": {
                    "group": "A",
                    "mode": "none"
                  },
                  "thresholdsStyle": {
                    "mode": "off"
                  }
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "red",
                      "value": 80
                    }
                  ]
                },
                "unit": "watt"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 12,
              "y": 0
            },
            "id": 2,
            "options": {
              "legend": {
                "calcs": ["lastNotNull", "mean"],
                "displayMode": "table",
                "placement": "right",
                "showLegend": true
              },
              "tooltip": {
                "mode": "single",
                "sort": "none"
              }
            },
            "pluginVersion": "10.2.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "power_gpu_power_watts",
                "legendFormat": "GPU {{gpu_index}} Power",
                "range": true,
                "refId": "A"
              }
            ],
            "title": "GPU Power Consumption",
            "type": "timeseries"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "max": 100,
                "min": 0,
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "yellow",
                      "value": 70
                    },
                    {
                      "color": "red",
                      "value": 90
                    }
                  ]
                },
                "unit": "percent"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 8,
              "x": 0,
              "y": 8
            },
            "id": 3,
            "options": {
              "orientation": "auto",
              "reduceOptions": {
                "values": false,
                "calcs": ["lastNotNull"],
                "fields": ""
              },
              "showThresholdLabels": false,
              "showThresholdMarkers": true
            },
            "pluginVersion": "10.2.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "power_gpu_utilization_percent",
                "legendFormat": "GPU {{gpu_index}}",
                "range": true,
                "refId": "A"
              }
            ],
            "title": "GPU Utilization",
            "type": "gauge"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "max": 12,
                "min": 0,
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "yellow",
                      "value": 8
                    },
                    {
                      "color": "red",
                      "value": 10
                    }
                  ]
                },
                "unit": "gbytes"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 8,
              "x": 8,
              "y": 8
            },
            "id": 4,
            "options": {
              "orientation": "auto",
              "reduceOptions": {
                "values": false,
                "calcs": ["lastNotNull"],
                "fields": ""
              },
              "showThresholdLabels": false,
              "showThresholdMarkers": true
            },
            "pluginVersion": "10.2.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "power_gpu_memory_used_gb",
                "legendFormat": "GPU {{gpu_index}}",
                "range": true,
                "refId": "A"
              }
            ],
            "title": "GPU Memory Used",
            "type": "gauge"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "max": 1,
                "min": 0,
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "red",
                      "value": null
                    },
                    {
                      "color": "green",
                      "value": 1
                    }
                  ]
                },
                "unit": "short"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 8,
              "x": 16,
              "y": 8
            },
            "id": 5,
            "options": {
              "colorMode": "value",
              "graphMode": "area",
              "justifyMode": "auto",
              "orientation": "auto",
              "reduceOptions": {
                "values": false,
                "calcs": ["lastNotNull"],
                "fields": ""
              },
              "textMode": "auto"
            },
            "pluginVersion": "10.2.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "sum(odin_model_loaded)",
                "legendFormat": "Models Loaded",
                "range": true,
                "refId": "A"
              }
            ],
            "title": "Models Loaded",
            "type": "stat"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisCenteredZero": false,
                  "axisColorMode": "text",
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 10,
                  "gradientMode": "none",
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  },
                  "insertNulls": false,
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "never",
                  "spanNulls": false,
                  "stacking": {
                    "group": "A",
                    "mode": "none"
                  },
                  "thresholdsStyle": {
                    "mode": "off"
                  }
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "red",
                      "value": 80
                    }
                  ]
                },
                "unit": "short"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 0,
              "y": 16
            },
            "id": 6,
            "options": {
              "legend": {
                "calcs": ["lastNotNull", "mean"],
                "displayMode": "table",
                "placement": "bottom",
                "showLegend": true
              },
              "tooltip": {
                "mode": "single",
                "sort": "none"
              }
            },
            "pluginVersion": "10.2.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "rate(odin_inference_requests_total[5m])",
                "legendFormat": "{{model}} requests/sec",
                "range": true,
                "refId": "A"
              }
            ],
            "title": "Inference Request Rate",
            "type": "timeseries"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisCenteredZero": false,
                  "axisColorMode": "text",
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 10,
                  "gradientMode": "none",
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  },
                  "insertNulls": false,
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "never",
                  "spanNulls": false,
                  "stacking": {
                    "group": "A",
                    "mode": "none"
                  },
                  "thresholdsStyle": {
                    "mode": "off"
                  }
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "red",
                      "value": 80
                    }
                  ]
                },
                "unit": "ms"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 12,
              "y": 16
            },
            "id": 7,
            "options": {
              "legend": {
                "calcs": ["lastNotNull", "mean", "max"],
                "displayMode": "table",
                "placement": "bottom",
                "showLegend": true
              },
              "tooltip": {
                "mode": "single",
                "sort": "none"
              }
            },
            "pluginVersion": "10.2.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "histogram_quantile(0.95, sum(rate(odin_inference_latency_seconds_bucket[5m])) by (le, model)) * 1000",
                "legendFormat": "{{model}} p95",
                "range": true,
                "refId": "A"
              },
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "histogram_quantile(0.99, sum(rate(odin_inference_latency_seconds_bucket[5m])) by (le, model)) * 1000",
                "legendFormat": "{{model}} p99",
                "range": true,
                "refId": "B"
              }
            ],
            "title": "Inference Latency (ms)",
            "type": "timeseries"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisCenteredZero": false,
                  "axisColorMode": "text",
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 10,
                  "gradientMode": "none",
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  },
                  "insertNulls": false,
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "never",
                  "spanNulls": false,
                  "stacking": {
                    "group": "A",
                    "mode": "none"
                  },
                  "thresholdsStyle": {
                    "mode": "off"
                  }
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "red",
                      "value": 80
                    }
                  ]
                },
                "unit": "gbytes"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 0,
              "y": 24
            },
            "id": 8,
            "options": {
              "legend": {
                "calcs": ["lastNotNull"],
                "displayMode": "list",
                "placement": "bottom",
                "showLegend": true
              },
              "tooltip": {
                "mode": "single",
                "sort": "none"
              }
            },
            "pluginVersion": "10.2.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "odin_gpu_memory_gb",
                "legendFormat": "GPU Memory Used",
                "range": true,
                "refId": "A"
              }
            ],
            "title": "Model GPU Memory Usage",
            "type": "timeseries"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "red",
                      "value": 1
                    }
                  ]
                },
                "unit": "short"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 12,
              "y": 24
            },
            "id": 9,
            "options": {
              "colorMode": "value",
              "graphMode": "area",
              "justifyMode": "auto",
              "orientation": "auto",
              "reduceOptions": {
                "values": false,
                "calcs": ["lastNotNull"],
                "fields": ""
              },
              "textMode": "auto"
            },
            "pluginVersion": "10.2.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "sum(rate(odin_inference_errors_total[5m]))",
                "legendFormat": "Errors/sec",
                "range": true,
                "refId": "A"
              }
            ],
            "title": "Inference Error Rate",
            "type": "stat"
          }
        ],
        "refresh": "5s",
        "schemaVersion": 38,
        "style": "dark",
        "tags": ["odin", "gpu", "ml"],
        "templating": {
          "list": []
        },
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "timepicker": {},
        "timezone": "",
        "title": "ODIN GPU Monitoring",
        "uid": "odin-gpu-monitoring",
        "version": 1,
        "weekStart": ""
      }
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"odin-gpu-monitoring.json":"{\n  \"annotations\": {\n    \"list\": [\n      {\n        \"builtIn\": 1,\n        \"datasource\": {\n          \"type\": \"grafana\",\n          \"uid\": \"-- Grafana --\"\n        },\n        \"enable\": true,\n        \"hide\": true,\n        \"iconColor\": \"rgba(0, 211, 255, 1)\",\n        \"name\": \"Annotations \u0026 Alerts\",\n        \"type\": \"dashboard\"\n      }\n    ]\n  },\n  \"editable\": true,\n  \"fiscalYearStartMonth\": 0,\n  \"graphTooltip\": 0,\n  \"id\": null,\n  \"links\": [],\n  \"liveNow\": false,\n  \"panels\": [\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisCenteredZero\": false,\n            \"axisColorMode\": \"text\",\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 10,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            },\n            \"insertNulls\": false,\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"never\",\n            \"spanNulls\": false,\n            \"stacking\": {\n              \"group\": \"A\",\n              \"mode\": \"none\"\n            },\n            \"thresholdsStyle\": {\n              \"mode\": \"off\"\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 80\n              }\n            ]\n          },\n          \"unit\": \"celsius\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 0,\n        \"y\": 0\n      },\n      \"id\": 1,\n      \"options\": {\n        \"legend\": {\n          \"calcs\": [\"lastNotNull\", \"max\"],\n          \"displayMode\": \"table\",\n          \"placement\": \"right\",\n          \"showLegend\": true\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        }\n      },\n      \"pluginVersion\": \"10.2.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"power_gpu_temperature_celsius\",\n          \"legendFormat\": \"GPU {{gpu_index}} Temperature\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"GPU Temperature\",\n      \"type\": \"timeseries\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisCenteredZero\": false,\n            \"axisColorMode\": \"text\",\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 10,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            },\n            \"insertNulls\": false,\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"never\",\n            \"spanNulls\": false,\n            \"stacking\": {\n              \"group\": \"A\",\n              \"mode\": \"none\"\n            },\n            \"thresholdsStyle\": {\n              \"mode\": \"off\"\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 80\n              }\n            ]\n          },\n          \"unit\": \"watt\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 0\n      },\n      \"id\": 2,\n      \"options\": {\n        \"legend\": {\n          \"calcs\": [\"lastNotNull\", \"mean\"],\n          \"displayMode\": \"table\",\n          \"placement\": \"right\",\n          \"showLegend\": true\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        }\n      },\n      \"pluginVersion\": \"10.2.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"power_gpu_power_watts\",\n          \"legendFormat\": \"GPU {{gpu_index}} Power\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"GPU Power Consumption\",\n      \"type\": \"timeseries\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"max\": 100,\n          \"min\": 0,\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"yellow\",\n                \"value\": 70\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 90\n              }\n            ]\n          },\n          \"unit\": \"percent\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 8,\n        \"x\": 0,\n        \"y\": 8\n      },\n      \"id\": 3,\n      \"options\": {\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"],\n          \"fields\": \"\"\n        },\n        \"showThresholdLabels\": false,\n        \"showThresholdMarkers\": true\n      },\n      \"pluginVersion\": \"10.2.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"power_gpu_utilization_percent\",\n          \"legendFormat\": \"GPU {{gpu_index}}\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"GPU Utilization\",\n      \"type\": \"gauge\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"max\": 12,\n          \"min\": 0,\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"yellow\",\n                \"value\": 8\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 10\n              }\n            ]\n          },\n          \"unit\": \"gbytes\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 8,\n        \"x\": 8,\n        \"y\": 8\n      },\n      \"id\": 4,\n      \"options\": {\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"],\n          \"fields\": \"\"\n        },\n        \"showThresholdLabels\": false,\n        \"showThresholdMarkers\": true\n      },\n      \"pluginVersion\": \"10.2.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"power_gpu_memory_used_gb\",\n          \"legendFormat\": \"GPU {{gpu_index}}\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"GPU Memory Used\",\n      \"type\": \"gauge\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"max\": 1,\n          \"min\": 0,\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"red\",\n                \"value\": null\n              },\n              {\n                \"color\": \"green\",\n                \"value\": 1\n              }\n            ]\n          },\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 8,\n        \"x\": 16,\n        \"y\": 8\n      },\n      \"id\": 5,\n      \"options\": {\n        \"colorMode\": \"value\",\n        \"graphMode\": \"area\",\n        \"justifyMode\": \"auto\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"],\n          \"fields\": \"\"\n        },\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"10.2.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"sum(odin_model_loaded)\",\n          \"legendFormat\": \"Models Loaded\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Models Loaded\",\n      \"type\": \"stat\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisCenteredZero\": false,\n            \"axisColorMode\": \"text\",\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 10,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            },\n            \"insertNulls\": false,\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"never\",\n            \"spanNulls\": false,\n            \"stacking\": {\n              \"group\": \"A\",\n              \"mode\": \"none\"\n            },\n            \"thresholdsStyle\": {\n              \"mode\": \"off\"\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 80\n              }\n            ]\n          },\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 0,\n        \"y\": 16\n      },\n      \"id\": 6,\n      \"options\": {\n        \"legend\": {\n          \"calcs\": [\"lastNotNull\", \"mean\"],\n          \"displayMode\": \"table\",\n          \"placement\": \"bottom\",\n          \"showLegend\": true\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        }\n      },\n      \"pluginVersion\": \"10.2.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"rate(odin_inference_requests_total[5m])\",\n          \"legendFormat\": \"{{model}} requests/sec\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Inference Request Rate\",\n      \"type\": \"timeseries\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisCenteredZero\": false,\n            \"axisColorMode\": \"text\",\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 10,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            },\n            \"insertNulls\": false,\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"never\",\n            \"spanNulls\": false,\n            \"stacking\": {\n              \"group\": \"A\",\n              \"mode\": \"none\"\n            },\n            \"thresholdsStyle\": {\n              \"mode\": \"off\"\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 80\n              }\n            ]\n          },\n          \"unit\": \"ms\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 16\n      },\n      \"id\": 7,\n      \"options\": {\n        \"legend\": {\n          \"calcs\": [\"lastNotNull\", \"mean\", \"max\"],\n          \"displayMode\": \"table\",\n          \"placement\": \"bottom\",\n          \"showLegend\": true\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        }\n      },\n      \"pluginVersion\": \"10.2.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"histogram_quantile(0.95, sum(rate(odin_inference_latency_seconds_bucket[5m])) by (le, model)) * 1000\",\n          \"legendFormat\": \"{{model}} p95\",\n          \"range\": true,\n          \"refId\": \"A\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"histogram_quantile(0.99, sum(rate(odin_inference_latency_seconds_bucket[5m])) by (le, model)) * 1000\",\n          \"legendFormat\": \"{{model}} p99\",\n          \"range\": true,\n          \"refId\": \"B\"\n        }\n      ],\n      \"title\": \"Inference Latency (ms)\",\n      \"type\": \"timeseries\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisCenteredZero\": false,\n            \"axisColorMode\": \"text\",\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 10,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            },\n            \"insertNulls\": false,\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"never\",\n            \"spanNulls\": false,\n            \"stacking\": {\n              \"group\": \"A\",\n              \"mode\": \"none\"\n            },\n            \"thresholdsStyle\": {\n              \"mode\": \"off\"\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 80\n              }\n            ]\n          },\n          \"unit\": \"gbytes\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 0,\n        \"y\": 24\n      },\n      \"id\": 8,\n      \"options\": {\n        \"legend\": {\n          \"calcs\": [\"lastNotNull\"],\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\",\n          \"showLegend\": true\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        }\n      },\n      \"pluginVersion\": \"10.2.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"odin_gpu_memory_gb\",\n          \"legendFormat\": \"GPU Memory Used\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Model GPU Memory Usage\",\n      \"type\": \"timeseries\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 1\n              }\n            ]\n          },\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 24\n      },\n      \"id\": 9,\n      \"options\": {\n        \"colorMode\": \"value\",\n        \"graphMode\": \"area\",\n        \"justifyMode\": \"auto\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"],\n          \"fields\": \"\"\n        },\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"10.2.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"sum(rate(odin_inference_errors_total[5m]))\",\n          \"legendFormat\": \"Errors/sec\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Inference Error Rate\",\n      \"type\": \"stat\"\n    }\n  ],\n  \"refresh\": \"5s\",\n  \"schemaVersion\": 38,\n  \"style\": \"dark\",\n  \"tags\": [\"odin\", \"gpu\", \"ml\"],\n  \"templating\": {\n    \"list\": []\n  },\n  \"time\": {\n    \"from\": \"now-1h\",\n    \"to\": \"now\"\n  },\n  \"timepicker\": {},\n  \"timezone\": \"\",\n  \"title\": \"ODIN GPU Monitoring\",\n  \"uid\": \"odin-gpu-monitoring\",\n  \"version\": 1,\n  \"weekStart\": \"\"\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"grafana_dashboard":"1"},"name":"odin-gpu-monitoring-dashboard","namespace":"monitoring"}}
    creationTimestamp: "2025-06-04T20:53:25Z"
    labels:
      grafana_dashboard: "1"
    name: odin-gpu-monitoring-dashboard
    namespace: monitoring
    resourceVersion: "3185393"
    uid: 4520a221-76eb-4cd6-9376-f175f15cbdae
- apiVersion: v1
  data:
    odin-llm-monitoring.json: |
      {
        "dashboard": {
          "id": null,
          "title": "ODIN Prime - LLM Monitoring",
          "tags": ["odin", "llm", "monitoring"],
          "style": "dark",
          "timezone": "browser",
          "panels": [
            {
              "id": 1,
              "title": "Alert Processing Overview",
              "type": "stat",
              "targets": [
                {
                  "expr": "increase(odin_alerts_received_total[1h])",
                  "legendFormat": "Alerts Received/hr"
                },
                {
                  "expr": "increase(odin_alerts_processed_total[1h])",
                  "legendFormat": "Processed/hr"
                },
                {
                  "expr": "increase(odin_alerts_escalated_total[1h])",
                  "legendFormat": "Escalated/hr"
                }
              ],
              "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0},
              "fieldConfig": {
                "defaults": {
                  "color": {"mode": "thresholds"},
                  "thresholds": {
                    "steps": [
                      {"color": "green", "value": null},
                      {"color": "yellow", "value": 50},
                      {"color": "red", "value": 100}
                    ]
                  },
                  "unit": "short"
                }
              }
            },
            {
              "id": 2,
              "title": "Tier Service Response Times",
              "type": "graph",
              "targets": [
                {
                  "expr": "histogram_quantile(0.50, odin_tier_response_seconds_bucket)",
                  "legendFormat": "p50"
                },
                {
                  "expr": "histogram_quantile(0.95, odin_tier_response_seconds_bucket)",
                  "legendFormat": "p95"
                },
                {
                  "expr": "histogram_quantile(0.99, odin_tier_response_seconds_bucket)",
                  "legendFormat": "p99"
                }
              ],
              "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0},
              "yAxes": [
                {
                  "label": "Response Time (s)",
                  "logBase": 1,
                  "max": null,
                  "min": 0
                }
              ]
            },
            {
              "id": 3,
              "title": "LLM Model Memory Usage",
              "type": "graph",
              "targets": [
                {
                  "expr": "odin_model_memory_gb",
                  "legendFormat": "Tier-1 GPU Memory"
                },
                {
                  "expr": "odin_code_model_memory_gb",
                  "legendFormat": "Tier-2 GPU Memory"
                },
                {
                  "expr": "odin_gpu_memory_gb",
                  "legendFormat": "Total GPU Memory"
                }
              ],
              "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8},
              "yAxes": [
                {
                  "label": "Memory (GB)",
                  "max": 12,
                  "min": 0
                }
              ],
              "alert": {
                "conditions": [
                  {
                    "evaluator": {"params": [10], "type": "gt"},
                    "operator": {"type": "and"},
                    "query": {"params": ["A", "5m", "now"]},
                    "reducer": {"params": [], "type": "last"},
                    "type": "query"
                  }
                ],
                "executionErrorState": "alerting",
                "for": "1m",
                "frequency": "10s",
                "handler": 1,
                "name": "GPU Memory Usage Alert",
                "noDataState": "no_data",
                "notifications": []
              }
            },
            {
              "id": 4,
              "title": "Pattern Matching Performance",
              "type": "stat",
              "targets": [
                {
                  "expr": "rate(odin_pattern_matches_total[5m])",
                  "legendFormat": "Matches/sec"
                },
                {
                  "expr": "rate(odin_pattern_matches_total[5m]) / rate(odin_alerts_received_total[5m]) * 100",
                  "legendFormat": "Match Rate %"
                }
              ],
              "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8},
              "fieldConfig": {
                "defaults": {
                  "color": {"mode": "thresholds"},
                  "thresholds": {
                    "steps": [
                      {"color": "red", "value": null},
                      {"color": "yellow", "value": 20},
                      {"color": "green", "value": 50}
                    ]
                  },
                  "unit": "percent"
                }
              }
            },
            {
              "id": 5,
              "title": "Tier Service Health",
              "type": "stat",
              "targets": [
                {
                  "expr": "up{job=\"tier1-triage\"}",
                  "legendFormat": "Tier-1 Triage"
                },
                {
                  "expr": "up{job=\"tier2-code\"}",
                  "legendFormat": "Tier-2 Code"
                },
                {
                  "expr": "up{job=\"tier3-general\"}",
                  "legendFormat": "Tier-3 General"
                }
              ],
              "gridPos": {"h": 6, "w": 8, "x": 0, "y": 16},
              "fieldConfig": {
                "defaults": {
                  "color": {"mode": "thresholds"},
                  "thresholds": {
                    "steps": [
                      {"color": "red", "value": 0},
                      {"color": "green", "value": 1}
                    ]
                  },
                  "mappings": [
                    {"options": {"0": {"text": "Down"}}, "type": "value"},
                    {"options": {"1": {"text": "Up"}}, "type": "value"}
                  ]
                }
              }
            },
            {
              "id": 6,
              "title": "Alert Processing Rate",
              "type": "graph",
              "targets": [
                {
                  "expr": "rate(odin_alerts_received_total[1m])",
                  "legendFormat": "Received/sec"
                },
                {
                  "expr": "rate(odin_alerts_processed_total[1m])",
                  "legendFormat": "Processed/sec"
                }
              ],
              "gridPos": {"h": 6, "w": 8, "x": 8, "y": 16},
              "yAxes": [
                {
                  "label": "Alerts/sec",
                  "min": 0
                }
              ]
            },
            {
              "id": 7,
              "title": "Escalation Rate",
              "type": "singlestat",
              "targets": [
                {
                  "expr": "rate(odin_alerts_escalated_total[5m]) / rate(odin_alerts_processed_total[5m]) * 100",
                  "legendFormat": "Escalation %"
                }
              ],
              "gridPos": {"h": 6, "w": 8, "x": 16, "y": 16},
              "valueName": "current",
              "format": "percent",
              "thresholds": "10,25",
              "colorBackground": true,
              "colors": ["rgba(50, 172, 45, 0.97)", "rgba(237, 129, 40, 0.89)", "rgba(245, 54, 54, 0.9)"]
            },
            {
              "id": 8,
              "title": "Inference Request Volume by Tier",
              "type": "graph",
              "targets": [
                {
                  "expr": "rate(odin_triage_requests_total[1m])",
                  "legendFormat": "Tier-1 Triage"
                },
                {
                  "expr": "rate(odin_code_analysis_requests_total[1m])",
                  "legendFormat": "Tier-2 Code"
                },
                {
                  "expr": "rate(odin_general_analysis_requests_total[1m])",
                  "legendFormat": "Tier-3 General"
                }
              ],
              "gridPos": {"h": 8, "w": 24, "x": 0, "y": 22},
              "yAxes": [
                {
                  "label": "Requests/sec",
                  "min": 0
                }
              ]
            },
            {
              "id": 9,
              "title": "Error Rates by Tier",
              "type": "graph",
              "targets": [
                {
                  "expr": "rate(odin_triage_errors_total[1m])",
                  "legendFormat": "Tier-1 Errors"
                },
                {
                  "expr": "rate(odin_code_analysis_errors_total[1m])",
                  "legendFormat": "Tier-2 Errors"
                },
                {
                  "expr": "rate(odin_general_analysis_errors_total[1m])",
                  "legendFormat": "Tier-3 Errors"
                }
              ],
              "gridPos": {"h": 8, "w": 12, "x": 0, "y": 30},
              "yAxes": [
                {
                  "label": "Errors/sec",
                  "min": 0
                }
              ]
            },
            {
              "id": 10,
              "title": "Model Loading Status",
              "type": "table",
              "targets": [
                {
                  "expr": "odin_active_models",
                  "legendFormat": "Active Models",
                  "format": "table"
                }
              ],
              "gridPos": {"h": 8, "w": 12, "x": 12, "y": 30},
              "styles": [
                {
                  "alias": "Time",
                  "type": "hidden"
                },
                {
                  "alias": "Model Count",
                  "pattern": "Value",
                  "type": "number"
                }
              ]
            }
          ],
          "time": {"from": "now-1h", "to": "now"},
          "timepicker": {},
          "templating": {"list": []},
          "annotations": {"list": []},
          "refresh": "30s",
          "schemaVersion": 16,
          "version": 0,
          "links": [],
          "gnetId": null
        }
      }
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"odin-llm-monitoring.json":"{\n  \"dashboard\": {\n    \"id\": null,\n    \"title\": \"ODIN Prime - LLM Monitoring\",\n    \"tags\": [\"odin\", \"llm\", \"monitoring\"],\n    \"style\": \"dark\",\n    \"timezone\": \"browser\",\n    \"panels\": [\n      {\n        \"id\": 1,\n        \"title\": \"Alert Processing Overview\",\n        \"type\": \"stat\",\n        \"targets\": [\n          {\n            \"expr\": \"increase(odin_alerts_received_total[1h])\",\n            \"legendFormat\": \"Alerts Received/hr\"\n          },\n          {\n            \"expr\": \"increase(odin_alerts_processed_total[1h])\",\n            \"legendFormat\": \"Processed/hr\"\n          },\n          {\n            \"expr\": \"increase(odin_alerts_escalated_total[1h])\",\n            \"legendFormat\": \"Escalated/hr\"\n          }\n        ],\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 0},\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"color\": {\"mode\": \"thresholds\"},\n            \"thresholds\": {\n              \"steps\": [\n                {\"color\": \"green\", \"value\": null},\n                {\"color\": \"yellow\", \"value\": 50},\n                {\"color\": \"red\", \"value\": 100}\n              ]\n            },\n            \"unit\": \"short\"\n          }\n        }\n      },\n      {\n        \"id\": 2,\n        \"title\": \"Tier Service Response Times\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"histogram_quantile(0.50, odin_tier_response_seconds_bucket)\",\n            \"legendFormat\": \"p50\"\n          },\n          {\n            \"expr\": \"histogram_quantile(0.95, odin_tier_response_seconds_bucket)\",\n            \"legendFormat\": \"p95\"\n          },\n          {\n            \"expr\": \"histogram_quantile(0.99, odin_tier_response_seconds_bucket)\",\n            \"legendFormat\": \"p99\"\n          }\n        ],\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 0},\n        \"yAxes\": [\n          {\n            \"label\": \"Response Time (s)\",\n            \"logBase\": 1,\n            \"max\": null,\n            \"min\": 0\n          }\n        ]\n      },\n      {\n        \"id\": 3,\n        \"title\": \"LLM Model Memory Usage\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"odin_model_memory_gb\",\n            \"legendFormat\": \"Tier-1 GPU Memory\"\n          },\n          {\n            \"expr\": \"odin_code_model_memory_gb\",\n            \"legendFormat\": \"Tier-2 GPU Memory\"\n          },\n          {\n            \"expr\": \"odin_gpu_memory_gb\",\n            \"legendFormat\": \"Total GPU Memory\"\n          }\n        ],\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 8},\n        \"yAxes\": [\n          {\n            \"label\": \"Memory (GB)\",\n            \"max\": 12,\n            \"min\": 0\n          }\n        ],\n        \"alert\": {\n          \"conditions\": [\n            {\n              \"evaluator\": {\"params\": [10], \"type\": \"gt\"},\n              \"operator\": {\"type\": \"and\"},\n              \"query\": {\"params\": [\"A\", \"5m\", \"now\"]},\n              \"reducer\": {\"params\": [], \"type\": \"last\"},\n              \"type\": \"query\"\n            }\n          ],\n          \"executionErrorState\": \"alerting\",\n          \"for\": \"1m\",\n          \"frequency\": \"10s\",\n          \"handler\": 1,\n          \"name\": \"GPU Memory Usage Alert\",\n          \"noDataState\": \"no_data\",\n          \"notifications\": []\n        }\n      },\n      {\n        \"id\": 4,\n        \"title\": \"Pattern Matching Performance\",\n        \"type\": \"stat\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(odin_pattern_matches_total[5m])\",\n            \"legendFormat\": \"Matches/sec\"\n          },\n          {\n            \"expr\": \"rate(odin_pattern_matches_total[5m]) / rate(odin_alerts_received_total[5m]) * 100\",\n            \"legendFormat\": \"Match Rate %\"\n          }\n        ],\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 8},\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"color\": {\"mode\": \"thresholds\"},\n            \"thresholds\": {\n              \"steps\": [\n                {\"color\": \"red\", \"value\": null},\n                {\"color\": \"yellow\", \"value\": 20},\n                {\"color\": \"green\", \"value\": 50}\n              ]\n            },\n            \"unit\": \"percent\"\n          }\n        }\n      },\n      {\n        \"id\": 5,\n        \"title\": \"Tier Service Health\",\n        \"type\": \"stat\",\n        \"targets\": [\n          {\n            \"expr\": \"up{job=\\\"tier1-triage\\\"}\",\n            \"legendFormat\": \"Tier-1 Triage\"\n          },\n          {\n            \"expr\": \"up{job=\\\"tier2-code\\\"}\",\n            \"legendFormat\": \"Tier-2 Code\"\n          },\n          {\n            \"expr\": \"up{job=\\\"tier3-general\\\"}\",\n            \"legendFormat\": \"Tier-3 General\"\n          }\n        ],\n        \"gridPos\": {\"h\": 6, \"w\": 8, \"x\": 0, \"y\": 16},\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"color\": {\"mode\": \"thresholds\"},\n            \"thresholds\": {\n              \"steps\": [\n                {\"color\": \"red\", \"value\": 0},\n                {\"color\": \"green\", \"value\": 1}\n              ]\n            },\n            \"mappings\": [\n              {\"options\": {\"0\": {\"text\": \"Down\"}}, \"type\": \"value\"},\n              {\"options\": {\"1\": {\"text\": \"Up\"}}, \"type\": \"value\"}\n            ]\n          }\n        }\n      },\n      {\n        \"id\": 6,\n        \"title\": \"Alert Processing Rate\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(odin_alerts_received_total[1m])\",\n            \"legendFormat\": \"Received/sec\"\n          },\n          {\n            \"expr\": \"rate(odin_alerts_processed_total[1m])\",\n            \"legendFormat\": \"Processed/sec\"\n          }\n        ],\n        \"gridPos\": {\"h\": 6, \"w\": 8, \"x\": 8, \"y\": 16},\n        \"yAxes\": [\n          {\n            \"label\": \"Alerts/sec\",\n            \"min\": 0\n          }\n        ]\n      },\n      {\n        \"id\": 7,\n        \"title\": \"Escalation Rate\",\n        \"type\": \"singlestat\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(odin_alerts_escalated_total[5m]) / rate(odin_alerts_processed_total[5m]) * 100\",\n            \"legendFormat\": \"Escalation %\"\n          }\n        ],\n        \"gridPos\": {\"h\": 6, \"w\": 8, \"x\": 16, \"y\": 16},\n        \"valueName\": \"current\",\n        \"format\": \"percent\",\n        \"thresholds\": \"10,25\",\n        \"colorBackground\": true,\n        \"colors\": [\"rgba(50, 172, 45, 0.97)\", \"rgba(237, 129, 40, 0.89)\", \"rgba(245, 54, 54, 0.9)\"]\n      },\n      {\n        \"id\": 8,\n        \"title\": \"Inference Request Volume by Tier\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(odin_triage_requests_total[1m])\",\n            \"legendFormat\": \"Tier-1 Triage\"\n          },\n          {\n            \"expr\": \"rate(odin_code_analysis_requests_total[1m])\",\n            \"legendFormat\": \"Tier-2 Code\"\n          },\n          {\n            \"expr\": \"rate(odin_general_analysis_requests_total[1m])\",\n            \"legendFormat\": \"Tier-3 General\"\n          }\n        ],\n        \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 22},\n        \"yAxes\": [\n          {\n            \"label\": \"Requests/sec\",\n            \"min\": 0\n          }\n        ]\n      },\n      {\n        \"id\": 9,\n        \"title\": \"Error Rates by Tier\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(odin_triage_errors_total[1m])\",\n            \"legendFormat\": \"Tier-1 Errors\"\n          },\n          {\n            \"expr\": \"rate(odin_code_analysis_errors_total[1m])\",\n            \"legendFormat\": \"Tier-2 Errors\"\n          },\n          {\n            \"expr\": \"rate(odin_general_analysis_errors_total[1m])\",\n            \"legendFormat\": \"Tier-3 Errors\"\n          }\n        ],\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 30},\n        \"yAxes\": [\n          {\n            \"label\": \"Errors/sec\",\n            \"min\": 0\n          }\n        ]\n      },\n      {\n        \"id\": 10,\n        \"title\": \"Model Loading Status\",\n        \"type\": \"table\",\n        \"targets\": [\n          {\n            \"expr\": \"odin_active_models\",\n            \"legendFormat\": \"Active Models\",\n            \"format\": \"table\"\n          }\n        ],\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 30},\n        \"styles\": [\n          {\n            \"alias\": \"Time\",\n            \"type\": \"hidden\"\n          },\n          {\n            \"alias\": \"Model Count\",\n            \"pattern\": \"Value\",\n            \"type\": \"number\"\n          }\n        ]\n      }\n    ],\n    \"time\": {\"from\": \"now-1h\", \"to\": \"now\"},\n    \"timepicker\": {},\n    \"templating\": {\"list\": []},\n    \"annotations\": {\"list\": []},\n    \"refresh\": \"30s\",\n    \"schemaVersion\": 16,\n    \"version\": 0,\n    \"links\": [],\n    \"gnetId\": null\n  }\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"grafana_dashboard":"1"},"name":"odin-llm-dashboard","namespace":"monitoring"}}
    creationTimestamp: "2025-06-04T22:06:26Z"
    labels:
      grafana_dashboard: "1"
    name: odin-llm-dashboard
    namespace: monitoring
    resourceVersion: "3217739"
    uid: 29662c8b-a6ed-4751-86b5-7d310cebb4a3
- apiVersion: v1
  data:
    ml-anomaly-detection.json: |
      {
        "dashboard": {
          "id": null,
          "uid": "ml-anomaly-detection",
          "title": "ML Anomaly Detection",
          "tags": ["odin", "anomaly", "ml", "ai"],
          "timezone": "browser",
          "schemaVersion": 38,
          "version": 1,
          "refresh": "30s",
          "panels": [
            {
              "datasource": "Prometheus",
              "gridPos": {"h": 4, "w": 24, "x": 0, "y": 0},
              "id": 1,
              "type": "text",
              "title": "",
              "options": {
                "mode": "markdown",
                "content": "# ML-Based Anomaly Detection\n\nThis dashboard shows anomaly scores using machine learning algorithms:\n- **0-40%**: Normal (Green)\n- **40-60%**: Slight Deviation (Yellow)\n- **60-80%**: Warning (Orange)\n- **80-100%**: Critical (Red)"
              }
            },
            {
              "datasource": "Prometheus",
              "fieldConfig": {
                "defaults": {
                  "color": {
                    "mode": "thresholds"
                  },
                  "thresholds": {
                    "mode": "absolute",
                    "steps": [
                      {"color": "green", "value": null},
                      {"color": "yellow", "value": 40},
                      {"color": "orange", "value": 60},
                      {"color": "red", "value": 80}
                    ]
                  },
                  "unit": "percent",
                  "min": 0,
                  "max": 100
                }
              },
              "gridPos": {"h": 8, "w": 12, "x": 0, "y": 4},
              "id": 2,
              "type": "timeseries",
              "title": "GPU Temperature Anomaly Score",
              "targets": [
                {
                  "expr": "anomaly_score{metric_name=\"nvidia_gpu_temperature_celsius\"}",
                  "legendFormat": "GPU Temp Anomaly",
                  "refId": "A"
                }
              ]
            },
            {
              "datasource": "Prometheus",
              "fieldConfig": {
                "defaults": {
                  "color": {
                    "mode": "thresholds"
                  },
                  "thresholds": {
                    "mode": "absolute",
                    "steps": [
                      {"color": "green", "value": null},
                      {"color": "yellow", "value": 40},
                      {"color": "orange", "value": 60},
                      {"color": "red", "value": 80}
                    ]
                  },
                  "unit": "percent",
                  "min": 0,
                  "max": 100
                }
              },
              "gridPos": {"h": 8, "w": 12, "x": 12, "y": 4},
              "id": 3,
              "type": "timeseries",
              "title": "GPU Power Anomaly Score",
              "targets": [
                {
                  "expr": "anomaly_score{metric_name=\"node_gpu_power_watts\"}",
                  "legendFormat": "GPU Power Anomaly",
                  "refId": "A"
                }
              ]
            },
            {
              "datasource": "Prometheus",
              "fieldConfig": {
                "defaults": {
                  "color": {
                    "mode": "thresholds"
                  },
                  "thresholds": {
                    "mode": "absolute",
                    "steps": [
                      {"color": "green", "value": null},
                      {"color": "yellow", "value": 40},
                      {"color": "orange", "value": 60},
                      {"color": "red", "value": 80}
                    ]
                  },
                  "unit": "percent",
                  "min": 0,
                  "max": 100
                }
              },
              "gridPos": {"h": 8, "w": 8, "x": 0, "y": 12},
              "id": 4,
              "type": "gauge",
              "title": "CPU Usage Anomaly",
              "targets": [
                {
                  "expr": "anomaly_score{metric_name=\"cpu_usage_percent\"}",
                  "instant": true,
                  "refId": "A"
                }
              ]
            },
            {
              "datasource": "Prometheus",
              "fieldConfig": {
                "defaults": {
                  "color": {
                    "mode": "thresholds"
                  },
                  "thresholds": {
                    "mode": "absolute",
                    "steps": [
                      {"color": "green", "value": null},
                      {"color": "yellow", "value": 40},
                      {"color": "orange", "value": 60},
                      {"color": "red", "value": 80}
                    ]
                  },
                  "unit": "percent",
                  "min": 0,
                  "max": 100
                }
              },
              "gridPos": {"h": 8, "w": 8, "x": 8, "y": 12},
              "id": 5,
              "type": "gauge",
              "title": "Memory Anomaly",
              "targets": [
                {
                  "expr": "anomaly_score{metric_name=\"node_memory_MemAvailable_bytes\"}",
                  "instant": true,
                  "refId": "A"
                }
              ]
            },
            {
              "datasource": "Prometheus",
              "fieldConfig": {
                "defaults": {
                  "color": {
                    "mode": "thresholds"
                  },
                  "thresholds": {
                    "mode": "absolute",
                    "steps": [
                      {"color": "green", "value": null},
                      {"color": "yellow", "value": 40},
                      {"color": "orange", "value": 60},
                      {"color": "red", "value": 80}
                    ]
                  },
                  "unit": "percent",
                  "min": 0,
                  "max": 100
                }
              },
              "gridPos": {"h": 8, "w": 8, "x": 16, "y": 12},
              "id": 6,
              "type": "gauge",
              "title": "Network Anomaly",
              "targets": [
                {
                  "expr": "anomaly_score{metric_name=\"network_receive_rate\"}",
                  "instant": true,
                  "refId": "A"
                }
              ]
            },
            {
              "datasource": "Prometheus",
              "fieldConfig": {
                "defaults": {
                  "custom": {
                    "align": "center",
                    "displayMode": "color-background"
                  },
                  "thresholds": {
                    "mode": "absolute",
                    "steps": [
                      {"color": "green", "value": null},
                      {"color": "yellow", "value": 40},
                      {"color": "orange", "value": 60},
                      {"color": "red", "value": 80}
                    ]
                  },
                  "unit": "percent"
                },
                "overrides": [
                  {
                    "matcher": {"id": "byName", "options": "Anomaly Score"},
                    "properties": [
                      {"id": "custom.displayMode", "value": "gradient-gauge"},
                      {"id": "custom.width", "value": 200}
                    ]
                  }
                ]
              },
              "gridPos": {"h": 8, "w": 24, "x": 0, "y": 20},
              "id": 7,
              "type": "table",
              "title": "All Anomaly Scores",
              "targets": [
                {
                  "expr": "anomaly_score",
                  "format": "table",
                  "instant": true,
                  "refId": "A"
                }
              ],
              "transformations": [
                {
                  "id": "organize",
                  "options": {
                    "excludeByName": {
                      "Time": true,
                      "__name__": true,
                      "job": true,
                      "instance": true
                    },
                    "renameByName": {
                      "metric_name": "Metric",
                      "algorithm": "Algorithm",
                      "Value": "Anomaly Score"
                    }
                  }
                }
              ]
            },
            {
              "datasource": "Prometheus",
              "gridPos": {"h": 6, "w": 12, "x": 0, "y": 28},
              "id": 8,
              "type": "stat",
              "title": "Anomaly Detector Health",
              "targets": [
                {
                  "expr": "anomaly_detector_health",
                  "refId": "A"
                }
              ],
              "fieldConfig": {
                "defaults": {
                  "thresholds": {
                    "steps": [
                      {"color": "red", "value": null},
                      {"color": "green", "value": 1}
                    ]
                  },
                  "mappings": [
                    {"options": {"0": {"text": "Unhealthy"}}, "type": "value"},
                    {"options": {"1": {"text": "Healthy"}}, "type": "value"}
                  ]
                }
              }
            },
            {
              "datasource": "Prometheus",
              "gridPos": {"h": 6, "w": 12, "x": 12, "y": 28},
              "id": 9,
              "type": "stat",
              "title": "Models Trained",
              "targets": [
                {
                  "expr": "count(count by (metric_name) (anomaly_model_updates_total))",
                  "refId": "A"
                }
              ],
              "fieldConfig": {
                "defaults": {
                  "unit": "short",
                  "decimals": 0
                }
              }
            }
          ]
        }
      }
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"ml-anomaly-detection.json":"{\n  \"dashboard\": {\n    \"id\": null,\n    \"uid\": \"ml-anomaly-detection\",\n    \"title\": \"ML Anomaly Detection\",\n    \"tags\": [\"odin\", \"anomaly\", \"ml\", \"ai\"],\n    \"timezone\": \"browser\",\n    \"schemaVersion\": 38,\n    \"version\": 1,\n    \"refresh\": \"30s\",\n    \"panels\": [\n      {\n        \"datasource\": \"Prometheus\",\n        \"gridPos\": {\"h\": 4, \"w\": 24, \"x\": 0, \"y\": 0},\n        \"id\": 1,\n        \"type\": \"text\",\n        \"title\": \"\",\n        \"options\": {\n          \"mode\": \"markdown\",\n          \"content\": \"# ML-Based Anomaly Detection\\n\\nThis dashboard shows anomaly scores using machine learning algorithms:\\n- **0-40%**: Normal (Green)\\n- **40-60%**: Slight Deviation (Yellow)\\n- **60-80%**: Warning (Orange)\\n- **80-100%**: Critical (Red)\"\n        }\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"color\": {\n              \"mode\": \"thresholds\"\n            },\n            \"thresholds\": {\n              \"mode\": \"absolute\",\n              \"steps\": [\n                {\"color\": \"green\", \"value\": null},\n                {\"color\": \"yellow\", \"value\": 40},\n                {\"color\": \"orange\", \"value\": 60},\n                {\"color\": \"red\", \"value\": 80}\n              ]\n            },\n            \"unit\": \"percent\",\n            \"min\": 0,\n            \"max\": 100\n          }\n        },\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 4},\n        \"id\": 2,\n        \"type\": \"timeseries\",\n        \"title\": \"GPU Temperature Anomaly Score\",\n        \"targets\": [\n          {\n            \"expr\": \"anomaly_score{metric_name=\\\"nvidia_gpu_temperature_celsius\\\"}\",\n            \"legendFormat\": \"GPU Temp Anomaly\",\n            \"refId\": \"A\"\n          }\n        ]\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"color\": {\n              \"mode\": \"thresholds\"\n            },\n            \"thresholds\": {\n              \"mode\": \"absolute\",\n              \"steps\": [\n                {\"color\": \"green\", \"value\": null},\n                {\"color\": \"yellow\", \"value\": 40},\n                {\"color\": \"orange\", \"value\": 60},\n                {\"color\": \"red\", \"value\": 80}\n              ]\n            },\n            \"unit\": \"percent\",\n            \"min\": 0,\n            \"max\": 100\n          }\n        },\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 4},\n        \"id\": 3,\n        \"type\": \"timeseries\",\n        \"title\": \"GPU Power Anomaly Score\",\n        \"targets\": [\n          {\n            \"expr\": \"anomaly_score{metric_name=\\\"node_gpu_power_watts\\\"}\",\n            \"legendFormat\": \"GPU Power Anomaly\",\n            \"refId\": \"A\"\n          }\n        ]\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"color\": {\n              \"mode\": \"thresholds\"\n            },\n            \"thresholds\": {\n              \"mode\": \"absolute\",\n              \"steps\": [\n                {\"color\": \"green\", \"value\": null},\n                {\"color\": \"yellow\", \"value\": 40},\n                {\"color\": \"orange\", \"value\": 60},\n                {\"color\": \"red\", \"value\": 80}\n              ]\n            },\n            \"unit\": \"percent\",\n            \"min\": 0,\n            \"max\": 100\n          }\n        },\n        \"gridPos\": {\"h\": 8, \"w\": 8, \"x\": 0, \"y\": 12},\n        \"id\": 4,\n        \"type\": \"gauge\",\n        \"title\": \"CPU Usage Anomaly\",\n        \"targets\": [\n          {\n            \"expr\": \"anomaly_score{metric_name=\\\"cpu_usage_percent\\\"}\",\n            \"instant\": true,\n            \"refId\": \"A\"\n          }\n        ]\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"color\": {\n              \"mode\": \"thresholds\"\n            },\n            \"thresholds\": {\n              \"mode\": \"absolute\",\n              \"steps\": [\n                {\"color\": \"green\", \"value\": null},\n                {\"color\": \"yellow\", \"value\": 40},\n                {\"color\": \"orange\", \"value\": 60},\n                {\"color\": \"red\", \"value\": 80}\n              ]\n            },\n            \"unit\": \"percent\",\n            \"min\": 0,\n            \"max\": 100\n          }\n        },\n        \"gridPos\": {\"h\": 8, \"w\": 8, \"x\": 8, \"y\": 12},\n        \"id\": 5,\n        \"type\": \"gauge\",\n        \"title\": \"Memory Anomaly\",\n        \"targets\": [\n          {\n            \"expr\": \"anomaly_score{metric_name=\\\"node_memory_MemAvailable_bytes\\\"}\",\n            \"instant\": true,\n            \"refId\": \"A\"\n          }\n        ]\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"color\": {\n              \"mode\": \"thresholds\"\n            },\n            \"thresholds\": {\n              \"mode\": \"absolute\",\n              \"steps\": [\n                {\"color\": \"green\", \"value\": null},\n                {\"color\": \"yellow\", \"value\": 40},\n                {\"color\": \"orange\", \"value\": 60},\n                {\"color\": \"red\", \"value\": 80}\n              ]\n            },\n            \"unit\": \"percent\",\n            \"min\": 0,\n            \"max\": 100\n          }\n        },\n        \"gridPos\": {\"h\": 8, \"w\": 8, \"x\": 16, \"y\": 12},\n        \"id\": 6,\n        \"type\": \"gauge\",\n        \"title\": \"Network Anomaly\",\n        \"targets\": [\n          {\n            \"expr\": \"anomaly_score{metric_name=\\\"network_receive_rate\\\"}\",\n            \"instant\": true,\n            \"refId\": \"A\"\n          }\n        ]\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"custom\": {\n              \"align\": \"center\",\n              \"displayMode\": \"color-background\"\n            },\n            \"thresholds\": {\n              \"mode\": \"absolute\",\n              \"steps\": [\n                {\"color\": \"green\", \"value\": null},\n                {\"color\": \"yellow\", \"value\": 40},\n                {\"color\": \"orange\", \"value\": 60},\n                {\"color\": \"red\", \"value\": 80}\n              ]\n            },\n            \"unit\": \"percent\"\n          },\n          \"overrides\": [\n            {\n              \"matcher\": {\"id\": \"byName\", \"options\": \"Anomaly Score\"},\n              \"properties\": [\n                {\"id\": \"custom.displayMode\", \"value\": \"gradient-gauge\"},\n                {\"id\": \"custom.width\", \"value\": 200}\n              ]\n            }\n          ]\n        },\n        \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 20},\n        \"id\": 7,\n        \"type\": \"table\",\n        \"title\": \"All Anomaly Scores\",\n        \"targets\": [\n          {\n            \"expr\": \"anomaly_score\",\n            \"format\": \"table\",\n            \"instant\": true,\n            \"refId\": \"A\"\n          }\n        ],\n        \"transformations\": [\n          {\n            \"id\": \"organize\",\n            \"options\": {\n              \"excludeByName\": {\n                \"Time\": true,\n                \"__name__\": true,\n                \"job\": true,\n                \"instance\": true\n              },\n              \"renameByName\": {\n                \"metric_name\": \"Metric\",\n                \"algorithm\": \"Algorithm\",\n                \"Value\": \"Anomaly Score\"\n              }\n            }\n          }\n        ]\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"gridPos\": {\"h\": 6, \"w\": 12, \"x\": 0, \"y\": 28},\n        \"id\": 8,\n        \"type\": \"stat\",\n        \"title\": \"Anomaly Detector Health\",\n        \"targets\": [\n          {\n            \"expr\": \"anomaly_detector_health\",\n            \"refId\": \"A\"\n          }\n        ],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"thresholds\": {\n              \"steps\": [\n                {\"color\": \"red\", \"value\": null},\n                {\"color\": \"green\", \"value\": 1}\n              ]\n            },\n            \"mappings\": [\n              {\"options\": {\"0\": {\"text\": \"Unhealthy\"}}, \"type\": \"value\"},\n              {\"options\": {\"1\": {\"text\": \"Healthy\"}}, \"type\": \"value\"}\n            ]\n          }\n        }\n      },\n      {\n        \"datasource\": \"Prometheus\",\n        \"gridPos\": {\"h\": 6, \"w\": 12, \"x\": 12, \"y\": 28},\n        \"id\": 9,\n        \"type\": \"stat\",\n        \"title\": \"Models Trained\",\n        \"targets\": [\n          {\n            \"expr\": \"count(count by (metric_name) (anomaly_model_updates_total))\",\n            \"refId\": \"A\"\n          }\n        ],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"unit\": \"short\",\n            \"decimals\": 0\n          }\n        }\n      }\n    ]\n  }\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"odin-ml-dashboards","namespace":"monitoring"}}
    creationTimestamp: "2025-05-30T02:18:24Z"
    name: odin-ml-dashboards
    namespace: monitoring
    resourceVersion: "91696"
    uid: 978a4d25-7638-4662-b130-d59ddbbbaff0
- apiVersion: v1
  data:
    odin-prime.rules.yaml: "groups:\n- name: odin-prime-services-resilient\n  interval:
      30s\n  rules:\n  \n  # Use Kubernetes deployment metrics instead of custom job
      scrapes\n  - alert: ODINPrimeAlertIngestionDown\n    expr: |\n      kube_deployment_status_ready_replicas{\n
      \       namespace=\"odin-prime\",\n        deployment=~\"alert-ingestion.*\"\n
      \     } == 0\n    for: 2m\n    labels:\n      severity: critical\n      component:
      odin-prime\n      service: alert-ingestion\n    annotations:\n      summary:
      \"ODIN Prime Alert Ingestion service is down\"\n      description: \"Alert ingestion
      deployment has 0 ready replicas for {{ $value }} minutes\"\n      action: \"kubectl
      rollout restart deployment/alert-ingestion-v2 -n odin-prime\"\n  \n  - alert:
      ODINPrimeEscalationServiceDown\n    expr: |\n      kube_deployment_status_ready_replicas{\n
      \       namespace=\"odin-prime\",\n        deployment=~\"escalation-service.*\"\n
      \     } == 0\n    for: 2m\n    labels:\n      severity: critical\n      component:
      odin-prime\n      service: escalation-service\n    annotations:\n      summary:
      \"ODIN Prime Escalation Service is down\"\n      description: \"Escalation service
      deployment has 0 ready replicas\"\n      action: \"kubectl rollout restart deployment/escalation-service-basic
      -n odin-prime\"\n  \n  - alert: ODINPrimeAutomationEngineDown\n    expr: |\n
      \     kube_deployment_status_ready_replicas{\n        namespace=\"odin-prime\",\n
      \       deployment=~\"automation-engine.*\"\n      } == 0\n    for: 2m\n    labels:\n
      \     severity: critical\n      component: odin-prime\n      service: automation-engine\n
      \   annotations:\n      summary: \"ODIN Prime Automation Engine is down\"\n
      \     description: \"Automation engine deployment has 0 ready replicas\"\n      action:
      \"kubectl rollout restart deployment/automation-engine -n odin-prime\"\n  \n
      \ - alert: ODINPrimeApprovalAPIDown\n    expr: |\n      kube_deployment_status_ready_replicas{\n
      \       namespace=\"odin-prime\",\n        deployment=~\"approval-api.*\"\n
      \     } == 0\n    for: 2m\n    labels:\n      severity: warning\n      component:
      odin-prime\n      service: approval-api\n    annotations:\n      summary: \"ODIN
      Prime Approval API is down\"\n      description: \"Approval API deployment has
      0 ready replicas\"\n      action: \"kubectl rollout restart deployment/approval-api
      -n odin-prime\"\n  \n  - alert: ODINPrimeAuditViewerDown\n    expr: |\n      kube_deployment_status_ready_replicas{\n
      \       namespace=\"odin-prime\",\n        deployment=~\"audit-viewer.*\"\n
      \     } == 0\n    for: 2m\n    labels:\n      severity: warning\n      component:
      odin-prime\n      service: audit-viewer\n    annotations:\n      summary: \"ODIN
      Prime Audit Viewer is down\"\n      description: \"Audit viewer deployment has
      0 ready replicas\"\n      action: \"kubectl rollout restart deployment/audit-viewer
      -n odin-prime\"\n  \n  - alert: ODINPrimeRedisDown\n    expr: |\n      kube_deployment_status_ready_replicas{\n
      \       namespace=\"odin-prime\",\n        deployment=~\"redis.*\"\n      }
      == 0\n    for: 2m\n    labels:\n      severity: critical\n      component: odin-prime\n
      \     dependency: redis\n    annotations:\n      summary: \"Redis cache for
      ODIN Prime is down\"\n      description: \"Redis deployment has 0 ready replicas\"\n
      \     action: \"kubectl rollout restart deployment/redis-cache -n odin-prime\"\n
      \ \n  - alert: ODINPrimePatternMatcherDown\n    expr: |\n      kube_deployment_status_ready_replicas{\n
      \       namespace=\"odin-prime\",\n        deployment=~\"pattern-matcher.*\"\n
      \     } == 0\n    for: 2m\n    labels:\n      severity: high\n      component:
      odin-prime\n      service: pattern-matcher\n    annotations:\n      summary:
      \"ODIN Prime Pattern Matcher is down\"\n      description: \"Pattern matcher
      deployment has 0 ready replicas\"\n      action: \"kubectl rollout restart deployment/pattern-matcher
      -n odin-prime\"\n  \n  # Pod-level monitoring for crash loops and readiness
      issues\n  - alert: ODINPrimePodCrashLooping\n    expr: |\n      rate(kube_pod_container_status_restarts_total{\n
      \       namespace=\"odin-prime\"\n      }[15m]) > 0.1\n    for: 5m\n    labels:\n
      \     severity: high\n      component: odin-prime\n    annotations:\n      summary:
      \"ODIN Prime pod is crash looping\"\n      description: \"Pod {{ $labels.pod
      }} has restarted {{ $value }} times in 15 minutes\"\n      action: \"kubectl
      logs -n odin-prime {{ $labels.pod }} --previous\"\n  \n  - alert: ODINPrimePodNotReady\n
      \   expr: |\n      kube_pod_status_ready{\n        namespace=\"odin-prime\",\n
      \       condition=\"false\"\n      } == 1\n    for: 10m\n    labels:\n      severity:
      warning\n      component: odin-prime\n    annotations:\n      summary: \"ODIN
      Prime pod not ready\"\n      description: \"Pod {{ $labels.pod }} has been not
      ready for 10+ minutes\"\n      action: \"kubectl describe pod -n odin-prime
      {{ $labels.pod }}\"\n  \n  # Service availability using endpoint monitoring\n
      \ - alert: ODINPrimeServiceEndpointDown\n    expr: |\n      kube_endpoint_subset_ready{\n
      \       namespace=\"odin-prime\"\n      } == 0 and \n      kube_endpoint_subset_total{\n
      \       namespace=\"odin-prime\"\n      } > 0\n    for: 5m\n    labels:\n      severity:
      warning\n      component: odin-prime\n    annotations:\n      summary: \"ODIN
      Prime service endpoint not ready\"\n      description: \"Service {{ $labels.service
      }} has no ready endpoints\"\n      action: \"kubectl get endpoints -n odin-prime
      {{ $labels.service }}\"\n  \n  # Deployment scaling and resource monitoring\n
      \ - alert: ODINPrimeDeploymentScaledToZero\n    expr: |\n      kube_deployment_spec_replicas{\n
      \       namespace=\"odin-prime\"\n      } == 0 and\n      kube_deployment_metadata_labels{\n
      \       namespace=\"odin-prime\",\n        label_component=\"odin-prime\"\n
      \     }\n    for: 5m\n    labels:\n      severity: warning\n      component:
      odin-prime\n    annotations:\n      summary: \"ODIN Prime deployment scaled
      to zero\"\n      description: \"Deployment {{ $labels.deployment }} is intentionally
      scaled to 0 replicas\"\n      action: \"Verify if this scaling is intentional\"\n
      \ \n  - alert: ODINPrimeDeploymentReplicaMismatch\n    expr: |\n      (\n        kube_deployment_spec_replicas{namespace=\"odin-prime\"}
      -\n        kube_deployment_status_ready_replicas{namespace=\"odin-prime\"}\n
      \     ) > 0\n    for: 10m\n    labels:\n      severity: warning\n      component:
      odin-prime\n    annotations:\n      summary: \"ODIN Prime deployment has replica
      mismatch\"\n      description: \"Deployment {{ $labels.deployment }} has {{
      $value }} missing replicas\"\n      action: \"kubectl rollout status deployment/{{
      $labels.deployment }} -n odin-prime\"\n  \n  # REMOVED: Self-healing test alert
      - not needed as a constant alert\n  # Use manual test alerts when actually testing
      the pipeline\n  \n  # Meta-monitoring: Check if ODIN Prime can self-heal\n  -
      alert: ODINPrimeSelfHealingFailure\n    expr: |\n      (\n        ALERTS{alertname=\"ODINPrimeAlertIngestionDown\",
      severity=\"critical\"} == 1 or\n        ALERTS{alertname=\"ODINPrimeEscalationServiceDown\",
      severity=\"critical\"} == 1 or\n        ALERTS{alertname=\"ODINPrimeAutomationEngineDown\",
      severity=\"critical\"} == 1\n      ) and\n      (time() - ALERTS_FOR_STATE{alertname=~\"ODINPrime.*Down\"}
      > 600)\n    for: 1m\n    labels:\n      severity: critical\n      component:
      odin-prime\n      service: self-healing\n    annotations:\n      summary: \"ODIN
      Prime failed to self-heal critical service\"\n      description: \"Critical
      ODIN Prime component has been down for 10+ minutes without automated recovery\"\n
      \     action: \"URGENT: Manual intervention required. Automation pipeline may
      be broken.\"\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"odin-prime.rules.yaml":"groups:\n- name: odin-prime-services-resilient\n  interval: 30s\n  rules:\n  \n  # Use Kubernetes deployment metrics instead of custom job scrapes\n  - alert: ODINPrimeAlertIngestionDown\n    expr: |\n      kube_deployment_status_ready_replicas{\n        namespace=\"odin-prime\",\n        deployment=~\"alert-ingestion.*\"\n      } == 0\n    for: 2m\n    labels:\n      severity: critical\n      component: odin-prime\n      service: alert-ingestion\n    annotations:\n      summary: \"ODIN Prime Alert Ingestion service is down\"\n      description: \"Alert ingestion deployment has 0 ready replicas for {{ $value }} minutes\"\n      action: \"kubectl rollout restart deployment/alert-ingestion-v2 -n odin-prime\"\n  \n  - alert: ODINPrimeEscalationServiceDown\n    expr: |\n      kube_deployment_status_ready_replicas{\n        namespace=\"odin-prime\",\n        deployment=~\"escalation-service.*\"\n      } == 0\n    for: 2m\n    labels:\n      severity: critical\n      component: odin-prime\n      service: escalation-service\n    annotations:\n      summary: \"ODIN Prime Escalation Service is down\"\n      description: \"Escalation service deployment has 0 ready replicas\"\n      action: \"kubectl rollout restart deployment/escalation-service-basic -n odin-prime\"\n  \n  - alert: ODINPrimeAutomationEngineDown\n    expr: |\n      kube_deployment_status_ready_replicas{\n        namespace=\"odin-prime\",\n        deployment=~\"automation-engine.*\"\n      } == 0\n    for: 2m\n    labels:\n      severity: critical\n      component: odin-prime\n      service: automation-engine\n    annotations:\n      summary: \"ODIN Prime Automation Engine is down\"\n      description: \"Automation engine deployment has 0 ready replicas\"\n      action: \"kubectl rollout restart deployment/automation-engine -n odin-prime\"\n  \n  - alert: ODINPrimeApprovalAPIDown\n    expr: |\n      kube_deployment_status_ready_replicas{\n        namespace=\"odin-prime\",\n        deployment=~\"approval-api.*\"\n      } == 0\n    for: 2m\n    labels:\n      severity: warning\n      component: odin-prime\n      service: approval-api\n    annotations:\n      summary: \"ODIN Prime Approval API is down\"\n      description: \"Approval API deployment has 0 ready replicas\"\n      action: \"kubectl rollout restart deployment/approval-api -n odin-prime\"\n  \n  - alert: ODINPrimeAuditViewerDown\n    expr: |\n      kube_deployment_status_ready_replicas{\n        namespace=\"odin-prime\",\n        deployment=~\"audit-viewer.*\"\n      } == 0\n    for: 2m\n    labels:\n      severity: warning\n      component: odin-prime\n      service: audit-viewer\n    annotations:\n      summary: \"ODIN Prime Audit Viewer is down\"\n      description: \"Audit viewer deployment has 0 ready replicas\"\n      action: \"kubectl rollout restart deployment/audit-viewer -n odin-prime\"\n  \n  - alert: ODINPrimeRedisDown\n    expr: |\n      kube_deployment_status_ready_replicas{\n        namespace=\"odin-prime\",\n        deployment=~\"redis.*\"\n      } == 0\n    for: 2m\n    labels:\n      severity: critical\n      component: odin-prime\n      dependency: redis\n    annotations:\n      summary: \"Redis cache for ODIN Prime is down\"\n      description: \"Redis deployment has 0 ready replicas\"\n      action: \"kubectl rollout restart deployment/redis-cache -n odin-prime\"\n  \n  - alert: ODINPrimePatternMatcherDown\n    expr: |\n      kube_deployment_status_ready_replicas{\n        namespace=\"odin-prime\",\n        deployment=~\"pattern-matcher.*\"\n      } == 0\n    for: 2m\n    labels:\n      severity: high\n      component: odin-prime\n      service: pattern-matcher\n    annotations:\n      summary: \"ODIN Prime Pattern Matcher is down\"\n      description: \"Pattern matcher deployment has 0 ready replicas\"\n      action: \"kubectl rollout restart deployment/pattern-matcher -n odin-prime\"\n  \n  # Pod-level monitoring for crash loops and readiness issues\n  - alert: ODINPrimePodCrashLooping\n    expr: |\n      rate(kube_pod_container_status_restarts_total{\n        namespace=\"odin-prime\"\n      }[15m]) \u003e 0.1\n    for: 5m\n    labels:\n      severity: high\n      component: odin-prime\n    annotations:\n      summary: \"ODIN Prime pod is crash looping\"\n      description: \"Pod {{ $labels.pod }} has restarted {{ $value }} times in 15 minutes\"\n      action: \"kubectl logs -n odin-prime {{ $labels.pod }} --previous\"\n  \n  - alert: ODINPrimePodNotReady\n    expr: |\n      kube_pod_status_ready{\n        namespace=\"odin-prime\",\n        condition=\"false\"\n      } == 1\n    for: 10m\n    labels:\n      severity: warning\n      component: odin-prime\n    annotations:\n      summary: \"ODIN Prime pod not ready\"\n      description: \"Pod {{ $labels.pod }} has been not ready for 10+ minutes\"\n      action: \"kubectl describe pod -n odin-prime {{ $labels.pod }}\"\n  \n  # Service availability using endpoint monitoring\n  - alert: ODINPrimeServiceEndpointDown\n    expr: |\n      kube_endpoint_subset_ready{\n        namespace=\"odin-prime\"\n      } == 0 and \n      kube_endpoint_subset_total{\n        namespace=\"odin-prime\"\n      } \u003e 0\n    for: 5m\n    labels:\n      severity: warning\n      component: odin-prime\n    annotations:\n      summary: \"ODIN Prime service endpoint not ready\"\n      description: \"Service {{ $labels.service }} has no ready endpoints\"\n      action: \"kubectl get endpoints -n odin-prime {{ $labels.service }}\"\n  \n  # Deployment scaling and resource monitoring\n  - alert: ODINPrimeDeploymentScaledToZero\n    expr: |\n      kube_deployment_spec_replicas{\n        namespace=\"odin-prime\"\n      } == 0 and\n      kube_deployment_metadata_labels{\n        namespace=\"odin-prime\",\n        label_component=\"odin-prime\"\n      }\n    for: 5m\n    labels:\n      severity: warning\n      component: odin-prime\n    annotations:\n      summary: \"ODIN Prime deployment scaled to zero\"\n      description: \"Deployment {{ $labels.deployment }} is intentionally scaled to 0 replicas\"\n      action: \"Verify if this scaling is intentional\"\n  \n  - alert: ODINPrimeDeploymentReplicaMismatch\n    expr: |\n      (\n        kube_deployment_spec_replicas{namespace=\"odin-prime\"} -\n        kube_deployment_status_ready_replicas{namespace=\"odin-prime\"}\n      ) \u003e 0\n    for: 10m\n    labels:\n      severity: warning\n      component: odin-prime\n    annotations:\n      summary: \"ODIN Prime deployment has replica mismatch\"\n      description: \"Deployment {{ $labels.deployment }} has {{ $value }} missing replicas\"\n      action: \"kubectl rollout status deployment/{{ $labels.deployment }} -n odin-prime\"\n  \n  # REMOVED: Self-healing test alert - not needed as a constant alert\n  # Use manual test alerts when actually testing the pipeline\n  \n  # Meta-monitoring: Check if ODIN Prime can self-heal\n  - alert: ODINPrimeSelfHealingFailure\n    expr: |\n      (\n        ALERTS{alertname=\"ODINPrimeAlertIngestionDown\", severity=\"critical\"} == 1 or\n        ALERTS{alertname=\"ODINPrimeEscalationServiceDown\", severity=\"critical\"} == 1 or\n        ALERTS{alertname=\"ODINPrimeAutomationEngineDown\", severity=\"critical\"} == 1\n      ) and\n      (time() - ALERTS_FOR_STATE{alertname=~\"ODINPrime.*Down\"} \u003e 600)\n    for: 1m\n    labels:\n      severity: critical\n      component: odin-prime\n      service: self-healing\n    annotations:\n      summary: \"ODIN Prime failed to self-heal critical service\"\n      description: \"Critical ODIN Prime component has been down for 10+ minutes without automated recovery\"\n      action: \"URGENT: Manual intervention required. Automation pipeline may be broken.\"\n"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"prometheus":"kube-prometheus","role":"alert-rules"},"name":"odin-prime-alerts","namespace":"monitoring"}}
    creationTimestamp: "2025-06-07T21:47:47Z"
    labels:
      prometheus: kube-prometheus
      role: alert-rules
    name: odin-prime-alerts
    namespace: monitoring
    resourceVersion: "5134428"
    uid: 9cc67643-31d2-42ee-b612-d0ee44307602
- apiVersion: v1
  data:
    odin-prime-automation.json: |
      {
        "annotations": {
          "list": [
            {
              "builtIn": 1,
              "datasource": "-- Grafana --",
              "enable": true,
              "hide": true,
              "iconColor": "rgba(0, 211, 255, 1)",
              "name": "Annotations & Alerts",
              "type": "dashboard"
            }
          ]
        },
        "editable": true,
        "gnetId": null,
        "graphTooltip": 0,
        "id": null,
        "links": [],
        "panels": [
          {
            "datasource": "Prometheus",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "red",
                      "value": null
                    },
                    {
                      "color": "yellow",
                      "value": 0.7
                    },
                    {
                      "color": "green",
                      "value": 0.9
                    }
                  ]
                },
                "unit": "percentunit"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 6,
              "w": 6,
              "x": 0,
              "y": 0
            },
            "id": 1,
            "options": {
              "colorMode": "value",
              "graphMode": "area",
              "justifyMode": "auto",
              "orientation": "auto",
              "reduceOptions": {
                "values": false,
                "calcs": ["lastNotNull"]
              },
              "text": {},
              "textMode": "auto"
            },
            "pluginVersion": "8.0.0",
            "targets": [
              {
                "expr": "sum(rate(odin_automation_executions_total{status=\"success\"}[1h])) / sum(rate(odin_automation_executions_total[1h]))",
                "refId": "A"
              }
            ],
            "title": "Automation Success Rate",
            "type": "stat"
          },
          {
            "datasource": "Prometheus",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "yellow",
                      "value": 10
                    },
                    {
                      "color": "red",
                      "value": 20
                    }
                  ]
                },
                "unit": "short"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 6,
              "w": 6,
              "x": 6,
              "y": 0
            },
            "id": 2,
            "options": {
              "colorMode": "value",
              "graphMode": "none",
              "justifyMode": "auto",
              "orientation": "auto",
              "reduceOptions": {
                "values": false,
                "calcs": ["lastNotNull"]
              },
              "text": {},
              "textMode": "auto"
            },
            "pluginVersion": "8.0.0",
            "targets": [
              {
                "expr": "sum(odin_approval_queue_size)",
                "refId": "A"
              }
            ],
            "title": "Pending Approvals",
            "type": "stat"
          },
          {
            "datasource": "Prometheus",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    }
                  ]
                },
                "unit": "short"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 6,
              "w": 6,
              "x": 12,
              "y": 0
            },
            "id": 3,
            "options": {
              "colorMode": "value",
              "graphMode": "area",
              "justifyMode": "auto",
              "orientation": "auto",
              "reduceOptions": {
                "values": false,
                "calcs": ["lastNotNull"]
              },
              "text": {},
              "textMode": "auto"
            },
            "pluginVersion": "8.0.0",
            "targets": [
              {
                "expr": "sum(increase(odin_rollbacks_total[24h]))",
                "refId": "A"
              }
            ],
            "title": "Rollbacks (24h)",
            "type": "stat"
          },
          {
            "datasource": "Prometheus",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "yellow",
                      "value": 60
                    },
                    {
                      "color": "red",
                      "value": 300
                    }
                  ]
                },
                "unit": "s"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 6,
              "w": 6,
              "x": 18,
              "y": 0
            },
            "id": 4,
            "options": {
              "colorMode": "value",
              "graphMode": "none",
              "justifyMode": "auto",
              "orientation": "auto",
              "reduceOptions": {
                "values": false,
                "calcs": ["mean"]
              },
              "text": {},
              "textMode": "auto"
            },
            "pluginVersion": "8.0.0",
            "targets": [
              {
                "expr": "avg(rate(odin_approval_response_time_seconds_sum[5m]) / rate(odin_approval_response_time_seconds_count[5m]))",
                "refId": "A"
              }
            ],
            "title": "Avg Approval Time",
            "type": "stat"
          },
          {
            "datasource": "Prometheus",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  }
                },
                "mappings": [],
                "unit": "short"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 0,
              "y": 6
            },
            "id": 5,
            "options": {
              "pieType": "donut",
              "tooltip": {
                "mode": "single"
              },
              "legend": {
                "displayMode": "table",
                "placement": "right",
                "values": ["value", "percent"]
              }
            },
            "pluginVersion": "8.0.0",
            "targets": [
              {
                "expr": "sum by (risk_level) (increase(odin_automation_risk_assessment_total[1h]))",
                "legendFormat": "{{risk_level}}",
                "refId": "A"
              }
            ],
            "title": "Risk Level Distribution",
            "type": "piechart"
          },
          {
            "datasource": "Prometheus",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 10,
                  "gradientMode": "none",
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  },
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "never",
                  "spanNulls": true
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    }
                  ]
                },
                "unit": "short"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 12,
              "y": 6
            },
            "id": 6,
            "options": {
              "tooltip": {
                "mode": "single"
              },
              "legend": {
                "calcs": [],
                "displayMode": "list",
                "placement": "bottom"
              }
            },
            "pluginVersion": "8.0.0",
            "targets": [
              {
                "expr": "sum(rate(odin_automation_executions_total{status=\"success\"}[5m])) * 60",
                "legendFormat": "Success/min",
                "refId": "A"
              },
              {
                "expr": "sum(rate(odin_automation_executions_total{status=\"failed\"}[5m])) * 60",
                "legendFormat": "Failed/min",
                "refId": "B"
              },
              {
                "expr": "sum(rate(odin_automation_executions_total{status=\"rollback\"}[5m])) * 60",
                "legendFormat": "Rollback/min",
                "refId": "C"
              }
            ],
            "title": "Automation Execution Rate",
            "type": "timeseries"
          },
          {
            "datasource": "Prometheus",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 10,
                  "gradientMode": "none",
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  },
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "never",
                  "spanNulls": true
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    }
                  ]
                },
                "unit": "s"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 0,
              "y": 14
            },
            "id": 7,
            "options": {
              "tooltip": {
                "mode": "single"
              },
              "legend": {
                "calcs": [],
                "displayMode": "list",
                "placement": "bottom"
              }
            },
            "pluginVersion": "8.0.0",
            "targets": [
              {
                "expr": "histogram_quantile(0.5, sum(rate(odin_automation_execution_duration_seconds_bucket[5m])) by (le))",
                "legendFormat": "p50",
                "refId": "A"
              },
              {
                "expr": "histogram_quantile(0.95, sum(rate(odin_automation_execution_duration_seconds_bucket[5m])) by (le))",
                "legendFormat": "p95",
                "refId": "B"
              },
              {
                "expr": "histogram_quantile(0.99, sum(rate(odin_automation_execution_duration_seconds_bucket[5m])) by (le))",
                "legendFormat": "p99",
                "refId": "C"
              }
            ],
            "title": "Automation Execution Time",
            "type": "timeseries"
          },
          {
            "datasource": "Prometheus",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  }
                },
                "mappings": [],
                "unit": "short"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 12,
              "y": 14
            },
            "id": 8,
            "options": {
              "pieType": "pie",
              "tooltip": {
                "mode": "single"
              },
              "legend": {
                "displayMode": "list",
                "placement": "right"
              }
            },
            "pluginVersion": "8.0.0",
            "targets": [
              {
                "expr": "sum by (action_type) (increase(odin_automation_actions_total[1h]))",
                "legendFormat": "{{action_type}}",
                "refId": "A"
              }
            ],
            "title": "Action Types",
            "type": "piechart"
          },
          {
            "datasource": "Prometheus",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "bars",
                  "fillOpacity": 100,
                  "gradientMode": "none",
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  },
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "never",
                  "spanNulls": true
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    }
                  ]
                },
                "unit": "short"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 24,
              "x": 0,
              "y": 22
            },
            "id": 9,
            "options": {
              "tooltip": {
                "mode": "single"
              },
              "legend": {
                "calcs": [],
                "displayMode": "list",
                "placement": "bottom"
              }
            },
            "pluginVersion": "8.0.0",
            "targets": [
              {
                "expr": "sum by (decision) (increase(odin_approval_decisions_total[1h]))",
                "legendFormat": "{{decision}}",
                "refId": "A"
              }
            ],
            "title": "Approval Decisions (Hourly)",
            "type": "timeseries"
          }
        ],
        "refresh": "10s",
        "schemaVersion": 27,
        "style": "dark",
        "tags": ["odin-prime", "automation", "performance"],
        "templating": {
          "list": []
        },
        "time": {
          "from": "now-3h",
          "to": "now"
        },
        "timepicker": {},
        "timezone": "",
        "title": "ODIN Prime - Automation Performance",
        "uid": "odin-prime-automation",
        "version": 0
      }
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"odin-prime-automation.json":"{\n  \"annotations\": {\n    \"list\": [\n      {\n        \"builtIn\": 1,\n        \"datasource\": \"-- Grafana --\",\n        \"enable\": true,\n        \"hide\": true,\n        \"iconColor\": \"rgba(0, 211, 255, 1)\",\n        \"name\": \"Annotations \u0026 Alerts\",\n        \"type\": \"dashboard\"\n      }\n    ]\n  },\n  \"editable\": true,\n  \"gnetId\": null,\n  \"graphTooltip\": 0,\n  \"id\": null,\n  \"links\": [],\n  \"panels\": [\n    {\n      \"datasource\": \"Prometheus\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"red\",\n                \"value\": null\n              },\n              {\n                \"color\": \"yellow\",\n                \"value\": 0.7\n              },\n              {\n                \"color\": \"green\",\n                \"value\": 0.9\n              }\n            ]\n          },\n          \"unit\": \"percentunit\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 6,\n        \"w\": 6,\n        \"x\": 0,\n        \"y\": 0\n      },\n      \"id\": 1,\n      \"options\": {\n        \"colorMode\": \"value\",\n        \"graphMode\": \"area\",\n        \"justifyMode\": \"auto\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"]\n        },\n        \"text\": {},\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"8.0.0\",\n      \"targets\": [\n        {\n          \"expr\": \"sum(rate(odin_automation_executions_total{status=\\\"success\\\"}[1h])) / sum(rate(odin_automation_executions_total[1h]))\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Automation Success Rate\",\n      \"type\": \"stat\"\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"yellow\",\n                \"value\": 10\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 20\n              }\n            ]\n          },\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 6,\n        \"w\": 6,\n        \"x\": 6,\n        \"y\": 0\n      },\n      \"id\": 2,\n      \"options\": {\n        \"colorMode\": \"value\",\n        \"graphMode\": \"none\",\n        \"justifyMode\": \"auto\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"]\n        },\n        \"text\": {},\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"8.0.0\",\n      \"targets\": [\n        {\n          \"expr\": \"sum(odin_approval_queue_size)\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Pending Approvals\",\n      \"type\": \"stat\"\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          },\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 6,\n        \"w\": 6,\n        \"x\": 12,\n        \"y\": 0\n      },\n      \"id\": 3,\n      \"options\": {\n        \"colorMode\": \"value\",\n        \"graphMode\": \"area\",\n        \"justifyMode\": \"auto\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"]\n        },\n        \"text\": {},\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"8.0.0\",\n      \"targets\": [\n        {\n          \"expr\": \"sum(increase(odin_rollbacks_total[24h]))\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Rollbacks (24h)\",\n      \"type\": \"stat\"\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"yellow\",\n                \"value\": 60\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 300\n              }\n            ]\n          },\n          \"unit\": \"s\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 6,\n        \"w\": 6,\n        \"x\": 18,\n        \"y\": 0\n      },\n      \"id\": 4,\n      \"options\": {\n        \"colorMode\": \"value\",\n        \"graphMode\": \"none\",\n        \"justifyMode\": \"auto\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"mean\"]\n        },\n        \"text\": {},\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"8.0.0\",\n      \"targets\": [\n        {\n          \"expr\": \"avg(rate(odin_approval_response_time_seconds_sum[5m]) / rate(odin_approval_response_time_seconds_count[5m]))\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Avg Approval Time\",\n      \"type\": \"stat\"\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            }\n          },\n          \"mappings\": [],\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 0,\n        \"y\": 6\n      },\n      \"id\": 5,\n      \"options\": {\n        \"pieType\": \"donut\",\n        \"tooltip\": {\n          \"mode\": \"single\"\n        },\n        \"legend\": {\n          \"displayMode\": \"table\",\n          \"placement\": \"right\",\n          \"values\": [\"value\", \"percent\"]\n        }\n      },\n      \"pluginVersion\": \"8.0.0\",\n      \"targets\": [\n        {\n          \"expr\": \"sum by (risk_level) (increase(odin_automation_risk_assessment_total[1h]))\",\n          \"legendFormat\": \"{{risk_level}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Risk Level Distribution\",\n      \"type\": \"piechart\"\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 10,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            },\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"never\",\n            \"spanNulls\": true\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          },\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 6\n      },\n      \"id\": 6,\n      \"options\": {\n        \"tooltip\": {\n          \"mode\": \"single\"\n        },\n        \"legend\": {\n          \"calcs\": [],\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\"\n        }\n      },\n      \"pluginVersion\": \"8.0.0\",\n      \"targets\": [\n        {\n          \"expr\": \"sum(rate(odin_automation_executions_total{status=\\\"success\\\"}[5m])) * 60\",\n          \"legendFormat\": \"Success/min\",\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"sum(rate(odin_automation_executions_total{status=\\\"failed\\\"}[5m])) * 60\",\n          \"legendFormat\": \"Failed/min\",\n          \"refId\": \"B\"\n        },\n        {\n          \"expr\": \"sum(rate(odin_automation_executions_total{status=\\\"rollback\\\"}[5m])) * 60\",\n          \"legendFormat\": \"Rollback/min\",\n          \"refId\": \"C\"\n        }\n      ],\n      \"title\": \"Automation Execution Rate\",\n      \"type\": \"timeseries\"\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 10,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            },\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"never\",\n            \"spanNulls\": true\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          },\n          \"unit\": \"s\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 0,\n        \"y\": 14\n      },\n      \"id\": 7,\n      \"options\": {\n        \"tooltip\": {\n          \"mode\": \"single\"\n        },\n        \"legend\": {\n          \"calcs\": [],\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\"\n        }\n      },\n      \"pluginVersion\": \"8.0.0\",\n      \"targets\": [\n        {\n          \"expr\": \"histogram_quantile(0.5, sum(rate(odin_automation_execution_duration_seconds_bucket[5m])) by (le))\",\n          \"legendFormat\": \"p50\",\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"histogram_quantile(0.95, sum(rate(odin_automation_execution_duration_seconds_bucket[5m])) by (le))\",\n          \"legendFormat\": \"p95\",\n          \"refId\": \"B\"\n        },\n        {\n          \"expr\": \"histogram_quantile(0.99, sum(rate(odin_automation_execution_duration_seconds_bucket[5m])) by (le))\",\n          \"legendFormat\": \"p99\",\n          \"refId\": \"C\"\n        }\n      ],\n      \"title\": \"Automation Execution Time\",\n      \"type\": \"timeseries\"\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            }\n          },\n          \"mappings\": [],\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 14\n      },\n      \"id\": 8,\n      \"options\": {\n        \"pieType\": \"pie\",\n        \"tooltip\": {\n          \"mode\": \"single\"\n        },\n        \"legend\": {\n          \"displayMode\": \"list\",\n          \"placement\": \"right\"\n        }\n      },\n      \"pluginVersion\": \"8.0.0\",\n      \"targets\": [\n        {\n          \"expr\": \"sum by (action_type) (increase(odin_automation_actions_total[1h]))\",\n          \"legendFormat\": \"{{action_type}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Action Types\",\n      \"type\": \"piechart\"\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"bars\",\n            \"fillOpacity\": 100,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            },\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"never\",\n            \"spanNulls\": true\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          },\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 24,\n        \"x\": 0,\n        \"y\": 22\n      },\n      \"id\": 9,\n      \"options\": {\n        \"tooltip\": {\n          \"mode\": \"single\"\n        },\n        \"legend\": {\n          \"calcs\": [],\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\"\n        }\n      },\n      \"pluginVersion\": \"8.0.0\",\n      \"targets\": [\n        {\n          \"expr\": \"sum by (decision) (increase(odin_approval_decisions_total[1h]))\",\n          \"legendFormat\": \"{{decision}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Approval Decisions (Hourly)\",\n      \"type\": \"timeseries\"\n    }\n  ],\n  \"refresh\": \"10s\",\n  \"schemaVersion\": 27,\n  \"style\": \"dark\",\n  \"tags\": [\"odin-prime\", \"automation\", \"performance\"],\n  \"templating\": {\n    \"list\": []\n  },\n  \"time\": {\n    \"from\": \"now-3h\",\n    \"to\": \"now\"\n  },\n  \"timepicker\": {},\n  \"timezone\": \"\",\n  \"title\": \"ODIN Prime - Automation Performance\",\n  \"uid\": \"odin-prime-automation\",\n  \"version\": 0\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"grafana_dashboard":"1"},"name":"odin-prime-automation-dashboard","namespace":"monitoring"}}
    creationTimestamp: "2025-06-05T23:29:11Z"
    labels:
      grafana_dashboard: "1"
    name: odin-prime-automation-dashboard
    namespace: monitoring
    resourceVersion: "3886785"
    uid: e31c707a-823b-4f60-9050-3bd109e89371
- apiVersion: v1
  data:
    odin-prime-claude.json: |
      {
        "annotations": {
          "list": [
            {
              "builtIn": 1,
              "datasource": "-- Grafana --",
              "enable": true,
              "hide": true,
              "iconColor": "rgba(0, 211, 255, 1)",
              "name": "Annotations & Alerts",
              "type": "dashboard"
            }
          ]
        },
        "editable": true,
        "gnetId": null,
        "graphTooltip": 0,
        "id": null,
        "links": [],
        "panels": [
          {
            "datasource": "Prometheus",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "yellow",
                      "value": 30
                    },
                    {
                      "color": "red",
                      "value": 45
                    }
                  ]
                },
                "unit": "currencyUSD"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 6,
              "w": 6,
              "x": 0,
              "y": 0
            },
            "id": 1,
            "options": {
              "colorMode": "value",
              "graphMode": "area",
              "justifyMode": "auto",
              "orientation": "auto",
              "reduceOptions": {
                "values": false,
                "calcs": ["lastNotNull"]
              },
              "text": {},
              "textMode": "auto"
            },
            "pluginVersion": "8.0.0",
            "targets": [
              {
                "expr": "sum(odin_claude_cost_dollars_total)",
                "refId": "A"
              }
            ],
            "title": "Total Cost Today",
            "type": "stat"
          },
          {
            "datasource": "Prometheus",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "max": 50,
                "min": 0,
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "yellow",
                      "value": 30
                    },
                    {
                      "color": "red",
                      "value": 45
                    }
                  ]
                },
                "unit": "currencyUSD"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 6,
              "w": 6,
              "x": 6,
              "y": 0
            },
            "id": 2,
            "options": {
              "orientation": "auto",
              "reduceOptions": {
                "values": false,
                "calcs": ["lastNotNull"]
              },
              "showThresholdLabels": false,
              "showThresholdMarkers": true,
              "text": {}
            },
            "pluginVersion": "8.0.0",
            "targets": [
              {
                "expr": "sum(odin_claude_cost_dollars_total)",
                "refId": "A"
              }
            ],
            "title": "Daily Budget Usage",
            "type": "gauge"
          },
          {
            "datasource": "Prometheus",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    }
                  ]
                },
                "unit": "short"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 6,
              "w": 6,
              "x": 12,
              "y": 0
            },
            "id": 3,
            "options": {
              "colorMode": "value",
              "graphMode": "none",
              "justifyMode": "auto",
              "orientation": "auto",
              "reduceOptions": {
                "values": false,
                "calcs": ["lastNotNull"]
              },
              "text": {},
              "textMode": "auto"
            },
            "pluginVersion": "8.0.0",
            "targets": [
              {
                "expr": "sum(odin_claude_requests_total)",
                "refId": "A"
              }
            ],
            "title": "Total API Requests",
            "type": "stat"
          },
          {
            "datasource": "Prometheus",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "yellow",
                      "value": 0.05
                    },
                    {
                      "color": "red",
                      "value": 0.1
                    }
                  ]
                },
                "unit": "percentunit"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 6,
              "w": 6,
              "x": 18,
              "y": 0
            },
            "id": 4,
            "options": {
              "colorMode": "value",
              "graphMode": "none",
              "justifyMode": "auto",
              "orientation": "auto",
              "reduceOptions": {
                "values": false,
                "calcs": ["lastNotNull"]
              },
              "text": {},
              "textMode": "auto"
            },
            "pluginVersion": "8.0.0",
            "targets": [
              {
                "expr": "sum(rate(odin_claude_errors_total[1h])) / sum(rate(odin_claude_requests_total[1h]))",
                "refId": "A"
              }
            ],
            "title": "Error Rate",
            "type": "stat"
          },
          {
            "datasource": "Prometheus",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 10,
                  "gradientMode": "none",
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  },
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "never",
                  "spanNulls": true
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    }
                  ]
                },
                "unit": "currencyUSD"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 0,
              "y": 6
            },
            "id": 5,
            "options": {
              "tooltip": {
                "mode": "single"
              },
              "legend": {
                "calcs": [],
                "displayMode": "list",
                "placement": "bottom"
              }
            },
            "pluginVersion": "8.0.0",
            "targets": [
              {
                "expr": "sum(rate(odin_claude_cost_dollars_total[5m])) * 60",
                "legendFormat": "Cost/min",
                "refId": "A"
              }
            ],
            "title": "Cost Rate",
            "type": "timeseries"
          },
          {
            "datasource": "Prometheus",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 10,
                  "gradientMode": "none",
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  },
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "never",
                  "spanNulls": true
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    }
                  ]
                },
                "unit": "short"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 12,
              "y": 6
            },
            "id": 6,
            "options": {
              "tooltip": {
                "mode": "single"
              },
              "legend": {
                "calcs": [],
                "displayMode": "list",
                "placement": "bottom"
              }
            },
            "pluginVersion": "8.0.0",
            "targets": [
              {
                "expr": "sum(rate(odin_claude_tokens_used_total{type=\"prompt\"}[5m])) * 60",
                "legendFormat": "Prompt tokens/min",
                "refId": "A"
              },
              {
                "expr": "sum(rate(odin_claude_tokens_used_total{type=\"completion\"}[5m])) * 60",
                "legendFormat": "Completion tokens/min",
                "refId": "B"
              }
            ],
            "title": "Token Usage Rate",
            "type": "timeseries"
          },
          {
            "datasource": "Prometheus",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 10,
                  "gradientMode": "none",
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  },
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "never",
                  "spanNulls": true
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    }
                  ]
                },
                "unit": "s"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 0,
              "y": 14
            },
            "id": 7,
            "options": {
              "tooltip": {
                "mode": "single"
              },
              "legend": {
                "calcs": [],
                "displayMode": "list",
                "placement": "bottom"
              }
            },
            "pluginVersion": "8.0.0",
            "targets": [
              {
                "expr": "histogram_quantile(0.5, sum(rate(odin_claude_request_duration_seconds_bucket[5m])) by (le))",
                "legendFormat": "p50",
                "refId": "A"
              },
              {
                "expr": "histogram_quantile(0.95, sum(rate(odin_claude_request_duration_seconds_bucket[5m])) by (le))",
                "legendFormat": "p95",
                "refId": "B"
              },
              {
                "expr": "histogram_quantile(0.99, sum(rate(odin_claude_request_duration_seconds_bucket[5m])) by (le))",
                "legendFormat": "p99",
                "refId": "C"
              }
            ],
            "title": "API Response Time",
            "type": "timeseries"
          },
          {
            "datasource": "Prometheus",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  }
                },
                "mappings": [],
                "unit": "short"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 12,
              "y": 14
            },
            "id": 8,
            "options": {
              "pieType": "pie",
              "tooltip": {
                "mode": "single"
              },
              "legend": {
                "displayMode": "list",
                "placement": "right"
              }
            },
            "pluginVersion": "8.0.0",
            "targets": [
              {
                "expr": "sum by (error_type) (increase(odin_claude_errors_total[1h]))",
                "legendFormat": "{{error_type}}",
                "refId": "A"
              }
            ],
            "title": "Error Types",
            "type": "piechart"
          },
          {
            "datasource": "Prometheus",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  }
                },
                "mappings": [],
                "unit": "short"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 0,
              "y": 22
            },
            "id": 9,
            "options": {
              "pieType": "donut",
              "tooltip": {
                "mode": "single"
              },
              "legend": {
                "displayMode": "table",
                "placement": "right",
                "values": ["value", "percent"]
              }
            },
            "pluginVersion": "8.0.0",
            "targets": [
              {
                "expr": "sum by (reason) (increase(odin_claude_escalations_total[1h]))",
                "legendFormat": "{{reason}}",
                "refId": "A"
              }
            ],
            "title": "Escalation Reasons",
            "type": "piechart"
          },
          {
            "datasource": "Prometheus",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 10,
                  "gradientMode": "none",
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  },
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "never",
                  "spanNulls": true
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    }
                  ]
                },
                "unit": "short"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 12,
              "y": 22
            },
            "id": 10,
            "options": {
              "tooltip": {
                "mode": "single"
              },
              "legend": {
                "calcs": [],
                "displayMode": "list",
                "placement": "bottom"
              }
            },
            "pluginVersion": "8.0.0",
            "targets": [
              {
                "expr": "odin_claude_rate_limit_remaining",
                "legendFormat": "Remaining requests",
                "refId": "A"
              },
              {
                "expr": "odin_claude_queue_size",
                "legendFormat": "Queue size",
                "refId": "B"
              },
              {
                "expr": "sum(odin_claude_retry_count_total)",
                "legendFormat": "Total retries",
                "refId": "C"
              }
            ],
            "title": "Rate Limiting & Queue",
            "type": "timeseries"
          }
        ],
        "refresh": "10s",
        "schemaVersion": 27,
        "style": "dark",
        "tags": ["odin-prime", "claude", "ai"],
        "templating": {
          "list": []
        },
        "time": {
          "from": "now-6h",
          "to": "now"
        },
        "timepicker": {},
        "timezone": "",
        "title": "ODIN Prime - Claude API Monitoring",
        "uid": "odin-prime-claude",
        "version": 0
      }
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"odin-prime-claude.json":"{\n  \"annotations\": {\n    \"list\": [\n      {\n        \"builtIn\": 1,\n        \"datasource\": \"-- Grafana --\",\n        \"enable\": true,\n        \"hide\": true,\n        \"iconColor\": \"rgba(0, 211, 255, 1)\",\n        \"name\": \"Annotations \u0026 Alerts\",\n        \"type\": \"dashboard\"\n      }\n    ]\n  },\n  \"editable\": true,\n  \"gnetId\": null,\n  \"graphTooltip\": 0,\n  \"id\": null,\n  \"links\": [],\n  \"panels\": [\n    {\n      \"datasource\": \"Prometheus\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"yellow\",\n                \"value\": 30\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 45\n              }\n            ]\n          },\n          \"unit\": \"currencyUSD\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 6,\n        \"w\": 6,\n        \"x\": 0,\n        \"y\": 0\n      },\n      \"id\": 1,\n      \"options\": {\n        \"colorMode\": \"value\",\n        \"graphMode\": \"area\",\n        \"justifyMode\": \"auto\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"]\n        },\n        \"text\": {},\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"8.0.0\",\n      \"targets\": [\n        {\n          \"expr\": \"sum(odin_claude_cost_dollars_total)\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Total Cost Today\",\n      \"type\": \"stat\"\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"max\": 50,\n          \"min\": 0,\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"yellow\",\n                \"value\": 30\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 45\n              }\n            ]\n          },\n          \"unit\": \"currencyUSD\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 6,\n        \"w\": 6,\n        \"x\": 6,\n        \"y\": 0\n      },\n      \"id\": 2,\n      \"options\": {\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"]\n        },\n        \"showThresholdLabels\": false,\n        \"showThresholdMarkers\": true,\n        \"text\": {}\n      },\n      \"pluginVersion\": \"8.0.0\",\n      \"targets\": [\n        {\n          \"expr\": \"sum(odin_claude_cost_dollars_total)\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Daily Budget Usage\",\n      \"type\": \"gauge\"\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          },\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 6,\n        \"w\": 6,\n        \"x\": 12,\n        \"y\": 0\n      },\n      \"id\": 3,\n      \"options\": {\n        \"colorMode\": \"value\",\n        \"graphMode\": \"none\",\n        \"justifyMode\": \"auto\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"]\n        },\n        \"text\": {},\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"8.0.0\",\n      \"targets\": [\n        {\n          \"expr\": \"sum(odin_claude_requests_total)\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Total API Requests\",\n      \"type\": \"stat\"\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"yellow\",\n                \"value\": 0.05\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 0.1\n              }\n            ]\n          },\n          \"unit\": \"percentunit\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 6,\n        \"w\": 6,\n        \"x\": 18,\n        \"y\": 0\n      },\n      \"id\": 4,\n      \"options\": {\n        \"colorMode\": \"value\",\n        \"graphMode\": \"none\",\n        \"justifyMode\": \"auto\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"]\n        },\n        \"text\": {},\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"8.0.0\",\n      \"targets\": [\n        {\n          \"expr\": \"sum(rate(odin_claude_errors_total[1h])) / sum(rate(odin_claude_requests_total[1h]))\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Error Rate\",\n      \"type\": \"stat\"\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 10,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            },\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"never\",\n            \"spanNulls\": true\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          },\n          \"unit\": \"currencyUSD\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 0,\n        \"y\": 6\n      },\n      \"id\": 5,\n      \"options\": {\n        \"tooltip\": {\n          \"mode\": \"single\"\n        },\n        \"legend\": {\n          \"calcs\": [],\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\"\n        }\n      },\n      \"pluginVersion\": \"8.0.0\",\n      \"targets\": [\n        {\n          \"expr\": \"sum(rate(odin_claude_cost_dollars_total[5m])) * 60\",\n          \"legendFormat\": \"Cost/min\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Cost Rate\",\n      \"type\": \"timeseries\"\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 10,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            },\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"never\",\n            \"spanNulls\": true\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          },\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 6\n      },\n      \"id\": 6,\n      \"options\": {\n        \"tooltip\": {\n          \"mode\": \"single\"\n        },\n        \"legend\": {\n          \"calcs\": [],\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\"\n        }\n      },\n      \"pluginVersion\": \"8.0.0\",\n      \"targets\": [\n        {\n          \"expr\": \"sum(rate(odin_claude_tokens_used_total{type=\\\"prompt\\\"}[5m])) * 60\",\n          \"legendFormat\": \"Prompt tokens/min\",\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"sum(rate(odin_claude_tokens_used_total{type=\\\"completion\\\"}[5m])) * 60\",\n          \"legendFormat\": \"Completion tokens/min\",\n          \"refId\": \"B\"\n        }\n      ],\n      \"title\": \"Token Usage Rate\",\n      \"type\": \"timeseries\"\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 10,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            },\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"never\",\n            \"spanNulls\": true\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          },\n          \"unit\": \"s\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 0,\n        \"y\": 14\n      },\n      \"id\": 7,\n      \"options\": {\n        \"tooltip\": {\n          \"mode\": \"single\"\n        },\n        \"legend\": {\n          \"calcs\": [],\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\"\n        }\n      },\n      \"pluginVersion\": \"8.0.0\",\n      \"targets\": [\n        {\n          \"expr\": \"histogram_quantile(0.5, sum(rate(odin_claude_request_duration_seconds_bucket[5m])) by (le))\",\n          \"legendFormat\": \"p50\",\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"histogram_quantile(0.95, sum(rate(odin_claude_request_duration_seconds_bucket[5m])) by (le))\",\n          \"legendFormat\": \"p95\",\n          \"refId\": \"B\"\n        },\n        {\n          \"expr\": \"histogram_quantile(0.99, sum(rate(odin_claude_request_duration_seconds_bucket[5m])) by (le))\",\n          \"legendFormat\": \"p99\",\n          \"refId\": \"C\"\n        }\n      ],\n      \"title\": \"API Response Time\",\n      \"type\": \"timeseries\"\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            }\n          },\n          \"mappings\": [],\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 14\n      },\n      \"id\": 8,\n      \"options\": {\n        \"pieType\": \"pie\",\n        \"tooltip\": {\n          \"mode\": \"single\"\n        },\n        \"legend\": {\n          \"displayMode\": \"list\",\n          \"placement\": \"right\"\n        }\n      },\n      \"pluginVersion\": \"8.0.0\",\n      \"targets\": [\n        {\n          \"expr\": \"sum by (error_type) (increase(odin_claude_errors_total[1h]))\",\n          \"legendFormat\": \"{{error_type}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Error Types\",\n      \"type\": \"piechart\"\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            }\n          },\n          \"mappings\": [],\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 0,\n        \"y\": 22\n      },\n      \"id\": 9,\n      \"options\": {\n        \"pieType\": \"donut\",\n        \"tooltip\": {\n          \"mode\": \"single\"\n        },\n        \"legend\": {\n          \"displayMode\": \"table\",\n          \"placement\": \"right\",\n          \"values\": [\"value\", \"percent\"]\n        }\n      },\n      \"pluginVersion\": \"8.0.0\",\n      \"targets\": [\n        {\n          \"expr\": \"sum by (reason) (increase(odin_claude_escalations_total[1h]))\",\n          \"legendFormat\": \"{{reason}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Escalation Reasons\",\n      \"type\": \"piechart\"\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 10,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            },\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"never\",\n            \"spanNulls\": true\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          },\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 22\n      },\n      \"id\": 10,\n      \"options\": {\n        \"tooltip\": {\n          \"mode\": \"single\"\n        },\n        \"legend\": {\n          \"calcs\": [],\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\"\n        }\n      },\n      \"pluginVersion\": \"8.0.0\",\n      \"targets\": [\n        {\n          \"expr\": \"odin_claude_rate_limit_remaining\",\n          \"legendFormat\": \"Remaining requests\",\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"odin_claude_queue_size\",\n          \"legendFormat\": \"Queue size\",\n          \"refId\": \"B\"\n        },\n        {\n          \"expr\": \"sum(odin_claude_retry_count_total)\",\n          \"legendFormat\": \"Total retries\",\n          \"refId\": \"C\"\n        }\n      ],\n      \"title\": \"Rate Limiting \u0026 Queue\",\n      \"type\": \"timeseries\"\n    }\n  ],\n  \"refresh\": \"10s\",\n  \"schemaVersion\": 27,\n  \"style\": \"dark\",\n  \"tags\": [\"odin-prime\", \"claude\", \"ai\"],\n  \"templating\": {\n    \"list\": []\n  },\n  \"time\": {\n    \"from\": \"now-6h\",\n    \"to\": \"now\"\n  },\n  \"timepicker\": {},\n  \"timezone\": \"\",\n  \"title\": \"ODIN Prime - Claude API Monitoring\",\n  \"uid\": \"odin-prime-claude\",\n  \"version\": 0\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"grafana_dashboard":"1"},"name":"odin-prime-claude-dashboard","namespace":"monitoring"}}
    creationTimestamp: "2025-06-05T23:29:06Z"
    labels:
      grafana_dashboard: "1"
    name: odin-prime-claude-dashboard
    namespace: monitoring
    resourceVersion: "3886751"
    uid: 9a358ef4-87b0-4fa1-9d30-42ef918eb3ef
- apiVersion: v1
  data:
    odin-prime.rules.yaml: "groups:\n- name: odin-prime-health\n  interval: 30s\n
      \ rules:\n  - alert: OdinPrimeAlertIngestionDown\n    expr: up{job=\"odin-prime-alert-ingestion\"}
      == 0\n    for: 2m\n    labels:\n      severity: critical\n      component: odin-prime\n
      \   annotations:\n      summary: \"ODIN Prime Alert Ingestion is down\"\n      description:
      \"The AI-powered alert analysis system is not responding. Alerts are not being
      analyzed.\"\n      \n  - alert: OdinPrimeHighLatency\n    expr: histogram_quantile(0.95,
      odin_alert_processing_duration_seconds_bucket) > 5\n    for: 5m\n    labels:\n
      \     severity: warning\n      component: odin-prime\n    annotations:\n      summary:
      \"ODIN Prime processing latency is high\"\n      description: \"Alert analysis
      is taking longer than 5 seconds at p95\"\n      \n  - alert: OdinPrimeClaudeAPIFailure\n
      \   expr: odin_claude_api_errors_total > 0\n    for: 1m\n    labels:\n      severity:
      warning\n      component: odin-prime\n    annotations:\n      summary: \"Claude
      API errors detected\"\n      description: \"ODIN Prime is experiencing errors
      when calling Claude API\"\n      \n  - alert: OdinPrimeAutomationFailures\n
      \   expr: rate(odin_automation_failed_total[5m]) > 0.1\n    for: 5m\n    labels:\n
      \     severity: warning\n      component: odin-prime\n    annotations:\n      summary:
      \"High automation failure rate\"\n      description: \"More than 10% of automation
      attempts are failing\"\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"odin-prime.rules.yaml":"groups:\n- name: odin-prime-health\n  interval: 30s\n  rules:\n  - alert: OdinPrimeAlertIngestionDown\n    expr: up{job=\"odin-prime-alert-ingestion\"} == 0\n    for: 2m\n    labels:\n      severity: critical\n      component: odin-prime\n    annotations:\n      summary: \"ODIN Prime Alert Ingestion is down\"\n      description: \"The AI-powered alert analysis system is not responding. Alerts are not being analyzed.\"\n      \n  - alert: OdinPrimeHighLatency\n    expr: histogram_quantile(0.95, odin_alert_processing_duration_seconds_bucket) \u003e 5\n    for: 5m\n    labels:\n      severity: warning\n      component: odin-prime\n    annotations:\n      summary: \"ODIN Prime processing latency is high\"\n      description: \"Alert analysis is taking longer than 5 seconds at p95\"\n      \n  - alert: OdinPrimeClaudeAPIFailure\n    expr: odin_claude_api_errors_total \u003e 0\n    for: 1m\n    labels:\n      severity: warning\n      component: odin-prime\n    annotations:\n      summary: \"Claude API errors detected\"\n      description: \"ODIN Prime is experiencing errors when calling Claude API\"\n      \n  - alert: OdinPrimeAutomationFailures\n    expr: rate(odin_automation_failed_total[5m]) \u003e 0.1\n    for: 5m\n    labels:\n      severity: warning\n      component: odin-prime\n    annotations:\n      summary: \"High automation failure rate\"\n      description: \"More than 10% of automation attempts are failing\"\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"odin-prime-monitoring-rules","namespace":"monitoring"}}
    creationTimestamp: "2025-06-05T04:18:02Z"
    name: odin-prime-monitoring-rules
    namespace: monitoring
    resourceVersion: "3378428"
    uid: 393bb58c-3abb-4eeb-8576-16a9f36e6c89
- apiVersion: v1
  data:
    odin-prime-overview.json: |
      {
        "annotations": {
          "list": [
            {
              "builtIn": 1,
              "datasource": "-- Grafana --",
              "enable": true,
              "hide": true,
              "iconColor": "rgba(0, 211, 255, 1)",
              "name": "Annotations & Alerts",
              "type": "dashboard"
            }
          ]
        },
        "editable": true,
        "gnetId": null,
        "graphTooltip": 0,
        "id": null,
        "links": [],
        "panels": [
          {
            "datasource": "Prometheus",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 10,
                  "gradientMode": "none",
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  },
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "never",
                  "spanNulls": true,
                  "stacking": {
                    "group": "A",
                    "mode": "none"
                  },
                  "thresholdsStyle": {
                    "mode": "off"
                  }
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "red",
                      "value": 80
                    }
                  ]
                },
                "unit": "short"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 0,
              "y": 0
            },
            "id": 2,
            "options": {
              "tooltip": {
                "mode": "single"
              },
              "legend": {
                "calcs": [],
                "displayMode": "list",
                "placement": "bottom"
              }
            },
            "pluginVersion": "8.0.0",
            "targets": [
              {
                "expr": "sum(rate(odin_alerts_received_total[5m])) * 60",
                "legendFormat": "Alerts/min",
                "refId": "A"
              },
              {
                "expr": "sum(rate(odin_alerts_processed_total[5m])) * 60",
                "legendFormat": "Processed/min",
                "refId": "B"
              },
              {
                "expr": "sum(rate(odin_alerts_escalated_total[5m])) * 60",
                "legendFormat": "Escalated/min",
                "refId": "C"
              }
            ],
            "title": "Alert Processing Rate",
            "type": "timeseries"
          },
          {
            "datasource": "Prometheus",
            "fieldConfig": {
              "defaults": {
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "red",
                      "value": 0.8
                    }
                  ]
                },
                "unit": "percentunit"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 6,
              "x": 12,
              "y": 0
            },
            "id": 3,
            "options": {
              "orientation": "auto",
              "reduceOptions": {
                "values": false,
                "calcs": ["lastNotNull"]
              },
              "showThresholdLabels": false,
              "showThresholdMarkers": true,
              "text": {}
            },
            "pluginVersion": "8.0.0",
            "targets": [
              {
                "expr": "sum(rate(odin_alerts_escalated_total[1h])) / sum(rate(odin_alerts_received_total[1h]))",
                "refId": "A"
              }
            ],
            "title": "Escalation Rate",
            "type": "gauge"
          },
          {
            "datasource": "Prometheus",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "yellow",
                      "value": 25
                    },
                    {
                      "color": "red",
                      "value": 45
                    }
                  ]
                },
                "unit": "currencyUSD"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 6,
              "x": 18,
              "y": 0
            },
            "id": 4,
            "options": {
              "colorMode": "value",
              "graphMode": "area",
              "justifyMode": "auto",
              "orientation": "auto",
              "reduceOptions": {
                "values": false,
                "calcs": ["lastNotNull"]
              },
              "text": {},
              "textMode": "auto"
            },
            "pluginVersion": "8.0.0",
            "targets": [
              {
                "expr": "sum(odin_claude_cost_dollars_total)",
                "refId": "A"
              }
            ],
            "title": "Claude API Cost Today",
            "type": "stat"
          },
          {
            "datasource": "Prometheus",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  }
                },
                "mappings": [],
                "unit": "short"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 0,
              "y": 8
            },
            "id": 5,
            "options": {
              "pieType": "pie",
              "tooltip": {
                "mode": "single"
              },
              "legend": {
                "displayMode": "list",
                "placement": "right"
              }
            },
            "pluginVersion": "8.0.0",
            "targets": [
              {
                "expr": "sum by (severity) (increase(odin_tier1_severity_total[1h]))",
                "legendFormat": "{{severity}}",
                "refId": "A"
              }
            ],
            "title": "Alert Severity Distribution",
            "type": "piechart"
          },
          {
            "datasource": "Prometheus",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 10,
                  "gradientMode": "none",
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  },
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "never",
                  "spanNulls": true
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    }
                  ]
                },
                "unit": "ms"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 12,
              "y": 8
            },
            "id": 6,
            "options": {
              "tooltip": {
                "mode": "single"
              },
              "legend": {
                "calcs": [],
                "displayMode": "list",
                "placement": "bottom"
              }
            },
            "pluginVersion": "8.0.0",
            "targets": [
              {
                "expr": "histogram_quantile(0.5, sum(rate(odin_alert_processing_seconds_bucket[5m])) by (le)) * 1000",
                "legendFormat": "p50",
                "refId": "A"
              },
              {
                "expr": "histogram_quantile(0.95, sum(rate(odin_alert_processing_seconds_bucket[5m])) by (le)) * 1000",
                "legendFormat": "p95",
                "refId": "B"
              },
              {
                "expr": "histogram_quantile(0.99, sum(rate(odin_alert_processing_seconds_bucket[5m])) by (le)) * 1000",
                "legendFormat": "p99",
                "refId": "C"
              }
            ],
            "title": "Alert Processing Latency",
            "type": "timeseries"
          },
          {
            "datasource": "Prometheus",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "red",
                      "value": null
                    },
                    {
                      "color": "yellow",
                      "value": 0.9
                    },
                    {
                      "color": "green",
                      "value": 0.95
                    }
                  ]
                },
                "unit": "percentunit"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 4,
              "w": 6,
              "x": 0,
              "y": 16
            },
            "id": 7,
            "options": {
              "colorMode": "value",
              "graphMode": "none",
              "justifyMode": "auto",
              "orientation": "auto",
              "reduceOptions": {
                "values": false,
                "calcs": ["lastNotNull"]
              },
              "text": {},
              "textMode": "auto"
            },
            "pluginVersion": "8.0.0",
            "targets": [
              {
                "expr": "avg(up{namespace=\"odin-prime\"})",
                "refId": "A"
              }
            ],
            "title": "Service Availability",
            "type": "stat"
          },
          {
            "datasource": "Prometheus",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "yellow",
                      "value": 100
                    },
                    {
                      "color": "red",
                      "value": 500
                    }
                  ]
                },
                "unit": "short"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 4,
              "w": 6,
              "x": 6,
              "y": 16
            },
            "id": 8,
            "options": {
              "colorMode": "value",
              "graphMode": "area",
              "justifyMode": "auto",
              "orientation": "auto",
              "reduceOptions": {
                "values": false,
                "calcs": ["lastNotNull"]
              },
              "text": {},
              "textMode": "auto"
            },
            "pluginVersion": "8.0.0",
            "targets": [
              {
                "expr": "sum(odin_pattern_matches_total)",
                "refId": "A"
              }
            ],
            "title": "Pattern Matches",
            "type": "stat"
          },
          {
            "datasource": "Prometheus",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  }
                },
                "mappings": [],
                "unit": "short"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 12,
              "y": 16
            },
            "id": 9,
            "options": {
              "pieType": "donut",
              "tooltip": {
                "mode": "single"
              },
              "legend": {
                "displayMode": "table",
                "placement": "right",
                "values": ["value", "percent"]
              }
            },
            "pluginVersion": "8.0.0",
            "targets": [
              {
                "expr": "sum by (path) (increase(odin_tier1_hybrid_path_usage_total[1h]))",
                "legendFormat": "{{path}}",
                "refId": "A"
              }
            ],
            "title": "Tier 1 Path Usage (Hybrid)",
            "type": "piechart"
          }
        ],
        "refresh": "10s",
        "schemaVersion": 27,
        "style": "dark",
        "tags": ["odin-prime", "automation", "overview"],
        "templating": {
          "list": []
        },
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "timepicker": {},
        "timezone": "",
        "title": "ODIN Prime - Overview",
        "uid": "odin-prime-overview",
        "version": 0
      }
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"odin-prime-overview.json":"{\n  \"annotations\": {\n    \"list\": [\n      {\n        \"builtIn\": 1,\n        \"datasource\": \"-- Grafana --\",\n        \"enable\": true,\n        \"hide\": true,\n        \"iconColor\": \"rgba(0, 211, 255, 1)\",\n        \"name\": \"Annotations \u0026 Alerts\",\n        \"type\": \"dashboard\"\n      }\n    ]\n  },\n  \"editable\": true,\n  \"gnetId\": null,\n  \"graphTooltip\": 0,\n  \"id\": null,\n  \"links\": [],\n  \"panels\": [\n    {\n      \"datasource\": \"Prometheus\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 10,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            },\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"never\",\n            \"spanNulls\": true,\n            \"stacking\": {\n              \"group\": \"A\",\n              \"mode\": \"none\"\n            },\n            \"thresholdsStyle\": {\n              \"mode\": \"off\"\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 80\n              }\n            ]\n          },\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 0,\n        \"y\": 0\n      },\n      \"id\": 2,\n      \"options\": {\n        \"tooltip\": {\n          \"mode\": \"single\"\n        },\n        \"legend\": {\n          \"calcs\": [],\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\"\n        }\n      },\n      \"pluginVersion\": \"8.0.0\",\n      \"targets\": [\n        {\n          \"expr\": \"sum(rate(odin_alerts_received_total[5m])) * 60\",\n          \"legendFormat\": \"Alerts/min\",\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"sum(rate(odin_alerts_processed_total[5m])) * 60\",\n          \"legendFormat\": \"Processed/min\",\n          \"refId\": \"B\"\n        },\n        {\n          \"expr\": \"sum(rate(odin_alerts_escalated_total[5m])) * 60\",\n          \"legendFormat\": \"Escalated/min\",\n          \"refId\": \"C\"\n        }\n      ],\n      \"title\": \"Alert Processing Rate\",\n      \"type\": \"timeseries\"\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 0.8\n              }\n            ]\n          },\n          \"unit\": \"percentunit\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 6,\n        \"x\": 12,\n        \"y\": 0\n      },\n      \"id\": 3,\n      \"options\": {\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"]\n        },\n        \"showThresholdLabels\": false,\n        \"showThresholdMarkers\": true,\n        \"text\": {}\n      },\n      \"pluginVersion\": \"8.0.0\",\n      \"targets\": [\n        {\n          \"expr\": \"sum(rate(odin_alerts_escalated_total[1h])) / sum(rate(odin_alerts_received_total[1h]))\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Escalation Rate\",\n      \"type\": \"gauge\"\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"yellow\",\n                \"value\": 25\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 45\n              }\n            ]\n          },\n          \"unit\": \"currencyUSD\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 6,\n        \"x\": 18,\n        \"y\": 0\n      },\n      \"id\": 4,\n      \"options\": {\n        \"colorMode\": \"value\",\n        \"graphMode\": \"area\",\n        \"justifyMode\": \"auto\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"]\n        },\n        \"text\": {},\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"8.0.0\",\n      \"targets\": [\n        {\n          \"expr\": \"sum(odin_claude_cost_dollars_total)\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Claude API Cost Today\",\n      \"type\": \"stat\"\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            }\n          },\n          \"mappings\": [],\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 0,\n        \"y\": 8\n      },\n      \"id\": 5,\n      \"options\": {\n        \"pieType\": \"pie\",\n        \"tooltip\": {\n          \"mode\": \"single\"\n        },\n        \"legend\": {\n          \"displayMode\": \"list\",\n          \"placement\": \"right\"\n        }\n      },\n      \"pluginVersion\": \"8.0.0\",\n      \"targets\": [\n        {\n          \"expr\": \"sum by (severity) (increase(odin_tier1_severity_total[1h]))\",\n          \"legendFormat\": \"{{severity}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Alert Severity Distribution\",\n      \"type\": \"piechart\"\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 10,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            },\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"never\",\n            \"spanNulls\": true\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          },\n          \"unit\": \"ms\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 8\n      },\n      \"id\": 6,\n      \"options\": {\n        \"tooltip\": {\n          \"mode\": \"single\"\n        },\n        \"legend\": {\n          \"calcs\": [],\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\"\n        }\n      },\n      \"pluginVersion\": \"8.0.0\",\n      \"targets\": [\n        {\n          \"expr\": \"histogram_quantile(0.5, sum(rate(odin_alert_processing_seconds_bucket[5m])) by (le)) * 1000\",\n          \"legendFormat\": \"p50\",\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"histogram_quantile(0.95, sum(rate(odin_alert_processing_seconds_bucket[5m])) by (le)) * 1000\",\n          \"legendFormat\": \"p95\",\n          \"refId\": \"B\"\n        },\n        {\n          \"expr\": \"histogram_quantile(0.99, sum(rate(odin_alert_processing_seconds_bucket[5m])) by (le)) * 1000\",\n          \"legendFormat\": \"p99\",\n          \"refId\": \"C\"\n        }\n      ],\n      \"title\": \"Alert Processing Latency\",\n      \"type\": \"timeseries\"\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"red\",\n                \"value\": null\n              },\n              {\n                \"color\": \"yellow\",\n                \"value\": 0.9\n              },\n              {\n                \"color\": \"green\",\n                \"value\": 0.95\n              }\n            ]\n          },\n          \"unit\": \"percentunit\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 4,\n        \"w\": 6,\n        \"x\": 0,\n        \"y\": 16\n      },\n      \"id\": 7,\n      \"options\": {\n        \"colorMode\": \"value\",\n        \"graphMode\": \"none\",\n        \"justifyMode\": \"auto\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"]\n        },\n        \"text\": {},\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"8.0.0\",\n      \"targets\": [\n        {\n          \"expr\": \"avg(up{namespace=\\\"odin-prime\\\"})\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Service Availability\",\n      \"type\": \"stat\"\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"yellow\",\n                \"value\": 100\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 500\n              }\n            ]\n          },\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 4,\n        \"w\": 6,\n        \"x\": 6,\n        \"y\": 16\n      },\n      \"id\": 8,\n      \"options\": {\n        \"colorMode\": \"value\",\n        \"graphMode\": \"area\",\n        \"justifyMode\": \"auto\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"]\n        },\n        \"text\": {},\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"8.0.0\",\n      \"targets\": [\n        {\n          \"expr\": \"sum(odin_pattern_matches_total)\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Pattern Matches\",\n      \"type\": \"stat\"\n    },\n    {\n      \"datasource\": \"Prometheus\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            }\n          },\n          \"mappings\": [],\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 16\n      },\n      \"id\": 9,\n      \"options\": {\n        \"pieType\": \"donut\",\n        \"tooltip\": {\n          \"mode\": \"single\"\n        },\n        \"legend\": {\n          \"displayMode\": \"table\",\n          \"placement\": \"right\",\n          \"values\": [\"value\", \"percent\"]\n        }\n      },\n      \"pluginVersion\": \"8.0.0\",\n      \"targets\": [\n        {\n          \"expr\": \"sum by (path) (increase(odin_tier1_hybrid_path_usage_total[1h]))\",\n          \"legendFormat\": \"{{path}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Tier 1 Path Usage (Hybrid)\",\n      \"type\": \"piechart\"\n    }\n  ],\n  \"refresh\": \"10s\",\n  \"schemaVersion\": 27,\n  \"style\": \"dark\",\n  \"tags\": [\"odin-prime\", \"automation\", \"overview\"],\n  \"templating\": {\n    \"list\": []\n  },\n  \"time\": {\n    \"from\": \"now-1h\",\n    \"to\": \"now\"\n  },\n  \"timepicker\": {},\n  \"timezone\": \"\",\n  \"title\": \"ODIN Prime - Overview\",\n  \"uid\": \"odin-prime-overview\",\n  \"version\": 0\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"grafana_dashboard":"1"},"name":"odin-prime-overview-dashboard","namespace":"monitoring"}}
    creationTimestamp: "2025-06-04T20:56:24Z"
    labels:
      grafana_dashboard: "1"
    name: odin-prime-overview-dashboard
    namespace: monitoring
    resourceVersion: "3886704"
    uid: df6b4532-dac3-4acd-995f-21e695b2c553
- apiVersion: v1
  data:
    odin-prime-scrape.yaml: |
      - job_name: 'odin-prime-alert-ingestion'
        static_configs:
          - targets: ['alert-ingestion-v2.odin-prime.svc.cluster.local:8080']
        metrics_path: '/metrics'
        scrape_interval: 30s

      - job_name: 'odin-prime-tier1-ml'
        static_configs:
          - targets: ['tier1-phi35-updated.odin-prime.svc.cluster.local:8080']
        metrics_path: '/metrics'
        scrape_interval: 30s
        scrape_timeout: 25s  # ML inference can be slow

      - job_name: 'odin-prime-escalation'
        static_configs:
          - targets: ['escalation-service-basic.odin-prime.svc.cluster.local:8080']
        metrics_path: '/metrics'
        scrape_interval: 30s

      - job_name: 'odin-prime-automation'
        static_configs:
          - targets: ['automation-engine.odin-prime.svc.cluster.local:8080']
        metrics_path: '/metrics'
        scrape_interval: 30s

      - job_name: 'odin-prime-pattern-matcher'
        static_configs:
          - targets: ['pattern-matcher.odin-prime.svc.cluster.local:8080']
        metrics_path: '/metrics'
        scrape_interval: 30s

      - job_name: 'odin-prime-claude-api'
        static_configs:
          - targets: ['escalation-service.odin-prime.svc.cluster.local:8080']
        metrics_path: '/metrics'
        scrape_interval: 60s  # Less frequent for external API
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"odin-prime-scrape.yaml":"- job_name: 'odin-prime-alert-ingestion'\n  static_configs:\n    - targets: ['alert-ingestion-v2.odin-prime.svc.cluster.local:8080']\n  metrics_path: '/metrics'\n  scrape_interval: 30s\n\n- job_name: 'odin-prime-tier1-ml'\n  static_configs:\n    - targets: ['tier1-phi35-updated.odin-prime.svc.cluster.local:8080']\n  metrics_path: '/metrics'\n  scrape_interval: 30s\n  scrape_timeout: 25s  # ML inference can be slow\n\n- job_name: 'odin-prime-escalation'\n  static_configs:\n    - targets: ['escalation-service-basic.odin-prime.svc.cluster.local:8080']\n  metrics_path: '/metrics'\n  scrape_interval: 30s\n\n- job_name: 'odin-prime-automation'\n  static_configs:\n    - targets: ['automation-engine.odin-prime.svc.cluster.local:8080']\n  metrics_path: '/metrics'\n  scrape_interval: 30s\n\n- job_name: 'odin-prime-pattern-matcher'\n  static_configs:\n    - targets: ['pattern-matcher.odin-prime.svc.cluster.local:8080']\n  metrics_path: '/metrics'\n  scrape_interval: 30s\n\n- job_name: 'odin-prime-claude-api'\n  static_configs:\n    - targets: ['escalation-service.odin-prime.svc.cluster.local:8080']\n  metrics_path: '/metrics'\n  scrape_interval: 60s  # Less frequent for external API\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"odin-prime-prometheus-config","namespace":"monitoring"}}
    creationTimestamp: "2025-06-06T15:03:37Z"
    name: odin-prime-prometheus-config
    namespace: monitoring
    resourceVersion: "4301137"
    uid: aa6ba4a0-36fd-4b6d-9018-b670dff5e320
- apiVersion: v1
  data:
    odin-stack-alerts.yaml: "groups:\n- name: odin_monitoring_stack\n  interval: 30s\n
      \ rules:\n  # Prometheus\n  - alert: PrometheusDown\n    expr: up{job=\"prometheus\"}
      == 0 or absent(up{job=\"prometheus\"})\n    for: 2m\n    labels:\n      severity:
      critical\n      component: monitoring-stack\n      service: prometheus\n    annotations:\n
      \     summary: \"Prometheus is down\"\n      description: \"Prometheus server
      is unreachable. All metrics collection has stopped.\"\n      \n  - alert: PrometheusStorageFull\n
      \   expr: (node_filesystem_avail_bytes{mountpoint=\"/var/lib/odin/prometheus\"}
      / node_filesystem_size_bytes{mountpoint=\"/var/lib/odin/prometheus\"}) < 0.1\n
      \   for: 5m\n    labels:\n      severity: critical\n      component: monitoring-stack\n
      \     service: prometheus\n    annotations:\n      summary: \"Prometheus storage
      is almost full\"\n      description: \"Prometheus storage has less than 10%
      free space. Metrics may be lost.\"\n      \n  - alert: PrometheusHighMemoryUsage\n
      \   expr: (container_memory_usage_bytes{namespace=\"monitoring\",pod=~\"prometheus-.*\"}
      / container_spec_memory_limit_bytes{namespace=\"monitoring\",pod=~\"prometheus-.*\"})
      > 0.9\n    for: 5m\n    labels:\n      severity: warning\n      component: monitoring-stack\n
      \     service: prometheus\n    annotations:\n      summary: \"Prometheus high
      memory usage\"\n      description: \"Prometheus is using {{ $value }}% of its
      memory limit\"\n      \n  - alert: PrometheusReloadFailed\n    expr: prometheus_config_last_reload_successful
      != 1\n    for: 5m\n    labels:\n      severity: warning\n      component: monitoring-stack\n
      \     service: prometheus\n    annotations:\n      summary: \"Prometheus configuration
      reload failed\"\n      description: \"Prometheus failed to reload its configuration.
      Check logs for details.\"\n      \n  # Grafana\n  - alert: GrafanaDown\n    expr:
      up{job=\"grafana\"} == 0 or probe_success{job=\"blackbox\",instance=~\".*grafana.*\"}
      == 0\n    for: 2m\n    labels:\n      severity: critical\n      component: monitoring-stack\n
      \     service: grafana\n    annotations:\n      summary: \"Grafana is down\"\n
      \     description: \"Grafana is unreachable. Dashboards and visualization unavailable.\"\n
      \     \n  - alert: GrafanaDatabaseError\n    expr: increase(grafana_database_failed_queries_total[5m])
      > 5\n    for: 5m\n    labels:\n      severity: warning\n      component: monitoring-stack\n
      \     service: grafana\n    annotations:\n      summary: \"Grafana database
      errors\"\n      description: \"Grafana is experiencing database query failures\"\n
      \     \n  # Loki\n  - alert: LokiDown\n    expr: up{job=\"loki\"} == 0 or absent(up{job=\"loki\"})\n
      \   for: 2m\n    labels:\n      severity: critical\n      component: monitoring-stack\n
      \     service: loki\n    annotations:\n      summary: \"Loki is down\"\n      description:
      \"Loki log aggregation service is unreachable. Logs are not being stored.\"\n
      \     \n  - alert: LokiStorageFull\n    expr: (node_filesystem_avail_bytes{mountpoint=\"/var/lib/odin/loki\"}
      / node_filesystem_size_bytes{mountpoint=\"/var/lib/odin/loki\"}) < 0.1\n    for:
      5m\n    labels:\n      severity: critical\n      component: monitoring-stack\n
      \     service: loki\n    annotations:\n      summary: \"Loki storage is almost
      full\"\n      description: \"Loki storage has less than 10% free space. Logs
      may be lost.\"\n      \n  - alert: LokiIngesterNotReady\n    expr: loki_ingester_ready
      == 0\n    for: 5m\n    labels:\n      severity: warning\n      component: monitoring-stack\n
      \     service: loki\n    annotations:\n      summary: \"Loki ingester not ready\"\n
      \     description: \"Loki ingester is not ready to accept logs\"\n      \n  #
      AlertManager\n  - alert: AlertManagerDown\n    expr: up{job=\"alertmanager\"}
      == 0 or absent(up{job=\"alertmanager\"})\n    for: 2m\n    labels:\n      severity:
      critical\n      component: monitoring-stack\n      service: alertmanager\n    annotations:\n
      \     summary: \"AlertManager is down\"\n      description: \"AlertManager is
      unreachable. Alerts will not be routed or sent.\"\n      \n  - alert: AlertManagerConfigNotSynced\n
      \   expr: alertmanager_config_last_reload_successful != 1\n    for: 5m\n    labels:\n
      \     severity: warning\n      component: monitoring-stack\n      service: alertmanager\n
      \   annotations:\n      summary: \"AlertManager configuration reload failed\"\n
      \     description: \"AlertManager failed to reload configuration\"\n      \n
      \ # Promtail\n  - alert: PromtailDown\n    expr: up{job=\"promtail\"} == 0 or
      absent(up{job=\"promtail\"})\n    for: 5m\n    labels:\n      severity: warning\n
      \     component: monitoring-stack\n      service: promtail\n    annotations:\n
      \     summary: \"Promtail is down\"\n      description: \"Promtail log collector
      on {{ $labels.instance }} is down. Logs not being collected.\"\n      \n  -
      alert: PromtailDroppedLogs\n    expr: rate(promtail_dropped_entries_total[5m])
      > 0\n    for: 5m\n    labels:\n      severity: warning\n      component: monitoring-stack\n
      \     service: promtail\n    annotations:\n      summary: \"Promtail dropping
      logs\"\n      description: \"Promtail is dropping {{ $value }} logs per second\"\n
      \     \n  # Node Exporter\n  - alert: NodeExporterDown\n    expr: up{job=\"node-exporter\"}
      == 0\n    for: 2m\n    labels:\n      severity: critical\n      component: monitoring-stack\n
      \     service: node-exporter\n    annotations:\n      summary: \"Node Exporter
      is down\"\n      description: \"Node Exporter on {{ $labels.instance }} is down.
      System metrics unavailable.\"\n      \n  # Power Exporter (GPU)\n  - alert:
      PowerExporterDown\n    expr: up{job=\"power-exporter\"} == 0\n    for: 5m\n
      \   labels:\n      severity: warning\n      component: monitoring-stack\n      service:
      power-exporter\n    annotations:\n      summary: \"Power Exporter is down\"\n
      \     description: \"Power Exporter is down. GPU metrics unavailable.\"\n      \n
      \ - alert: PowerExporterUnhealthy\n    expr: power_exporter_health_status !=
      1\n    for: 5m\n    labels:\n      severity: warning\n      component: monitoring-stack\n
      \     service: power-exporter\n    annotations:\n      summary: \"Power Exporter
      is unhealthy\"\n      description: \"Power Exporter health check is failing\"\n
      \     \n  # cAdvisor\n  - alert: CAdvisorDown\n    expr: up{job=\"cadvisor\"}
      == 0\n    for: 5m\n    labels:\n      severity: warning\n      component: monitoring-stack\n
      \     service: cadvisor\n    annotations:\n      summary: \"cAdvisor is down\"\n
      \     description: \"cAdvisor container metrics collector is down\"\n      \n
      \ # Kube State Metrics\n  - alert: KubeStateMetricsDown\n    expr: up{job=\"kube-state-metrics\"}
      == 0 or absent(up{job=\"kube-state-metrics\"})\n    for: 5m\n    labels:\n      severity:
      warning\n      component: monitoring-stack\n      service: kube-state-metrics\n
      \   annotations:\n      summary: \"Kube State Metrics is down\"\n      description:
      \"Kube State Metrics is down. Kubernetes resource metrics unavailable.\"\n      \n
      \ # Claude Code Exporter\n  - alert: ClaudeCodeExporterDown\n    expr: up{job=\"claude-code-exporter\"}
      == 0\n    for: 5m\n    labels:\n      severity: info\n      component: monitoring-stack\n
      \     service: claude-code-exporter\n    annotations:\n      summary: \"Claude
      Code Exporter is down\"\n      description: \"Claude Code metrics exporter is
      down\"\n      \n  # Network Exporter\n  - alert: NetworkExporterDown\n    expr:
      up{job=\"network-exporter\"} == 0\n    for: 5m\n    labels:\n      severity:
      info\n      component: monitoring-stack\n      service: network-exporter\n    annotations:\n
      \     summary: \"Network Exporter is down\"\n      description: \"Network metrics
      exporter is down\"\n      \n  # Overall Stack Health\n  - alert: MonitoringStackDegraded\n
      \   expr: |\n      (count(up{job=~\"prometheus|grafana|loki|alertmanager|node-exporter\"}
      == 0) > 0) or\n      (count(ALERTS{alertname=~\".*Down\",severity=\"critical\"})
      > 0)\n    for: 5m\n    labels:\n      severity: warning\n      component: monitoring-stack\n
      \   annotations:\n      summary: \"Monitoring stack is degraded\"\n      description:
      \"One or more critical monitoring components are down\"\n      \n  - alert:
      MonitoringStackCritical\n    expr: |\n      count(up{job=~\"prometheus|grafana|loki|alertmanager\"}
      == 0) > 2\n    for: 2m\n    labels:\n      severity: critical\n      component:
      monitoring-stack\n    annotations:\n      summary: \"Monitoring stack critically
      degraded\"\n      description: \"Multiple core monitoring components are down.
      Immediate action required!\"\n      \n- name: odin_backup_alerts\n  interval:
      60s\n  rules:\n  - alert: DashboardBackupFailed\n    expr: time() - backup_dashboard_last_success_timestamp
      > 93600  # 26 hours\n    for: 5m\n    labels:\n      severity: warning\n      component:
      monitoring-stack\n      service: backup\n    annotations:\n      summary: \"Dashboard
      backup has not run successfully\"\n      description: \"Dashboard backup hasn't
      completed successfully in {{ $value | humanizeDuration }}\"\n      \n  - alert:
      BackupStorageFull\n    expr: (node_filesystem_avail_bytes{mountpoint=\"/home/magicat777/projects/ODIN/backups\"}
      / node_filesystem_size_bytes{mountpoint=\"/home/magicat777/projects/ODIN/backups\"})
      < 0.05\n    for: 5m\n    labels:\n      severity: critical\n      component:
      monitoring-stack\n      service: backup\n    annotations:\n      summary: \"Backup
      storage is full\"\n      description: \"Backup storage has less than 5% free
      space\"\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"odin-stack-alerts.yaml":"groups:\n- name: odin_monitoring_stack\n  interval: 30s\n  rules:\n  # Prometheus\n  - alert: PrometheusDown\n    expr: up{job=\"prometheus\"} == 0 or absent(up{job=\"prometheus\"})\n    for: 2m\n    labels:\n      severity: critical\n      component: monitoring-stack\n      service: prometheus\n    annotations:\n      summary: \"Prometheus is down\"\n      description: \"Prometheus server is unreachable. All metrics collection has stopped.\"\n      \n  - alert: PrometheusStorageFull\n    expr: (node_filesystem_avail_bytes{mountpoint=\"/var/lib/odin/prometheus\"} / node_filesystem_size_bytes{mountpoint=\"/var/lib/odin/prometheus\"}) \u003c 0.1\n    for: 5m\n    labels:\n      severity: critical\n      component: monitoring-stack\n      service: prometheus\n    annotations:\n      summary: \"Prometheus storage is almost full\"\n      description: \"Prometheus storage has less than 10% free space. Metrics may be lost.\"\n      \n  - alert: PrometheusHighMemoryUsage\n    expr: (container_memory_usage_bytes{namespace=\"monitoring\",pod=~\"prometheus-.*\"} / container_spec_memory_limit_bytes{namespace=\"monitoring\",pod=~\"prometheus-.*\"}) \u003e 0.9\n    for: 5m\n    labels:\n      severity: warning\n      component: monitoring-stack\n      service: prometheus\n    annotations:\n      summary: \"Prometheus high memory usage\"\n      description: \"Prometheus is using {{ $value }}% of its memory limit\"\n      \n  - alert: PrometheusReloadFailed\n    expr: prometheus_config_last_reload_successful != 1\n    for: 5m\n    labels:\n      severity: warning\n      component: monitoring-stack\n      service: prometheus\n    annotations:\n      summary: \"Prometheus configuration reload failed\"\n      description: \"Prometheus failed to reload its configuration. Check logs for details.\"\n      \n  # Grafana\n  - alert: GrafanaDown\n    expr: up{job=\"grafana\"} == 0 or probe_success{job=\"blackbox\",instance=~\".*grafana.*\"} == 0\n    for: 2m\n    labels:\n      severity: critical\n      component: monitoring-stack\n      service: grafana\n    annotations:\n      summary: \"Grafana is down\"\n      description: \"Grafana is unreachable. Dashboards and visualization unavailable.\"\n      \n  - alert: GrafanaDatabaseError\n    expr: increase(grafana_database_failed_queries_total[5m]) \u003e 5\n    for: 5m\n    labels:\n      severity: warning\n      component: monitoring-stack\n      service: grafana\n    annotations:\n      summary: \"Grafana database errors\"\n      description: \"Grafana is experiencing database query failures\"\n      \n  # Loki\n  - alert: LokiDown\n    expr: up{job=\"loki\"} == 0 or absent(up{job=\"loki\"})\n    for: 2m\n    labels:\n      severity: critical\n      component: monitoring-stack\n      service: loki\n    annotations:\n      summary: \"Loki is down\"\n      description: \"Loki log aggregation service is unreachable. Logs are not being stored.\"\n      \n  - alert: LokiStorageFull\n    expr: (node_filesystem_avail_bytes{mountpoint=\"/var/lib/odin/loki\"} / node_filesystem_size_bytes{mountpoint=\"/var/lib/odin/loki\"}) \u003c 0.1\n    for: 5m\n    labels:\n      severity: critical\n      component: monitoring-stack\n      service: loki\n    annotations:\n      summary: \"Loki storage is almost full\"\n      description: \"Loki storage has less than 10% free space. Logs may be lost.\"\n      \n  - alert: LokiIngesterNotReady\n    expr: loki_ingester_ready == 0\n    for: 5m\n    labels:\n      severity: warning\n      component: monitoring-stack\n      service: loki\n    annotations:\n      summary: \"Loki ingester not ready\"\n      description: \"Loki ingester is not ready to accept logs\"\n      \n  # AlertManager\n  - alert: AlertManagerDown\n    expr: up{job=\"alertmanager\"} == 0 or absent(up{job=\"alertmanager\"})\n    for: 2m\n    labels:\n      severity: critical\n      component: monitoring-stack\n      service: alertmanager\n    annotations:\n      summary: \"AlertManager is down\"\n      description: \"AlertManager is unreachable. Alerts will not be routed or sent.\"\n      \n  - alert: AlertManagerConfigNotSynced\n    expr: alertmanager_config_last_reload_successful != 1\n    for: 5m\n    labels:\n      severity: warning\n      component: monitoring-stack\n      service: alertmanager\n    annotations:\n      summary: \"AlertManager configuration reload failed\"\n      description: \"AlertManager failed to reload configuration\"\n      \n  # Promtail\n  - alert: PromtailDown\n    expr: up{job=\"promtail\"} == 0 or absent(up{job=\"promtail\"})\n    for: 5m\n    labels:\n      severity: warning\n      component: monitoring-stack\n      service: promtail\n    annotations:\n      summary: \"Promtail is down\"\n      description: \"Promtail log collector on {{ $labels.instance }} is down. Logs not being collected.\"\n      \n  - alert: PromtailDroppedLogs\n    expr: rate(promtail_dropped_entries_total[5m]) \u003e 0\n    for: 5m\n    labels:\n      severity: warning\n      component: monitoring-stack\n      service: promtail\n    annotations:\n      summary: \"Promtail dropping logs\"\n      description: \"Promtail is dropping {{ $value }} logs per second\"\n      \n  # Node Exporter\n  - alert: NodeExporterDown\n    expr: up{job=\"node-exporter\"} == 0\n    for: 2m\n    labels:\n      severity: critical\n      component: monitoring-stack\n      service: node-exporter\n    annotations:\n      summary: \"Node Exporter is down\"\n      description: \"Node Exporter on {{ $labels.instance }} is down. System metrics unavailable.\"\n      \n  # Power Exporter (GPU)\n  - alert: PowerExporterDown\n    expr: up{job=\"power-exporter\"} == 0\n    for: 5m\n    labels:\n      severity: warning\n      component: monitoring-stack\n      service: power-exporter\n    annotations:\n      summary: \"Power Exporter is down\"\n      description: \"Power Exporter is down. GPU metrics unavailable.\"\n      \n  - alert: PowerExporterUnhealthy\n    expr: power_exporter_health_status != 1\n    for: 5m\n    labels:\n      severity: warning\n      component: monitoring-stack\n      service: power-exporter\n    annotations:\n      summary: \"Power Exporter is unhealthy\"\n      description: \"Power Exporter health check is failing\"\n      \n  # cAdvisor\n  - alert: CAdvisorDown\n    expr: up{job=\"cadvisor\"} == 0\n    for: 5m\n    labels:\n      severity: warning\n      component: monitoring-stack\n      service: cadvisor\n    annotations:\n      summary: \"cAdvisor is down\"\n      description: \"cAdvisor container metrics collector is down\"\n      \n  # Kube State Metrics\n  - alert: KubeStateMetricsDown\n    expr: up{job=\"kube-state-metrics\"} == 0 or absent(up{job=\"kube-state-metrics\"})\n    for: 5m\n    labels:\n      severity: warning\n      component: monitoring-stack\n      service: kube-state-metrics\n    annotations:\n      summary: \"Kube State Metrics is down\"\n      description: \"Kube State Metrics is down. Kubernetes resource metrics unavailable.\"\n      \n  # Claude Code Exporter\n  - alert: ClaudeCodeExporterDown\n    expr: up{job=\"claude-code-exporter\"} == 0\n    for: 5m\n    labels:\n      severity: info\n      component: monitoring-stack\n      service: claude-code-exporter\n    annotations:\n      summary: \"Claude Code Exporter is down\"\n      description: \"Claude Code metrics exporter is down\"\n      \n  # Network Exporter\n  - alert: NetworkExporterDown\n    expr: up{job=\"network-exporter\"} == 0\n    for: 5m\n    labels:\n      severity: info\n      component: monitoring-stack\n      service: network-exporter\n    annotations:\n      summary: \"Network Exporter is down\"\n      description: \"Network metrics exporter is down\"\n      \n  # Overall Stack Health\n  - alert: MonitoringStackDegraded\n    expr: |\n      (count(up{job=~\"prometheus|grafana|loki|alertmanager|node-exporter\"} == 0) \u003e 0) or\n      (count(ALERTS{alertname=~\".*Down\",severity=\"critical\"}) \u003e 0)\n    for: 5m\n    labels:\n      severity: warning\n      component: monitoring-stack\n    annotations:\n      summary: \"Monitoring stack is degraded\"\n      description: \"One or more critical monitoring components are down\"\n      \n  - alert: MonitoringStackCritical\n    expr: |\n      count(up{job=~\"prometheus|grafana|loki|alertmanager\"} == 0) \u003e 2\n    for: 2m\n    labels:\n      severity: critical\n      component: monitoring-stack\n    annotations:\n      summary: \"Monitoring stack critically degraded\"\n      description: \"Multiple core monitoring components are down. Immediate action required!\"\n      \n- name: odin_backup_alerts\n  interval: 60s\n  rules:\n  - alert: DashboardBackupFailed\n    expr: time() - backup_dashboard_last_success_timestamp \u003e 93600  # 26 hours\n    for: 5m\n    labels:\n      severity: warning\n      component: monitoring-stack\n      service: backup\n    annotations:\n      summary: \"Dashboard backup has not run successfully\"\n      description: \"Dashboard backup hasn't completed successfully in {{ $value | humanizeDuration }}\"\n      \n  - alert: BackupStorageFull\n    expr: (node_filesystem_avail_bytes{mountpoint=\"/home/magicat777/projects/ODIN/backups\"} / node_filesystem_size_bytes{mountpoint=\"/home/magicat777/projects/ODIN/backups\"}) \u003c 0.05\n    for: 5m\n    labels:\n      severity: critical\n      component: monitoring-stack\n      service: backup\n    annotations:\n      summary: \"Backup storage is full\"\n      description: \"Backup storage has less than 5% free space\"\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"odin-stack-alert-rules","namespace":"monitoring"}}
    creationTimestamp: "2025-05-29T23:07:31Z"
    name: odin-stack-alert-rules
    namespace: monitoring
    resourceVersion: "3017936"
    uid: ce1d17cd-53ed-43d2-ae03-96124091b176
- apiVersion: v1
  data:
    cache-metrics.yaml: "groups:\n- name: pattern_cache_metrics\n  interval: 30s\n
      \ rules:\n  - record: pattern_cache_hit_rate\n    expr: |\n      rate(pattern_cache_hits_total[5m])
      / \n      (rate(pattern_cache_hits_total[5m]) + rate(pattern_cache_misses_total[5m]))\n
      \ \n  - alert: PatternCacheLowHitRate\n    expr: pattern_cache_hit_rate < 0.5\n
      \   for: 10m\n    labels:\n      severity: warning\n      component: pattern-matcher\n
      \   annotations:\n      summary: \"Pattern cache hit rate is low\"\n      description:
      \"Cache hit rate is {{ $value | humanizePercentage }} - may need cache warming\"\n
      \ \n  - alert: PatternCacheErrors\n    expr: rate(pattern_cache_errors_total[5m])
      > 0.1\n    for: 5m\n    labels:\n      severity: warning\n      component: pattern-matcher\n
      \   annotations:\n      summary: \"Pattern cache experiencing errors\"\n      description:
      \"Cache error rate: {{ $value }} errors/sec\"\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"cache-metrics.yaml":"groups:\n- name: pattern_cache_metrics\n  interval: 30s\n  rules:\n  - record: pattern_cache_hit_rate\n    expr: |\n      rate(pattern_cache_hits_total[5m]) / \n      (rate(pattern_cache_hits_total[5m]) + rate(pattern_cache_misses_total[5m]))\n  \n  - alert: PatternCacheLowHitRate\n    expr: pattern_cache_hit_rate \u003c 0.5\n    for: 10m\n    labels:\n      severity: warning\n      component: pattern-matcher\n    annotations:\n      summary: \"Pattern cache hit rate is low\"\n      description: \"Cache hit rate is {{ $value | humanizePercentage }} - may need cache warming\"\n  \n  - alert: PatternCacheErrors\n    expr: rate(pattern_cache_errors_total[5m]) \u003e 0.1\n    for: 5m\n    labels:\n      severity: warning\n      component: pattern-matcher\n    annotations:\n      summary: \"Pattern cache experiencing errors\"\n      description: \"Cache error rate: {{ $value }} errors/sec\"\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"pattern-cache-metrics-rules","namespace":"monitoring"}}
    creationTimestamp: "2025-06-08T01:19:48Z"
    name: pattern-cache-metrics-rules
    namespace: monitoring
    resourceVersion: "5212842"
    uid: 5fe2adef-9446-4265-b8a2-c0dd1228b21f
- apiVersion: v1
  data:
    performance-baselines.json: "{\n  \"id\": null,\n  \"uid\": \"performance-baselines\",\n
      \ \"title\": \"Performance Baseline Profiles\",\n  \"tags\": [\"performance\",
      \"baseline\", \"profiles\"],\n  \"timezone\": \"browser\",\n  \"schemaVersion\":
      30,\n  \"version\": 6,\n  \"refresh\": \"30s\",\n  \"time\": {\n    \"from\":
      \"now-6h\",\n    \"to\": \"now\"\n  },\n  \"panels\": [\n      {\n        \"id\":
      1,\n        \"gridPos\": {\"h\": 3, \"w\": 24, \"x\": 0, \"y\": 0},\n        \"type\":
      \"text\",\n        \"title\": \"ODIN Performance Monitoring & Baseline Profiles\",\n
      \       \"options\": {\n          \"content\": \"# Razer Blade 18 Performance
      Analysis\\n\\n## Active Workload Profiles\\n- **\U0001F7E2 Idle** (CPU: <5%,
      Temp: <45°C, Power: <25W) - System at rest\\n- **\U0001F535 Development** (CPU:
      <40%, Temp: <65°C, Power: <65W) - Coding, compiling, debugging\\n- **\U0001F7E3
      AI/ML** (CPU: <60%, Temp: <75°C, Power: <150W) - Claude Code, LLMs, inference\\n-
      **\U0001F7E0 Gaming** (CPU: <70%, Temp: <85°C, Power: <280W) - High-performance
      gaming\\n- **\U0001F534 Video** (CPU: <90%, Temp: <80°C, Power: <250W) - 4K
      editing, rendering\\n- **⚫ Stress** (CPU: 100%, Temp: <95°C, Power: <330W) -
      Maximum load testing\\n\\n## Performance Score Algorithm\\n**ODIN Score** =
      100 - Weighted stress factors (CPU 30% + Memory 25% + GPU 25% + Thermal 20%)\",\n
      \         \"mode\": \"markdown\"\n        }\n      },\n      {\n        \"id\":
      2,\n        \"gridPos\": {\"h\": 8, \"w\": 8, \"x\": 0, \"y\": 3},\n        \"type\":
      \"gauge\",\n        \"title\": \"ODIN Performance Score\",\n        \"targets\":
      [\n          {\n            \"expr\": \"100 - avg(rate(node_cpu_seconds_total{mode=\\\\\\\"idle\\\\\\\"}[5m]))
      * 100\",\n            \"legendFormat\": \"Performance Score\",\n            \"refId\":
      \"A\"\n          }\n        ],\n        \"fieldConfig\": {\n          \"defaults\":
      {\n            \"unit\": \"percent\",\n            \"decimals\": 1,\n            \"min\":
      0,\n            \"max\": 100,\n            \"thresholds\": {\n              \"mode\":
      \"absolute\",\n              \"steps\": [\n                {\"color\": \"red\",
      \"value\": 0},\n                {\"color\": \"orange\", \"value\": 30},\n                {\"color\":
      \"yellow\", \"value\": 50},\n                {\"color\": \"green\", \"value\":
      70},\n                {\"color\": \"dark-green\", \"value\": 85}\n              ]\n
      \           }\n          }\n        },\n        \"options\": {\n          \"orientation\":
      \"auto\",\n          \"showThresholdLabels\": true,\n          \"showThresholdMarkers\":
      true,\n          \"displayMode\": \"gradient\"\n        }\n      },\n      {\n
      \       \"id\": 3,\n        \"gridPos\": {\"h\": 4, \"w\": 8, \"x\": 8, \"y\":
      3},\n        \"type\": \"stat\",\n        \"title\": \"Active Workload Profile\",\n
      \       \"targets\": [\n          {\n            \"expr\": \"(100 - (avg(rate(node_cpu_seconds_total{mode=\\\"idle\\\"}[5m]))
      * 100))\",\n            \"refId\": \"A\"\n          },\n          {\n            \"expr\":
      \"nvidia_gpu_utilization_percent\",\n            \"refId\": \"B\"\n          },\n
      \         {\n            \"expr\": \"max(node_hwmon_temp_celsius)\",\n            \"refId\":
      \"C\"\n          }\n        ],\n        \"fieldConfig\": {\n          \"defaults\":
      {\n            \"unit\": \"percent\",\n            \"decimals\": 0,\n            \"mappings\":
      [\n              {\n                \"type\": \"range\",\n                \"options\":
      {\n                  \"from\": 0,\n                  \"to\": 10,\n                  \"result\":
      {\"text\": \"\U0001F7E2 IDLE\", \"color\": \"green\"}\n                }\n              },\n
      \             {\n                \"type\": \"range\",\n                \"options\":
      {\n                  \"from\": 10,\n                  \"to\": 50,\n                  \"result\":
      {\"text\": \"\U0001F535 DEVELOPMENT\", \"color\": \"blue\"}\n                }\n
      \             },\n              {\n                \"type\": \"range\",\n                \"options\":
      {\n                  \"from\": 50,\n                  \"to\": 70,\n                  \"result\":
      {\"text\": \"\U0001F7E3 AI/ML\", \"color\": \"purple\"}\n                }\n
      \             },\n              {\n                \"type\": \"range\",\n                \"options\":
      {\n                  \"from\": 70,\n                  \"to\": 85,\n                  \"result\":
      {\"text\": \"\U0001F7E0 GAMING\", \"color\": \"orange\"}\n                }\n
      \             },\n              {\n                \"type\": \"range\",\n                \"options\":
      {\n                  \"from\": 85,\n                  \"to\": 100,\n                  \"result\":
      {\"text\": \"\U0001F534 VIDEO/STRESS\", \"color\": \"red\"}\n                }\n
      \             }\n            ]\n          }\n        },\n        \"options\":
      {\n          \"colorMode\": \"background\",\n          \"graphMode\": \"none\",\n
      \         \"justifyMode\": \"center\",\n          \"textMode\": \"value_and_name\"\n
      \       }\n      },\n      {\n        \"id\": 4,\n        \"gridPos\": {\"h\":
      4, \"w\": 8, \"x\": 16, \"y\": 3},\n        \"type\": \"stat\",\n        \"title\":
      \"System Efficiency Rating\",\n        \"targets\": [\n          {\n            \"expr\":
      \"100 - (sum(node_gpu_power_watts) / 330 * 100)\",\n            \"refId\": \"A\"\n
      \         }\n        ],\n        \"fieldConfig\": {\n          \"defaults\":
      {\n            \"unit\": \"percent\",\n            \"decimals\": 1,\n            \"thresholds\":
      {\n              \"mode\": \"absolute\",\n              \"steps\": [\n                {\"color\":
      \"red\", \"value\": 0},\n                {\"color\": \"yellow\", \"value\":
      50},\n                {\"color\": \"green\", \"value\": 75}\n              ]\n
      \           }\n          }\n        },\n        \"options\": {\n          \"colorMode\":
      \"background\",\n          \"graphMode\": \"area\",\n          \"justifyMode\":
      \"center\"\n        }\n      },\n      {\n        \"id\": 5,\n        \"gridPos\":
      {\"h\": 4, \"w\": 4, \"x\": 8, \"y\": 7},\n        \"type\": \"stat\",\n        \"title\":
      \"CPU Score\",\n        \"targets\": [\n          {\n            \"expr\": \"100
      - (100 - (avg(rate(node_cpu_seconds_total{mode=\\\"idle\\\"}[5m])) * 100))\",\n
      \           \"refId\": \"A\"\n          }\n        ],\n        \"fieldConfig\":
      {\n          \"defaults\": {\n            \"unit\": \"percent\",\n            \"decimals\":
      0,\n            \"thresholds\": {\n              \"mode\": \"absolute\",\n              \"steps\":
      [\n                {\"color\": \"red\", \"value\": 0},\n                {\"color\":
      \"yellow\", \"value\": 40},\n                {\"color\": \"green\", \"value\":
      70}\n              ]\n            }\n          }\n        },\n        \"options\":
      {\n          \"colorMode\": \"background\",\n          \"graphMode\": \"none\"\n
      \       }\n      },\n      {\n        \"id\": 6,\n        \"gridPos\": {\"h\":
      4, \"w\": 4, \"x\": 12, \"y\": 7},\n        \"type\": \"stat\",\n        \"title\":
      \"Memory Score\",\n        \"targets\": [\n          {\n            \"expr\":
      \"100 - ((1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes))
      * 100)\",\n            \"refId\": \"A\"\n          }\n        ],\n        \"fieldConfig\":
      {\n          \"defaults\": {\n            \"unit\": \"percent\",\n            \"decimals\":
      0,\n            \"thresholds\": {\n              \"mode\": \"absolute\",\n              \"steps\":
      [\n                {\"color\": \"red\", \"value\": 0},\n                {\"color\":
      \"yellow\", \"value\": 40},\n                {\"color\": \"green\", \"value\":
      70}\n              ]\n            }\n          }\n        },\n        \"options\":
      {\n          \"colorMode\": \"background\",\n          \"graphMode\": \"none\"\n
      \       }\n      },\n      {\n        \"id\": 7,\n        \"gridPos\": {\"h\":
      4, \"w\": 4, \"x\": 16, \"y\": 7},\n        \"type\": \"stat\",\n        \"title\":
      \"GPU Score\",\n        \"targets\": [\n          {\n            \"expr\": \"100
      - nvidia_gpu_utilization_percent\",\n            \"refId\": \"A\"\n          }\n
      \       ],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"unit\":
      \"percent\",\n            \"decimals\": 0,\n            \"thresholds\": {\n
      \             \"mode\": \"absolute\",\n              \"steps\": [\n                {\"color\":
      \"red\", \"value\": 0},\n                {\"color\": \"yellow\", \"value\":
      40},\n                {\"color\": \"green\", \"value\": 70}\n              ]\n
      \           }\n          }\n        },\n        \"options\": {\n          \"colorMode\":
      \"background\",\n          \"graphMode\": \"none\"\n        }\n      },\n      {\n
      \       \"id\": 8,\n        \"gridPos\": {\"h\": 4, \"w\": 4, \"x\": 20, \"y\":
      7},\n        \"type\": \"stat\",\n        \"title\": \"Thermal Score\",\n        \"targets\":
      [\n          {\n            \"expr\": \"100 - (max(node_hwmon_temp_celsius)
      / 85 * 100)\",\n            \"refId\": \"A\"\n          }\n        ],\n        \"fieldConfig\":
      {\n          \"defaults\": {\n            \"unit\": \"percent\",\n            \"decimals\":
      0,\n            \"thresholds\": {\n              \"mode\": \"absolute\",\n              \"steps\":
      [\n                {\"color\": \"red\", \"value\": 0},\n                {\"color\":
      \"yellow\", \"value\": 40},\n                {\"color\": \"green\", \"value\":
      70}\n              ]\n            }\n          }\n        },\n        \"options\":
      {\n          \"colorMode\": \"background\",\n          \"graphMode\": \"none\"\n
      \       }\n      },\n      {\n        \"id\": 9,\n        \"gridPos\": {\"h\":
      8, \"w\": 12, \"x\": 0, \"y\": 11},\n        \"type\": \"timeseries\",\n        \"title\":
      \"CPU Usage vs Profile Baselines\",\n        \"targets\": [\n          {\n            \"expr\":
      \"100 - (avg(rate(node_cpu_seconds_total{mode=\\\"idle\\\"}[5m])) * 100)\",\n
      \           \"legendFormat\": \"Current CPU %\",\n            \"refId\": \"A\"\n
      \         },\n          {\n            \"expr\": \"5\",\n            \"legendFormat\":
      \"\U0001F7E2 Idle Baseline (5%)\",\n            \"refId\": \"B\"\n          },\n
      \         {\n            \"expr\": \"40\",\n            \"legendFormat\": \"\U0001F535
      Development Baseline (40%)\",\n            \"refId\": \"C\"\n          },\n
      \         {\n            \"expr\": \"60\",\n            \"legendFormat\": \"\U0001F7E3
      AI/ML Baseline (60%)\",\n            \"refId\": \"D\"\n          },\n          {\n
      \           \"expr\": \"70\",\n            \"legendFormat\": \"\U0001F7E0 Gaming
      Baseline (70%)\",\n            \"refId\": \"E\"\n          },\n          {\n
      \           \"expr\": \"90\",\n            \"legendFormat\": \"\U0001F534 Video
      Baseline (90%)\",\n            \"refId\": \"F\"\n          }\n        ],\n        \"fieldConfig\":
      {\n          \"defaults\": {\n            \"unit\": \"percent\",\n            \"decimals\":
      1,\n            \"color\": {\"mode\": \"palette-classic\"},\n            \"custom\":
      {\n              \"lineInterpolation\": \"smooth\",\n              \"lineWidth\":
      2,\n              \"fillOpacity\": 10,\n              \"showPoints\": \"never\"\n
      \           },\n            \"thresholds\": {\n              \"mode\": \"absolute\",\n
      \             \"steps\": [\n                {\"color\": \"green\", \"value\":
      null},\n                {\"color\": \"yellow\", \"value\": 60},\n                {\"color\":
      \"red\", \"value\": 80}\n              ]\n            }\n          },\n          \"overrides\":
      [\n            {\n              \"matcher\": {\"id\": \"byName\", \"options\":
      \"Current CPU %\"},\n              \"properties\": [\n                {\"id\":
      \"custom.lineWidth\", \"value\": 4},\n                {\"id\": \"custom.fillOpacity\",
      \"value\": 25},\n                {\"id\": \"color\", \"value\": {\"mode\": \"fixed\",
      \"fixedColor\": \"blue\"}}\n              ]\n            }\n          ]\n        }\n
      \     },\n      {\n        \"id\": 10,\n        \"gridPos\": {\"h\": 8, \"w\":
      12, \"x\": 12, \"y\": 11},\n        \"type\": \"timeseries\",\n        \"title\":
      \"Memory Usage vs Profile Baselines\",\n        \"targets\": [\n          {\n
      \           \"expr\": \"(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes))
      * 100\",\n            \"legendFormat\": \"Current Memory %\",\n            \"refId\":
      \"A\"\n          },\n          {\n            \"expr\": \"20\",\n            \"legendFormat\":
      \"\U0001F7E2 Idle Baseline (20%)\",\n            \"refId\": \"B\"\n          },\n
      \         {\n            \"expr\": \"60\",\n            \"legendFormat\": \"\U0001F535
      Development Baseline (60%)\",\n            \"refId\": \"C\"\n          },\n
      \         {\n            \"expr\": \"70\",\n            \"legendFormat\": \"\U0001F7E3
      AI/ML Baseline (70%)\",\n            \"refId\": \"D\"\n          },\n          {\n
      \           \"expr\": \"65\",\n            \"legendFormat\": \"\U0001F7E0 Gaming
      Baseline (65%)\",\n            \"refId\": \"E\"\n          },\n          {\n
      \           \"expr\": \"85\",\n            \"legendFormat\": \"\U0001F534 Video
      Baseline (85%)\",\n            \"refId\": \"F\"\n          }\n        ],\n        \"fieldConfig\":
      {\n          \"defaults\": {\n            \"unit\": \"percent\",\n            \"decimals\":
      1,\n            \"color\": {\"mode\": \"palette-classic\"},\n            \"custom\":
      {\n              \"lineInterpolation\": \"smooth\",\n              \"lineWidth\":
      2,\n              \"fillOpacity\": 10,\n              \"showPoints\": \"never\"\n
      \           }\n          },\n          \"overrides\": [\n            {\n              \"matcher\":
      {\"id\": \"byName\", \"options\": \"Current Memory %\"},\n              \"properties\":
      [\n                {\"id\": \"custom.lineWidth\", \"value\": 4},\n                {\"id\":
      \"custom.fillOpacity\", \"value\": 25},\n                {\"id\": \"color\",
      \"value\": {\"mode\": \"fixed\", \"fixedColor\": \"green\"}}\n              ]\n
      \           }\n          ]\n        }\n      },\n      {\n        \"id\": 11,\n
      \       \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 19},\n        \"type\":
      \"timeseries\",\n        \"title\": \"GPU Usage vs Profile Baselines\",\n        \"targets\":
      [\n          {\n            \"expr\": \"nvidia_gpu_utilization_percent\",\n
      \           \"legendFormat\": \"Current GPU %\",\n            \"refId\": \"A\"\n
      \         },\n          {\n            \"expr\": \"5\",\n            \"legendFormat\":
      \"\U0001F7E2 Idle Baseline (5%)\",\n            \"refId\": \"B\"\n          },\n
      \         {\n            \"expr\": \"10\",\n            \"legendFormat\": \"\U0001F535
      Development Baseline (10%)\",\n            \"refId\": \"C\"\n          },\n
      \         {\n            \"expr\": \"80\",\n            \"legendFormat\": \"\U0001F7E3
      AI/ML Baseline (80%)\",\n            \"refId\": \"D\"\n          },\n          {\n
      \           \"expr\": \"95\",\n            \"legendFormat\": \"\U0001F7E0 Gaming
      Baseline (95%)\",\n            \"refId\": \"E\"\n          },\n          {\n
      \           \"expr\": \"90\",\n            \"legendFormat\": \"\U0001F534 Video
      Baseline (90%)\",\n            \"refId\": \"F\"\n          }\n        ],\n        \"fieldConfig\":
      {\n          \"defaults\": {\n            \"unit\": \"percent\",\n            \"decimals\":
      1,\n            \"color\": {\"mode\": \"palette-classic\"},\n            \"custom\":
      {\n              \"lineInterpolation\": \"smooth\",\n              \"lineWidth\":
      2,\n              \"fillOpacity\": 10,\n              \"showPoints\": \"never\"\n
      \           }\n          },\n          \"overrides\": [\n            {\n              \"matcher\":
      {\"id\": \"byName\", \"options\": \"Current GPU %\"},\n              \"properties\":
      [\n                {\"id\": \"custom.lineWidth\", \"value\": 4},\n                {\"id\":
      \"custom.fillOpacity\", \"value\": 25},\n                {\"id\": \"color\",
      \"value\": {\"mode\": \"fixed\", \"fixedColor\": \"purple\"}}\n              ]\n
      \           }\n          ]\n        }\n      },\n      {\n        \"id\": 12,\n
      \       \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 19},\n        \"type\":
      \"timeseries\",\n        \"title\": \"Temperature vs Profile Baselines\",\n
      \       \"targets\": [\n          {\n            \"expr\": \"max(node_hwmon_temp_celsius)\",\n
      \           \"legendFormat\": \"Current Max Temperature\",\n            \"refId\":
      \"A\"\n          },\n          {\n            \"expr\": \"node_hwmon_temp_celsius\",\n
      \           \"legendFormat\": \"CPU Temp\",\n            \"refId\": \"B\"\n
      \         },\n          {\n            \"expr\": \"nvidia_gpu_temperature_celsius\",\n
      \           \"legendFormat\": \"GPU Temp\",\n            \"refId\": \"C\"\n
      \         },\n          {\n            \"expr\": \"45\",\n            \"legendFormat\":
      \"\U0001F7E2 Idle Baseline (45°C)\",\n            \"refId\": \"D\"\n          },\n
      \         {\n            \"expr\": \"65\",\n            \"legendFormat\": \"\U0001F535
      Development Baseline (65°C)\",\n            \"refId\": \"E\"\n          },\n
      \         {\n            \"expr\": \"75\",\n            \"legendFormat\": \"\U0001F7E3
      AI/ML Baseline (75°C)\",\n            \"refId\": \"F\"\n          },\n          {\n
      \           \"expr\": \"85\",\n            \"legendFormat\": \"\U0001F7E0 Gaming
      Baseline (85°C)\",\n            \"refId\": \"G\"\n          }\n        ],\n
      \       \"fieldConfig\": {\n          \"defaults\": {\n            \"unit\":
      \"celsius\",\n            \"decimals\": 0,\n            \"color\": {\"mode\":
      \"palette-classic\"},\n            \"custom\": {\n              \"lineInterpolation\":
      \"smooth\",\n              \"lineWidth\": 2,\n              \"fillOpacity\":
      10,\n              \"showPoints\": \"never\"\n            },\n            \"thresholds\":
      {\n              \"mode\": \"absolute\",\n              \"steps\": [\n                {\"color\":
      \"green\", \"value\": null},\n                {\"color\": \"yellow\", \"value\":
      70},\n                {\"color\": \"red\", \"value\": 85}\n              ]\n
      \           }\n          },\n          \"overrides\": [\n            {\n              \"matcher\":
      {\"id\": \"byName\", \"options\": \"Current Max Temperature\"},\n              \"properties\":
      [\n                {\"id\": \"custom.lineWidth\", \"value\": 4},\n                {\"id\":
      \"custom.fillOpacity\", \"value\": 25},\n                {\"id\": \"color\",
      \"value\": {\"mode\": \"fixed\", \"fixedColor\": \"red\"}}\n              ]\n
      \           }\n          ]\n        }\n      },\n      {\n        \"id\": 13,\n
      \       \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 27},\n        \"type\":
      \"timeseries\",\n        \"title\": \"Power Consumption vs Profile Baselines\",\n
      \       \"targets\": [\n          {\n            \"expr\": \"sum(node_gpu_power_watts)\",\n
      \           \"legendFormat\": \"Current Total Power\",\n            \"refId\":
      \"A\"\n          },\n          {\n            \"expr\": \"node_gpu_power_watts\",\n
      \           \"legendFormat\": \"CPU Power\",\n            \"refId\": \"B\"\n
      \         },\n          {\n            \"expr\": \"node_gpu_power_watts\",\n
      \           \"legendFormat\": \"GPU Power\",\n            \"refId\": \"C\"\n
      \         },\n          {\n            \"expr\": \"25\",\n            \"legendFormat\":
      \"\U0001F7E2 Idle Baseline (25W)\",\n            \"refId\": \"D\"\n          },\n
      \         {\n            \"expr\": \"65\",\n            \"legendFormat\": \"\U0001F535
      Development Baseline (65W)\",\n            \"refId\": \"E\"\n          },\n
      \         {\n            \"expr\": \"150\",\n            \"legendFormat\": \"\U0001F7E3
      AI/ML Baseline (150W)\",\n            \"refId\": \"F\"\n          },\n          {\n
      \           \"expr\": \"280\",\n            \"legendFormat\": \"\U0001F7E0 Gaming
      Baseline (280W)\",\n            \"refId\": \"G\"\n          }\n        ],\n
      \       \"fieldConfig\": {\n          \"defaults\": {\n            \"unit\":
      \"watt\",\n            \"decimals\": 0,\n            \"color\": {\"mode\": \"palette-classic\"},\n
      \           \"custom\": {\n              \"lineInterpolation\": \"smooth\",\n
      \             \"lineWidth\": 2,\n              \"fillOpacity\": 10,\n              \"showPoints\":
      \"never\"\n            }\n          },\n          \"overrides\": [\n            {\n
      \             \"matcher\": {\"id\": \"byName\", \"options\": \"Current Total
      Power\"},\n              \"properties\": [\n                {\"id\": \"custom.lineWidth\",
      \"value\": 4},\n                {\"id\": \"custom.fillOpacity\", \"value\":
      25},\n                {\"id\": \"color\", \"value\": {\"mode\": \"fixed\", \"fixedColor\":
      \"orange\"}}\n              ]\n            }\n          ]\n        }\n      },\n
      \     {\n        \"id\": 14,\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\":
      12, \"y\": 27},\n        \"type\": \"heatmap\",\n        \"title\": \"Performance
      Distribution Heatmap\",\n        \"targets\": [\n          {\n            \"expr\":
      \"rate(node_cpu_seconds_total{mode!=\\\"idle\\\"}[5m]) * 100\",\n            \"format\":
      \"time_series\",\n            \"legendFormat\": \"CPU {{cpu}}\",\n            \"refId\":
      \"A\"\n          }\n        ],\n        \"fieldConfig\": {\n          \"defaults\":
      {\n            \"custom\": {\n              \"scaleDistribution\": {\"type\":
      \"linear\"},\n              \"hideFrom\": {\"tooltip\": false, \"viz\": false,
      \"legend\": false}\n            }\n          }\n        },\n        \"options\":
      {\n          \"calculate\": false,\n          \"cellGap\": 1,\n          \"color\":
      {\n            \"mode\": \"scheme\",\n            \"scheme\": \"Spectral\",\n
      \           \"steps\": 64\n          },\n          \"yAxis\": {\n            \"axisPlacement\":
      \"left\",\n            \"reverse\": false,\n            \"unit\": \"percent\"\n
      \         }\n        }\n      },\n      {\n        \"id\": 15,\n        \"gridPos\":
      {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 35},\n        \"type\": \"timeseries\",\n
      \       \"title\": \"ODIN Performance Score Timeline with Component Breakdown\",\n
      \       \"targets\": [\n          {\n            \"expr\": \"100 - ((((100 -
      (avg(rate(node_cpu_seconds_total{mode=\\\"idle\\\"}[5m])) * 100)) / 100) + ((1
      - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes))) + (max(node_hwmon_temp_celsius)
      / 100)) / 3 * 100)\",\n            \"legendFormat\": \"\U0001F3AF ODIN Performance
      Score\",\n            \"refId\": \"A\"\n          },\n          {\n            \"expr\":
      \"100 - (100 - (avg(rate(node_cpu_seconds_total{mode=\\\"idle\\\"}[5m])) * 100))\",\n
      \           \"legendFormat\": \"\U0001F4BB CPU Component Score\",\n            \"refId\":
      \"B\"\n          },\n          {\n            \"expr\": \"100 - ((1 - (node_memory_MemAvailable_bytes
      / node_memory_MemTotal_bytes)) * 100)\",\n            \"legendFormat\": \"\U0001F9E0
      Memory Component Score\",\n            \"refId\": \"C\"\n          },\n          {\n
      \           \"expr\": \"100 - nvidia_gpu_utilization_percent\",\n            \"legendFormat\":
      \"\U0001F3AE GPU Component Score\",\n            \"refId\": \"D\"\n          },\n
      \         {\n            \"expr\": \"100 - (max(node_hwmon_temp_celsius) / 85
      * 100)\",\n            \"legendFormat\": \"\U0001F321️ Thermal Component Score\",\n
      \           \"refId\": \"E\"\n          }\n        ],\n        \"fieldConfig\":
      {\n          \"defaults\": {\n            \"unit\": \"percent\",\n            \"decimals\":
      1,\n            \"color\": {\"mode\": \"palette-classic\"},\n            \"custom\":
      {\n              \"lineInterpolation\": \"smooth\",\n              \"lineWidth\":
      2,\n              \"fillOpacity\": 15,\n              \"showPoints\": \"never\"\n
      \           },\n            \"min\": 0,\n            \"max\": 100\n          },\n
      \         \"overrides\": [\n            {\n              \"matcher\": {\"id\":
      \"byName\", \"options\": \"\U0001F3AF ODIN Performance Score\"},\n              \"properties\":
      [\n                {\"id\": \"custom.lineWidth\", \"value\": 5},\n                {\"id\":
      \"custom.fillOpacity\", \"value\": 30},\n                {\"id\": \"color\",
      \"value\": {\"mode\": \"fixed\", \"fixedColor\": \"blue\"}}\n              ]\n
      \           }\n          ]\n        },\n        \"options\": {\n          \"legend\":
      {\n            \"displayMode\": \"table\",\n            \"placement\": \"right\",\n
      \           \"calcs\": [\"lastNotNull\", \"mean\", \"min\", \"max\"]\n          },\n
      \         \"tooltip\": {\n            \"mode\": \"multi\",\n            \"sort\":
      \"desc\"\n          }\n        }\n      }\n    ]\n}\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: "{\"apiVersion\":\"v1\",\"data\":{\"performance-baselines.json\":\"{\\n
        \ \\\"id\\\": null,\\n  \\\"uid\\\": \\\"performance-baselines\\\",\\n  \\\"title\\\":
        \\\"Performance Baseline Profiles\\\",\\n  \\\"tags\\\": [\\\"performance\\\",
        \\\"baseline\\\", \\\"profiles\\\"],\\n  \\\"timezone\\\": \\\"browser\\\",\\n
        \ \\\"schemaVersion\\\": 30,\\n  \\\"version\\\": 6,\\n  \\\"refresh\\\":
        \\\"30s\\\",\\n  \\\"time\\\": {\\n    \\\"from\\\": \\\"now-6h\\\",\\n    \\\"to\\\":
        \\\"now\\\"\\n  },\\n  \\\"panels\\\": [\\n      {\\n        \\\"id\\\": 1,\\n
        \       \\\"gridPos\\\": {\\\"h\\\": 3, \\\"w\\\": 24, \\\"x\\\": 0, \\\"y\\\":
        0},\\n        \\\"type\\\": \\\"text\\\",\\n        \\\"title\\\": \\\"ODIN
        Performance Monitoring \\u0026 Baseline Profiles\\\",\\n        \\\"options\\\":
        {\\n          \\\"content\\\": \\\"# Razer Blade 18 Performance Analysis\\\\n\\\\n##
        Active Workload Profiles\\\\n- **\U0001F7E2 Idle** (CPU: \\u003c5%, Temp:
        \\u003c45°C, Power: \\u003c25W) - System at rest\\\\n- **\U0001F535 Development**
        (CPU: \\u003c40%, Temp: \\u003c65°C, Power: \\u003c65W) - Coding, compiling,
        debugging\\\\n- **\U0001F7E3 AI/ML** (CPU: \\u003c60%, Temp: \\u003c75°C,
        Power: \\u003c150W) - Claude Code, LLMs, inference\\\\n- **\U0001F7E0 Gaming**
        (CPU: \\u003c70%, Temp: \\u003c85°C, Power: \\u003c280W) - High-performance
        gaming\\\\n- **\U0001F534 Video** (CPU: \\u003c90%, Temp: \\u003c80°C, Power:
        \\u003c250W) - 4K editing, rendering\\\\n- **⚫ Stress** (CPU: 100%, Temp:
        \\u003c95°C, Power: \\u003c330W) - Maximum load testing\\\\n\\\\n## Performance
        Score Algorithm\\\\n**ODIN Score** = 100 - Weighted stress factors (CPU 30%
        + Memory 25% + GPU 25% + Thermal 20%)\\\",\\n          \\\"mode\\\": \\\"markdown\\\"\\n
        \       }\\n      },\\n      {\\n        \\\"id\\\": 2,\\n        \\\"gridPos\\\":
        {\\\"h\\\": 8, \\\"w\\\": 8, \\\"x\\\": 0, \\\"y\\\": 3},\\n        \\\"type\\\":
        \\\"gauge\\\",\\n        \\\"title\\\": \\\"ODIN Performance Score\\\",\\n
        \       \\\"targets\\\": [\\n          {\\n            \\\"expr\\\": \\\"100
        - avg(rate(node_cpu_seconds_total{mode=\\\\\\\\\\\\\\\"idle\\\\\\\\\\\\\\\"}[5m]))
        * 100\\\",\\n            \\\"legendFormat\\\": \\\"Performance Score\\\",\\n
        \           \\\"refId\\\": \\\"A\\\"\\n          }\\n        ],\\n        \\\"fieldConfig\\\":
        {\\n          \\\"defaults\\\": {\\n            \\\"unit\\\": \\\"percent\\\",\\n
        \           \\\"decimals\\\": 1,\\n            \\\"min\\\": 0,\\n            \\\"max\\\":
        100,\\n            \\\"thresholds\\\": {\\n              \\\"mode\\\": \\\"absolute\\\",\\n
        \             \\\"steps\\\": [\\n                {\\\"color\\\": \\\"red\\\",
        \\\"value\\\": 0},\\n                {\\\"color\\\": \\\"orange\\\", \\\"value\\\":
        30},\\n                {\\\"color\\\": \\\"yellow\\\", \\\"value\\\": 50},\\n
        \               {\\\"color\\\": \\\"green\\\", \\\"value\\\": 70},\\n                {\\\"color\\\":
        \\\"dark-green\\\", \\\"value\\\": 85}\\n              ]\\n            }\\n
        \         }\\n        },\\n        \\\"options\\\": {\\n          \\\"orientation\\\":
        \\\"auto\\\",\\n          \\\"showThresholdLabels\\\": true,\\n          \\\"showThresholdMarkers\\\":
        true,\\n          \\\"displayMode\\\": \\\"gradient\\\"\\n        }\\n      },\\n
        \     {\\n        \\\"id\\\": 3,\\n        \\\"gridPos\\\": {\\\"h\\\": 4,
        \\\"w\\\": 8, \\\"x\\\": 8, \\\"y\\\": 3},\\n        \\\"type\\\": \\\"stat\\\",\\n
        \       \\\"title\\\": \\\"Active Workload Profile\\\",\\n        \\\"targets\\\":
        [\\n          {\\n            \\\"expr\\\": \\\"(100 - (avg(rate(node_cpu_seconds_total{mode=\\\\\\\"idle\\\\\\\"}[5m]))
        * 100))\\\",\\n            \\\"refId\\\": \\\"A\\\"\\n          },\\n          {\\n
        \           \\\"expr\\\": \\\"nvidia_gpu_utilization_percent\\\",\\n            \\\"refId\\\":
        \\\"B\\\"\\n          },\\n          {\\n            \\\"expr\\\": \\\"max(node_hwmon_temp_celsius)\\\",\\n
        \           \\\"refId\\\": \\\"C\\\"\\n          }\\n        ],\\n        \\\"fieldConfig\\\":
        {\\n          \\\"defaults\\\": {\\n            \\\"unit\\\": \\\"percent\\\",\\n
        \           \\\"decimals\\\": 0,\\n            \\\"mappings\\\": [\\n              {\\n
        \               \\\"type\\\": \\\"range\\\",\\n                \\\"options\\\":
        {\\n                  \\\"from\\\": 0,\\n                  \\\"to\\\": 10,\\n
        \                 \\\"result\\\": {\\\"text\\\": \\\"\U0001F7E2 IDLE\\\",
        \\\"color\\\": \\\"green\\\"}\\n                }\\n              },\\n              {\\n
        \               \\\"type\\\": \\\"range\\\",\\n                \\\"options\\\":
        {\\n                  \\\"from\\\": 10,\\n                  \\\"to\\\": 50,\\n
        \                 \\\"result\\\": {\\\"text\\\": \\\"\U0001F535 DEVELOPMENT\\\",
        \\\"color\\\": \\\"blue\\\"}\\n                }\\n              },\\n              {\\n
        \               \\\"type\\\": \\\"range\\\",\\n                \\\"options\\\":
        {\\n                  \\\"from\\\": 50,\\n                  \\\"to\\\": 70,\\n
        \                 \\\"result\\\": {\\\"text\\\": \\\"\U0001F7E3 AI/ML\\\",
        \\\"color\\\": \\\"purple\\\"}\\n                }\\n              },\\n              {\\n
        \               \\\"type\\\": \\\"range\\\",\\n                \\\"options\\\":
        {\\n                  \\\"from\\\": 70,\\n                  \\\"to\\\": 85,\\n
        \                 \\\"result\\\": {\\\"text\\\": \\\"\U0001F7E0 GAMING\\\",
        \\\"color\\\": \\\"orange\\\"}\\n                }\\n              },\\n              {\\n
        \               \\\"type\\\": \\\"range\\\",\\n                \\\"options\\\":
        {\\n                  \\\"from\\\": 85,\\n                  \\\"to\\\": 100,\\n
        \                 \\\"result\\\": {\\\"text\\\": \\\"\U0001F534 VIDEO/STRESS\\\",
        \\\"color\\\": \\\"red\\\"}\\n                }\\n              }\\n            ]\\n
        \         }\\n        },\\n        \\\"options\\\": {\\n          \\\"colorMode\\\":
        \\\"background\\\",\\n          \\\"graphMode\\\": \\\"none\\\",\\n          \\\"justifyMode\\\":
        \\\"center\\\",\\n          \\\"textMode\\\": \\\"value_and_name\\\"\\n        }\\n
        \     },\\n      {\\n        \\\"id\\\": 4,\\n        \\\"gridPos\\\": {\\\"h\\\":
        4, \\\"w\\\": 8, \\\"x\\\": 16, \\\"y\\\": 3},\\n        \\\"type\\\": \\\"stat\\\",\\n
        \       \\\"title\\\": \\\"System Efficiency Rating\\\",\\n        \\\"targets\\\":
        [\\n          {\\n            \\\"expr\\\": \\\"100 - (sum(node_gpu_power_watts)
        / 330 * 100)\\\",\\n            \\\"refId\\\": \\\"A\\\"\\n          }\\n
        \       ],\\n        \\\"fieldConfig\\\": {\\n          \\\"defaults\\\":
        {\\n            \\\"unit\\\": \\\"percent\\\",\\n            \\\"decimals\\\":
        1,\\n            \\\"thresholds\\\": {\\n              \\\"mode\\\": \\\"absolute\\\",\\n
        \             \\\"steps\\\": [\\n                {\\\"color\\\": \\\"red\\\",
        \\\"value\\\": 0},\\n                {\\\"color\\\": \\\"yellow\\\", \\\"value\\\":
        50},\\n                {\\\"color\\\": \\\"green\\\", \\\"value\\\": 75}\\n
        \             ]\\n            }\\n          }\\n        },\\n        \\\"options\\\":
        {\\n          \\\"colorMode\\\": \\\"background\\\",\\n          \\\"graphMode\\\":
        \\\"area\\\",\\n          \\\"justifyMode\\\": \\\"center\\\"\\n        }\\n
        \     },\\n      {\\n        \\\"id\\\": 5,\\n        \\\"gridPos\\\": {\\\"h\\\":
        4, \\\"w\\\": 4, \\\"x\\\": 8, \\\"y\\\": 7},\\n        \\\"type\\\": \\\"stat\\\",\\n
        \       \\\"title\\\": \\\"CPU Score\\\",\\n        \\\"targets\\\": [\\n
        \         {\\n            \\\"expr\\\": \\\"100 - (100 - (avg(rate(node_cpu_seconds_total{mode=\\\\\\\"idle\\\\\\\"}[5m]))
        * 100))\\\",\\n            \\\"refId\\\": \\\"A\\\"\\n          }\\n        ],\\n
        \       \\\"fieldConfig\\\": {\\n          \\\"defaults\\\": {\\n            \\\"unit\\\":
        \\\"percent\\\",\\n            \\\"decimals\\\": 0,\\n            \\\"thresholds\\\":
        {\\n              \\\"mode\\\": \\\"absolute\\\",\\n              \\\"steps\\\":
        [\\n                {\\\"color\\\": \\\"red\\\", \\\"value\\\": 0},\\n                {\\\"color\\\":
        \\\"yellow\\\", \\\"value\\\": 40},\\n                {\\\"color\\\": \\\"green\\\",
        \\\"value\\\": 70}\\n              ]\\n            }\\n          }\\n        },\\n
        \       \\\"options\\\": {\\n          \\\"colorMode\\\": \\\"background\\\",\\n
        \         \\\"graphMode\\\": \\\"none\\\"\\n        }\\n      },\\n      {\\n
        \       \\\"id\\\": 6,\\n        \\\"gridPos\\\": {\\\"h\\\": 4, \\\"w\\\":
        4, \\\"x\\\": 12, \\\"y\\\": 7},\\n        \\\"type\\\": \\\"stat\\\",\\n
        \       \\\"title\\\": \\\"Memory Score\\\",\\n        \\\"targets\\\": [\\n
        \         {\\n            \\\"expr\\\": \\\"100 - ((1 - (node_memory_MemAvailable_bytes
        / node_memory_MemTotal_bytes)) * 100)\\\",\\n            \\\"refId\\\": \\\"A\\\"\\n
        \         }\\n        ],\\n        \\\"fieldConfig\\\": {\\n          \\\"defaults\\\":
        {\\n            \\\"unit\\\": \\\"percent\\\",\\n            \\\"decimals\\\":
        0,\\n            \\\"thresholds\\\": {\\n              \\\"mode\\\": \\\"absolute\\\",\\n
        \             \\\"steps\\\": [\\n                {\\\"color\\\": \\\"red\\\",
        \\\"value\\\": 0},\\n                {\\\"color\\\": \\\"yellow\\\", \\\"value\\\":
        40},\\n                {\\\"color\\\": \\\"green\\\", \\\"value\\\": 70}\\n
        \             ]\\n            }\\n          }\\n        },\\n        \\\"options\\\":
        {\\n          \\\"colorMode\\\": \\\"background\\\",\\n          \\\"graphMode\\\":
        \\\"none\\\"\\n        }\\n      },\\n      {\\n        \\\"id\\\": 7,\\n
        \       \\\"gridPos\\\": {\\\"h\\\": 4, \\\"w\\\": 4, \\\"x\\\": 16, \\\"y\\\":
        7},\\n        \\\"type\\\": \\\"stat\\\",\\n        \\\"title\\\": \\\"GPU
        Score\\\",\\n        \\\"targets\\\": [\\n          {\\n            \\\"expr\\\":
        \\\"100 - nvidia_gpu_utilization_percent\\\",\\n            \\\"refId\\\":
        \\\"A\\\"\\n          }\\n        ],\\n        \\\"fieldConfig\\\": {\\n          \\\"defaults\\\":
        {\\n            \\\"unit\\\": \\\"percent\\\",\\n            \\\"decimals\\\":
        0,\\n            \\\"thresholds\\\": {\\n              \\\"mode\\\": \\\"absolute\\\",\\n
        \             \\\"steps\\\": [\\n                {\\\"color\\\": \\\"red\\\",
        \\\"value\\\": 0},\\n                {\\\"color\\\": \\\"yellow\\\", \\\"value\\\":
        40},\\n                {\\\"color\\\": \\\"green\\\", \\\"value\\\": 70}\\n
        \             ]\\n            }\\n          }\\n        },\\n        \\\"options\\\":
        {\\n          \\\"colorMode\\\": \\\"background\\\",\\n          \\\"graphMode\\\":
        \\\"none\\\"\\n        }\\n      },\\n      {\\n        \\\"id\\\": 8,\\n
        \       \\\"gridPos\\\": {\\\"h\\\": 4, \\\"w\\\": 4, \\\"x\\\": 20, \\\"y\\\":
        7},\\n        \\\"type\\\": \\\"stat\\\",\\n        \\\"title\\\": \\\"Thermal
        Score\\\",\\n        \\\"targets\\\": [\\n          {\\n            \\\"expr\\\":
        \\\"100 - (max(node_hwmon_temp_celsius) / 85 * 100)\\\",\\n            \\\"refId\\\":
        \\\"A\\\"\\n          }\\n        ],\\n        \\\"fieldConfig\\\": {\\n          \\\"defaults\\\":
        {\\n            \\\"unit\\\": \\\"percent\\\",\\n            \\\"decimals\\\":
        0,\\n            \\\"thresholds\\\": {\\n              \\\"mode\\\": \\\"absolute\\\",\\n
        \             \\\"steps\\\": [\\n                {\\\"color\\\": \\\"red\\\",
        \\\"value\\\": 0},\\n                {\\\"color\\\": \\\"yellow\\\", \\\"value\\\":
        40},\\n                {\\\"color\\\": \\\"green\\\", \\\"value\\\": 70}\\n
        \             ]\\n            }\\n          }\\n        },\\n        \\\"options\\\":
        {\\n          \\\"colorMode\\\": \\\"background\\\",\\n          \\\"graphMode\\\":
        \\\"none\\\"\\n        }\\n      },\\n      {\\n        \\\"id\\\": 9,\\n
        \       \\\"gridPos\\\": {\\\"h\\\": 8, \\\"w\\\": 12, \\\"x\\\": 0, \\\"y\\\":
        11},\\n        \\\"type\\\": \\\"timeseries\\\",\\n        \\\"title\\\":
        \\\"CPU Usage vs Profile Baselines\\\",\\n        \\\"targets\\\": [\\n          {\\n
        \           \\\"expr\\\": \\\"100 - (avg(rate(node_cpu_seconds_total{mode=\\\\\\\"idle\\\\\\\"}[5m]))
        * 100)\\\",\\n            \\\"legendFormat\\\": \\\"Current CPU %\\\",\\n
        \           \\\"refId\\\": \\\"A\\\"\\n          },\\n          {\\n            \\\"expr\\\":
        \\\"5\\\",\\n            \\\"legendFormat\\\": \\\"\U0001F7E2 Idle Baseline
        (5%)\\\",\\n            \\\"refId\\\": \\\"B\\\"\\n          },\\n          {\\n
        \           \\\"expr\\\": \\\"40\\\",\\n            \\\"legendFormat\\\":
        \\\"\U0001F535 Development Baseline (40%)\\\",\\n            \\\"refId\\\":
        \\\"C\\\"\\n          },\\n          {\\n            \\\"expr\\\": \\\"60\\\",\\n
        \           \\\"legendFormat\\\": \\\"\U0001F7E3 AI/ML Baseline (60%)\\\",\\n
        \           \\\"refId\\\": \\\"D\\\"\\n          },\\n          {\\n            \\\"expr\\\":
        \\\"70\\\",\\n            \\\"legendFormat\\\": \\\"\U0001F7E0 Gaming Baseline
        (70%)\\\",\\n            \\\"refId\\\": \\\"E\\\"\\n          },\\n          {\\n
        \           \\\"expr\\\": \\\"90\\\",\\n            \\\"legendFormat\\\":
        \\\"\U0001F534 Video Baseline (90%)\\\",\\n            \\\"refId\\\": \\\"F\\\"\\n
        \         }\\n        ],\\n        \\\"fieldConfig\\\": {\\n          \\\"defaults\\\":
        {\\n            \\\"unit\\\": \\\"percent\\\",\\n            \\\"decimals\\\":
        1,\\n            \\\"color\\\": {\\\"mode\\\": \\\"palette-classic\\\"},\\n
        \           \\\"custom\\\": {\\n              \\\"lineInterpolation\\\": \\\"smooth\\\",\\n
        \             \\\"lineWidth\\\": 2,\\n              \\\"fillOpacity\\\": 10,\\n
        \             \\\"showPoints\\\": \\\"never\\\"\\n            },\\n            \\\"thresholds\\\":
        {\\n              \\\"mode\\\": \\\"absolute\\\",\\n              \\\"steps\\\":
        [\\n                {\\\"color\\\": \\\"green\\\", \\\"value\\\": null},\\n
        \               {\\\"color\\\": \\\"yellow\\\", \\\"value\\\": 60},\\n                {\\\"color\\\":
        \\\"red\\\", \\\"value\\\": 80}\\n              ]\\n            }\\n          },\\n
        \         \\\"overrides\\\": [\\n            {\\n              \\\"matcher\\\":
        {\\\"id\\\": \\\"byName\\\", \\\"options\\\": \\\"Current CPU %\\\"},\\n              \\\"properties\\\":
        [\\n                {\\\"id\\\": \\\"custom.lineWidth\\\", \\\"value\\\":
        4},\\n                {\\\"id\\\": \\\"custom.fillOpacity\\\", \\\"value\\\":
        25},\\n                {\\\"id\\\": \\\"color\\\", \\\"value\\\": {\\\"mode\\\":
        \\\"fixed\\\", \\\"fixedColor\\\": \\\"blue\\\"}}\\n              ]\\n            }\\n
        \         ]\\n        }\\n      },\\n      {\\n        \\\"id\\\": 10,\\n
        \       \\\"gridPos\\\": {\\\"h\\\": 8, \\\"w\\\": 12, \\\"x\\\": 12, \\\"y\\\":
        11},\\n        \\\"type\\\": \\\"timeseries\\\",\\n        \\\"title\\\":
        \\\"Memory Usage vs Profile Baselines\\\",\\n        \\\"targets\\\": [\\n
        \         {\\n            \\\"expr\\\": \\\"(1 - (node_memory_MemAvailable_bytes
        / node_memory_MemTotal_bytes)) * 100\\\",\\n            \\\"legendFormat\\\":
        \\\"Current Memory %\\\",\\n            \\\"refId\\\": \\\"A\\\"\\n          },\\n
        \         {\\n            \\\"expr\\\": \\\"20\\\",\\n            \\\"legendFormat\\\":
        \\\"\U0001F7E2 Idle Baseline (20%)\\\",\\n            \\\"refId\\\": \\\"B\\\"\\n
        \         },\\n          {\\n            \\\"expr\\\": \\\"60\\\",\\n            \\\"legendFormat\\\":
        \\\"\U0001F535 Development Baseline (60%)\\\",\\n            \\\"refId\\\":
        \\\"C\\\"\\n          },\\n          {\\n            \\\"expr\\\": \\\"70\\\",\\n
        \           \\\"legendFormat\\\": \\\"\U0001F7E3 AI/ML Baseline (70%)\\\",\\n
        \           \\\"refId\\\": \\\"D\\\"\\n          },\\n          {\\n            \\\"expr\\\":
        \\\"65\\\",\\n            \\\"legendFormat\\\": \\\"\U0001F7E0 Gaming Baseline
        (65%)\\\",\\n            \\\"refId\\\": \\\"E\\\"\\n          },\\n          {\\n
        \           \\\"expr\\\": \\\"85\\\",\\n            \\\"legendFormat\\\":
        \\\"\U0001F534 Video Baseline (85%)\\\",\\n            \\\"refId\\\": \\\"F\\\"\\n
        \         }\\n        ],\\n        \\\"fieldConfig\\\": {\\n          \\\"defaults\\\":
        {\\n            \\\"unit\\\": \\\"percent\\\",\\n            \\\"decimals\\\":
        1,\\n            \\\"color\\\": {\\\"mode\\\": \\\"palette-classic\\\"},\\n
        \           \\\"custom\\\": {\\n              \\\"lineInterpolation\\\": \\\"smooth\\\",\\n
        \             \\\"lineWidth\\\": 2,\\n              \\\"fillOpacity\\\": 10,\\n
        \             \\\"showPoints\\\": \\\"never\\\"\\n            }\\n          },\\n
        \         \\\"overrides\\\": [\\n            {\\n              \\\"matcher\\\":
        {\\\"id\\\": \\\"byName\\\", \\\"options\\\": \\\"Current Memory %\\\"},\\n
        \             \\\"properties\\\": [\\n                {\\\"id\\\": \\\"custom.lineWidth\\\",
        \\\"value\\\": 4},\\n                {\\\"id\\\": \\\"custom.fillOpacity\\\",
        \\\"value\\\": 25},\\n                {\\\"id\\\": \\\"color\\\", \\\"value\\\":
        {\\\"mode\\\": \\\"fixed\\\", \\\"fixedColor\\\": \\\"green\\\"}}\\n              ]\\n
        \           }\\n          ]\\n        }\\n      },\\n      {\\n        \\\"id\\\":
        11,\\n        \\\"gridPos\\\": {\\\"h\\\": 8, \\\"w\\\": 12, \\\"x\\\": 0,
        \\\"y\\\": 19},\\n        \\\"type\\\": \\\"timeseries\\\",\\n        \\\"title\\\":
        \\\"GPU Usage vs Profile Baselines\\\",\\n        \\\"targets\\\": [\\n          {\\n
        \           \\\"expr\\\": \\\"nvidia_gpu_utilization_percent\\\",\\n            \\\"legendFormat\\\":
        \\\"Current GPU %\\\",\\n            \\\"refId\\\": \\\"A\\\"\\n          },\\n
        \         {\\n            \\\"expr\\\": \\\"5\\\",\\n            \\\"legendFormat\\\":
        \\\"\U0001F7E2 Idle Baseline (5%)\\\",\\n            \\\"refId\\\": \\\"B\\\"\\n
        \         },\\n          {\\n            \\\"expr\\\": \\\"10\\\",\\n            \\\"legendFormat\\\":
        \\\"\U0001F535 Development Baseline (10%)\\\",\\n            \\\"refId\\\":
        \\\"C\\\"\\n          },\\n          {\\n            \\\"expr\\\": \\\"80\\\",\\n
        \           \\\"legendFormat\\\": \\\"\U0001F7E3 AI/ML Baseline (80%)\\\",\\n
        \           \\\"refId\\\": \\\"D\\\"\\n          },\\n          {\\n            \\\"expr\\\":
        \\\"95\\\",\\n            \\\"legendFormat\\\": \\\"\U0001F7E0 Gaming Baseline
        (95%)\\\",\\n            \\\"refId\\\": \\\"E\\\"\\n          },\\n          {\\n
        \           \\\"expr\\\": \\\"90\\\",\\n            \\\"legendFormat\\\":
        \\\"\U0001F534 Video Baseline (90%)\\\",\\n            \\\"refId\\\": \\\"F\\\"\\n
        \         }\\n        ],\\n        \\\"fieldConfig\\\": {\\n          \\\"defaults\\\":
        {\\n            \\\"unit\\\": \\\"percent\\\",\\n            \\\"decimals\\\":
        1,\\n            \\\"color\\\": {\\\"mode\\\": \\\"palette-classic\\\"},\\n
        \           \\\"custom\\\": {\\n              \\\"lineInterpolation\\\": \\\"smooth\\\",\\n
        \             \\\"lineWidth\\\": 2,\\n              \\\"fillOpacity\\\": 10,\\n
        \             \\\"showPoints\\\": \\\"never\\\"\\n            }\\n          },\\n
        \         \\\"overrides\\\": [\\n            {\\n              \\\"matcher\\\":
        {\\\"id\\\": \\\"byName\\\", \\\"options\\\": \\\"Current GPU %\\\"},\\n              \\\"properties\\\":
        [\\n                {\\\"id\\\": \\\"custom.lineWidth\\\", \\\"value\\\":
        4},\\n                {\\\"id\\\": \\\"custom.fillOpacity\\\", \\\"value\\\":
        25},\\n                {\\\"id\\\": \\\"color\\\", \\\"value\\\": {\\\"mode\\\":
        \\\"fixed\\\", \\\"fixedColor\\\": \\\"purple\\\"}}\\n              ]\\n            }\\n
        \         ]\\n        }\\n      },\\n      {\\n        \\\"id\\\": 12,\\n
        \       \\\"gridPos\\\": {\\\"h\\\": 8, \\\"w\\\": 12, \\\"x\\\": 12, \\\"y\\\":
        19},\\n        \\\"type\\\": \\\"timeseries\\\",\\n        \\\"title\\\":
        \\\"Temperature vs Profile Baselines\\\",\\n        \\\"targets\\\": [\\n
        \         {\\n            \\\"expr\\\": \\\"max(node_hwmon_temp_celsius)\\\",\\n
        \           \\\"legendFormat\\\": \\\"Current Max Temperature\\\",\\n            \\\"refId\\\":
        \\\"A\\\"\\n          },\\n          {\\n            \\\"expr\\\": \\\"node_hwmon_temp_celsius\\\",\\n
        \           \\\"legendFormat\\\": \\\"CPU Temp\\\",\\n            \\\"refId\\\":
        \\\"B\\\"\\n          },\\n          {\\n            \\\"expr\\\": \\\"nvidia_gpu_temperature_celsius\\\",\\n
        \           \\\"legendFormat\\\": \\\"GPU Temp\\\",\\n            \\\"refId\\\":
        \\\"C\\\"\\n          },\\n          {\\n            \\\"expr\\\": \\\"45\\\",\\n
        \           \\\"legendFormat\\\": \\\"\U0001F7E2 Idle Baseline (45°C)\\\",\\n
        \           \\\"refId\\\": \\\"D\\\"\\n          },\\n          {\\n            \\\"expr\\\":
        \\\"65\\\",\\n            \\\"legendFormat\\\": \\\"\U0001F535 Development
        Baseline (65°C)\\\",\\n            \\\"refId\\\": \\\"E\\\"\\n          },\\n
        \         {\\n            \\\"expr\\\": \\\"75\\\",\\n            \\\"legendFormat\\\":
        \\\"\U0001F7E3 AI/ML Baseline (75°C)\\\",\\n            \\\"refId\\\": \\\"F\\\"\\n
        \         },\\n          {\\n            \\\"expr\\\": \\\"85\\\",\\n            \\\"legendFormat\\\":
        \\\"\U0001F7E0 Gaming Baseline (85°C)\\\",\\n            \\\"refId\\\": \\\"G\\\"\\n
        \         }\\n        ],\\n        \\\"fieldConfig\\\": {\\n          \\\"defaults\\\":
        {\\n            \\\"unit\\\": \\\"celsius\\\",\\n            \\\"decimals\\\":
        0,\\n            \\\"color\\\": {\\\"mode\\\": \\\"palette-classic\\\"},\\n
        \           \\\"custom\\\": {\\n              \\\"lineInterpolation\\\": \\\"smooth\\\",\\n
        \             \\\"lineWidth\\\": 2,\\n              \\\"fillOpacity\\\": 10,\\n
        \             \\\"showPoints\\\": \\\"never\\\"\\n            },\\n            \\\"thresholds\\\":
        {\\n              \\\"mode\\\": \\\"absolute\\\",\\n              \\\"steps\\\":
        [\\n                {\\\"color\\\": \\\"green\\\", \\\"value\\\": null},\\n
        \               {\\\"color\\\": \\\"yellow\\\", \\\"value\\\": 70},\\n                {\\\"color\\\":
        \\\"red\\\", \\\"value\\\": 85}\\n              ]\\n            }\\n          },\\n
        \         \\\"overrides\\\": [\\n            {\\n              \\\"matcher\\\":
        {\\\"id\\\": \\\"byName\\\", \\\"options\\\": \\\"Current Max Temperature\\\"},\\n
        \             \\\"properties\\\": [\\n                {\\\"id\\\": \\\"custom.lineWidth\\\",
        \\\"value\\\": 4},\\n                {\\\"id\\\": \\\"custom.fillOpacity\\\",
        \\\"value\\\": 25},\\n                {\\\"id\\\": \\\"color\\\", \\\"value\\\":
        {\\\"mode\\\": \\\"fixed\\\", \\\"fixedColor\\\": \\\"red\\\"}}\\n              ]\\n
        \           }\\n          ]\\n        }\\n      },\\n      {\\n        \\\"id\\\":
        13,\\n        \\\"gridPos\\\": {\\\"h\\\": 8, \\\"w\\\": 12, \\\"x\\\": 0,
        \\\"y\\\": 27},\\n        \\\"type\\\": \\\"timeseries\\\",\\n        \\\"title\\\":
        \\\"Power Consumption vs Profile Baselines\\\",\\n        \\\"targets\\\":
        [\\n          {\\n            \\\"expr\\\": \\\"sum(node_gpu_power_watts)\\\",\\n
        \           \\\"legendFormat\\\": \\\"Current Total Power\\\",\\n            \\\"refId\\\":
        \\\"A\\\"\\n          },\\n          {\\n            \\\"expr\\\": \\\"node_gpu_power_watts\\\",\\n
        \           \\\"legendFormat\\\": \\\"CPU Power\\\",\\n            \\\"refId\\\":
        \\\"B\\\"\\n          },\\n          {\\n            \\\"expr\\\": \\\"node_gpu_power_watts\\\",\\n
        \           \\\"legendFormat\\\": \\\"GPU Power\\\",\\n            \\\"refId\\\":
        \\\"C\\\"\\n          },\\n          {\\n            \\\"expr\\\": \\\"25\\\",\\n
        \           \\\"legendFormat\\\": \\\"\U0001F7E2 Idle Baseline (25W)\\\",\\n
        \           \\\"refId\\\": \\\"D\\\"\\n          },\\n          {\\n            \\\"expr\\\":
        \\\"65\\\",\\n            \\\"legendFormat\\\": \\\"\U0001F535 Development
        Baseline (65W)\\\",\\n            \\\"refId\\\": \\\"E\\\"\\n          },\\n
        \         {\\n            \\\"expr\\\": \\\"150\\\",\\n            \\\"legendFormat\\\":
        \\\"\U0001F7E3 AI/ML Baseline (150W)\\\",\\n            \\\"refId\\\": \\\"F\\\"\\n
        \         },\\n          {\\n            \\\"expr\\\": \\\"280\\\",\\n            \\\"legendFormat\\\":
        \\\"\U0001F7E0 Gaming Baseline (280W)\\\",\\n            \\\"refId\\\": \\\"G\\\"\\n
        \         }\\n        ],\\n        \\\"fieldConfig\\\": {\\n          \\\"defaults\\\":
        {\\n            \\\"unit\\\": \\\"watt\\\",\\n            \\\"decimals\\\":
        0,\\n            \\\"color\\\": {\\\"mode\\\": \\\"palette-classic\\\"},\\n
        \           \\\"custom\\\": {\\n              \\\"lineInterpolation\\\": \\\"smooth\\\",\\n
        \             \\\"lineWidth\\\": 2,\\n              \\\"fillOpacity\\\": 10,\\n
        \             \\\"showPoints\\\": \\\"never\\\"\\n            }\\n          },\\n
        \         \\\"overrides\\\": [\\n            {\\n              \\\"matcher\\\":
        {\\\"id\\\": \\\"byName\\\", \\\"options\\\": \\\"Current Total Power\\\"},\\n
        \             \\\"properties\\\": [\\n                {\\\"id\\\": \\\"custom.lineWidth\\\",
        \\\"value\\\": 4},\\n                {\\\"id\\\": \\\"custom.fillOpacity\\\",
        \\\"value\\\": 25},\\n                {\\\"id\\\": \\\"color\\\", \\\"value\\\":
        {\\\"mode\\\": \\\"fixed\\\", \\\"fixedColor\\\": \\\"orange\\\"}}\\n              ]\\n
        \           }\\n          ]\\n        }\\n      },\\n      {\\n        \\\"id\\\":
        14,\\n        \\\"gridPos\\\": {\\\"h\\\": 8, \\\"w\\\": 12, \\\"x\\\": 12,
        \\\"y\\\": 27},\\n        \\\"type\\\": \\\"heatmap\\\",\\n        \\\"title\\\":
        \\\"Performance Distribution Heatmap\\\",\\n        \\\"targets\\\": [\\n
        \         {\\n            \\\"expr\\\": \\\"rate(node_cpu_seconds_total{mode!=\\\\\\\"idle\\\\\\\"}[5m])
        * 100\\\",\\n            \\\"format\\\": \\\"time_series\\\",\\n            \\\"legendFormat\\\":
        \\\"CPU {{cpu}}\\\",\\n            \\\"refId\\\": \\\"A\\\"\\n          }\\n
        \       ],\\n        \\\"fieldConfig\\\": {\\n          \\\"defaults\\\":
        {\\n            \\\"custom\\\": {\\n              \\\"scaleDistribution\\\":
        {\\\"type\\\": \\\"linear\\\"},\\n              \\\"hideFrom\\\": {\\\"tooltip\\\":
        false, \\\"viz\\\": false, \\\"legend\\\": false}\\n            }\\n          }\\n
        \       },\\n        \\\"options\\\": {\\n          \\\"calculate\\\": false,\\n
        \         \\\"cellGap\\\": 1,\\n          \\\"color\\\": {\\n            \\\"mode\\\":
        \\\"scheme\\\",\\n            \\\"scheme\\\": \\\"Spectral\\\",\\n            \\\"steps\\\":
        64\\n          },\\n          \\\"yAxis\\\": {\\n            \\\"axisPlacement\\\":
        \\\"left\\\",\\n            \\\"reverse\\\": false,\\n            \\\"unit\\\":
        \\\"percent\\\"\\n          }\\n        }\\n      },\\n      {\\n        \\\"id\\\":
        15,\\n        \\\"gridPos\\\": {\\\"h\\\": 8, \\\"w\\\": 24, \\\"x\\\": 0,
        \\\"y\\\": 35},\\n        \\\"type\\\": \\\"timeseries\\\",\\n        \\\"title\\\":
        \\\"ODIN Performance Score Timeline with Component Breakdown\\\",\\n        \\\"targets\\\":
        [\\n          {\\n            \\\"expr\\\": \\\"100 - ((((100 - (avg(rate(node_cpu_seconds_total{mode=\\\\\\\"idle\\\\\\\"}[5m]))
        * 100)) / 100) + ((1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)))
        + (max(node_hwmon_temp_celsius) / 100)) / 3 * 100)\\\",\\n            \\\"legendFormat\\\":
        \\\"\U0001F3AF ODIN Performance Score\\\",\\n            \\\"refId\\\": \\\"A\\\"\\n
        \         },\\n          {\\n            \\\"expr\\\": \\\"100 - (100 - (avg(rate(node_cpu_seconds_total{mode=\\\\\\\"idle\\\\\\\"}[5m]))
        * 100))\\\",\\n            \\\"legendFormat\\\": \\\"\U0001F4BB CPU Component
        Score\\\",\\n            \\\"refId\\\": \\\"B\\\"\\n          },\\n          {\\n
        \           \\\"expr\\\": \\\"100 - ((1 - (node_memory_MemAvailable_bytes
        / node_memory_MemTotal_bytes)) * 100)\\\",\\n            \\\"legendFormat\\\":
        \\\"\U0001F9E0 Memory Component Score\\\",\\n            \\\"refId\\\": \\\"C\\\"\\n
        \         },\\n          {\\n            \\\"expr\\\": \\\"100 - nvidia_gpu_utilization_percent\\\",\\n
        \           \\\"legendFormat\\\": \\\"\U0001F3AE GPU Component Score\\\",\\n
        \           \\\"refId\\\": \\\"D\\\"\\n          },\\n          {\\n            \\\"expr\\\":
        \\\"100 - (max(node_hwmon_temp_celsius) / 85 * 100)\\\",\\n            \\\"legendFormat\\\":
        \\\"\U0001F321️ Thermal Component Score\\\",\\n            \\\"refId\\\":
        \\\"E\\\"\\n          }\\n        ],\\n        \\\"fieldConfig\\\": {\\n          \\\"defaults\\\":
        {\\n            \\\"unit\\\": \\\"percent\\\",\\n            \\\"decimals\\\":
        1,\\n            \\\"color\\\": {\\\"mode\\\": \\\"palette-classic\\\"},\\n
        \           \\\"custom\\\": {\\n              \\\"lineInterpolation\\\": \\\"smooth\\\",\\n
        \             \\\"lineWidth\\\": 2,\\n              \\\"fillOpacity\\\": 15,\\n
        \             \\\"showPoints\\\": \\\"never\\\"\\n            },\\n            \\\"min\\\":
        0,\\n            \\\"max\\\": 100\\n          },\\n          \\\"overrides\\\":
        [\\n            {\\n              \\\"matcher\\\": {\\\"id\\\": \\\"byName\\\",
        \\\"options\\\": \\\"\U0001F3AF ODIN Performance Score\\\"},\\n              \\\"properties\\\":
        [\\n                {\\\"id\\\": \\\"custom.lineWidth\\\", \\\"value\\\":
        5},\\n                {\\\"id\\\": \\\"custom.fillOpacity\\\", \\\"value\\\":
        30},\\n                {\\\"id\\\": \\\"color\\\", \\\"value\\\": {\\\"mode\\\":
        \\\"fixed\\\", \\\"fixedColor\\\": \\\"blue\\\"}}\\n              ]\\n            }\\n
        \         ]\\n        },\\n        \\\"options\\\": {\\n          \\\"legend\\\":
        {\\n            \\\"displayMode\\\": \\\"table\\\",\\n            \\\"placement\\\":
        \\\"right\\\",\\n            \\\"calcs\\\": [\\\"lastNotNull\\\", \\\"mean\\\",
        \\\"min\\\", \\\"max\\\"]\\n          },\\n          \\\"tooltip\\\": {\\n
        \           \\\"mode\\\": \\\"multi\\\",\\n            \\\"sort\\\": \\\"desc\\\"\\n
        \         }\\n        }\\n      }\\n    ]\\n}\\n\"},\"kind\":\"ConfigMap\",\"metadata\":{\"annotations\":{},\"name\":\"performance-baseline-dashboard\",\"namespace\":\"monitoring\"}}\n"
    creationTimestamp: "2025-05-28T00:31:42Z"
    name: performance-baseline-dashboard
    namespace: monitoring
    resourceVersion: "1994782"
    uid: 996cdfe7-a7b0-40b9-9afe-a9b0f39ff211
- apiVersion: v1
  data:
    profiles.yaml: "# Performance Baseline Profiles for Razer Blade 18\n# These thresholds
      are based on typical workloads\n\nprofiles:\n  idle:\n    name: \"Idle/Light
      Usage\"\n    description: \"System at rest or light browsing\"\n    thresholds:\n
      \     cpu_usage_percent: 5\n      memory_usage_percent: 20\n      gpu_usage_percent:
      5\n      power_consumption_watts: 25\n      temperature_celsius: 45\n      network_bandwidth_mbps:
      10\n      disk_io_mbps: 5\n  \n  development:\n    name: \"Software Development\"\n
      \   description: \"IDE, compiling, debugging, containers\"\n    thresholds:\n
      \     cpu_usage_percent: 40\n      memory_usage_percent: 60\n      gpu_usage_percent:
      10\n      power_consumption_watts: 65\n      temperature_celsius: 65\n      network_bandwidth_mbps:
      50\n      disk_io_mbps: 100\n  \n  ai_inference:\n    name: \"AI/ML Inference\"\n
      \   description: \"Running Claude Code, Copilot, local LLMs\"\n    thresholds:\n
      \     cpu_usage_percent: 60\n      memory_usage_percent: 70\n      gpu_usage_percent:
      80\n      power_consumption_watts: 150\n      temperature_celsius: 75\n      network_bandwidth_mbps:
      20\n      disk_io_mbps: 50\n  \n  gaming:\n    name: \"Gaming\"\n    description:
      \"High-performance gaming workload\"\n    thresholds:\n      cpu_usage_percent:
      70\n      memory_usage_percent: 65\n      gpu_usage_percent: 95\n      power_consumption_watts:
      280\n      temperature_celsius: 85\n      network_bandwidth_mbps: 100\n      disk_io_mbps:
      200\n  \n  video_editing:\n    name: \"Video Editing/Rendering\"\n    description:
      \"4K video editing, encoding, effects\"\n    thresholds:\n      cpu_usage_percent:
      90\n      memory_usage_percent: 85\n      gpu_usage_percent: 90\n      power_consumption_watts:
      250\n      temperature_celsius: 80\n      network_bandwidth_mbps: 30\n      disk_io_mbps:
      500\n  \n  stress_test:\n    name: \"Stress Test\"\n    description: \"Maximum
      system load for testing\"\n    thresholds:\n      cpu_usage_percent: 100\n      memory_usage_percent:
      95\n      gpu_usage_percent: 100\n      power_consumption_watts: 330\n      temperature_celsius:
      95\n      network_bandwidth_mbps: 1000\n      disk_io_mbps: 1000\n\nalert_rules:\n
      \ - name: \"Performance Anomaly Detection\"\n    rules:\n      - alert: \"CPU
      Usage Exceeds Profile\"\n        expr: |\n          (100 - (avg(rate(node_cpu_seconds_total{mode=\"idle\"}[5m]))
      * 100)) \n          > on() group_left() performance_profile_cpu_threshold\n
      \       for: 5m\n        \n      - alert: \"Memory Usage Exceeds Profile\"\n
      \       expr: |\n          ((1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes))
      * 100)\n          > on() group_left() performance_profile_memory_threshold\n
      \       for: 5m\n        \n      - alert: \"Temperature Exceeds Profile\"\n
      \       expr: |\n          max(node_hwmon_temp_celsius)\n          > on() group_left()
      performance_profile_temperature_threshold\n        for: 3m\n        \n      -
      alert: \"Power Consumption Exceeds Profile\"\n        expr: |\n          sum(node_cpu_package_power_watts)
      + sum(node_gpu_power_watts)\n          > on() group_left() performance_profile_power_threshold\n
      \       for: 5m\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"profiles.yaml":"# Performance Baseline Profiles for Razer Blade 18\n# These thresholds are based on typical workloads\n\nprofiles:\n  idle:\n    name: \"Idle/Light Usage\"\n    description: \"System at rest or light browsing\"\n    thresholds:\n      cpu_usage_percent: 5\n      memory_usage_percent: 20\n      gpu_usage_percent: 5\n      power_consumption_watts: 25\n      temperature_celsius: 45\n      network_bandwidth_mbps: 10\n      disk_io_mbps: 5\n  \n  development:\n    name: \"Software Development\"\n    description: \"IDE, compiling, debugging, containers\"\n    thresholds:\n      cpu_usage_percent: 40\n      memory_usage_percent: 60\n      gpu_usage_percent: 10\n      power_consumption_watts: 65\n      temperature_celsius: 65\n      network_bandwidth_mbps: 50\n      disk_io_mbps: 100\n  \n  ai_inference:\n    name: \"AI/ML Inference\"\n    description: \"Running Claude Code, Copilot, local LLMs\"\n    thresholds:\n      cpu_usage_percent: 60\n      memory_usage_percent: 70\n      gpu_usage_percent: 80\n      power_consumption_watts: 150\n      temperature_celsius: 75\n      network_bandwidth_mbps: 20\n      disk_io_mbps: 50\n  \n  gaming:\n    name: \"Gaming\"\n    description: \"High-performance gaming workload\"\n    thresholds:\n      cpu_usage_percent: 70\n      memory_usage_percent: 65\n      gpu_usage_percent: 95\n      power_consumption_watts: 280\n      temperature_celsius: 85\n      network_bandwidth_mbps: 100\n      disk_io_mbps: 200\n  \n  video_editing:\n    name: \"Video Editing/Rendering\"\n    description: \"4K video editing, encoding, effects\"\n    thresholds:\n      cpu_usage_percent: 90\n      memory_usage_percent: 85\n      gpu_usage_percent: 90\n      power_consumption_watts: 250\n      temperature_celsius: 80\n      network_bandwidth_mbps: 30\n      disk_io_mbps: 500\n  \n  stress_test:\n    name: \"Stress Test\"\n    description: \"Maximum system load for testing\"\n    thresholds:\n      cpu_usage_percent: 100\n      memory_usage_percent: 95\n      gpu_usage_percent: 100\n      power_consumption_watts: 330\n      temperature_celsius: 95\n      network_bandwidth_mbps: 1000\n      disk_io_mbps: 1000\n\nalert_rules:\n  - name: \"Performance Anomaly Detection\"\n    rules:\n      - alert: \"CPU Usage Exceeds Profile\"\n        expr: |\n          (100 - (avg(rate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)) \n          \u003e on() group_left() performance_profile_cpu_threshold\n        for: 5m\n        \n      - alert: \"Memory Usage Exceeds Profile\"\n        expr: |\n          ((1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100)\n          \u003e on() group_left() performance_profile_memory_threshold\n        for: 5m\n        \n      - alert: \"Temperature Exceeds Profile\"\n        expr: |\n          max(node_hwmon_temp_celsius)\n          \u003e on() group_left() performance_profile_temperature_threshold\n        for: 3m\n        \n      - alert: \"Power Consumption Exceeds Profile\"\n        expr: |\n          sum(node_cpu_package_power_watts) + sum(node_gpu_power_watts)\n          \u003e on() group_left() performance_profile_power_threshold\n        for: 5m\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"performance-profiles","namespace":"monitoring"}}
    creationTimestamp: "2025-05-28T00:31:42Z"
    name: performance-profiles
    namespace: monitoring
    resourceVersion: "7298"
    uid: 176529cd-10ce-428c-99df-ac9978dcdb7f
- apiVersion: v1
  data:
    container-metrics.json: |
      {
        "id": null,
        "title": "Container Metrics",
        "tags": ["containers", "kubernetes"],
        "style": "dark",
        "timezone": "browser",
        "refresh": "30s",
        "schemaVersion": 27,
        "version": 1,
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "panels": [
          {
            "id": 1,
            "title": "Monitoring Pods Status",
            "type": "stat",
            "targets": [
              {
                "expr": "count(kube_pod_info{namespace=\"monitoring\"})",
                "legendFormat": "Total Pods",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "short",
                "color": {
                  "mode": "thresholds"
                },
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": null},
                    {"color": "green", "value": 1}
                  ]
                }
              }
            },
            "gridPos": {"h": 6, "w": 6, "x": 0, "y": 0}
          },
          {
            "id": 2,
            "title": "Running Pods",
            "type": "stat",
            "targets": [
              {
                "expr": "count(kube_pod_status_phase{namespace=\"monitoring\", phase=\"Running\"})",
                "legendFormat": "Running",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "short",
                "color": {
                  "mode": "thresholds"
                },
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": null},
                    {"color": "green", "value": 1}
                  ]
                }
              }
            },
            "gridPos": {"h": 6, "w": 6, "x": 6, "y": 0}
          },
          {
            "id": 3,
            "title": "Pod Restart Count",
            "type": "stat",
            "targets": [
              {
                "expr": "sum(kube_pod_container_status_restarts_total{namespace=\"monitoring\"})",
                "legendFormat": "Total Restarts",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "short",
                "color": {
                  "mode": "thresholds"
                },
                "thresholds": {
                  "steps": [
                    {"color": "green", "value": null},
                    {"color": "yellow", "value": 1},
                    {"color": "red", "value": 10}
                  ]
                }
              }
            },
            "gridPos": {"h": 6, "w": 6, "x": 12, "y": 0}
          },
          {
            "id": 4,
            "title": "Container States",
            "type": "stat",
            "targets": [
              {
                "expr": "count(kube_pod_container_status_ready{namespace=\"monitoring\"} == 1)",
                "legendFormat": "Ready",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "short",
                "color": {
                  "mode": "thresholds"
                },
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": null},
                    {"color": "green", "value": 1}
                  ]
                }
              }
            },
            "gridPos": {"h": 6, "w": 6, "x": 18, "y": 0}
          },
          {
            "id": 5,
            "title": "Pod Information",
            "type": "table",
            "targets": [
              {
                "expr": "kube_pod_info{namespace=\"monitoring\"}",
                "format": "table",
                "instant": true,
                "refId": "A"
              }
            ],
            "transformations": [
              {
                "id": "organize",
                "options": {
                  "excludeByName": {
                    "Time": true,
                    "__name__": true,
                    "instance": true,
                    "job": true,
                    "uid": true
                  },
                  "indexByName": {},
                  "renameByName": {}
                }
              }
            ],
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 6}
          },
          {
            "id": 6,
            "title": "Pod Status Over Time",
            "type": "timeseries",
            "targets": [
              {
                "expr": "kube_pod_status_phase{namespace=\"monitoring\"}",
                "legendFormat": "{{ pod }} - {{ phase }}",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "short"
              }
            },
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 6}
          }
        ]
      }
    gpu-monitoring.json: |
      {
        "id": null,
        "title": "GPU Monitoring",
        "tags": ["gpu", "nvidia"],
        "style": "dark",
        "timezone": "browser",
        "refresh": "30s",
        "schemaVersion": 27,
        "version": 1,
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "panels": [
          {
            "id": 1,
            "title": "GPU Device Plugin Status",
            "type": "stat",
            "targets": [
              {
                "expr": "up{job=\"kubernetes-service-discovery\", instance=~\".*nvidia.*\"}",
                "legendFormat": "Device Plugin",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "short",
                "mappings": [
                  {"type": "value", "value": "0", "text": "DOWN"},
                  {"type": "value", "value": "1", "text": "UP"}
                ],
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": null},
                    {"color": "green", "value": 1}
                  ]
                }
              }
            },
            "gridPos": {"h": 6, "w": 6, "x": 0, "y": 0}
          },
          {
            "id": 2,
            "title": "GPU Temperature",
            "type": "timeseries",
            "targets": [
              {
                "expr": "nvidia_gpu_temperature_celsius",
                "legendFormat": "GPU {{gpu}} Temperature",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "celsius",
                "thresholds": {
                  "steps": [
                    {"color": "green", "value": null},
                    {"color": "yellow", "value": 70},
                    {"color": "red", "value": 85}
                  ]
                }
              }
            },
            "gridPos": {"h": 8, "w": 12, "x": 6, "y": 0}
          },
          {
            "id": 3,
            "title": "GPU Utilization",
            "type": "timeseries",
            "targets": [
              {
                "expr": "nvidia_gpu_utilization_percent",
                "legendFormat": "GPU {{gpu}} Utilization",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "percent",
                "min": 0,
                "max": 100
              }
            },
            "gridPos": {"h": 8, "w": 12, "x": 18, "y": 0}
          },
          {
            "id": 4,
            "title": "GPU Memory Usage",
            "type": "timeseries",
            "targets": [
              {
                "expr": "nvidia_gpu_memory_used_mb",
                "legendFormat": "GPU {{gpu}} Memory Used",
                "refId": "A"
              },
              {
                "expr": "nvidia_gpu_memory_total_mb - nvidia_gpu_memory_used_mb",
                "legendFormat": "GPU {{gpu}} Memory Free",
                "refId": "B"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "decmbytes"
              }
            },
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8}
          },
          {
            "id": 5,
            "title": "GPU Power Usage",
            "type": "timeseries",
            "targets": [
              {
                "expr": "node_gpu_power_watts",
                "legendFormat": "GPU {{gpu}} Power",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "watt"
              }
            },
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8}
          },
          {
            "id": 6,
            "title": "GPU Status Information",
            "type": "table",
            "targets": [
              {
                "expr": "kube_node_status_capacity{resource=\"nvidia_com_gpu\"}",
                "format": "table",
                "instant": true,
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "custom": {
                  "displayMode": "table"
                }
              }
            },
            "gridPos": {"h": 6, "w": 24, "x": 0, "y": 16}
          }
        ]
      }
    monitoring-overview.json: |
      {
        "id": null,
        "title": "Monitoring Stack Overview",
        "tags": ["monitoring", "odin"],
        "style": "dark",
        "timezone": "browser",
        "refresh": "30s",
        "schemaVersion": 27,
        "version": 1,
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "panels": [
          {
            "id": 1,
            "title": "Monitoring Stack Status",
            "type": "stat",
            "targets": [
              {
                "expr": "up{job=~\"prometheus|node-exporter|alertmanager\"}",
                "legendFormat": "{{ job }}",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "mappings": [
                  {"type": "value", "value": "0", "text": "DOWN"},
                  {"type": "value", "value": "1", "text": "UP"}
                ],
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "green", "value": 1}
                  ]
                }
              }
            },
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 0}
          },
          {
            "id": 2,
            "title": "Prometheus Target Health",
            "type": "table",
            "targets": [
              {
                "expr": "up",
                "format": "table",
                "instant": true,
                "refId": "A"
              }
            ],
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8}
          },
          {
            "id": 3,
            "title": "Alerts Overview",
            "type": "table",
            "targets": [
              {
                "expr": "ALERTS",
                "format": "table",
                "instant": true,
                "refId": "A"
              }
            ],
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8}
          }
        ]
      }
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"container-metrics.json":"{\n  \"id\": null,\n  \"title\": \"Container Metrics\",\n  \"tags\": [\"containers\", \"kubernetes\"],\n  \"style\": \"dark\",\n  \"timezone\": \"browser\",\n  \"refresh\": \"30s\",\n  \"schemaVersion\": 27,\n  \"version\": 1,\n  \"time\": {\n    \"from\": \"now-1h\",\n    \"to\": \"now\"\n  },\n  \"panels\": [\n    {\n      \"id\": 1,\n      \"title\": \"Monitoring Pods Status\",\n      \"type\": \"stat\",\n      \"targets\": [\n        {\n          \"expr\": \"count(kube_pod_info{namespace=\\\"monitoring\\\"})\",\n          \"legendFormat\": \"Total Pods\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"red\", \"value\": null},\n              {\"color\": \"green\", \"value\": 1}\n            ]\n          }\n        }\n      },\n      \"gridPos\": {\"h\": 6, \"w\": 6, \"x\": 0, \"y\": 0}\n    },\n    {\n      \"id\": 2,\n      \"title\": \"Running Pods\",\n      \"type\": \"stat\",\n      \"targets\": [\n        {\n          \"expr\": \"count(kube_pod_status_phase{namespace=\\\"monitoring\\\", phase=\\\"Running\\\"})\",\n          \"legendFormat\": \"Running\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"red\", \"value\": null},\n              {\"color\": \"green\", \"value\": 1}\n            ]\n          }\n        }\n      },\n      \"gridPos\": {\"h\": 6, \"w\": 6, \"x\": 6, \"y\": 0}\n    },\n    {\n      \"id\": 3,\n      \"title\": \"Pod Restart Count\",\n      \"type\": \"stat\",\n      \"targets\": [\n        {\n          \"expr\": \"sum(kube_pod_container_status_restarts_total{namespace=\\\"monitoring\\\"})\",\n          \"legendFormat\": \"Total Restarts\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 1},\n              {\"color\": \"red\", \"value\": 10}\n            ]\n          }\n        }\n      },\n      \"gridPos\": {\"h\": 6, \"w\": 6, \"x\": 12, \"y\": 0}\n    },\n    {\n      \"id\": 4,\n      \"title\": \"Container States\",\n      \"type\": \"stat\",\n      \"targets\": [\n        {\n          \"expr\": \"count(kube_pod_container_status_ready{namespace=\\\"monitoring\\\"} == 1)\",\n          \"legendFormat\": \"Ready\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"red\", \"value\": null},\n              {\"color\": \"green\", \"value\": 1}\n            ]\n          }\n        }\n      },\n      \"gridPos\": {\"h\": 6, \"w\": 6, \"x\": 18, \"y\": 0}\n    },\n    {\n      \"id\": 5,\n      \"title\": \"Pod Information\",\n      \"type\": \"table\",\n      \"targets\": [\n        {\n          \"expr\": \"kube_pod_info{namespace=\\\"monitoring\\\"}\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"transformations\": [\n        {\n          \"id\": \"organize\",\n          \"options\": {\n            \"excludeByName\": {\n              \"Time\": true,\n              \"__name__\": true,\n              \"instance\": true,\n              \"job\": true,\n              \"uid\": true\n            },\n            \"indexByName\": {},\n            \"renameByName\": {}\n          }\n        }\n      ],\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 6}\n    },\n    {\n      \"id\": 6,\n      \"title\": \"Pod Status Over Time\",\n      \"type\": \"timeseries\",\n      \"targets\": [\n        {\n          \"expr\": \"kube_pod_status_phase{namespace=\\\"monitoring\\\"}\",\n          \"legendFormat\": \"{{ pod }} - {{ phase }}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\"\n        }\n      },\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 6}\n    }\n  ]\n}\n","gpu-monitoring.json":"{\n  \"id\": null,\n  \"title\": \"GPU Monitoring\",\n  \"tags\": [\"gpu\", \"nvidia\"],\n  \"style\": \"dark\",\n  \"timezone\": \"browser\",\n  \"refresh\": \"30s\",\n  \"schemaVersion\": 27,\n  \"version\": 1,\n  \"time\": {\n    \"from\": \"now-1h\",\n    \"to\": \"now\"\n  },\n  \"panels\": [\n    {\n      \"id\": 1,\n      \"title\": \"GPU Device Plugin Status\",\n      \"type\": \"stat\",\n      \"targets\": [\n        {\n          \"expr\": \"up{job=\\\"kubernetes-service-discovery\\\", instance=~\\\".*nvidia.*\\\"}\",\n          \"legendFormat\": \"Device Plugin\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"mappings\": [\n            {\"type\": \"value\", \"value\": \"0\", \"text\": \"DOWN\"},\n            {\"type\": \"value\", \"value\": \"1\", \"text\": \"UP\"}\n          ],\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"red\", \"value\": null},\n              {\"color\": \"green\", \"value\": 1}\n            ]\n          }\n        }\n      },\n      \"gridPos\": {\"h\": 6, \"w\": 6, \"x\": 0, \"y\": 0}\n    },\n    {\n      \"id\": 2,\n      \"title\": \"GPU Temperature\",\n      \"type\": \"timeseries\",\n      \"targets\": [\n        {\n          \"expr\": \"nvidia_gpu_temperature_celsius\",\n          \"legendFormat\": \"GPU {{gpu}} Temperature\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"celsius\",\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 70},\n              {\"color\": \"red\", \"value\": 85}\n            ]\n          }\n        }\n      },\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 6, \"y\": 0}\n    },\n    {\n      \"id\": 3,\n      \"title\": \"GPU Utilization\",\n      \"type\": \"timeseries\",\n      \"targets\": [\n        {\n          \"expr\": \"nvidia_gpu_utilization_percent\",\n          \"legendFormat\": \"GPU {{gpu}} Utilization\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"percent\",\n          \"min\": 0,\n          \"max\": 100\n        }\n      },\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 18, \"y\": 0}\n    },\n    {\n      \"id\": 4,\n      \"title\": \"GPU Memory Usage\",\n      \"type\": \"timeseries\",\n      \"targets\": [\n        {\n          \"expr\": \"nvidia_gpu_memory_used_mb\",\n          \"legendFormat\": \"GPU {{gpu}} Memory Used\",\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"nvidia_gpu_memory_total_mb - nvidia_gpu_memory_used_mb\",\n          \"legendFormat\": \"GPU {{gpu}} Memory Free\",\n          \"refId\": \"B\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"decmbytes\"\n        }\n      },\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 8}\n    },\n    {\n      \"id\": 5,\n      \"title\": \"GPU Power Usage\",\n      \"type\": \"timeseries\",\n      \"targets\": [\n        {\n          \"expr\": \"node_gpu_power_watts\",\n          \"legendFormat\": \"GPU {{gpu}} Power\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"watt\"\n        }\n      },\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 8}\n    },\n    {\n      \"id\": 6,\n      \"title\": \"GPU Status Information\",\n      \"type\": \"table\",\n      \"targets\": [\n        {\n          \"expr\": \"kube_node_status_capacity{resource=\\\"nvidia_com_gpu\\\"}\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"custom\": {\n            \"displayMode\": \"table\"\n          }\n        }\n      },\n      \"gridPos\": {\"h\": 6, \"w\": 24, \"x\": 0, \"y\": 16}\n    }\n  ]\n}\n","monitoring-overview.json":"{\n  \"id\": null,\n  \"title\": \"Monitoring Stack Overview\",\n  \"tags\": [\"monitoring\", \"odin\"],\n  \"style\": \"dark\",\n  \"timezone\": \"browser\",\n  \"refresh\": \"30s\",\n  \"schemaVersion\": 27,\n  \"version\": 1,\n  \"time\": {\n    \"from\": \"now-1h\",\n    \"to\": \"now\"\n  },\n  \"panels\": [\n    {\n      \"id\": 1,\n      \"title\": \"Monitoring Stack Status\",\n      \"type\": \"stat\",\n      \"targets\": [\n        {\n          \"expr\": \"up{job=~\\\"prometheus|node-exporter|alertmanager\\\"}\",\n          \"legendFormat\": \"{{ job }}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"mappings\": [\n            {\"type\": \"value\", \"value\": \"0\", \"text\": \"DOWN\"},\n            {\"type\": \"value\", \"value\": \"1\", \"text\": \"UP\"}\n          ],\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"red\", \"value\": 0},\n              {\"color\": \"green\", \"value\": 1}\n            ]\n          }\n        }\n      },\n      \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 0}\n    },\n    {\n      \"id\": 2,\n      \"title\": \"Prometheus Target Health\",\n      \"type\": \"table\",\n      \"targets\": [\n        {\n          \"expr\": \"up\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 8}\n    },\n    {\n      \"id\": 3,\n      \"title\": \"Alerts Overview\",\n      \"type\": \"table\",\n      \"targets\": [\n        {\n          \"expr\": \"ALERTS\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 8}\n    }\n  ]\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"creationTimestamp":"2025-05-27T22:25:38Z","name":"phase2-dashboards","namespace":"monitoring","resourceVersion":"10863","uid":"8377f989-c347-4a1e-a47c-43392ce44ea4"}}
    creationTimestamp: "2025-05-27T22:25:38Z"
    name: phase2-dashboards
    namespace: monitoring
    resourceVersion: "76733"
    uid: 8377f989-c347-4a1e-a47c-43392ce44ea4
- apiVersion: v1
  data:
    power-alerts.yaml: |
      groups:
      - name: power
        rules:
        - alert: GPUHighPower
          expr: gpu_power_watts > 300
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "GPU power usage is high: {{ $value }}W"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"power-alerts.yaml":"groups:\n- name: power\n  rules:\n  - alert: GPUHighPower\n    expr: gpu_power_watts \u003e 300\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n      summary: \"GPU power usage is high: {{ $value }}W\"\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"power-alert-rules","namespace":"monitoring"}}
    creationTimestamp: "2025-06-04T14:47:34Z"
    name: power-alert-rules
    namespace: monitoring
    resourceVersion: "3018030"
    uid: 4402d16d-8a6a-47d2-bc52-adc3ca5a3f8b
- apiVersion: v1
  data:
    power-exporter-alerts.yaml: "groups:\n- name: power_exporter_health\n  interval:
      30s\n  rules:\n  # Exporter Health Alerts\n  - alert: PowerExporterDown\n    expr:
      up{job=\"kubernetes-service-discovery\",instance=~\".*power-exporter.*\"} ==
      0\n    for: 2m\n    labels:\n      severity: critical\n      component: power-exporter\n
      \   annotations:\n      summary: \"Power exporter is down\"\n      description:
      \"Power exporter on {{ $labels.instance }} has been down for more than 2 minutes\"\n
      \     \n  - alert: PowerExporterScrapeErrors\n    expr: rate(power_exporter_scrape_errors_total[5m])
      > 0.1\n    for: 5m\n    labels:\n      severity: warning\n      component: power-exporter\n
      \   annotations:\n      summary: \"Power exporter scrape errors\"\n      description:
      \"Power exporter component {{ $labels.component }} is experiencing {{ $value
      }} errors per second\"\n      \n  - alert: PowerExporterStale\n    expr: time()
      - power_exporter_last_successful_scrape_timestamp > 120\n    for: 2m\n    labels:\n
      \     severity: warning\n      component: power-exporter\n    annotations:\n
      \     summary: \"Power exporter metrics are stale\"\n      description: \"Power
      exporter hasn't successfully collected metrics in {{ $value }} seconds\"\n      \n
      \ - alert: GPUMetricsUnavailable\n    expr: power_exporter_gpu_available ==
      0\n    for: 5m\n    labels:\n      severity: warning\n      component: power-exporter\n
      \   annotations:\n      summary: \"GPU metrics unavailable\"\n      description:
      \"Power exporter cannot collect GPU metrics on {{ $labels.instance }}\"\n      \n
      \ # Component-specific health alerts\n  - alert: RAPLMetricsFailure\n    expr:
      increase(power_exporter_scrape_errors_total{component=\"rapl\"}[5m]) > 5\n    for:
      5m\n    labels:\n      severity: warning\n      component: power-exporter\n
      \   annotations:\n      summary: \"RAPL metrics collection failing\"\n      description:
      \"Power exporter RAPL component has {{ $value }} errors in the last 5 minutes\"\n
      \     \n  - alert: BatteryMetricsFailure\n    expr: increase(power_exporter_scrape_errors_total{component=\"battery\"}[5m])
      > 5\n    for: 5m\n    labels:\n      severity: warning\n      component: power-exporter\n
      \   annotations:\n      summary: \"Battery metrics collection failing\"\n      description:
      \"Power exporter battery component has {{ $value }} errors in the last 5 minutes\"\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"power-exporter-alerts.yaml":"groups:\n- name: power_exporter_health\n  interval: 30s\n  rules:\n  # Exporter Health Alerts\n  - alert: PowerExporterDown\n    expr: up{job=\"kubernetes-service-discovery\",instance=~\".*power-exporter.*\"} == 0\n    for: 2m\n    labels:\n      severity: critical\n      component: power-exporter\n    annotations:\n      summary: \"Power exporter is down\"\n      description: \"Power exporter on {{ $labels.instance }} has been down for more than 2 minutes\"\n      \n  - alert: PowerExporterScrapeErrors\n    expr: rate(power_exporter_scrape_errors_total[5m]) \u003e 0.1\n    for: 5m\n    labels:\n      severity: warning\n      component: power-exporter\n    annotations:\n      summary: \"Power exporter scrape errors\"\n      description: \"Power exporter component {{ $labels.component }} is experiencing {{ $value }} errors per second\"\n      \n  - alert: PowerExporterStale\n    expr: time() - power_exporter_last_successful_scrape_timestamp \u003e 120\n    for: 2m\n    labels:\n      severity: warning\n      component: power-exporter\n    annotations:\n      summary: \"Power exporter metrics are stale\"\n      description: \"Power exporter hasn't successfully collected metrics in {{ $value }} seconds\"\n      \n  - alert: GPUMetricsUnavailable\n    expr: power_exporter_gpu_available == 0\n    for: 5m\n    labels:\n      severity: warning\n      component: power-exporter\n    annotations:\n      summary: \"GPU metrics unavailable\"\n      description: \"Power exporter cannot collect GPU metrics on {{ $labels.instance }}\"\n      \n  # Component-specific health alerts\n  - alert: RAPLMetricsFailure\n    expr: increase(power_exporter_scrape_errors_total{component=\"rapl\"}[5m]) \u003e 5\n    for: 5m\n    labels:\n      severity: warning\n      component: power-exporter\n    annotations:\n      summary: \"RAPL metrics collection failing\"\n      description: \"Power exporter RAPL component has {{ $value }} errors in the last 5 minutes\"\n      \n  - alert: BatteryMetricsFailure\n    expr: increase(power_exporter_scrape_errors_total{component=\"battery\"}[5m]) \u003e 5\n    for: 5m\n    labels:\n      severity: warning\n      component: power-exporter\n    annotations:\n      summary: \"Battery metrics collection failing\"\n      description: \"Power exporter battery component has {{ $value }} errors in the last 5 minutes\"\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"power-exporter-alert-rules","namespace":"monitoring"}}
    creationTimestamp: "2025-05-28T14:57:07Z"
    name: power-exporter-alert-rules
    namespace: monitoring
    resourceVersion: "1881437"
    uid: e2b0c9b1-f91a-431d-989a-4f31341782ca
- apiVersion: v1
  data:
    power-exporter.py: "#!/usr/bin/env python3\nimport os\nimport time\nimport glob\nimport
      threading\nfrom datetime import datetime, timedelta\nfrom prometheus_client
      import start_http_server, Gauge, Counter, Info\nfrom http.server import HTTPServer,
      BaseHTTPRequestHandler\n\n# Define Prometheus metrics\ncpu_package_power = Gauge('node_cpu_package_power_watts',
      'CPU package power consumption', ['package'])\ncpu_core_power = Gauge('node_cpu_core_power_watts',
      'CPU core power consumption', ['core'])\ndram_power = Gauge('node_dram_power_watts',
      'DRAM power consumption', ['socket'])\ngpu_power = Gauge('node_gpu_power_watts',
      'GPU power consumption', ['gpu'])\ngpu_temp = Gauge('nvidia_gpu_temperature_celsius',
      'GPU Temperature in Celsius', ['gpu', 'name'])\ngpu_memory_used = Gauge('nvidia_gpu_memory_used_mb',
      'GPU Memory Used in MB', ['gpu', 'name'])\ngpu_memory_total = Gauge('nvidia_gpu_memory_total_mb',
      'GPU Memory Total in MB', ['gpu', 'name'])\ngpu_utilization = Gauge('nvidia_gpu_utilization_percent',
      'GPU Utilization Percentage', ['gpu', 'name'])\ngpu_fan_speed = Gauge('nvidia_gpu_fan_speed_percent',
      'GPU Fan Speed Percentage', ['gpu', 'name'])\nbattery_capacity = Gauge('node_battery_capacity_wh',
      'Battery capacity in Wh', ['battery'])\nbattery_voltage = Gauge('node_battery_voltage_volts',
      'Battery voltage', ['battery'])\nbattery_current = Gauge('node_battery_current_amps',
      'Battery current', ['battery'])\nbattery_power = Gauge('node_battery_power_watts',
      'Battery power consumption', ['battery'])\nbattery_health = Gauge('node_battery_health_percent',
      'Battery health percentage', ['battery'])\nac_power = Gauge('node_ac_adapter_power_watts',
      'AC adapter power', ['adapter'])\n\n# Health check metrics\nlast_successful_scrape
      = Gauge('power_exporter_last_successful_scrape_timestamp', 'Unix timestamp of
      last successful scrape')\nscrape_errors_total = Counter('power_exporter_scrape_errors_total',
      'Total number of scrape errors', ['component'])\nexporter_info = Info('power_exporter_info',
      'Power exporter information')\ngpu_available = Gauge('power_exporter_gpu_available',
      'Whether GPU metrics are available (1=yes, 0=no)')\n\n# Global health status\nhealth_status
      = {\n    'healthy': True,\n    'last_update': datetime.now(),\n    'errors':
      [],\n    'gpu_available': False,\n    'components': {\n        'rapl': {'healthy':
      True, 'last_success': datetime.now()},\n        'battery': {'healthy': True,
      'last_success': datetime.now()},\n        'gpu': {'healthy': True, 'last_success':
      datetime.now()}\n    }\n}\n\ndef read_value(path, default=0):\n    \"\"\"Read
      numeric value from file\"\"\"\n    try:\n        with open(path, 'r') as f:\n
      \           return float(f.read().strip())\n    except:\n        return default\n\nclass
      HealthCheckHandler(BaseHTTPRequestHandler):\n    \"\"\"HTTP handler for health
      checks\"\"\"\n    def do_GET(self):\n        if self.path == '/health':\n            self.send_health_response()\n
      \       elif self.path == '/healthz':\n            self.send_healthz_response()\n
      \       elif self.path == '/ready':\n            self.send_ready_response()\n
      \       else:\n            self.send_error(404)\n    \n    def send_health_response(self):\n
      \       \"\"\"Detailed health check response\"\"\"\n        now = datetime.now()\n
      \       status_code = 200 if health_status['healthy'] else 503\n        \n        #
      Check if we've had recent successful scrapes\n        for component, info in
      health_status['components'].items():\n            if now - info['last_success']
      > timedelta(minutes=2):\n                status_code = 503\n                \n
      \       response = {\n            'status': 'healthy' if status_code == 200
      else 'unhealthy',\n            'timestamp': now.isoformat(),\n            'components':
      {}\n        }\n        \n        for component, info in health_status['components'].items():\n
      \           response['components'][component] = {\n                'healthy':
      info['healthy'],\n                'last_success': info['last_success'].isoformat()\n
      \           }\n        \n        if health_status['errors']:\n            response['recent_errors']
      = health_status['errors'][-5:]  # Last 5 errors\n            \n        self.send_response(status_code)\n
      \       self.send_header('Content-Type', 'application/json')\n        self.end_headers()\n
      \       import json\n        self.wfile.write(json.dumps(response).encode())\n
      \   \n    def send_healthz_response(self):\n        \"\"\"Simple health check
      for k8s\"\"\"\n        if health_status['healthy']:\n            self.send_response(200)\n
      \           self.end_headers()\n            self.wfile.write(b'OK')\n        else:\n
      \           self.send_response(503)\n            self.end_headers()\n            self.wfile.write(b'Unhealthy')\n
      \   \n    def send_ready_response(self):\n        \"\"\"Readiness check\"\"\"\n
      \       # Check if we've collected metrics recently\n        now = datetime.now()\n
      \       if now - health_status['last_update'] < timedelta(seconds=30):\n            self.send_response(200)\n
      \           self.end_headers()\n            self.wfile.write(b'Ready')\n        else:\n
      \           self.send_response(503)\n            self.end_headers()\n            self.wfile.write(b'Not
      Ready')\n    \n    def log_message(self, format, *args):\n        # Suppress
      access logs\n        pass\n\ndef run_health_server():\n    \"\"\"Run the health
      check HTTP server\"\"\"\n    server = HTTPServer(('', 8080), HealthCheckHandler)\n
      \   server.serve_forever()\n\ndef collect_rapl_metrics():\n    \"\"\"Collect
      Intel RAPL (Running Average Power Limit) metrics\"\"\"\n    try:\n        rapl_path
      = \"/sys/class/powercap/intel-rapl/\"\n        \n        # Find all RAPL domains\n
      \       domains = glob.glob(rapl_path + \"intel-rapl:*\")\n        \n        for
      domain in domains:\n            name_path = os.path.join(domain, \"name\")\n
      \           energy_path = os.path.join(domain, \"energy_uj\")\n            \n
      \           if os.path.exists(name_path) and os.path.exists(energy_path):\n
      \               name = read_value(name_path, \"unknown\")\n                \n
      \               # Read energy in microjoules\n                energy_uj = read_value(energy_path)\n
      \               \n                # Convert to watts (this is instantaneous
      reading)\n                if \"package\" in name:\n                    package_num
      = domain.split(\":\")[-1]\n                    cpu_package_power.labels(package=package_num).set(energy_uj
      / 1000000)\n                elif \"core\" in name:\n                    core_num
      = domain.split(\":\")[-1]\n                    cpu_core_power.labels(core=core_num).set(energy_uj
      / 1000000)\n                elif \"dram\" in name:\n                    socket_num
      = domain.split(\":\")[-1]\n                    dram_power.labels(socket=socket_num).set(energy_uj
      / 1000000)\n        \n        health_status['components']['rapl']['healthy']
      = True\n        health_status['components']['rapl']['last_success'] = datetime.now()\n
      \   except Exception as e:\n        print(f\"Error collecting RAPL metrics:
      {e}\")\n        health_status['components']['rapl']['healthy'] = False\n        health_status['errors'].append(f\"RAPL
      error: {str(e)}\")\n        scrape_errors_total.labels(component='rapl').inc()\n\ndef
      collect_battery_metrics():\n    \"\"\"Collect battery power metrics\"\"\"\n
      \   try:\n        power_supply_path = \"/sys/class/power_supply/\"\n        \n
      \       # Find all batteries\n        batteries = glob.glob(power_supply_path
      + \"BAT*\")\n        \n        for battery in batteries:\n            bat_name
      = os.path.basename(battery)\n            \n            # Read battery values\n
      \           voltage_now = read_value(os.path.join(battery, \"voltage_now\"))
      / 1000000  # Convert to volts\n            current_now = read_value(os.path.join(battery,
      \"current_now\")) / 1000000  # Convert to amps\n            charge_full = read_value(os.path.join(battery,
      \"charge_full\")) / 1000000\n            charge_full_design = read_value(os.path.join(battery,
      \"charge_full_design\")) / 1000000\n            energy_full = read_value(os.path.join(battery,
      \"energy_full\")) / 1000000  # Convert to Wh\n            \n            # Calculate
      metrics\n            if voltage_now > 0:\n                battery_voltage.labels(battery=bat_name).set(voltage_now)\n
      \               \n                if current_now > 0:\n                    battery_current.labels(battery=bat_name).set(current_now)\n
      \                   power_watts = voltage_now * current_now\n                    battery_power.labels(battery=bat_name).set(power_watts)\n
      \               \n                if energy_full > 0:\n                    battery_capacity.labels(battery=bat_name).set(energy_full)\n
      \               \n                if charge_full_design > 0 and charge_full
      > 0:\n                    health_percent = (charge_full / charge_full_design)
      * 100\n                    battery_health.labels(battery=bat_name).set(health_percent)\n
      \       \n        # AC adapter\n        adapters = glob.glob(power_supply_path
      + \"ADP*\")\n        for adapter in adapters:\n            adapter_name = os.path.basename(adapter)\n
      \           online = read_value(os.path.join(adapter, \"online\"))\n            if
      online:\n                # Estimate AC power based on battery charging\n                #
      This is a rough estimate - actual measurement would require hardware support\n
      \               ac_power.labels(adapter=adapter_name).set(65)  # Default 65W
      for Razer Blade\n        \n        health_status['components']['battery']['healthy']
      = True\n        health_status['components']['battery']['last_success'] = datetime.now()\n
      \   except Exception as e:\n        print(f\"Error collecting battery metrics:
      {e}\")\n        health_status['components']['battery']['healthy'] = False\n
      \       health_status['errors'].append(f\"Battery error: {str(e)}\")\n        scrape_errors_total.labels(component='battery').inc()\n\ndef
      collect_gpu_power():\n    \"\"\"Collect GPU metrics from nvidia-smi\"\"\"\n
      \   try:\n        import subprocess\n        # Get comprehensive GPU metrics\n
      \       result = subprocess.run([\n            'nvidia-smi', \n            '--query-gpu=index,name,temperature.gpu,power.draw,memory.used,memory.total,utilization.gpu,fan.speed',\n
      \           '--format=csv,noheader,nounits'\n        ], capture_output=True,
      text=True)\n        \n        if result.returncode == 0:\n            for line
      in result.stdout.strip().split('\\n'):\n                if not line:\n                    continue\n
      \               parts = [p.strip() for p in line.split(',')]\n                if
      len(parts) >= 8:\n                    idx = parts[0]\n                    name
      = parts[1]\n                    \n                    # Temperature\n                    try:\n
      \                       gpu_temp.labels(gpu=idx, name=name).set(float(parts[2]))\n
      \                   except:\n                        pass\n                    \n
      \                   # Power\n                    try:\n                        gpu_power.labels(gpu=f\"gpu{idx}\").set(float(parts[3]))\n
      \                   except:\n                        pass\n                    \n
      \                   # Memory\n                    try:\n                        gpu_memory_used.labels(gpu=idx,
      name=name).set(float(parts[4]))\n                        gpu_memory_total.labels(gpu=idx,
      name=name).set(float(parts[5]))\n                    except:\n                        pass\n
      \                   \n                    # Utilization\n                    try:\n
      \                       gpu_utilization.labels(gpu=idx, name=name).set(float(parts[6]))\n
      \                   except:\n                        pass\n                    \n
      \                   # Fan speed\n                    try:\n                        if
      parts[7] != '[N/A]':\n                            gpu_fan_speed.labels(gpu=idx,
      name=name).set(float(parts[7]))\n                    except:\n                        pass\n
      \           \n            # Mark GPU as available and healthy\n            health_status['gpu_available']
      = True\n            gpu_available.set(1)\n            health_status['components']['gpu']['healthy']
      = True\n            health_status['components']['gpu']['last_success'] = datetime.now()\n
      \       else:\n            health_status['gpu_available'] = False\n            gpu_available.set(0)\n
      \   except Exception as e:\n        print(f\"Error collecting GPU metrics: {e}\")\n
      \       health_status['components']['gpu']['healthy'] = False\n        health_status['gpu_available']
      = False\n        gpu_available.set(0)\n        health_status['errors'].append(f\"GPU
      error: {str(e)}\")\n        scrape_errors_total.labels(component='gpu').inc()\n\nif
      __name__ == '__main__':\n    # Start Prometheus metrics server\n    start_http_server(9402)\n
      \   \n    # Start health check server in a separate thread\n    health_thread
      = threading.Thread(target=run_health_server, daemon=True)\n    health_thread.start()\n
      \   print(\"Health check server started on port 8080\")\n    \n    # Set exporter
      info\n    exporter_info.info({'version': '1.0', 'gpu_support': 'nvidia-smi'})\n
      \   \n    # Collect metrics every 5 seconds\n    while True:\n        try:\n
      \           # Clear old errors (keep last 10)\n            if len(health_status['errors'])
      > 10:\n                health_status['errors'] = health_status['errors'][-10:]\n
      \           \n            # Collect metrics\n            collect_rapl_metrics()\n
      \           collect_battery_metrics()\n            collect_gpu_power()\n            \n
      \           # Update overall health status\n            health_status['healthy']
      = all(comp['healthy'] for comp in health_status['components'].values())\n            health_status['last_update']
      = datetime.now()\n            \n            # Update timestamp metric\n            last_successful_scrape.set(time.time())\n
      \           \n        except Exception as e:\n            print(f\"Error collecting
      metrics: {e}\")\n            health_status['healthy'] = False\n            scrape_errors_total.labels(component='main').inc()\n
      \           \n        time.sleep(5)\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"power-exporter.py":"#!/usr/bin/env python3\nimport os\nimport time\nimport glob\nimport threading\nfrom datetime import datetime, timedelta\nfrom prometheus_client import start_http_server, Gauge, Counter, Info\nfrom http.server import HTTPServer, BaseHTTPRequestHandler\n\n# Define Prometheus metrics\ncpu_package_power = Gauge('node_cpu_package_power_watts', 'CPU package power consumption', ['package'])\ncpu_core_power = Gauge('node_cpu_core_power_watts', 'CPU core power consumption', ['core'])\ndram_power = Gauge('node_dram_power_watts', 'DRAM power consumption', ['socket'])\ngpu_power = Gauge('node_gpu_power_watts', 'GPU power consumption', ['gpu'])\ngpu_temp = Gauge('nvidia_gpu_temperature_celsius', 'GPU Temperature in Celsius', ['gpu', 'name'])\ngpu_memory_used = Gauge('nvidia_gpu_memory_used_mb', 'GPU Memory Used in MB', ['gpu', 'name'])\ngpu_memory_total = Gauge('nvidia_gpu_memory_total_mb', 'GPU Memory Total in MB', ['gpu', 'name'])\ngpu_utilization = Gauge('nvidia_gpu_utilization_percent', 'GPU Utilization Percentage', ['gpu', 'name'])\ngpu_fan_speed = Gauge('nvidia_gpu_fan_speed_percent', 'GPU Fan Speed Percentage', ['gpu', 'name'])\nbattery_capacity = Gauge('node_battery_capacity_wh', 'Battery capacity in Wh', ['battery'])\nbattery_voltage = Gauge('node_battery_voltage_volts', 'Battery voltage', ['battery'])\nbattery_current = Gauge('node_battery_current_amps', 'Battery current', ['battery'])\nbattery_power = Gauge('node_battery_power_watts', 'Battery power consumption', ['battery'])\nbattery_health = Gauge('node_battery_health_percent', 'Battery health percentage', ['battery'])\nac_power = Gauge('node_ac_adapter_power_watts', 'AC adapter power', ['adapter'])\n\n# Health check metrics\nlast_successful_scrape = Gauge('power_exporter_last_successful_scrape_timestamp', 'Unix timestamp of last successful scrape')\nscrape_errors_total = Counter('power_exporter_scrape_errors_total', 'Total number of scrape errors', ['component'])\nexporter_info = Info('power_exporter_info', 'Power exporter information')\ngpu_available = Gauge('power_exporter_gpu_available', 'Whether GPU metrics are available (1=yes, 0=no)')\n\n# Global health status\nhealth_status = {\n    'healthy': True,\n    'last_update': datetime.now(),\n    'errors': [],\n    'gpu_available': False,\n    'components': {\n        'rapl': {'healthy': True, 'last_success': datetime.now()},\n        'battery': {'healthy': True, 'last_success': datetime.now()},\n        'gpu': {'healthy': True, 'last_success': datetime.now()}\n    }\n}\n\ndef read_value(path, default=0):\n    \"\"\"Read numeric value from file\"\"\"\n    try:\n        with open(path, 'r') as f:\n            return float(f.read().strip())\n    except:\n        return default\n\nclass HealthCheckHandler(BaseHTTPRequestHandler):\n    \"\"\"HTTP handler for health checks\"\"\"\n    def do_GET(self):\n        if self.path == '/health':\n            self.send_health_response()\n        elif self.path == '/healthz':\n            self.send_healthz_response()\n        elif self.path == '/ready':\n            self.send_ready_response()\n        else:\n            self.send_error(404)\n    \n    def send_health_response(self):\n        \"\"\"Detailed health check response\"\"\"\n        now = datetime.now()\n        status_code = 200 if health_status['healthy'] else 503\n        \n        # Check if we've had recent successful scrapes\n        for component, info in health_status['components'].items():\n            if now - info['last_success'] \u003e timedelta(minutes=2):\n                status_code = 503\n                \n        response = {\n            'status': 'healthy' if status_code == 200 else 'unhealthy',\n            'timestamp': now.isoformat(),\n            'components': {}\n        }\n        \n        for component, info in health_status['components'].items():\n            response['components'][component] = {\n                'healthy': info['healthy'],\n                'last_success': info['last_success'].isoformat()\n            }\n        \n        if health_status['errors']:\n            response['recent_errors'] = health_status['errors'][-5:]  # Last 5 errors\n            \n        self.send_response(status_code)\n        self.send_header('Content-Type', 'application/json')\n        self.end_headers()\n        import json\n        self.wfile.write(json.dumps(response).encode())\n    \n    def send_healthz_response(self):\n        \"\"\"Simple health check for k8s\"\"\"\n        if health_status['healthy']:\n            self.send_response(200)\n            self.end_headers()\n            self.wfile.write(b'OK')\n        else:\n            self.send_response(503)\n            self.end_headers()\n            self.wfile.write(b'Unhealthy')\n    \n    def send_ready_response(self):\n        \"\"\"Readiness check\"\"\"\n        # Check if we've collected metrics recently\n        now = datetime.now()\n        if now - health_status['last_update'] \u003c timedelta(seconds=30):\n            self.send_response(200)\n            self.end_headers()\n            self.wfile.write(b'Ready')\n        else:\n            self.send_response(503)\n            self.end_headers()\n            self.wfile.write(b'Not Ready')\n    \n    def log_message(self, format, *args):\n        # Suppress access logs\n        pass\n\ndef run_health_server():\n    \"\"\"Run the health check HTTP server\"\"\"\n    server = HTTPServer(('', 8080), HealthCheckHandler)\n    server.serve_forever()\n\ndef collect_rapl_metrics():\n    \"\"\"Collect Intel RAPL (Running Average Power Limit) metrics\"\"\"\n    try:\n        rapl_path = \"/sys/class/powercap/intel-rapl/\"\n        \n        # Find all RAPL domains\n        domains = glob.glob(rapl_path + \"intel-rapl:*\")\n        \n        for domain in domains:\n            name_path = os.path.join(domain, \"name\")\n            energy_path = os.path.join(domain, \"energy_uj\")\n            \n            if os.path.exists(name_path) and os.path.exists(energy_path):\n                name = read_value(name_path, \"unknown\")\n                \n                # Read energy in microjoules\n                energy_uj = read_value(energy_path)\n                \n                # Convert to watts (this is instantaneous reading)\n                if \"package\" in name:\n                    package_num = domain.split(\":\")[-1]\n                    cpu_package_power.labels(package=package_num).set(energy_uj / 1000000)\n                elif \"core\" in name:\n                    core_num = domain.split(\":\")[-1]\n                    cpu_core_power.labels(core=core_num).set(energy_uj / 1000000)\n                elif \"dram\" in name:\n                    socket_num = domain.split(\":\")[-1]\n                    dram_power.labels(socket=socket_num).set(energy_uj / 1000000)\n        \n        health_status['components']['rapl']['healthy'] = True\n        health_status['components']['rapl']['last_success'] = datetime.now()\n    except Exception as e:\n        print(f\"Error collecting RAPL metrics: {e}\")\n        health_status['components']['rapl']['healthy'] = False\n        health_status['errors'].append(f\"RAPL error: {str(e)}\")\n        scrape_errors_total.labels(component='rapl').inc()\n\ndef collect_battery_metrics():\n    \"\"\"Collect battery power metrics\"\"\"\n    try:\n        power_supply_path = \"/sys/class/power_supply/\"\n        \n        # Find all batteries\n        batteries = glob.glob(power_supply_path + \"BAT*\")\n        \n        for battery in batteries:\n            bat_name = os.path.basename(battery)\n            \n            # Read battery values\n            voltage_now = read_value(os.path.join(battery, \"voltage_now\")) / 1000000  # Convert to volts\n            current_now = read_value(os.path.join(battery, \"current_now\")) / 1000000  # Convert to amps\n            charge_full = read_value(os.path.join(battery, \"charge_full\")) / 1000000\n            charge_full_design = read_value(os.path.join(battery, \"charge_full_design\")) / 1000000\n            energy_full = read_value(os.path.join(battery, \"energy_full\")) / 1000000  # Convert to Wh\n            \n            # Calculate metrics\n            if voltage_now \u003e 0:\n                battery_voltage.labels(battery=bat_name).set(voltage_now)\n                \n                if current_now \u003e 0:\n                    battery_current.labels(battery=bat_name).set(current_now)\n                    power_watts = voltage_now * current_now\n                    battery_power.labels(battery=bat_name).set(power_watts)\n                \n                if energy_full \u003e 0:\n                    battery_capacity.labels(battery=bat_name).set(energy_full)\n                \n                if charge_full_design \u003e 0 and charge_full \u003e 0:\n                    health_percent = (charge_full / charge_full_design) * 100\n                    battery_health.labels(battery=bat_name).set(health_percent)\n        \n        # AC adapter\n        adapters = glob.glob(power_supply_path + \"ADP*\")\n        for adapter in adapters:\n            adapter_name = os.path.basename(adapter)\n            online = read_value(os.path.join(adapter, \"online\"))\n            if online:\n                # Estimate AC power based on battery charging\n                # This is a rough estimate - actual measurement would require hardware support\n                ac_power.labels(adapter=adapter_name).set(65)  # Default 65W for Razer Blade\n        \n        health_status['components']['battery']['healthy'] = True\n        health_status['components']['battery']['last_success'] = datetime.now()\n    except Exception as e:\n        print(f\"Error collecting battery metrics: {e}\")\n        health_status['components']['battery']['healthy'] = False\n        health_status['errors'].append(f\"Battery error: {str(e)}\")\n        scrape_errors_total.labels(component='battery').inc()\n\ndef collect_gpu_power():\n    \"\"\"Collect GPU metrics from nvidia-smi\"\"\"\n    try:\n        import subprocess\n        # Get comprehensive GPU metrics\n        result = subprocess.run([\n            'nvidia-smi', \n            '--query-gpu=index,name,temperature.gpu,power.draw,memory.used,memory.total,utilization.gpu,fan.speed',\n            '--format=csv,noheader,nounits'\n        ], capture_output=True, text=True)\n        \n        if result.returncode == 0:\n            for line in result.stdout.strip().split('\\n'):\n                if not line:\n                    continue\n                parts = [p.strip() for p in line.split(',')]\n                if len(parts) \u003e= 8:\n                    idx = parts[0]\n                    name = parts[1]\n                    \n                    # Temperature\n                    try:\n                        gpu_temp.labels(gpu=idx, name=name).set(float(parts[2]))\n                    except:\n                        pass\n                    \n                    # Power\n                    try:\n                        gpu_power.labels(gpu=f\"gpu{idx}\").set(float(parts[3]))\n                    except:\n                        pass\n                    \n                    # Memory\n                    try:\n                        gpu_memory_used.labels(gpu=idx, name=name).set(float(parts[4]))\n                        gpu_memory_total.labels(gpu=idx, name=name).set(float(parts[5]))\n                    except:\n                        pass\n                    \n                    # Utilization\n                    try:\n                        gpu_utilization.labels(gpu=idx, name=name).set(float(parts[6]))\n                    except:\n                        pass\n                    \n                    # Fan speed\n                    try:\n                        if parts[7] != '[N/A]':\n                            gpu_fan_speed.labels(gpu=idx, name=name).set(float(parts[7]))\n                    except:\n                        pass\n            \n            # Mark GPU as available and healthy\n            health_status['gpu_available'] = True\n            gpu_available.set(1)\n            health_status['components']['gpu']['healthy'] = True\n            health_status['components']['gpu']['last_success'] = datetime.now()\n        else:\n            health_status['gpu_available'] = False\n            gpu_available.set(0)\n    except Exception as e:\n        print(f\"Error collecting GPU metrics: {e}\")\n        health_status['components']['gpu']['healthy'] = False\n        health_status['gpu_available'] = False\n        gpu_available.set(0)\n        health_status['errors'].append(f\"GPU error: {str(e)}\")\n        scrape_errors_total.labels(component='gpu').inc()\n\nif __name__ == '__main__':\n    # Start Prometheus metrics server\n    start_http_server(9402)\n    \n    # Start health check server in a separate thread\n    health_thread = threading.Thread(target=run_health_server, daemon=True)\n    health_thread.start()\n    print(\"Health check server started on port 8080\")\n    \n    # Set exporter info\n    exporter_info.info({'version': '1.0', 'gpu_support': 'nvidia-smi'})\n    \n    # Collect metrics every 5 seconds\n    while True:\n        try:\n            # Clear old errors (keep last 10)\n            if len(health_status['errors']) \u003e 10:\n                health_status['errors'] = health_status['errors'][-10:]\n            \n            # Collect metrics\n            collect_rapl_metrics()\n            collect_battery_metrics()\n            collect_gpu_power()\n            \n            # Update overall health status\n            health_status['healthy'] = all(comp['healthy'] for comp in health_status['components'].values())\n            health_status['last_update'] = datetime.now()\n            \n            # Update timestamp metric\n            last_successful_scrape.set(time.time())\n            \n        except Exception as e:\n            print(f\"Error collecting metrics: {e}\")\n            health_status['healthy'] = False\n            scrape_errors_total.labels(component='main').inc()\n            \n        time.sleep(5)\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"power-exporter-script","namespace":"monitoring"}}
    creationTimestamp: "2025-05-27T23:35:32Z"
    name: power-exporter-script
    namespace: monitoring
    resourceVersion: "32138"
    uid: 6b02d4ff-a148-4f6f-afe5-85fe30113807
- apiVersion: v1
  data:
    power-thermal-analysis.json: "{\n  \"id\": null,\n  \"title\": \"Power & Thermal
      Management\",\n  \"description\": \"Advanced power consumption and thermal monitoring
      for Razer Blade 18\",\n  \"tags\": [\"power\", \"thermal\", \"battery\", \"performance\"],\n
      \ \"style\": \"dark\",\n  \"timezone\": \"browser\",\n  \"refresh\": \"5s\",\n
      \ \"schemaVersion\": 27,\n  \"version\": 1,\n  \"time\": {\n    \"from\": \"now-6h\",\n
      \   \"to\": \"now\"\n  },\n  \"panels\": [\n    {\n      \"id\": 1,\n      \"title\":
      \"Battery Status\",\n      \"type\": \"stat\",\n      \"targets\": [\n        {\n
      \         \"expr\": \"node_power_supply_capacity\",\n          \"legendFormat\":
      \"Battery %\",\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\":
      \"node_power_supply_online\",\n          \"legendFormat\": \"AC Power\",\n          \"refId\":
      \"B\"\n        },\n        {\n          \"expr\": \"node_power_supply_cyclecount\",\n
      \         \"legendFormat\": \"Charge Cycles\",\n          \"refId\": \"C\"\n
      \       }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\":
      \"percent\"\n        },\n        \"overrides\": [\n          {\n            \"matcher\":
      {\"id\": \"byName\", \"options\": \"AC Power\"},\n            \"properties\":
      [\n              {\"id\": \"unit\", \"value\": \"short\"},\n              {\"id\":
      \"mappings\", \"value\": [\n                {\"type\": \"value\", \"value\":
      \"0\", \"text\": \"\U0001F50B Battery\"},\n                {\"type\": \"value\",
      \"value\": \"1\", \"text\": \"\U0001F50C AC Power\"}\n              ]},\n              {\"id\":
      \"color\", \"value\": {\"mode\": \"thresholds\"}},\n              {\"id\": \"thresholds\",
      \"value\": {\n                \"steps\": [\n                  {\"color\": \"orange\",
      \"value\": null},\n                  {\"color\": \"green\", \"value\": 1}\n
      \               ]\n              }}\n            ]\n          },\n          {\n
      \           \"matcher\": {\"id\": \"byName\", \"options\": \"Charge Cycles\"},\n
      \           \"properties\": [{\"id\": \"unit\", \"value\": \"short\"}]\n          }\n
      \       ]\n      },\n      \"gridPos\": {\"h\": 6, \"w\": 8, \"x\": 0, \"y\":
      0}\n    },\n    {\n      \"id\": 2,\n      \"title\": \"Battery Health\",\n
      \     \"type\": \"gauge\",\n      \"targets\": [\n        {\n          \"expr\":
      \"(node_power_supply_charge_full / node_power_supply_charge_full_design) * 100\",\n
      \         \"legendFormat\": \"Battery Health\",\n          \"refId\": \"A\"\n
      \       }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\":
      \"percent\",\n          \"min\": 0,\n          \"max\": 100,\n          \"thresholds\":
      {\n            \"steps\": [\n              {\"color\": \"red\", \"value\": null},\n
      \             {\"color\": \"orange\", \"value\": 50},\n              {\"color\":
      \"yellow\", \"value\": 70},\n              {\"color\": \"green\", \"value\":
      85}\n            ]\n          }\n        }\n      },\n      \"gridPos\": {\"h\":
      6, \"w\": 8, \"x\": 8, \"y\": 0}\n    },\n    {\n      \"id\": 3,\n      \"title\":
      \"Power Draw\",\n      \"type\": \"stat\",\n      \"targets\": [\n        {\n
      \         \"expr\": \"node_power_supply_current_ampere * node_power_supply_voltage_min_design
      / 1000000\",\n          \"legendFormat\": \"Current Power Draw\",\n          \"refId\":
      \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\":
      {\n          \"unit\": \"watt\",\n          \"thresholds\": {\n            \"steps\":
      [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\":
      \"yellow\", \"value\": 50},\n              {\"color\": \"orange\", \"value\":
      100},\n              {\"color\": \"red\", \"value\": 150}\n            ]\n          }\n
      \       }\n      },\n      \"gridPos\": {\"h\": 6, \"w\": 8, \"x\": 16, \"y\":
      0}\n    },\n    {\n      \"id\": 4,\n      \"title\": \"CPU Temperature Zones\",\n
      \     \"type\": \"timeseries\",\n      \"targets\": [\n        {\n          \"expr\":
      \"node_hwmon_temp_celsius{chip=~\\\".*coretemp.*\\\"}\",\n          \"legendFormat\":
      \"Core {{ sensor }}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\":
      {\n        \"defaults\": {\n          \"unit\": \"celsius\",\n          \"custom\":
      {\n            \"fillOpacity\": 10,\n            \"gradientMode\": \"opacity\"\n
      \         },\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\":
      \"blue\", \"value\": null},\n              {\"color\": \"green\", \"value\":
      40},\n              {\"color\": \"yellow\", \"value\": 60},\n              {\"color\":
      \"orange\", \"value\": 75},\n              {\"color\": \"red\", \"value\": 85}\n
      \           ]\n          }\n        }\n      },\n      \"gridPos\": {\"h\":
      10, \"w\": 12, \"x\": 0, \"y\": 6}\n    },\n    {\n      \"id\": 5,\n      \"title\":
      \"Thermal Throttling Alert\",\n      \"type\": \"stat\",\n      \"targets\":
      [\n        {\n          \"expr\": \"max(node_hwmon_temp_celsius) > 85\",\n          \"legendFormat\":
      \"Thermal Warning\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\":
      {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"mappings\":
      [\n            {\"type\": \"value\", \"value\": \"0\", \"text\": \"✓ Normal\"},\n
      \           {\"type\": \"value\", \"value\": \"1\", \"text\": \"⚠️ HOT!\"}\n
      \         ],\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\":
      \"green\", \"value\": null},\n              {\"color\": \"red\", \"value\":
      1}\n            ]\n          }\n        }\n      },\n      \"gridPos\": {\"h\":
      4, \"w\": 6, \"x\": 12, \"y\": 6}\n    },\n    {\n      \"id\": 6,\n      \"title\":
      \"Fan Speed\",\n      \"type\": \"gauge\",\n      \"targets\": [\n        {\n
      \         \"expr\": \"node_hwmon_fan_rpm\",\n          \"legendFormat\": \"{{
      sensor }}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\":
      {\n        \"defaults\": {\n          \"unit\": \"rpm\",\n          \"min\":
      0,\n          \"max\": 6000,\n          \"thresholds\": {\n            \"steps\":
      [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\":
      \"yellow\", \"value\": 3000},\n              {\"color\": \"orange\", \"value\":
      4500},\n              {\"color\": \"red\", \"value\": 5500}\n            ]\n
      \         }\n        }\n      },\n      \"gridPos\": {\"h\": 6, \"w\": 6, \"x\":
      18, \"y\": 6}\n    },\n    {\n      \"id\": 7,\n      \"title\": \"CPU Package
      Power\",\n      \"type\": \"timeseries\",\n      \"targets\": [\n        {\n
      \         \"expr\": \"node_hwmon_power_average_watt\",\n          \"legendFormat\":
      \"{{ chip }} - {{ sensor }}\",\n          \"refId\": \"A\"\n        }\n      ],\n
      \     \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"watt\",\n
      \         \"custom\": {\n            \"fillOpacity\": 20,\n            \"gradientMode\":
      \"scheme\",\n            \"thresholdsStyle\": {\n              \"mode\": \"line+area\"\n
      \           }\n          },\n          \"thresholds\": {\n            \"steps\":
      [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\":
      \"yellow\", \"value\": 45},\n              {\"color\": \"orange\", \"value\":
      65},\n              {\"color\": \"red\", \"value\": 85}\n            ]\n          }\n
      \       }\n      },\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\":
      10}\n    },\n    {\n      \"id\": 8,\n      \"title\": \"Power & Temperature
      Correlation\",\n      \"type\": \"timeseries\",\n      \"targets\": [\n        {\n
      \         \"expr\": \"avg(node_hwmon_temp_celsius{chip=~\\\".*coretemp.*\\\"})\",\n
      \         \"legendFormat\": \"Avg CPU Temp\",\n          \"refId\": \"A\"\n
      \       },\n        {\n          \"expr\": \"100 - (avg(rate(node_cpu_seconds_total{mode=\\\"idle\\\"}[1m]))
      * 100)\",\n          \"legendFormat\": \"CPU Usage %\",\n          \"refId\":
      \"B\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\":
      {\n          \"custom\": {\n            \"axisPlacement\": \"auto\",\n            \"axisSoftMin\":
      0\n          }\n        },\n        \"overrides\": [\n          {\n            \"matcher\":
      {\"id\": \"byName\", \"options\": \"Avg CPU Temp\"},\n            \"properties\":
      [\n              {\"id\": \"unit\", \"value\": \"celsius\"},\n              {\"id\":
      \"custom.axisPlacement\", \"value\": \"left\"}\n            ]\n          },\n
      \         {\n            \"matcher\": {\"id\": \"byName\", \"options\": \"CPU
      Usage %\"},\n            \"properties\": [\n              {\"id\": \"unit\",
      \"value\": \"percent\"},\n              {\"id\": \"custom.axisPlacement\", \"value\":
      \"right\"}\n            ]\n          }\n        ]\n      },\n      \"gridPos\":
      {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 16}\n    },\n    {\n      \"id\": 9,\n
      \     \"title\": \"Voltage Rails\",\n      \"type\": \"timeseries\",\n      \"targets\":
      [\n        {\n          \"expr\": \"node_hwmon_in_volts\",\n          \"legendFormat\":
      \"{{ chip }} - {{ sensor }}\",\n          \"refId\": \"A\"\n        }\n      ],\n
      \     \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"volt\",\n
      \         \"custom\": {\n            \"drawStyle\": \"line\",\n            \"lineWidth\":
      1\n          }\n        }\n      },\n      \"gridPos\": {\"h\": 8, \"w\": 12,
      \"x\": 12, \"y\": 18}\n    },\n    {\n      \"id\": 10,\n      \"title\": \"Battery
      Charge History\",\n      \"type\": \"timeseries\",\n      \"targets\": [\n        {\n
      \         \"expr\": \"node_power_supply_capacity\",\n          \"legendFormat\":
      \"Battery Level\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\":
      {\n        \"defaults\": {\n          \"unit\": \"percent\",\n          \"min\":
      0,\n          \"max\": 100,\n          \"custom\": {\n            \"fillOpacity\":
      30,\n            \"gradientMode\": \"hue\",\n            \"thresholdsStyle\":
      {\n              \"mode\": \"area\"\n            }\n          },\n          \"thresholds\":
      {\n            \"steps\": [\n              {\"color\": \"red\", \"value\": null},\n
      \             {\"color\": \"orange\", \"value\": 20},\n              {\"color\":
      \"yellow\", \"value\": 40},\n              {\"color\": \"green\", \"value\":
      60}\n            ]\n          }\n        }\n      },\n      \"gridPos\": {\"h\":
      8, \"w\": 24, \"x\": 0, \"y\": 24}\n    }\n  ]\n}\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: "{\"apiVersion\":\"v1\",\"data\":{\"power-thermal-analysis.json\":\"{\\n
        \ \\\"id\\\": null,\\n  \\\"title\\\": \\\"Power \\u0026 Thermal Management\\\",\\n
        \ \\\"description\\\": \\\"Advanced power consumption and thermal monitoring
        for Razer Blade 18\\\",\\n  \\\"tags\\\": [\\\"power\\\", \\\"thermal\\\",
        \\\"battery\\\", \\\"performance\\\"],\\n  \\\"style\\\": \\\"dark\\\",\\n
        \ \\\"timezone\\\": \\\"browser\\\",\\n  \\\"refresh\\\": \\\"5s\\\",\\n  \\\"schemaVersion\\\":
        27,\\n  \\\"version\\\": 1,\\n  \\\"time\\\": {\\n    \\\"from\\\": \\\"now-6h\\\",\\n
        \   \\\"to\\\": \\\"now\\\"\\n  },\\n  \\\"panels\\\": [\\n    {\\n      \\\"id\\\":
        1,\\n      \\\"title\\\": \\\"Battery Status\\\",\\n      \\\"type\\\": \\\"stat\\\",\\n
        \     \\\"targets\\\": [\\n        {\\n          \\\"expr\\\": \\\"node_power_supply_capacity\\\",\\n
        \         \\\"legendFormat\\\": \\\"Battery %\\\",\\n          \\\"refId\\\":
        \\\"A\\\"\\n        },\\n        {\\n          \\\"expr\\\": \\\"node_power_supply_online\\\",\\n
        \         \\\"legendFormat\\\": \\\"AC Power\\\",\\n          \\\"refId\\\":
        \\\"B\\\"\\n        },\\n        {\\n          \\\"expr\\\": \\\"node_power_supply_cyclecount\\\",\\n
        \         \\\"legendFormat\\\": \\\"Charge Cycles\\\",\\n          \\\"refId\\\":
        \\\"C\\\"\\n        }\\n      ],\\n      \\\"fieldConfig\\\": {\\n        \\\"defaults\\\":
        {\\n          \\\"unit\\\": \\\"percent\\\"\\n        },\\n        \\\"overrides\\\":
        [\\n          {\\n            \\\"matcher\\\": {\\\"id\\\": \\\"byName\\\",
        \\\"options\\\": \\\"AC Power\\\"},\\n            \\\"properties\\\": [\\n
        \             {\\\"id\\\": \\\"unit\\\", \\\"value\\\": \\\"short\\\"},\\n
        \             {\\\"id\\\": \\\"mappings\\\", \\\"value\\\": [\\n                {\\\"type\\\":
        \\\"value\\\", \\\"value\\\": \\\"0\\\", \\\"text\\\": \\\"\U0001F50B Battery\\\"},\\n
        \               {\\\"type\\\": \\\"value\\\", \\\"value\\\": \\\"1\\\", \\\"text\\\":
        \\\"\U0001F50C AC Power\\\"}\\n              ]},\\n              {\\\"id\\\":
        \\\"color\\\", \\\"value\\\": {\\\"mode\\\": \\\"thresholds\\\"}},\\n              {\\\"id\\\":
        \\\"thresholds\\\", \\\"value\\\": {\\n                \\\"steps\\\": [\\n
        \                 {\\\"color\\\": \\\"orange\\\", \\\"value\\\": null},\\n
        \                 {\\\"color\\\": \\\"green\\\", \\\"value\\\": 1}\\n                ]\\n
        \             }}\\n            ]\\n          },\\n          {\\n            \\\"matcher\\\":
        {\\\"id\\\": \\\"byName\\\", \\\"options\\\": \\\"Charge Cycles\\\"},\\n            \\\"properties\\\":
        [{\\\"id\\\": \\\"unit\\\", \\\"value\\\": \\\"short\\\"}]\\n          }\\n
        \       ]\\n      },\\n      \\\"gridPos\\\": {\\\"h\\\": 6, \\\"w\\\": 8,
        \\\"x\\\": 0, \\\"y\\\": 0}\\n    },\\n    {\\n      \\\"id\\\": 2,\\n      \\\"title\\\":
        \\\"Battery Health\\\",\\n      \\\"type\\\": \\\"gauge\\\",\\n      \\\"targets\\\":
        [\\n        {\\n          \\\"expr\\\": \\\"(node_power_supply_charge_full
        / node_power_supply_charge_full_design) * 100\\\",\\n          \\\"legendFormat\\\":
        \\\"Battery Health\\\",\\n          \\\"refId\\\": \\\"A\\\"\\n        }\\n
        \     ],\\n      \\\"fieldConfig\\\": {\\n        \\\"defaults\\\": {\\n          \\\"unit\\\":
        \\\"percent\\\",\\n          \\\"min\\\": 0,\\n          \\\"max\\\": 100,\\n
        \         \\\"thresholds\\\": {\\n            \\\"steps\\\": [\\n              {\\\"color\\\":
        \\\"red\\\", \\\"value\\\": null},\\n              {\\\"color\\\": \\\"orange\\\",
        \\\"value\\\": 50},\\n              {\\\"color\\\": \\\"yellow\\\", \\\"value\\\":
        70},\\n              {\\\"color\\\": \\\"green\\\", \\\"value\\\": 85}\\n
        \           ]\\n          }\\n        }\\n      },\\n      \\\"gridPos\\\":
        {\\\"h\\\": 6, \\\"w\\\": 8, \\\"x\\\": 8, \\\"y\\\": 0}\\n    },\\n    {\\n
        \     \\\"id\\\": 3,\\n      \\\"title\\\": \\\"Power Draw\\\",\\n      \\\"type\\\":
        \\\"stat\\\",\\n      \\\"targets\\\": [\\n        {\\n          \\\"expr\\\":
        \\\"node_power_supply_current_ampere * node_power_supply_voltage_min_design
        / 1000000\\\",\\n          \\\"legendFormat\\\": \\\"Current Power Draw\\\",\\n
        \         \\\"refId\\\": \\\"A\\\"\\n        }\\n      ],\\n      \\\"fieldConfig\\\":
        {\\n        \\\"defaults\\\": {\\n          \\\"unit\\\": \\\"watt\\\",\\n
        \         \\\"thresholds\\\": {\\n            \\\"steps\\\": [\\n              {\\\"color\\\":
        \\\"green\\\", \\\"value\\\": null},\\n              {\\\"color\\\": \\\"yellow\\\",
        \\\"value\\\": 50},\\n              {\\\"color\\\": \\\"orange\\\", \\\"value\\\":
        100},\\n              {\\\"color\\\": \\\"red\\\", \\\"value\\\": 150}\\n
        \           ]\\n          }\\n        }\\n      },\\n      \\\"gridPos\\\":
        {\\\"h\\\": 6, \\\"w\\\": 8, \\\"x\\\": 16, \\\"y\\\": 0}\\n    },\\n    {\\n
        \     \\\"id\\\": 4,\\n      \\\"title\\\": \\\"CPU Temperature Zones\\\",\\n
        \     \\\"type\\\": \\\"timeseries\\\",\\n      \\\"targets\\\": [\\n        {\\n
        \         \\\"expr\\\": \\\"node_hwmon_temp_celsius{chip=~\\\\\\\".*coretemp.*\\\\\\\"}\\\",\\n
        \         \\\"legendFormat\\\": \\\"Core {{ sensor }}\\\",\\n          \\\"refId\\\":
        \\\"A\\\"\\n        }\\n      ],\\n      \\\"fieldConfig\\\": {\\n        \\\"defaults\\\":
        {\\n          \\\"unit\\\": \\\"celsius\\\",\\n          \\\"custom\\\": {\\n
        \           \\\"fillOpacity\\\": 10,\\n            \\\"gradientMode\\\": \\\"opacity\\\"\\n
        \         },\\n          \\\"thresholds\\\": {\\n            \\\"steps\\\":
        [\\n              {\\\"color\\\": \\\"blue\\\", \\\"value\\\": null},\\n              {\\\"color\\\":
        \\\"green\\\", \\\"value\\\": 40},\\n              {\\\"color\\\": \\\"yellow\\\",
        \\\"value\\\": 60},\\n              {\\\"color\\\": \\\"orange\\\", \\\"value\\\":
        75},\\n              {\\\"color\\\": \\\"red\\\", \\\"value\\\": 85}\\n            ]\\n
        \         }\\n        }\\n      },\\n      \\\"gridPos\\\": {\\\"h\\\": 10,
        \\\"w\\\": 12, \\\"x\\\": 0, \\\"y\\\": 6}\\n    },\\n    {\\n      \\\"id\\\":
        5,\\n      \\\"title\\\": \\\"Thermal Throttling Alert\\\",\\n      \\\"type\\\":
        \\\"stat\\\",\\n      \\\"targets\\\": [\\n        {\\n          \\\"expr\\\":
        \\\"max(node_hwmon_temp_celsius) \\u003e 85\\\",\\n          \\\"legendFormat\\\":
        \\\"Thermal Warning\\\",\\n          \\\"refId\\\": \\\"A\\\"\\n        }\\n
        \     ],\\n      \\\"fieldConfig\\\": {\\n        \\\"defaults\\\": {\\n          \\\"unit\\\":
        \\\"short\\\",\\n          \\\"mappings\\\": [\\n            {\\\"type\\\":
        \\\"value\\\", \\\"value\\\": \\\"0\\\", \\\"text\\\": \\\"✓ Normal\\\"},\\n
        \           {\\\"type\\\": \\\"value\\\", \\\"value\\\": \\\"1\\\", \\\"text\\\":
        \\\"⚠️ HOT!\\\"}\\n          ],\\n          \\\"thresholds\\\": {\\n            \\\"steps\\\":
        [\\n              {\\\"color\\\": \\\"green\\\", \\\"value\\\": null},\\n
        \             {\\\"color\\\": \\\"red\\\", \\\"value\\\": 1}\\n            ]\\n
        \         }\\n        }\\n      },\\n      \\\"gridPos\\\": {\\\"h\\\": 4,
        \\\"w\\\": 6, \\\"x\\\": 12, \\\"y\\\": 6}\\n    },\\n    {\\n      \\\"id\\\":
        6,\\n      \\\"title\\\": \\\"Fan Speed\\\",\\n      \\\"type\\\": \\\"gauge\\\",\\n
        \     \\\"targets\\\": [\\n        {\\n          \\\"expr\\\": \\\"node_hwmon_fan_rpm\\\",\\n
        \         \\\"legendFormat\\\": \\\"{{ sensor }}\\\",\\n          \\\"refId\\\":
        \\\"A\\\"\\n        }\\n      ],\\n      \\\"fieldConfig\\\": {\\n        \\\"defaults\\\":
        {\\n          \\\"unit\\\": \\\"rpm\\\",\\n          \\\"min\\\": 0,\\n          \\\"max\\\":
        6000,\\n          \\\"thresholds\\\": {\\n            \\\"steps\\\": [\\n
        \             {\\\"color\\\": \\\"green\\\", \\\"value\\\": null},\\n              {\\\"color\\\":
        \\\"yellow\\\", \\\"value\\\": 3000},\\n              {\\\"color\\\": \\\"orange\\\",
        \\\"value\\\": 4500},\\n              {\\\"color\\\": \\\"red\\\", \\\"value\\\":
        5500}\\n            ]\\n          }\\n        }\\n      },\\n      \\\"gridPos\\\":
        {\\\"h\\\": 6, \\\"w\\\": 6, \\\"x\\\": 18, \\\"y\\\": 6}\\n    },\\n    {\\n
        \     \\\"id\\\": 7,\\n      \\\"title\\\": \\\"CPU Package Power\\\",\\n
        \     \\\"type\\\": \\\"timeseries\\\",\\n      \\\"targets\\\": [\\n        {\\n
        \         \\\"expr\\\": \\\"node_hwmon_power_average_watt\\\",\\n          \\\"legendFormat\\\":
        \\\"{{ chip }} - {{ sensor }}\\\",\\n          \\\"refId\\\": \\\"A\\\"\\n
        \       }\\n      ],\\n      \\\"fieldConfig\\\": {\\n        \\\"defaults\\\":
        {\\n          \\\"unit\\\": \\\"watt\\\",\\n          \\\"custom\\\": {\\n
        \           \\\"fillOpacity\\\": 20,\\n            \\\"gradientMode\\\": \\\"scheme\\\",\\n
        \           \\\"thresholdsStyle\\\": {\\n              \\\"mode\\\": \\\"line+area\\\"\\n
        \           }\\n          },\\n          \\\"thresholds\\\": {\\n            \\\"steps\\\":
        [\\n              {\\\"color\\\": \\\"green\\\", \\\"value\\\": null},\\n
        \             {\\\"color\\\": \\\"yellow\\\", \\\"value\\\": 45},\\n              {\\\"color\\\":
        \\\"orange\\\", \\\"value\\\": 65},\\n              {\\\"color\\\": \\\"red\\\",
        \\\"value\\\": 85}\\n            ]\\n          }\\n        }\\n      },\\n
        \     \\\"gridPos\\\": {\\\"h\\\": 8, \\\"w\\\": 12, \\\"x\\\": 12, \\\"y\\\":
        10}\\n    },\\n    {\\n      \\\"id\\\": 8,\\n      \\\"title\\\": \\\"Power
        \\u0026 Temperature Correlation\\\",\\n      \\\"type\\\": \\\"timeseries\\\",\\n
        \     \\\"targets\\\": [\\n        {\\n          \\\"expr\\\": \\\"avg(node_hwmon_temp_celsius{chip=~\\\\\\\".*coretemp.*\\\\\\\"})\\\",\\n
        \         \\\"legendFormat\\\": \\\"Avg CPU Temp\\\",\\n          \\\"refId\\\":
        \\\"A\\\"\\n        },\\n        {\\n          \\\"expr\\\": \\\"100 - (avg(rate(node_cpu_seconds_total{mode=\\\\\\\"idle\\\\\\\"}[1m]))
        * 100)\\\",\\n          \\\"legendFormat\\\": \\\"CPU Usage %\\\",\\n          \\\"refId\\\":
        \\\"B\\\"\\n        }\\n      ],\\n      \\\"fieldConfig\\\": {\\n        \\\"defaults\\\":
        {\\n          \\\"custom\\\": {\\n            \\\"axisPlacement\\\": \\\"auto\\\",\\n
        \           \\\"axisSoftMin\\\": 0\\n          }\\n        },\\n        \\\"overrides\\\":
        [\\n          {\\n            \\\"matcher\\\": {\\\"id\\\": \\\"byName\\\",
        \\\"options\\\": \\\"Avg CPU Temp\\\"},\\n            \\\"properties\\\":
        [\\n              {\\\"id\\\": \\\"unit\\\", \\\"value\\\": \\\"celsius\\\"},\\n
        \             {\\\"id\\\": \\\"custom.axisPlacement\\\", \\\"value\\\": \\\"left\\\"}\\n
        \           ]\\n          },\\n          {\\n            \\\"matcher\\\":
        {\\\"id\\\": \\\"byName\\\", \\\"options\\\": \\\"CPU Usage %\\\"},\\n            \\\"properties\\\":
        [\\n              {\\\"id\\\": \\\"unit\\\", \\\"value\\\": \\\"percent\\\"},\\n
        \             {\\\"id\\\": \\\"custom.axisPlacement\\\", \\\"value\\\": \\\"right\\\"}\\n
        \           ]\\n          }\\n        ]\\n      },\\n      \\\"gridPos\\\":
        {\\\"h\\\": 8, \\\"w\\\": 12, \\\"x\\\": 0, \\\"y\\\": 16}\\n    },\\n    {\\n
        \     \\\"id\\\": 9,\\n      \\\"title\\\": \\\"Voltage Rails\\\",\\n      \\\"type\\\":
        \\\"timeseries\\\",\\n      \\\"targets\\\": [\\n        {\\n          \\\"expr\\\":
        \\\"node_hwmon_in_volts\\\",\\n          \\\"legendFormat\\\": \\\"{{ chip
        }} - {{ sensor }}\\\",\\n          \\\"refId\\\": \\\"A\\\"\\n        }\\n
        \     ],\\n      \\\"fieldConfig\\\": {\\n        \\\"defaults\\\": {\\n          \\\"unit\\\":
        \\\"volt\\\",\\n          \\\"custom\\\": {\\n            \\\"drawStyle\\\":
        \\\"line\\\",\\n            \\\"lineWidth\\\": 1\\n          }\\n        }\\n
        \     },\\n      \\\"gridPos\\\": {\\\"h\\\": 8, \\\"w\\\": 12, \\\"x\\\":
        12, \\\"y\\\": 18}\\n    },\\n    {\\n      \\\"id\\\": 10,\\n      \\\"title\\\":
        \\\"Battery Charge History\\\",\\n      \\\"type\\\": \\\"timeseries\\\",\\n
        \     \\\"targets\\\": [\\n        {\\n          \\\"expr\\\": \\\"node_power_supply_capacity\\\",\\n
        \         \\\"legendFormat\\\": \\\"Battery Level\\\",\\n          \\\"refId\\\":
        \\\"A\\\"\\n        }\\n      ],\\n      \\\"fieldConfig\\\": {\\n        \\\"defaults\\\":
        {\\n          \\\"unit\\\": \\\"percent\\\",\\n          \\\"min\\\": 0,\\n
        \         \\\"max\\\": 100,\\n          \\\"custom\\\": {\\n            \\\"fillOpacity\\\":
        30,\\n            \\\"gradientMode\\\": \\\"hue\\\",\\n            \\\"thresholdsStyle\\\":
        {\\n              \\\"mode\\\": \\\"area\\\"\\n            }\\n          },\\n
        \         \\\"thresholds\\\": {\\n            \\\"steps\\\": [\\n              {\\\"color\\\":
        \\\"red\\\", \\\"value\\\": null},\\n              {\\\"color\\\": \\\"orange\\\",
        \\\"value\\\": 20},\\n              {\\\"color\\\": \\\"yellow\\\", \\\"value\\\":
        40},\\n              {\\\"color\\\": \\\"green\\\", \\\"value\\\": 60}\\n
        \           ]\\n          }\\n        }\\n      },\\n      \\\"gridPos\\\":
        {\\\"h\\\": 8, \\\"w\\\": 24, \\\"x\\\": 0, \\\"y\\\": 24}\\n    }\\n  ]\\n}\\n\"},\"kind\":\"ConfigMap\",\"metadata\":{\"annotations\":{},\"name\":\"power-thermal-dashboard\",\"namespace\":\"monitoring\"}}\n"
    creationTimestamp: "2025-05-27T23:17:04Z"
    name: power-thermal-dashboard
    namespace: monitoring
    resourceVersion: "3998"
    uid: eedeb320-fb8b-438a-b381-6e793c323af1
- apiVersion: v1
  data:
    process-anomaly-alerts.yaml: "groups:\n- name: process_anomaly_detection\n  interval:
      60s\n  rules:\n  # Process Anomaly Detector Health\n  # Fixed: Changed job name
      from \"advanced-process-anomaly-detector\" to \"process-anomaly-detector\"\n
      \ - alert: ProcessAnomalyDetectorDown\n    expr: up{job=\"process-anomaly-detector\"}
      == 0\n    for: 2m\n    labels:\n      severity: critical\n      component: process-anomaly-detector\n
      \   annotations:\n      summary: \"Process anomaly detector is down\"\n      description:
      \"Process anomaly detector has been down for more than 2 minutes\"\n      \n
      \ - alert: ProcessAnomalyDetectorNoModels\n    expr: process_anomaly_model_last_trained_timestamp
      == 0\n    for: 10m\n    labels:\n      severity: warning\n      component: process-anomaly-detector\n
      \   annotations:\n      summary: \"Process anomaly detector has no trained models\"\n
      \     description: \"Process anomaly detector has not trained any models yet\"\n
      \     \n  # CPU Anomaly Detection\n  - alert: ProcessCPUAnomalyDetected\n    expr:
      process_cpu_anomaly_score < 0.3\n    for: 2m\n    labels:\n      severity: warning\n
      \     component: process-anomaly-detector\n      anomaly_type: cpu\n    annotations:\n
      \     summary: \"Process CPU usage anomaly detected\"\n      description: \"Process
      {{ $labels.groupname }} on {{ $labels.instance }} shows abnormal CPU usage (anomaly
      score: {{ $value }})\"\n      \n  - alert: ProcessCPUAnomalyCritical\n    expr:
      process_cpu_anomaly_score < 0.1\n    for: 1m\n    labels:\n      severity: critical\n
      \     component: process-anomaly-detector\n      anomaly_type: cpu\n    annotations:\n
      \     summary: \"Critical process CPU usage anomaly\"\n      description: \"Process
      {{ $labels.groupname }} on {{ $labels.instance }} shows severe CPU usage anomaly
      (score: {{ $value }})\"\n      \n  # Memory Anomaly Detection\n  - alert: ProcessMemoryAnomalyDetected\n
      \   expr: process_memory_anomaly_score < 0.3\n    for: 2m\n    labels:\n      severity:
      warning\n      component: process-anomaly-detector\n      anomaly_type: memory\n
      \   annotations:\n      summary: \"Process memory usage anomaly detected\"\n
      \     description: \"Process {{ $labels.groupname }} on {{ $labels.instance
      }} shows abnormal memory usage (anomaly score: {{ $value }})\"\n      \n  -
      alert: ProcessMemoryAnomalyCritical\n    expr: process_memory_anomaly_score
      < 0.1\n    for: 1m\n    labels:\n      severity: critical\n      component:
      process-anomaly-detector\n      anomaly_type: memory\n    annotations:\n      summary:
      \"Critical process memory usage anomaly\"\n      description: \"Process {{ $labels.groupname
      }} on {{ $labels.instance }} shows severe memory usage anomaly (score: {{ $value
      }})\"\n      \n  # Process Count Anomaly Detection\n  - alert: ProcessCountAnomalyDetected\n
      \   expr: process_count_anomaly_score < 0.3\n    for: 2m\n    labels:\n      severity:
      warning\n      component: process-anomaly-detector\n      anomaly_type: count\n
      \   annotations:\n      summary: \"Process count anomaly detected\"\n      description:
      \"Process {{ $labels.groupname }} on {{ $labels.instance }} shows abnormal process
      count (anomaly score: {{ $value }})\"\n      \n  # New Process Detection\n  -
      alert: NewProcessDetected\n    expr: increase(process_new_process_detected_total[5m])
      > 0\n    for: 0m\n    labels:\n      severity: info\n      component: process-anomaly-detector\n
      \     anomaly_type: new_process\n    annotations:\n      summary: \"New process
      detected\"\n      description: \"New process {{ $labels.groupname }} detected
      on {{ $labels.instance }}\"\n      \n  # High Number of Anomaly Alerts\n  -
      alert: HighProcessAnomalyRate\n    expr: rate(process_anomaly_alerts_total[5m])
      > 0.5\n    for: 5m\n    labels:\n      severity: warning\n      component: process-anomaly-detector\n
      \   annotations:\n      summary: \"High rate of process anomalies\"\n      description:
      \"Process anomaly detector is generating {{ $value }} alerts per second\"\n
      \     \n  # Model Staleness\n  - alert: ProcessAnomalyModelStale\n    expr:
      time() - process_anomaly_model_last_trained_timestamp > 86400\n    for: 1h\n
      \   labels:\n      severity: warning\n      component: process-anomaly-detector\n
      \   annotations:\n      summary: \"Process anomaly models are stale\"\n      description:
      \"Process anomaly detection models haven't been retrained in over 24 hours\"\n
      \     \n  # Detection Performance\n  - alert: ProcessAnomalyDetectionSlow\n
      \   expr: histogram_quantile(0.95, rate(process_anomaly_detection_duration_seconds_bucket[5m]))
      > 30\n    for: 10m\n    labels:\n      severity: warning\n      component: process-anomaly-detector\n
      \   annotations:\n      summary: \"Process anomaly detection is slow\"\n      description:
      \"95th percentile detection time is {{ $value }} seconds, above 30 second threshold\"\n
      \     \n  # Low Process Coverage\n  - alert: LowProcessAnalysisCoverage\n    expr:
      process_anomaly_processes_analyzed_total < 10\n    for: 15m\n    labels:\n      severity:
      warning\n      component: process-anomaly-detector\n    annotations:\n      summary:
      \"Low number of processes being analyzed\"\n      description: \"Only {{ $value
      }} processes are being analyzed for anomalies\"\n\n- name: security_process_anomalies\n
      \ interval: 30s\n  rules:\n  # Security-focused process anomaly detection\n
      \ - alert: SuspiciousProcessBehaviorDetected\n    expr: |\n      (\n        process_cpu_anomaly_score{groupname=~\".*crypto.*|.*miner.*|.*coin.*|.*hash.*\"}
      < 0.2\n        or\n        process_memory_anomaly_score{groupname=~\".*crypto.*|.*miner.*|.*coin.*|.*hash.*\"}
      < 0.2\n      )\n    for: 1m\n    labels:\n      severity: critical\n      component:
      process-anomaly-detector\n      security_risk: high\n    annotations:\n      summary:
      \"Suspicious process behavior - potential crypto mining\"\n      description:
      \"Process {{ $labels.groupname }} on {{ $labels.instance }} shows patterns consistent
      with crypto mining (anomaly score: {{ $value }})\"\n      \n  - alert: ShellProcessAnomalyDetected\n
      \   expr: |\n      (\n        process_cpu_anomaly_score{groupname=~\".*bash.*|.*sh.*|.*zsh.*|.*fish.*\"}
      < 0.2\n        or\n        process_memory_anomaly_score{groupname=~\".*bash.*|.*sh.*|.*zsh.*|.*fish.*\"}
      < 0.2\n      )\n    for: 2m\n    labels:\n      severity: warning\n      component:
      process-anomaly-detector\n      security_risk: medium\n    annotations:\n      summary:
      \"Shell process anomaly detected\"\n      description: \"Shell process {{ $labels.groupname
      }} on {{ $labels.instance }} shows abnormal resource usage (score: {{ $value
      }})\"\n      \n  - alert: NetworkToolAnomalyDetected\n    expr: |\n      (\n
      \       process_cpu_anomaly_score{groupname=~\".*nmap.*|.*nc.*|.*netcat.*|.*wget.*|.*curl.*\"}
      < 0.2\n        or\n        process_memory_anomaly_score{groupname=~\".*nmap.*|.*nc.*|.*netcat.*|.*wget.*|.*curl.*\"}
      < 0.2\n      )\n    for: 1m\n    labels:\n      severity: warning\n      component:
      process-anomaly-detector\n      security_risk: medium\n    annotations:\n      summary:
      \"Network tool anomaly detected\"\n      description: \"Network tool {{ $labels.groupname
      }} on {{ $labels.instance }} shows unusual behavior (score: {{ $value }})\"\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"process-anomaly-alerts.yaml":"groups:\n- name: process_anomaly_detection\n  interval: 60s\n  rules:\n  # Process Anomaly Detector Health\n  # Fixed: Changed job name from \"advanced-process-anomaly-detector\" to \"process-anomaly-detector\"\n  - alert: ProcessAnomalyDetectorDown\n    expr: up{job=\"process-anomaly-detector\"} == 0\n    for: 2m\n    labels:\n      severity: critical\n      component: process-anomaly-detector\n    annotations:\n      summary: \"Process anomaly detector is down\"\n      description: \"Process anomaly detector has been down for more than 2 minutes\"\n      \n  - alert: ProcessAnomalyDetectorNoModels\n    expr: process_anomaly_model_last_trained_timestamp == 0\n    for: 10m\n    labels:\n      severity: warning\n      component: process-anomaly-detector\n    annotations:\n      summary: \"Process anomaly detector has no trained models\"\n      description: \"Process anomaly detector has not trained any models yet\"\n      \n  # CPU Anomaly Detection\n  - alert: ProcessCPUAnomalyDetected\n    expr: process_cpu_anomaly_score \u003c 0.3\n    for: 2m\n    labels:\n      severity: warning\n      component: process-anomaly-detector\n      anomaly_type: cpu\n    annotations:\n      summary: \"Process CPU usage anomaly detected\"\n      description: \"Process {{ $labels.groupname }} on {{ $labels.instance }} shows abnormal CPU usage (anomaly score: {{ $value }})\"\n      \n  - alert: ProcessCPUAnomalyCritical\n    expr: process_cpu_anomaly_score \u003c 0.1\n    for: 1m\n    labels:\n      severity: critical\n      component: process-anomaly-detector\n      anomaly_type: cpu\n    annotations:\n      summary: \"Critical process CPU usage anomaly\"\n      description: \"Process {{ $labels.groupname }} on {{ $labels.instance }} shows severe CPU usage anomaly (score: {{ $value }})\"\n      \n  # Memory Anomaly Detection\n  - alert: ProcessMemoryAnomalyDetected\n    expr: process_memory_anomaly_score \u003c 0.3\n    for: 2m\n    labels:\n      severity: warning\n      component: process-anomaly-detector\n      anomaly_type: memory\n    annotations:\n      summary: \"Process memory usage anomaly detected\"\n      description: \"Process {{ $labels.groupname }} on {{ $labels.instance }} shows abnormal memory usage (anomaly score: {{ $value }})\"\n      \n  - alert: ProcessMemoryAnomalyCritical\n    expr: process_memory_anomaly_score \u003c 0.1\n    for: 1m\n    labels:\n      severity: critical\n      component: process-anomaly-detector\n      anomaly_type: memory\n    annotations:\n      summary: \"Critical process memory usage anomaly\"\n      description: \"Process {{ $labels.groupname }} on {{ $labels.instance }} shows severe memory usage anomaly (score: {{ $value }})\"\n      \n  # Process Count Anomaly Detection\n  - alert: ProcessCountAnomalyDetected\n    expr: process_count_anomaly_score \u003c 0.3\n    for: 2m\n    labels:\n      severity: warning\n      component: process-anomaly-detector\n      anomaly_type: count\n    annotations:\n      summary: \"Process count anomaly detected\"\n      description: \"Process {{ $labels.groupname }} on {{ $labels.instance }} shows abnormal process count (anomaly score: {{ $value }})\"\n      \n  # New Process Detection\n  - alert: NewProcessDetected\n    expr: increase(process_new_process_detected_total[5m]) \u003e 0\n    for: 0m\n    labels:\n      severity: info\n      component: process-anomaly-detector\n      anomaly_type: new_process\n    annotations:\n      summary: \"New process detected\"\n      description: \"New process {{ $labels.groupname }} detected on {{ $labels.instance }}\"\n      \n  # High Number of Anomaly Alerts\n  - alert: HighProcessAnomalyRate\n    expr: rate(process_anomaly_alerts_total[5m]) \u003e 0.5\n    for: 5m\n    labels:\n      severity: warning\n      component: process-anomaly-detector\n    annotations:\n      summary: \"High rate of process anomalies\"\n      description: \"Process anomaly detector is generating {{ $value }} alerts per second\"\n      \n  # Model Staleness\n  - alert: ProcessAnomalyModelStale\n    expr: time() - process_anomaly_model_last_trained_timestamp \u003e 86400\n    for: 1h\n    labels:\n      severity: warning\n      component: process-anomaly-detector\n    annotations:\n      summary: \"Process anomaly models are stale\"\n      description: \"Process anomaly detection models haven't been retrained in over 24 hours\"\n      \n  # Detection Performance\n  - alert: ProcessAnomalyDetectionSlow\n    expr: histogram_quantile(0.95, rate(process_anomaly_detection_duration_seconds_bucket[5m])) \u003e 30\n    for: 10m\n    labels:\n      severity: warning\n      component: process-anomaly-detector\n    annotations:\n      summary: \"Process anomaly detection is slow\"\n      description: \"95th percentile detection time is {{ $value }} seconds, above 30 second threshold\"\n      \n  # Low Process Coverage\n  - alert: LowProcessAnalysisCoverage\n    expr: process_anomaly_processes_analyzed_total \u003c 10\n    for: 15m\n    labels:\n      severity: warning\n      component: process-anomaly-detector\n    annotations:\n      summary: \"Low number of processes being analyzed\"\n      description: \"Only {{ $value }} processes are being analyzed for anomalies\"\n\n- name: security_process_anomalies\n  interval: 30s\n  rules:\n  # Security-focused process anomaly detection\n  - alert: SuspiciousProcessBehaviorDetected\n    expr: |\n      (\n        process_cpu_anomaly_score{groupname=~\".*crypto.*|.*miner.*|.*coin.*|.*hash.*\"} \u003c 0.2\n        or\n        process_memory_anomaly_score{groupname=~\".*crypto.*|.*miner.*|.*coin.*|.*hash.*\"} \u003c 0.2\n      )\n    for: 1m\n    labels:\n      severity: critical\n      component: process-anomaly-detector\n      security_risk: high\n    annotations:\n      summary: \"Suspicious process behavior - potential crypto mining\"\n      description: \"Process {{ $labels.groupname }} on {{ $labels.instance }} shows patterns consistent with crypto mining (anomaly score: {{ $value }})\"\n      \n  - alert: ShellProcessAnomalyDetected\n    expr: |\n      (\n        process_cpu_anomaly_score{groupname=~\".*bash.*|.*sh.*|.*zsh.*|.*fish.*\"} \u003c 0.2\n        or\n        process_memory_anomaly_score{groupname=~\".*bash.*|.*sh.*|.*zsh.*|.*fish.*\"} \u003c 0.2\n      )\n    for: 2m\n    labels:\n      severity: warning\n      component: process-anomaly-detector\n      security_risk: medium\n    annotations:\n      summary: \"Shell process anomaly detected\"\n      description: \"Shell process {{ $labels.groupname }} on {{ $labels.instance }} shows abnormal resource usage (score: {{ $value }})\"\n      \n  - alert: NetworkToolAnomalyDetected\n    expr: |\n      (\n        process_cpu_anomaly_score{groupname=~\".*nmap.*|.*nc.*|.*netcat.*|.*wget.*|.*curl.*\"} \u003c 0.2\n        or\n        process_memory_anomaly_score{groupname=~\".*nmap.*|.*nc.*|.*netcat.*|.*wget.*|.*curl.*\"} \u003c 0.2\n      )\n    for: 1m\n    labels:\n      severity: warning\n      component: process-anomaly-detector\n      security_risk: medium\n    annotations:\n      summary: \"Network tool anomaly detected\"\n      description: \"Network tool {{ $labels.groupname }} on {{ $labels.instance }} shows unusual behavior (score: {{ $value }})\"\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"process-anomaly-alert-rules","namespace":"monitoring"}}
    creationTimestamp: "2025-06-02T19:07:30Z"
    name: process-anomaly-alert-rules
    namespace: monitoring
    resourceVersion: "4507698"
    uid: 54421a12-d794-496d-8aad-555f620fc93d
- apiVersion: v1
  data:
    process-anomaly-improved.json: "{\n  \"uid\": \"process-anomaly-improved\",\n
      \ \"title\": \"ODIN Process Anomaly Detection (Improved)\",\n  \"tags\": [\"anomaly\",
      \"process\", \"ml\", \"security\", \"odin\"],\n  \"timezone\": \"America/Los_Angeles\",\n
      \ \"schemaVersion\": 38,\n  \"version\": 1,\n  \"refresh\": \"30s\",\n  \"time\":
      {\n    \"from\": \"now-3h\",\n    \"to\": \"now\"\n  },\n  \"templating\": {\n
      \   \"list\": [\n      {\n        \"name\": \"groupname\",\n        \"type\":
      \"query\",\n        \"datasource\": \"Prometheus\",\n        \"query\": \"label_values(process_cpu_anomaly_score,
      groupname)\",\n        \"refresh\": 1,\n        \"includeAll\": true,\n        \"allValue\":
      \".*\",\n        \"multi\": true,\n        \"sort\": 1\n      },\n      {\n
      \       \"name\": \"top_n\",\n        \"type\": \"custom\",\n        \"current\":
      {\n          \"text\": \"20\",\n          \"value\": \"20\"\n        },\n        \"options\":
      [\n          {\"text\": \"10\", \"value\": \"10\"},\n          {\"text\": \"20\",
      \"value\": \"20\"},\n          {\"text\": \"30\", \"value\": \"30\"},\n          {\"text\":
      \"50\", \"value\": \"50\"},\n          {\"text\": \"100\", \"value\": \"100\"}\n
      \       ],\n        \"query\": \"10,20,30,50,100\",\n        \"description\":
      \"Number of top anomalous processes to show\"\n      },\n      {\n        \"name\":
      \"anomaly_threshold\",\n        \"type\": \"custom\",\n        \"current\":
      {\n          \"text\": \"0.7\",\n          \"value\": \"0.7\"\n        },\n
      \       \"options\": [\n          {\"text\": \"0.5 (High Sensitivity)\", \"value\":
      \"0.5\"},\n          {\"text\": \"0.6\", \"value\": \"0.6\"},\n          {\"text\":
      \"0.7 (Medium)\", \"value\": \"0.7\"},\n          {\"text\": \"0.8\", \"value\":
      \"0.8\"},\n          {\"text\": \"0.9 (Low Sensitivity)\", \"value\": \"0.9\"}\n
      \       ],\n        \"query\": \"0.5,0.6,0.7,0.8,0.9\",\n        \"description\":
      \"Anomaly score threshold for filtering\"\n      }\n    ]\n  },\n  \"panels\":
      [\n    {\n      \"gridPos\": {\"h\": 1, \"w\": 24, \"x\": 0, \"y\": 0},\n      \"id\":
      1,\n      \"type\": \"row\",\n      \"title\": \"Most Anomalous Processes\",\n
      \     \"collapsed\": false\n    },\n    {\n      \"gridPos\": {\"h\": 10, \"w\":
      24, \"x\": 0, \"y\": 1},\n      \"id\": 2,\n      \"type\": \"barchart\",\n
      \     \"title\": \"Top $top_n Most Anomalous Processes (Combined Score)\",\n
      \     \"targets\": [\n        {\n          \"expr\": \"bottomk($top_n, \\n  min
      by (groupname) (\\n    process_cpu_anomaly_score{groupname=~\\\"$groupname\\\"}
      < $anomaly_threshold\\n    or process_memory_anomaly_score{groupname=~\\\"$groupname\\\"}
      < $anomaly_threshold\\n  )\\n)\",\n          \"legendFormat\": \"{{groupname}}\",\n
      \         \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"orientation\":
      \"horizontal\",\n        \"displayMode\": \"gradient\",\n        \"showValue\":
      \"always\",\n        \"legend\": {\n          \"displayMode\": \"hidden\"\n
      \       },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\":
      \"none\"\n        }\n      },\n      \"fieldConfig\": {\n        \"defaults\":
      {\n          \"color\": {\n            \"mode\": \"continuous-GrYlRd\"\n          },\n
      \         \"custom\": {\n            \"axisCenteredZero\": false,\n            \"hideFrom\":
      {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\":
      false\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\":
      {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"color\":
      \"red\", \"value\": 0},\n              {\"color\": \"yellow\", \"value\": 0.3},\n
      \             {\"color\": \"green\", \"value\": 0.7}\n            ]\n          },\n
      \         \"unit\": \"percentunit\",\n          \"min\": 0,\n          \"max\":
      1\n        }\n      }\n    },\n    {\n      \"gridPos\": {\"h\": 1, \"w\": 24,
      \"x\": 0, \"y\": 11},\n      \"id\": 3,\n      \"type\": \"row\",\n      \"title\":
      \"Anomaly Score Treemap (Hierarchical View)\",\n      \"collapsed\": false\n
      \   },\n    {\n      \"gridPos\": {\"h\": 12, \"w\": 12, \"x\": 0, \"y\": 12},\n
      \     \"id\": 4,\n      \"type\": \"piechart\",\n      \"title\": \"CPU Anomaly
      Distribution by Severity\",\n      \"targets\": [\n        {\n          \"expr\":
      \"count by (severity) (\\n  label_replace(\\n    process_cpu_anomaly_score{groupname=~\\\"$groupname\\\"},\\n
      \   \\\"severity\\\", \\\"Critical\\\", \\\"groupname\\\", \\\".*\\\"\\n  )
      < 0.3\\n  or label_replace(\\n    process_cpu_anomaly_score{groupname=~\\\"$groupname\\\"},\\n
      \   \\\"severity\\\", \\\"Warning\\\", \\\"groupname\\\", \\\".*\\\"\\n  ) >=
      0.3 < 0.7\\n  or label_replace(\\n    process_cpu_anomaly_score{groupname=~\\\"$groupname\\\"},\\n
      \   \\\"severity\\\", \\\"Normal\\\", \\\"groupname\\\", \\\".*\\\"\\n  ) >=
      0.7\\n)\",\n          \"refId\": \"A\",\n          \"format\": \"time_series\",\n
      \         \"instant\": true\n        }\n      ],\n      \"options\": {\n        \"pieType\":
      \"donut\",\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\":
      \"none\"\n        },\n        \"legend\": {\n          \"displayMode\": \"table\",\n
      \         \"placement\": \"right\",\n          \"showLegend\": true,\n          \"values\":
      [\"value\", \"percent\"]\n        },\n        \"displayLabels\": [\"name\",
      \"percent\"],\n        \"reduceOptions\": {\n          \"values\": false,\n
      \         \"calcs\": [\"lastNotNull\"]\n        }\n      },\n      \"fieldConfig\":
      {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n
      \         },\n          \"custom\": {\n            \"hideFrom\": {\n              \"tooltip\":
      false,\n              \"viz\": false,\n              \"legend\": false\n            }\n
      \         },\n          \"mappings\": [\n            {\n              \"type\":
      \"value\",\n              \"value\": \"Critical\",\n              \"text\":
      \"Critical (< 0.3)\",\n              \"color\": \"red\"\n            },\n            {\n
      \             \"type\": \"value\", \n              \"value\": \"Warning\",\n
      \             \"text\": \"Warning (0.3-0.7)\",\n              \"color\": \"yellow\"\n
      \           },\n            {\n              \"type\": \"value\",\n              \"value\":
      \"Normal\",\n              \"text\": \"Normal (> 0.7)\", \n              \"color\":
      \"green\"\n            }\n          ]\n        }\n      }\n    },\n    {\n      \"gridPos\":
      {\"h\": 12, \"w\": 12, \"x\": 12, \"y\": 12},\n      \"id\": 5,\n      \"type\":
      \"state-timeline\",\n      \"title\": \"Process Anomaly State Timeline (Top
      $top_n)\",\n      \"targets\": [\n        {\n          \"expr\": \"bottomk($top_n,
      process_cpu_anomaly_score{groupname=~\\\"$groupname\\\"} < $anomaly_threshold)\",\n
      \         \"legendFormat\": \"{{groupname}}\",\n          \"refId\": \"A\"\n
      \       }\n      ],\n      \"options\": {\n        \"legend\": {\n          \"displayMode\":
      \"list\",\n          \"placement\": \"right\",\n          \"showLegend\": true\n
      \       },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\":
      \"none\"\n        },\n        \"timezone\": [\"browser\"],\n        \"rowHeight\":
      0.5\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"custom\":
      {\n            \"lineWidth\": 0,\n            \"fillOpacity\": 70,\n            \"spanNulls\":
      false,\n            \"insertNulls\": false,\n            \"hideFrom\": {\n              \"tooltip\":
      false,\n              \"viz\": false,\n              \"legend\": false\n            }\n
      \         },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\":
      \"absolute\",\n            \"steps\": [\n              {\"color\": \"red\",
      \"value\": 0},\n              {\"color\": \"orange\", \"value\": 0.3},\n              {\"color\":
      \"yellow\", \"value\": 0.5},\n              {\"color\": \"green\", \"value\":
      0.7}\n            ]\n          },\n          \"unit\": \"percentunit\",\n          \"min\":
      0,\n          \"max\": 1\n        }\n      }\n    },\n    {\n      \"gridPos\":
      {\"h\": 1, \"w\": 24, \"x\": 0, \"y\": 24},\n      \"id\": 6,\n      \"type\":
      \"row\",\n      \"title\": \"Grouped Anomaly Analysis\",\n      \"collapsed\":
      false\n    },\n    {\n      \"gridPos\": {\"h\": 10, \"w\": 12, \"x\": 0, \"y\":
      25},\n      \"id\": 7,\n      \"type\": \"heatmap\",\n      \"title\": \"Anomaly
      Heatmap - System Processes\",\n      \"targets\": [\n        {\n          \"expr\":
      \"process_cpu_anomaly_score{groupname=~\\\"systemd.*|kernel.*|init.*|cron.*|ssh.*|NetworkManager.*\\\"}\",\n
      \         \"format\": \"time_series\",\n          \"refId\": \"A\"\n        }\n
      \     ],\n      \"options\": {\n        \"calculate\": false,\n        \"cellGap\":
      1,\n        \"cellValues\": {},\n        \"color\": {\n          \"exponent\":
      0.5,\n          \"fill\": \"#b4ff00\",\n          \"max\": 1,\n          \"min\":
      0,\n          \"mode\": \"opacity\",\n          \"reverse\": true,\n          \"scale\":
      \"exponential\",\n          \"scheme\": \"RdYlGn\",\n          \"steps\": 128\n
      \       },\n        \"exemplars\": {\n          \"color\": \"rgba(255,0,255,0.7)\"\n
      \       },\n        \"filterValues\": {\n          \"le\": 1e-9\n        },\n
      \       \"legend\": {\n          \"show\": true\n        },\n        \"rowsFrame\":
      {\n          \"layout\": \"auto\"\n        },\n        \"showValue\": \"never\",\n
      \       \"tooltip\": {\n          \"show\": true,\n          \"yHistogram\":
      false\n        },\n        \"yAxis\": {\n          \"axisPlacement\": \"left\",\n
      \         \"reverse\": false,\n          \"unit\": \"percentunit\"\n        }\n
      \     }\n    },\n    {\n      \"gridPos\": {\"h\": 10, \"w\": 12, \"x\": 12,
      \"y\": 25},\n      \"id\": 8,\n      \"type\": \"heatmap\",\n      \"title\":
      \"Anomaly Heatmap - Container Processes\",\n      \"targets\": [\n        {\n
      \         \"expr\": \"process_cpu_anomaly_score{groupname=~\\\"containerd.*|docker.*|k3s.*|kubelet.*|coredns.*|pause.*|metrics-server.*\\\"}\",\n
      \         \"format\": \"time_series\",\n          \"refId\": \"A\"\n        }\n
      \     ],\n      \"options\": {\n        \"calculate\": false,\n        \"cellGap\":
      1,\n        \"cellValues\": {},\n        \"color\": {\n          \"exponent\":
      0.5,\n          \"fill\": \"#b4ff00\",\n          \"max\": 1,\n          \"min\":
      0,\n          \"mode\": \"opacity\",\n          \"reverse\": true,\n          \"scale\":
      \"exponential\",\n          \"scheme\": \"RdYlGn\",\n          \"steps\": 128\n
      \       },\n        \"exemplars\": {\n          \"color\": \"rgba(255,0,255,0.7)\"\n
      \       },\n        \"filterValues\": {\n          \"le\": 1e-9\n        },\n
      \       \"legend\": {\n          \"show\": true\n        },\n        \"rowsFrame\":
      {\n          \"layout\": \"auto\"\n        },\n        \"showValue\": \"never\",\n
      \       \"tooltip\": {\n          \"show\": true,\n          \"yHistogram\":
      false\n        },\n        \"yAxis\": {\n          \"axisPlacement\": \"left\",\n
      \         \"reverse\": false,\n          \"unit\": \"percentunit\"\n        }\n
      \     }\n    },\n    {\n      \"gridPos\": {\"h\": 10, \"w\": 24, \"x\": 0,
      \"y\": 35},\n      \"id\": 9,\n      \"type\": \"table\",\n      \"title\":
      \"Process Anomaly Summary Table\",\n      \"transformations\": [\n        {\n
      \         \"id\": \"merge\",\n          \"options\": {}\n        },\n        {\n
      \         \"id\": \"organize\",\n          \"options\": {\n            \"excludeByName\":
      {\n              \"Time\": true,\n              \"__name__\": true,\n              \"job\":
      true\n            },\n            \"indexByName\": {\n              \"groupname\":
      0,\n              \"instance\": 1,\n              \"Value #A\": 2,\n              \"Value
      #B\": 3,\n              \"Value #C\": 4\n            },\n            \"renameByName\":
      {\n              \"groupname\": \"Process\",\n              \"instance\": \"Host\",\n
      \             \"Value #A\": \"CPU Score\",\n              \"Value #B\": \"Memory
      Score\",\n              \"Value #C\": \"Count Score\"\n            }\n          }\n
      \       },\n        {\n          \"id\": \"filterByValue\",\n          \"options\":
      {\n            \"filters\": [\n              {\n                \"fieldName\":
      \"CPU Score\",\n                \"config\": {\n                  \"id\": \"thresholds\",\n
      \                 \"options\": {\n                    \"match\": \"outside\",\n
      \                   \"result\": {\n                      \"index\": 0\n                    }\n
      \                 }\n                }\n              }\n            ],\n            \"match\":
      \"any\",\n            \"type\": \"exclude\"\n          }\n        }\n      ],\n
      \     \"targets\": [\n        {\n          \"expr\": \"process_cpu_anomaly_score{groupname=~\\\"$groupname\\\"}
      < $anomaly_threshold\",\n          \"format\": \"table\",\n          \"instant\":
      true,\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\":
      \"process_memory_anomaly_score{groupname=~\\\"$groupname\\\"} < $anomaly_threshold\",\n
      \         \"format\": \"table\", \n          \"instant\": true,\n          \"refId\":
      \"B\"\n        },\n        {\n          \"expr\": \"process_count_anomaly_score{groupname=~\\\"$groupname\\\"}
      < $anomaly_threshold\",\n          \"format\": \"table\",\n          \"instant\":
      true,\n          \"refId\": \"C\"\n        }\n      ],\n      \"options\": {\n
      \       \"showHeader\": true,\n        \"sortBy\": [\n          {\n            \"desc\":
      false,\n            \"displayName\": \"CPU Score\"\n          }\n        ],\n
      \       \"footer\": {\n          \"show\": false,\n          \"reducer\": [\"sum\"],\n
      \         \"fields\": \"\"\n        }\n      },\n      \"fieldConfig\": {\n
      \       \"defaults\": {\n          \"custom\": {\n            \"align\": \"auto\",\n
      \           \"displayMode\": \"color-background-solid\",\n            \"inspect\":
      false,\n            \"filterable\": true\n          },\n          \"mappings\":
      [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\":
      [\n              {\"color\": \"red\", \"value\": 0},\n              {\"color\":
      \"yellow\", \"value\": 0.3},\n              {\"color\": \"green\", \"value\":
      0.7}\n            ]\n          },\n          \"unit\": \"percentunit\",\n          \"min\":
      0,\n          \"max\": 1\n        },\n        \"overrides\": [\n          {\n
      \           \"matcher\": {\n              \"id\": \"byName\",\n              \"options\":
      \"Process\"\n            },\n            \"properties\": [\n              {\n
      \               \"id\": \"custom.width\",\n                \"value\": 200\n
      \             },\n              {\n                \"id\": \"custom.displayMode\",\n
      \               \"value\": \"auto\"\n              }\n            ]\n          },\n
      \         {\n            \"matcher\": {\n              \"id\": \"byName\", \n
      \             \"options\": \"Host\"\n            },\n            \"properties\":
      [\n              {\n                \"id\": \"custom.width\",\n                \"value\":
      150\n              },\n              {\n                \"id\": \"custom.displayMode\",\n
      \               \"value\": \"auto\"\n              }\n            ]\n          }\n
      \       ]\n      }\n    }\n  ],\n  \"editable\": true\n}\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"process-anomaly-improved.json":"{\n  \"uid\": \"process-anomaly-improved\",\n  \"title\": \"ODIN Process Anomaly Detection (Improved)\",\n  \"tags\": [\"anomaly\", \"process\", \"ml\", \"security\", \"odin\"],\n  \"timezone\": \"America/Los_Angeles\",\n  \"schemaVersion\": 38,\n  \"version\": 1,\n  \"refresh\": \"30s\",\n  \"time\": {\n    \"from\": \"now-3h\",\n    \"to\": \"now\"\n  },\n  \"templating\": {\n    \"list\": [\n      {\n        \"name\": \"groupname\",\n        \"type\": \"query\",\n        \"datasource\": \"Prometheus\",\n        \"query\": \"label_values(process_cpu_anomaly_score, groupname)\",\n        \"refresh\": 1,\n        \"includeAll\": true,\n        \"allValue\": \".*\",\n        \"multi\": true,\n        \"sort\": 1\n      },\n      {\n        \"name\": \"top_n\",\n        \"type\": \"custom\",\n        \"current\": {\n          \"text\": \"20\",\n          \"value\": \"20\"\n        },\n        \"options\": [\n          {\"text\": \"10\", \"value\": \"10\"},\n          {\"text\": \"20\", \"value\": \"20\"},\n          {\"text\": \"30\", \"value\": \"30\"},\n          {\"text\": \"50\", \"value\": \"50\"},\n          {\"text\": \"100\", \"value\": \"100\"}\n        ],\n        \"query\": \"10,20,30,50,100\",\n        \"description\": \"Number of top anomalous processes to show\"\n      },\n      {\n        \"name\": \"anomaly_threshold\",\n        \"type\": \"custom\",\n        \"current\": {\n          \"text\": \"0.7\",\n          \"value\": \"0.7\"\n        },\n        \"options\": [\n          {\"text\": \"0.5 (High Sensitivity)\", \"value\": \"0.5\"},\n          {\"text\": \"0.6\", \"value\": \"0.6\"},\n          {\"text\": \"0.7 (Medium)\", \"value\": \"0.7\"},\n          {\"text\": \"0.8\", \"value\": \"0.8\"},\n          {\"text\": \"0.9 (Low Sensitivity)\", \"value\": \"0.9\"}\n        ],\n        \"query\": \"0.5,0.6,0.7,0.8,0.9\",\n        \"description\": \"Anomaly score threshold for filtering\"\n      }\n    ]\n  },\n  \"panels\": [\n    {\n      \"gridPos\": {\"h\": 1, \"w\": 24, \"x\": 0, \"y\": 0},\n      \"id\": 1,\n      \"type\": \"row\",\n      \"title\": \"Most Anomalous Processes\",\n      \"collapsed\": false\n    },\n    {\n      \"gridPos\": {\"h\": 10, \"w\": 24, \"x\": 0, \"y\": 1},\n      \"id\": 2,\n      \"type\": \"barchart\",\n      \"title\": \"Top $top_n Most Anomalous Processes (Combined Score)\",\n      \"targets\": [\n        {\n          \"expr\": \"bottomk($top_n, \\n  min by (groupname) (\\n    process_cpu_anomaly_score{groupname=~\\\"$groupname\\\"} \u003c $anomaly_threshold\\n    or process_memory_anomaly_score{groupname=~\\\"$groupname\\\"} \u003c $anomaly_threshold\\n  )\\n)\",\n          \"legendFormat\": \"{{groupname}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"orientation\": \"horizontal\",\n        \"displayMode\": \"gradient\",\n        \"showValue\": \"always\",\n        \"legend\": {\n          \"displayMode\": \"hidden\"\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        }\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"continuous-GrYlRd\"\n          },\n          \"custom\": {\n            \"axisCenteredZero\": false,\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"color\": \"red\", \"value\": 0},\n              {\"color\": \"yellow\", \"value\": 0.3},\n              {\"color\": \"green\", \"value\": 0.7}\n            ]\n          },\n          \"unit\": \"percentunit\",\n          \"min\": 0,\n          \"max\": 1\n        }\n      }\n    },\n    {\n      \"gridPos\": {\"h\": 1, \"w\": 24, \"x\": 0, \"y\": 11},\n      \"id\": 3,\n      \"type\": \"row\",\n      \"title\": \"Anomaly Score Treemap (Hierarchical View)\",\n      \"collapsed\": false\n    },\n    {\n      \"gridPos\": {\"h\": 12, \"w\": 12, \"x\": 0, \"y\": 12},\n      \"id\": 4,\n      \"type\": \"piechart\",\n      \"title\": \"CPU Anomaly Distribution by Severity\",\n      \"targets\": [\n        {\n          \"expr\": \"count by (severity) (\\n  label_replace(\\n    process_cpu_anomaly_score{groupname=~\\\"$groupname\\\"},\\n    \\\"severity\\\", \\\"Critical\\\", \\\"groupname\\\", \\\".*\\\"\\n  ) \u003c 0.3\\n  or label_replace(\\n    process_cpu_anomaly_score{groupname=~\\\"$groupname\\\"},\\n    \\\"severity\\\", \\\"Warning\\\", \\\"groupname\\\", \\\".*\\\"\\n  ) \u003e= 0.3 \u003c 0.7\\n  or label_replace(\\n    process_cpu_anomaly_score{groupname=~\\\"$groupname\\\"},\\n    \\\"severity\\\", \\\"Normal\\\", \\\"groupname\\\", \\\".*\\\"\\n  ) \u003e= 0.7\\n)\",\n          \"refId\": \"A\",\n          \"format\": \"time_series\",\n          \"instant\": true\n        }\n      ],\n      \"options\": {\n        \"pieType\": \"donut\",\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        },\n        \"legend\": {\n          \"displayMode\": \"table\",\n          \"placement\": \"right\",\n          \"showLegend\": true,\n          \"values\": [\"value\", \"percent\"]\n        },\n        \"displayLabels\": [\"name\", \"percent\"],\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"]\n        }\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            }\n          },\n          \"mappings\": [\n            {\n              \"type\": \"value\",\n              \"value\": \"Critical\",\n              \"text\": \"Critical (\u003c 0.3)\",\n              \"color\": \"red\"\n            },\n            {\n              \"type\": \"value\", \n              \"value\": \"Warning\",\n              \"text\": \"Warning (0.3-0.7)\",\n              \"color\": \"yellow\"\n            },\n            {\n              \"type\": \"value\",\n              \"value\": \"Normal\",\n              \"text\": \"Normal (\u003e 0.7)\", \n              \"color\": \"green\"\n            }\n          ]\n        }\n      }\n    },\n    {\n      \"gridPos\": {\"h\": 12, \"w\": 12, \"x\": 12, \"y\": 12},\n      \"id\": 5,\n      \"type\": \"state-timeline\",\n      \"title\": \"Process Anomaly State Timeline (Top $top_n)\",\n      \"targets\": [\n        {\n          \"expr\": \"bottomk($top_n, process_cpu_anomaly_score{groupname=~\\\"$groupname\\\"} \u003c $anomaly_threshold)\",\n          \"legendFormat\": \"{{groupname}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"legend\": {\n          \"displayMode\": \"list\",\n          \"placement\": \"right\",\n          \"showLegend\": true\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        },\n        \"timezone\": [\"browser\"],\n        \"rowHeight\": 0.5\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"custom\": {\n            \"lineWidth\": 0,\n            \"fillOpacity\": 70,\n            \"spanNulls\": false,\n            \"insertNulls\": false,\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"color\": \"red\", \"value\": 0},\n              {\"color\": \"orange\", \"value\": 0.3},\n              {\"color\": \"yellow\", \"value\": 0.5},\n              {\"color\": \"green\", \"value\": 0.7}\n            ]\n          },\n          \"unit\": \"percentunit\",\n          \"min\": 0,\n          \"max\": 1\n        }\n      }\n    },\n    {\n      \"gridPos\": {\"h\": 1, \"w\": 24, \"x\": 0, \"y\": 24},\n      \"id\": 6,\n      \"type\": \"row\",\n      \"title\": \"Grouped Anomaly Analysis\",\n      \"collapsed\": false\n    },\n    {\n      \"gridPos\": {\"h\": 10, \"w\": 12, \"x\": 0, \"y\": 25},\n      \"id\": 7,\n      \"type\": \"heatmap\",\n      \"title\": \"Anomaly Heatmap - System Processes\",\n      \"targets\": [\n        {\n          \"expr\": \"process_cpu_anomaly_score{groupname=~\\\"systemd.*|kernel.*|init.*|cron.*|ssh.*|NetworkManager.*\\\"}\",\n          \"format\": \"time_series\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"calculate\": false,\n        \"cellGap\": 1,\n        \"cellValues\": {},\n        \"color\": {\n          \"exponent\": 0.5,\n          \"fill\": \"#b4ff00\",\n          \"max\": 1,\n          \"min\": 0,\n          \"mode\": \"opacity\",\n          \"reverse\": true,\n          \"scale\": \"exponential\",\n          \"scheme\": \"RdYlGn\",\n          \"steps\": 128\n        },\n        \"exemplars\": {\n          \"color\": \"rgba(255,0,255,0.7)\"\n        },\n        \"filterValues\": {\n          \"le\": 1e-9\n        },\n        \"legend\": {\n          \"show\": true\n        },\n        \"rowsFrame\": {\n          \"layout\": \"auto\"\n        },\n        \"showValue\": \"never\",\n        \"tooltip\": {\n          \"show\": true,\n          \"yHistogram\": false\n        },\n        \"yAxis\": {\n          \"axisPlacement\": \"left\",\n          \"reverse\": false,\n          \"unit\": \"percentunit\"\n        }\n      }\n    },\n    {\n      \"gridPos\": {\"h\": 10, \"w\": 12, \"x\": 12, \"y\": 25},\n      \"id\": 8,\n      \"type\": \"heatmap\",\n      \"title\": \"Anomaly Heatmap - Container Processes\",\n      \"targets\": [\n        {\n          \"expr\": \"process_cpu_anomaly_score{groupname=~\\\"containerd.*|docker.*|k3s.*|kubelet.*|coredns.*|pause.*|metrics-server.*\\\"}\",\n          \"format\": \"time_series\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"calculate\": false,\n        \"cellGap\": 1,\n        \"cellValues\": {},\n        \"color\": {\n          \"exponent\": 0.5,\n          \"fill\": \"#b4ff00\",\n          \"max\": 1,\n          \"min\": 0,\n          \"mode\": \"opacity\",\n          \"reverse\": true,\n          \"scale\": \"exponential\",\n          \"scheme\": \"RdYlGn\",\n          \"steps\": 128\n        },\n        \"exemplars\": {\n          \"color\": \"rgba(255,0,255,0.7)\"\n        },\n        \"filterValues\": {\n          \"le\": 1e-9\n        },\n        \"legend\": {\n          \"show\": true\n        },\n        \"rowsFrame\": {\n          \"layout\": \"auto\"\n        },\n        \"showValue\": \"never\",\n        \"tooltip\": {\n          \"show\": true,\n          \"yHistogram\": false\n        },\n        \"yAxis\": {\n          \"axisPlacement\": \"left\",\n          \"reverse\": false,\n          \"unit\": \"percentunit\"\n        }\n      }\n    },\n    {\n      \"gridPos\": {\"h\": 10, \"w\": 24, \"x\": 0, \"y\": 35},\n      \"id\": 9,\n      \"type\": \"table\",\n      \"title\": \"Process Anomaly Summary Table\",\n      \"transformations\": [\n        {\n          \"id\": \"merge\",\n          \"options\": {}\n        },\n        {\n          \"id\": \"organize\",\n          \"options\": {\n            \"excludeByName\": {\n              \"Time\": true,\n              \"__name__\": true,\n              \"job\": true\n            },\n            \"indexByName\": {\n              \"groupname\": 0,\n              \"instance\": 1,\n              \"Value #A\": 2,\n              \"Value #B\": 3,\n              \"Value #C\": 4\n            },\n            \"renameByName\": {\n              \"groupname\": \"Process\",\n              \"instance\": \"Host\",\n              \"Value #A\": \"CPU Score\",\n              \"Value #B\": \"Memory Score\",\n              \"Value #C\": \"Count Score\"\n            }\n          }\n        },\n        {\n          \"id\": \"filterByValue\",\n          \"options\": {\n            \"filters\": [\n              {\n                \"fieldName\": \"CPU Score\",\n                \"config\": {\n                  \"id\": \"thresholds\",\n                  \"options\": {\n                    \"match\": \"outside\",\n                    \"result\": {\n                      \"index\": 0\n                    }\n                  }\n                }\n              }\n            ],\n            \"match\": \"any\",\n            \"type\": \"exclude\"\n          }\n        }\n      ],\n      \"targets\": [\n        {\n          \"expr\": \"process_cpu_anomaly_score{groupname=~\\\"$groupname\\\"} \u003c $anomaly_threshold\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"process_memory_anomaly_score{groupname=~\\\"$groupname\\\"} \u003c $anomaly_threshold\",\n          \"format\": \"table\", \n          \"instant\": true,\n          \"refId\": \"B\"\n        },\n        {\n          \"expr\": \"process_count_anomaly_score{groupname=~\\\"$groupname\\\"} \u003c $anomaly_threshold\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"C\"\n        }\n      ],\n      \"options\": {\n        \"showHeader\": true,\n        \"sortBy\": [\n          {\n            \"desc\": false,\n            \"displayName\": \"CPU Score\"\n          }\n        ],\n        \"footer\": {\n          \"show\": false,\n          \"reducer\": [\"sum\"],\n          \"fields\": \"\"\n        }\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"custom\": {\n            \"align\": \"auto\",\n            \"displayMode\": \"color-background-solid\",\n            \"inspect\": false,\n            \"filterable\": true\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"color\": \"red\", \"value\": 0},\n              {\"color\": \"yellow\", \"value\": 0.3},\n              {\"color\": \"green\", \"value\": 0.7}\n            ]\n          },\n          \"unit\": \"percentunit\",\n          \"min\": 0,\n          \"max\": 1\n        },\n        \"overrides\": [\n          {\n            \"matcher\": {\n              \"id\": \"byName\",\n              \"options\": \"Process\"\n            },\n            \"properties\": [\n              {\n                \"id\": \"custom.width\",\n                \"value\": 200\n              },\n              {\n                \"id\": \"custom.displayMode\",\n                \"value\": \"auto\"\n              }\n            ]\n          },\n          {\n            \"matcher\": {\n              \"id\": \"byName\", \n              \"options\": \"Host\"\n            },\n            \"properties\": [\n              {\n                \"id\": \"custom.width\",\n                \"value\": 150\n              },\n              {\n                \"id\": \"custom.displayMode\",\n                \"value\": \"auto\"\n              }\n            ]\n          }\n        ]\n      }\n    }\n  ],\n  \"editable\": true\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"process-anomaly-dashboard-improved","namespace":"monitoring"}}
    creationTimestamp: "2025-06-07T01:40:15Z"
    name: process-anomaly-dashboard-improved
    namespace: monitoring
    resourceVersion: "4583640"
    uid: e6650dfa-5df2-4f01-a160-b6dd25ac6f4a
- apiVersion: v1
  data:
    Dockerfile: |
      FROM python:3.11-slim

      # Install system dependencies
      RUN apt-get update && apt-get install -y \
          gcc \
          g++ \
          && rm -rf /var/lib/apt/lists/*

      # Install Python dependencies
      RUN pip install --no-cache-dir \
          prometheus-client==0.19.0 \
          requests==2.31.0 \
          numpy==1.24.3 \
          pandas==2.0.3 \
          scikit-learn==1.3.0 \
          kubernetes==27.2.0

      # Create app directory
      WORKDIR /app

      # Set environment variables
      ENV PYTHONUNBUFFERED=1

      # Default command
      CMD ["python", "/app/process_anomaly_detector.py"]
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"Dockerfile":"FROM python:3.11-slim\n\n# Install system dependencies\nRUN apt-get update \u0026\u0026 apt-get install -y \\\n    gcc \\\n    g++ \\\n    \u0026\u0026 rm -rf /var/lib/apt/lists/*\n\n# Install Python dependencies\nRUN pip install --no-cache-dir \\\n    prometheus-client==0.19.0 \\\n    requests==2.31.0 \\\n    numpy==1.24.3 \\\n    pandas==2.0.3 \\\n    scikit-learn==1.3.0 \\\n    kubernetes==27.2.0\n\n# Create app directory\nWORKDIR /app\n\n# Set environment variables\nENV PYTHONUNBUFFERED=1\n\n# Default command\nCMD [\"python\", \"/app/process_anomaly_detector.py\"]\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"process-anomaly-detector-dockerfile","namespace":"monitoring"}}
    creationTimestamp: "2025-06-04T04:13:40Z"
    name: process-anomaly-detector-dockerfile
    namespace: monitoring
    resourceVersion: "2744680"
    uid: 559d343b-5453-43ea-b9f4-8d7d403e8f7d
- apiVersion: v1
  data:
    process_anomaly_detector.py: "#!/usr/bin/env python3\nimport time\nimport numpy
      as np\nimport pandas as pd\nfrom datetime import datetime, timedelta\nimport
      requests\nimport logging\nimport json\nimport os\nimport pickle\nimport threading\nimport
      re\nimport gc\nfrom prometheus_client import start_http_server, Gauge, Counter,
      Histogram\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.preprocessing
      import StandardScaler\nfrom http.server import HTTPServer, BaseHTTPRequestHandler\nimport
      warnings\nwarnings.filterwarnings('ignore')\n\n# Configure logging\nlogging.basicConfig(\n
      \   level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s
      - %(message)s'\n)\nlogger = logging.getLogger('process-anomaly-detector')\n\n#
      Prometheus metrics\nprocess_anomaly_score = Gauge('process_anomaly_score', 'Process
      anomaly score', ['process_name', 'anomaly_type', 'algorithm'])\nunusual_process_detected
      = Gauge('unusual_process_detected', 'Unusual process detected', ['process_name',
      'reason'])\nprocess_resource_anomaly = Gauge('process_resource_anomaly_score',
      'Process resource usage anomaly', ['process_name', 'resource_type'])\nnew_process_alert
      = Gauge('new_process_alert', 'New/unknown process detected', ['process_name',
      'command'])\nmodel_training_duration = Histogram('process_anomaly_model_training_duration_seconds',
      'Model training duration')\nmodel_updates = Counter('process_anomaly_model_updates_total',
      'Total model updates', ['anomaly_type'])\ndetection_errors = Counter('process_anomaly_detection_errors_total',
      'Total detection errors', ['anomaly_type'])\nhealth_status = Gauge('process_anomaly_detector_health',
      'Health status of process anomaly detector')\nprocesses_analyzed = Counter('processes_analyzed_total',
      'Total processes analyzed', ['analysis_type'])\ndetector_memory_usage = Gauge('process_anomaly_detector_memory_mb',
      'Detector memory usage in MB')\n\n# Configuration\nPROMETHEUS_URL = os.getenv('PROMETHEUS_URL',
      'http://prometheus:9090')\nMODEL_PATH = '/models'\nUPDATE_INTERVAL = int(os.getenv('UPDATE_INTERVAL',
      '120'))  # 2 minutes\nTRAINING_WINDOW = os.getenv('TRAINING_WINDOW', '7d')\n\n#
      Simplified process metrics with memory optimization\nPROCESS_METRICS = [\n    {\n
      \       'name': 'cpu_usage_per_process',\n        'query': 'topk(10, rate(namedprocess_namegroup_cpu_seconds_total[5m]))',
      \ # Reduced from 20\n        'algorithm': 'statistical',\n        'z_threshold':
      3,\n        'min_samples': 20\n    },\n    {\n        'name': 'memory_usage_per_process',\n
      \       'query': 'topk(10, namedprocess_namegroup_memory_bytes)',  # Reduced
      from 20\n        'algorithm': 'statistical',\n        'z_threshold': 3,\n        'min_samples':
      20\n    }\n]\n\n# Simplified suspicious patterns\nSUSPICIOUS_PATTERNS = [\n
      \   {\n        'name': 'crypto_miners',\n        'patterns': [r'.*miner.*',
      r'.*xmrig.*', r'.*mining.*'],\n        'severity': 'critical'\n    },\n    {\n
      \       'name': 'reverse_shells',\n        'patterns': [r'.*nc\\s+-l.*', r'.*netcat.*-l.*'],\n
      \       'severity': 'critical'\n    }\n]\n\n# Expected System Processes (whitelist)\nEXPECTED_PROCESSES
      = {\n    'system': ['systemd', 'kthreadd', 'ksoftirqd', 'rcu_preempt'],\n    'kernel':
      ['migration', 'idle_inject', 'cpuhp', 'kworker'],\n    'monitoring': ['prometheus',
      'grafana', 'loki', 'promtail', 'alertmanager'],\n    'containers': ['containerd',
      'k3s', 'kubectl', 'docker']\n}\n\n# Global health status\nhealth_info = {\n
      \   'healthy': True,\n    'last_update': datetime.now(),\n    'prometheus_available':
      False\n}\n\nclass HealthCheckHandler(BaseHTTPRequestHandler):\n    \"\"\"Simple
      health check handler\"\"\"\n    def do_GET(self):\n        if self.path in ['/health',
      '/healthz', '/ready']:\n            if health_info['healthy']:\n                self.send_response(200)\n
      \               self.end_headers()\n                self.wfile.write(b'OK')\n
      \           else:\n                self.send_response(503)\n                self.end_headers()\n
      \               self.wfile.write(b'Unhealthy')\n        else:\n            self.send_error(404)\n
      \   \n    def log_message(self, format, *args):\n        pass  # Suppress logs\n\ndef
      run_health_server():\n    \"\"\"Run the health check HTTP server\"\"\"\n    server
      = HTTPServer(('', 8080), HealthCheckHandler)\n    server.serve_forever()\n\nclass
      ProcessAnomalyDetector:\n    def __init__(self):\n        self.thresholds =
      {}\n        self.known_processes = set()\n        os.makedirs(MODEL_PATH, exist_ok=True)\n
      \       \n        # Initialize known processes\n        for category, processes
      in EXPECTED_PROCESSES.items():\n            self.known_processes.update(processes)\n
      \           \n        self.load_models()\n        \n    def load_models(self):\n
      \       \"\"\"Load saved models from disk\"\"\"\n        try:\n            model_file
      = os.path.join(MODEL_PATH, 'process_thresholds.pkl')\n            if os.path.exists(model_file):\n
      \               with open(model_file, 'rb') as f:\n                    data
      = pickle.load(f)\n                    self.thresholds = data.get('thresholds',
      {})\n                    self.known_processes.update(data.get('known_processes',
      set()))\n                    logger.info(f\"Loaded process models\")\n        except
      Exception as e:\n            logger.error(f\"Failed to load models: {e}\")\n
      \           \n    def save_models(self):\n        \"\"\"Save models to disk\"\"\"\n
      \       try:\n            model_file = os.path.join(MODEL_PATH, 'process_thresholds.pkl')\n
      \           with open(model_file, 'wb') as f:\n                pickle.dump({\n
      \                   'thresholds': self.thresholds,\n                    'known_processes':
      self.known_processes\n                }, f)\n            logger.info(f\"Saved
      process models\")\n        except Exception as e:\n            logger.error(f\"Failed
      to save models: {e}\")\n            \n    def query_prometheus(self, query,
      start_time=None, end_time=None, step='300s'):\n        \"\"\"Query Prometheus
      for metric data\"\"\"\n        if not start_time:\n            end_time = datetime.now()\n
      \           start_time = end_time - timedelta(days=1)  # Reduced from 7 days\n
      \           \n        params = {\n            'query': query,\n            'start':
      start_time.timestamp(),\n            'end': end_time.timestamp(),\n            'step':
      step\n        }\n        \n        try:\n            response = requests.get(f\"{PROMETHEUS_URL}/api/v1/query_range\",
      \n                                  params=params, timeout=10)\n            response.raise_for_status()\n
      \           data = response.json()\n            \n            health_info['prometheus_available']
      = True\n            \n            if data['status'] == 'success' and data['data']['result']:\n
      \               # Process data with memory optimization\n                all_data
      = []\n                for result in data['data']['result']:\n                    #
      Limit data points\n                    values = result['values'][-100:]  # Last
      100 points only\n                    for timestamp, value in values:\n                        row
      = {\n                            'timestamp': float(timestamp), \n                            'value':
      float(value),\n                            'groupname': result['metric'].get('groupname',
      'unknown')\n                        }\n                        all_data.append(row)\n
      \               \n                return pd.DataFrame(all_data) if all_data
      else pd.DataFrame()\n                \n        except Exception as e:\n            logger.error(f\"Failed
      to query Prometheus: {e}\")\n            health_info['prometheus_available']
      = False\n            detection_errors.labels(anomaly_type=query).inc()\n            \n
      \       return pd.DataFrame()\n        \n    def query_instant(self, query):\n
      \       \"\"\"Query Prometheus for instant values\"\"\"\n        try:\n            response
      = requests.get(f\"{PROMETHEUS_URL}/api/v1/query\", \n                                  params={'query':
      query}, timeout=5)\n            response.raise_for_status()\n            data
      = response.json()\n            \n            health_info['prometheus_available']
      = True\n            \n            if data['status'] == 'success' and data['data']['result']:\n
      \               return data['data']['result']\n                \n        except
      Exception as e:\n            logger.error(f\"Failed to query instant value:
      {e}\")\n            health_info['prometheus_available'] = False\n            \n
      \       return []\n        \n    def check_suspicious_patterns(self, process_name):\n
      \       \"\"\"Check if a process matches suspicious patterns\"\"\"\n        process_lower
      = process_name.lower()\n        \n        for pattern_group in SUSPICIOUS_PATTERNS:\n
      \           for pattern in pattern_group['patterns']:\n                if re.search(pattern,
      process_lower):\n                    return {\n                        'matched':
      True,\n                        'pattern_type': pattern_group['name'],\n                        'severity':
      pattern_group['severity']\n                    }\n        return {'matched':
      False}\n        \n    def detect_anomalies(self):\n        \"\"\"Simplified
      anomaly detection\"\"\"\n        try:\n            # Check memory usage\n            import
      psutil\n            process = psutil.Process()\n            memory_mb = process.memory_info().rss
      / 1024 / 1024\n            detector_memory_usage.set(memory_mb)\n            \n
      \           # Force garbage collection if memory is high\n            if memory_mb
      > 500:\n                gc.collect()\n            \n            for metric_config
      in PROCESS_METRICS:\n                try:\n                    # Query current
      values\n                    results = self.query_instant(metric_config['query'])\n
      \                   \n                    for result in results:\n                        current_value
      = float(result['value'][1])\n                        process_name = result['metric'].get('groupname',
      'unknown')\n                        \n                        processes_analyzed.labels(analysis_type='anomaly_detection').inc()\n
      \                       \n                        # Simple threshold-based detection\n
      \                       if process_name in self.thresholds.get(metric_config['name'],
      {}):\n                            thresh = self.thresholds[metric_config['name']][process_name]\n
      \                           z_score = abs((current_value - thresh['mean']) /
      (thresh['std'] + 1e-10))\n                            score = min(100, (z_score
      / metric_config['z_threshold']) * 100)\n                        else:\n                            #
      No baseline, check if suspicious\n                            suspicious = self.check_suspicious_patterns(process_name)\n
      \                           score = 80 if suspicious['matched'] else 20\n                            \n
      \                           if suspicious['matched']:\n                                unusual_process_detected.labels(\n
      \                                   process_name=process_name,\n                                    reason=suspicious['pattern_type']\n
      \                               ).set(1)\n                        \n                        process_anomaly_score.labels(\n
      \                           process_name=process_name,\n                            anomaly_type=metric_config['name'],\n
      \                           algorithm='statistical'\n                        ).set(score)\n
      \                       \n                        if score > 80:\n                            logger.warning(f\"Anomaly:
      {process_name} - {metric_config['name']} score: {score}\")\n                            \n
      \               except Exception as e:\n                    logger.error(f\"Error
      detecting anomalies for {metric_config['name']}: {e}\")\n                    detection_errors.labels(anomaly_type=metric_config['name']).inc()\n
      \                   \n        except Exception as e:\n            logger.error(f\"Error
      in anomaly detection: {e}\")\n            \n    def update_models(self):\n        \"\"\"Update
      statistical models\"\"\"\n        logger.info(\"Updating process models...\")\n
      \       \n        for metric_config in PROCESS_METRICS:\n            try:\n
      \               # Query training data\n                training_data = self.query_prometheus(metric_config['query'])\n
      \               \n                if training_data.empty:\n                    continue\n
      \                   \n                # Calculate simple statistics per process\n
      \               if metric_config['name'] not in self.thresholds:\n                    self.thresholds[metric_config['name']]
      = {}\n                    \n                for process in training_data['groupname'].unique():\n
      \                   process_data = training_data[training_data['groupname']
      == process]['value']\n                    if len(process_data) >= 10:\n                        self.thresholds[metric_config['name']][process]
      = {\n                            'mean': process_data.mean(),\n                            'std':
      process_data.std(),\n                            'p95': process_data.quantile(0.95)\n
      \                       }\n                        self.known_processes.add(process)\n
      \                       \n                model_updates.labels(anomaly_type=metric_config['name']).inc()\n
      \               \n            except Exception as e:\n                logger.error(f\"Failed
      to update model for {metric_config['name']}: {e}\")\n                \n        self.save_models()\n
      \       gc.collect()  # Clean up after model update\n                \n    def
      run(self):\n        \"\"\"Main detection loop\"\"\"\n        # Initial model
      training\n        self.update_models()\n        \n        last_model_update
      = time.time()\n        \n        while True:\n            try:\n                #
      Detect anomalies\n                self.detect_anomalies()\n                \n
      \               # Update models periodically (every 6 hours)\n                if
      time.time() - last_model_update > 21600:\n                    self.update_models()\n
      \                   last_model_update = time.time()\n                    \n
      \               # Update health status\n                health_info['healthy']
      = health_info['prometheus_available']\n                health_info['last_update']
      = datetime.now()\n                health_status.set(1 if health_info['healthy']
      else 0)\n                \n                time.sleep(UPDATE_INTERVAL)\n                \n
      \           except Exception as e:\n                logger.error(f\"Error in
      main loop: {e}\")\n                health_info['healthy'] = False\n                health_status.set(0)\n
      \               time.sleep(60)\n\ndef main():\n    # Start Prometheus metrics
      server\n    start_http_server(9407)\n    logger.info(\"Started process anomaly
      detection metrics server on port 9407\")\n    \n    # Start health check server\n
      \   health_thread = threading.Thread(target=run_health_server, daemon=True)\n
      \   health_thread.start()\n    logger.info(\"Started health check server on
      port 8080\")\n    \n    # Start detector\n    detector = ProcessAnomalyDetector()\n
      \   detector.run()\n\nif __name__ == '__main__':\n    main()\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"process_anomaly_detector.py":"#!/usr/bin/env python3\nimport time\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta\nimport requests\nimport logging\nimport json\nimport os\nimport pickle\nimport threading\nimport re\nimport gc\nfrom prometheus_client import start_http_server, Gauge, Counter, Histogram\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.preprocessing import StandardScaler\nfrom http.server import HTTPServer, BaseHTTPRequestHandler\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger('process-anomaly-detector')\n\n# Prometheus metrics\nprocess_anomaly_score = Gauge('process_anomaly_score', 'Process anomaly score', ['process_name', 'anomaly_type', 'algorithm'])\nunusual_process_detected = Gauge('unusual_process_detected', 'Unusual process detected', ['process_name', 'reason'])\nprocess_resource_anomaly = Gauge('process_resource_anomaly_score', 'Process resource usage anomaly', ['process_name', 'resource_type'])\nnew_process_alert = Gauge('new_process_alert', 'New/unknown process detected', ['process_name', 'command'])\nmodel_training_duration = Histogram('process_anomaly_model_training_duration_seconds', 'Model training duration')\nmodel_updates = Counter('process_anomaly_model_updates_total', 'Total model updates', ['anomaly_type'])\ndetection_errors = Counter('process_anomaly_detection_errors_total', 'Total detection errors', ['anomaly_type'])\nhealth_status = Gauge('process_anomaly_detector_health', 'Health status of process anomaly detector')\nprocesses_analyzed = Counter('processes_analyzed_total', 'Total processes analyzed', ['analysis_type'])\ndetector_memory_usage = Gauge('process_anomaly_detector_memory_mb', 'Detector memory usage in MB')\n\n# Configuration\nPROMETHEUS_URL = os.getenv('PROMETHEUS_URL', 'http://prometheus:9090')\nMODEL_PATH = '/models'\nUPDATE_INTERVAL = int(os.getenv('UPDATE_INTERVAL', '120'))  # 2 minutes\nTRAINING_WINDOW = os.getenv('TRAINING_WINDOW', '7d')\n\n# Simplified process metrics with memory optimization\nPROCESS_METRICS = [\n    {\n        'name': 'cpu_usage_per_process',\n        'query': 'topk(10, rate(namedprocess_namegroup_cpu_seconds_total[5m]))',  # Reduced from 20\n        'algorithm': 'statistical',\n        'z_threshold': 3,\n        'min_samples': 20\n    },\n    {\n        'name': 'memory_usage_per_process',\n        'query': 'topk(10, namedprocess_namegroup_memory_bytes)',  # Reduced from 20\n        'algorithm': 'statistical',\n        'z_threshold': 3,\n        'min_samples': 20\n    }\n]\n\n# Simplified suspicious patterns\nSUSPICIOUS_PATTERNS = [\n    {\n        'name': 'crypto_miners',\n        'patterns': [r'.*miner.*', r'.*xmrig.*', r'.*mining.*'],\n        'severity': 'critical'\n    },\n    {\n        'name': 'reverse_shells',\n        'patterns': [r'.*nc\\s+-l.*', r'.*netcat.*-l.*'],\n        'severity': 'critical'\n    }\n]\n\n# Expected System Processes (whitelist)\nEXPECTED_PROCESSES = {\n    'system': ['systemd', 'kthreadd', 'ksoftirqd', 'rcu_preempt'],\n    'kernel': ['migration', 'idle_inject', 'cpuhp', 'kworker'],\n    'monitoring': ['prometheus', 'grafana', 'loki', 'promtail', 'alertmanager'],\n    'containers': ['containerd', 'k3s', 'kubectl', 'docker']\n}\n\n# Global health status\nhealth_info = {\n    'healthy': True,\n    'last_update': datetime.now(),\n    'prometheus_available': False\n}\n\nclass HealthCheckHandler(BaseHTTPRequestHandler):\n    \"\"\"Simple health check handler\"\"\"\n    def do_GET(self):\n        if self.path in ['/health', '/healthz', '/ready']:\n            if health_info['healthy']:\n                self.send_response(200)\n                self.end_headers()\n                self.wfile.write(b'OK')\n            else:\n                self.send_response(503)\n                self.end_headers()\n                self.wfile.write(b'Unhealthy')\n        else:\n            self.send_error(404)\n    \n    def log_message(self, format, *args):\n        pass  # Suppress logs\n\ndef run_health_server():\n    \"\"\"Run the health check HTTP server\"\"\"\n    server = HTTPServer(('', 8080), HealthCheckHandler)\n    server.serve_forever()\n\nclass ProcessAnomalyDetector:\n    def __init__(self):\n        self.thresholds = {}\n        self.known_processes = set()\n        os.makedirs(MODEL_PATH, exist_ok=True)\n        \n        # Initialize known processes\n        for category, processes in EXPECTED_PROCESSES.items():\n            self.known_processes.update(processes)\n            \n        self.load_models()\n        \n    def load_models(self):\n        \"\"\"Load saved models from disk\"\"\"\n        try:\n            model_file = os.path.join(MODEL_PATH, 'process_thresholds.pkl')\n            if os.path.exists(model_file):\n                with open(model_file, 'rb') as f:\n                    data = pickle.load(f)\n                    self.thresholds = data.get('thresholds', {})\n                    self.known_processes.update(data.get('known_processes', set()))\n                    logger.info(f\"Loaded process models\")\n        except Exception as e:\n            logger.error(f\"Failed to load models: {e}\")\n            \n    def save_models(self):\n        \"\"\"Save models to disk\"\"\"\n        try:\n            model_file = os.path.join(MODEL_PATH, 'process_thresholds.pkl')\n            with open(model_file, 'wb') as f:\n                pickle.dump({\n                    'thresholds': self.thresholds,\n                    'known_processes': self.known_processes\n                }, f)\n            logger.info(f\"Saved process models\")\n        except Exception as e:\n            logger.error(f\"Failed to save models: {e}\")\n            \n    def query_prometheus(self, query, start_time=None, end_time=None, step='300s'):\n        \"\"\"Query Prometheus for metric data\"\"\"\n        if not start_time:\n            end_time = datetime.now()\n            start_time = end_time - timedelta(days=1)  # Reduced from 7 days\n            \n        params = {\n            'query': query,\n            'start': start_time.timestamp(),\n            'end': end_time.timestamp(),\n            'step': step\n        }\n        \n        try:\n            response = requests.get(f\"{PROMETHEUS_URL}/api/v1/query_range\", \n                                  params=params, timeout=10)\n            response.raise_for_status()\n            data = response.json()\n            \n            health_info['prometheus_available'] = True\n            \n            if data['status'] == 'success' and data['data']['result']:\n                # Process data with memory optimization\n                all_data = []\n                for result in data['data']['result']:\n                    # Limit data points\n                    values = result['values'][-100:]  # Last 100 points only\n                    for timestamp, value in values:\n                        row = {\n                            'timestamp': float(timestamp), \n                            'value': float(value),\n                            'groupname': result['metric'].get('groupname', 'unknown')\n                        }\n                        all_data.append(row)\n                \n                return pd.DataFrame(all_data) if all_data else pd.DataFrame()\n                \n        except Exception as e:\n            logger.error(f\"Failed to query Prometheus: {e}\")\n            health_info['prometheus_available'] = False\n            detection_errors.labels(anomaly_type=query).inc()\n            \n        return pd.DataFrame()\n        \n    def query_instant(self, query):\n        \"\"\"Query Prometheus for instant values\"\"\"\n        try:\n            response = requests.get(f\"{PROMETHEUS_URL}/api/v1/query\", \n                                  params={'query': query}, timeout=5)\n            response.raise_for_status()\n            data = response.json()\n            \n            health_info['prometheus_available'] = True\n            \n            if data['status'] == 'success' and data['data']['result']:\n                return data['data']['result']\n                \n        except Exception as e:\n            logger.error(f\"Failed to query instant value: {e}\")\n            health_info['prometheus_available'] = False\n            \n        return []\n        \n    def check_suspicious_patterns(self, process_name):\n        \"\"\"Check if a process matches suspicious patterns\"\"\"\n        process_lower = process_name.lower()\n        \n        for pattern_group in SUSPICIOUS_PATTERNS:\n            for pattern in pattern_group['patterns']:\n                if re.search(pattern, process_lower):\n                    return {\n                        'matched': True,\n                        'pattern_type': pattern_group['name'],\n                        'severity': pattern_group['severity']\n                    }\n        return {'matched': False}\n        \n    def detect_anomalies(self):\n        \"\"\"Simplified anomaly detection\"\"\"\n        try:\n            # Check memory usage\n            import psutil\n            process = psutil.Process()\n            memory_mb = process.memory_info().rss / 1024 / 1024\n            detector_memory_usage.set(memory_mb)\n            \n            # Force garbage collection if memory is high\n            if memory_mb \u003e 500:\n                gc.collect()\n            \n            for metric_config in PROCESS_METRICS:\n                try:\n                    # Query current values\n                    results = self.query_instant(metric_config['query'])\n                    \n                    for result in results:\n                        current_value = float(result['value'][1])\n                        process_name = result['metric'].get('groupname', 'unknown')\n                        \n                        processes_analyzed.labels(analysis_type='anomaly_detection').inc()\n                        \n                        # Simple threshold-based detection\n                        if process_name in self.thresholds.get(metric_config['name'], {}):\n                            thresh = self.thresholds[metric_config['name']][process_name]\n                            z_score = abs((current_value - thresh['mean']) / (thresh['std'] + 1e-10))\n                            score = min(100, (z_score / metric_config['z_threshold']) * 100)\n                        else:\n                            # No baseline, check if suspicious\n                            suspicious = self.check_suspicious_patterns(process_name)\n                            score = 80 if suspicious['matched'] else 20\n                            \n                            if suspicious['matched']:\n                                unusual_process_detected.labels(\n                                    process_name=process_name,\n                                    reason=suspicious['pattern_type']\n                                ).set(1)\n                        \n                        process_anomaly_score.labels(\n                            process_name=process_name,\n                            anomaly_type=metric_config['name'],\n                            algorithm='statistical'\n                        ).set(score)\n                        \n                        if score \u003e 80:\n                            logger.warning(f\"Anomaly: {process_name} - {metric_config['name']} score: {score}\")\n                            \n                except Exception as e:\n                    logger.error(f\"Error detecting anomalies for {metric_config['name']}: {e}\")\n                    detection_errors.labels(anomaly_type=metric_config['name']).inc()\n                    \n        except Exception as e:\n            logger.error(f\"Error in anomaly detection: {e}\")\n            \n    def update_models(self):\n        \"\"\"Update statistical models\"\"\"\n        logger.info(\"Updating process models...\")\n        \n        for metric_config in PROCESS_METRICS:\n            try:\n                # Query training data\n                training_data = self.query_prometheus(metric_config['query'])\n                \n                if training_data.empty:\n                    continue\n                    \n                # Calculate simple statistics per process\n                if metric_config['name'] not in self.thresholds:\n                    self.thresholds[metric_config['name']] = {}\n                    \n                for process in training_data['groupname'].unique():\n                    process_data = training_data[training_data['groupname'] == process]['value']\n                    if len(process_data) \u003e= 10:\n                        self.thresholds[metric_config['name']][process] = {\n                            'mean': process_data.mean(),\n                            'std': process_data.std(),\n                            'p95': process_data.quantile(0.95)\n                        }\n                        self.known_processes.add(process)\n                        \n                model_updates.labels(anomaly_type=metric_config['name']).inc()\n                \n            except Exception as e:\n                logger.error(f\"Failed to update model for {metric_config['name']}: {e}\")\n                \n        self.save_models()\n        gc.collect()  # Clean up after model update\n                \n    def run(self):\n        \"\"\"Main detection loop\"\"\"\n        # Initial model training\n        self.update_models()\n        \n        last_model_update = time.time()\n        \n        while True:\n            try:\n                # Detect anomalies\n                self.detect_anomalies()\n                \n                # Update models periodically (every 6 hours)\n                if time.time() - last_model_update \u003e 21600:\n                    self.update_models()\n                    last_model_update = time.time()\n                    \n                # Update health status\n                health_info['healthy'] = health_info['prometheus_available']\n                health_info['last_update'] = datetime.now()\n                health_status.set(1 if health_info['healthy'] else 0)\n                \n                time.sleep(UPDATE_INTERVAL)\n                \n            except Exception as e:\n                logger.error(f\"Error in main loop: {e}\")\n                health_info['healthy'] = False\n                health_status.set(0)\n                time.sleep(60)\n\ndef main():\n    # Start Prometheus metrics server\n    start_http_server(9407)\n    logger.info(\"Started process anomaly detection metrics server on port 9407\")\n    \n    # Start health check server\n    health_thread = threading.Thread(target=run_health_server, daemon=True)\n    health_thread.start()\n    logger.info(\"Started health check server on port 8080\")\n    \n    # Start detector\n    detector = ProcessAnomalyDetector()\n    detector.run()\n\nif __name__ == '__main__':\n    main()\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"process-anomaly-detector-script","namespace":"monitoring"}}
    creationTimestamp: "2025-05-31T20:27:37Z"
    name: process-anomaly-detector-script
    namespace: monitoring
    resourceVersion: "2744681"
    uid: 42d35e61-60be-48e6-bb14-e9014056c664
- apiVersion: v1
  data:
    process-anomaly-improved.json: |
      {
        "uid": "process-anomaly-improved",
        "title": "ODIN Process Anomaly Detection (Improved)",
        "tags": ["anomaly", "process", "ml", "security", "odin", "improved"],
        "timezone": "America/Los_Angeles",
        "schemaVersion": 38,
        "version": 1,
        "refresh": "30s",
        "editable": true,
        "time": {
          "from": "now-3h",
          "to": "now"
        },
        "templating": {
          "list": [
            {
              "name": "top_n",
              "type": "custom",
              "current": {
                "text": "30",
                "value": "30"
              },
              "options": [
                {"text": "10", "value": "10"},
                {"text": "20", "value": "20"},
                {"text": "30", "value": "30"},
                {"text": "50", "value": "50"},
                {"text": "100", "value": "100"}
              ],
              "query": "10,20,30,50,100",
              "description": "Number of top anomalous processes to show"
            }
          ]
        },
        "panels": [
          {
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 0},
            "id": 1,
            "type": "barchart",
            "title": "Top $top_n Most Anomalous Processes",
            "datasource": "Prometheus",
            "targets": [
              {
                "expr": "bottomk($top_n, min by (groupname) (process_cpu_anomaly_score < 0.8 or process_memory_anomaly_score < 0.8))",
                "legendFormat": "{{groupname}}",
                "refId": "A"
              }
            ],
            "options": {
              "orientation": "horizontal",
              "displayMode": "gradient",
              "showValue": "always",
              "legend": {
                "displayMode": "hidden"
              }
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "continuous-GrYlRd"
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "yellow", "value": 0.3},
                    {"color": "green", "value": 0.7}
                  ]
                },
                "unit": "percentunit",
                "min": 0,
                "max": 1
              }
            }
          },
          {
            "gridPos": {"h": 10, "w": 12, "x": 0, "y": 8},
            "id": 2,
            "type": "timeseries",
            "title": "CPU Anomaly Trends (Top $top_n)",
            "datasource": "Prometheus",
            "targets": [
              {
                "expr": "bottomk($top_n, process_cpu_anomaly_score < 0.8)",
                "legendFormat": "{{groupname}}",
                "refId": "A"
              }
            ],
            "options": {
              "tooltip": {"mode": "multi"},
              "legend": {"displayMode": "table", "placement": "right", "calcs": ["lastNotNull", "min"]}
            },
            "fieldConfig": {
              "defaults": {
                "color": {"mode": "palette-classic"},
                "custom": {
                  "drawStyle": "line",
                  "lineInterpolation": "smooth",
                  "lineWidth": 2,
                  "fillOpacity": 10,
                  "pointSize": 3
                },
                "unit": "percentunit",
                "min": 0,
                "max": 1,
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "yellow", "value": 0.3},
                    {"color": "green", "value": 0.7}
                  ]
                }
              }
            }
          },
          {
            "gridPos": {"h": 10, "w": 12, "x": 12, "y": 8},
            "id": 3,
            "type": "timeseries",
            "title": "Memory Anomaly Trends (Top $top_n)",
            "datasource": "Prometheus",
            "targets": [
              {
                "expr": "bottomk($top_n, process_memory_anomaly_score < 0.8)",
                "legendFormat": "{{groupname}}",
                "refId": "A"
              }
            ],
            "options": {
              "tooltip": {"mode": "multi"},
              "legend": {"displayMode": "table", "placement": "right", "calcs": ["lastNotNull", "min"]}
            },
            "fieldConfig": {
              "defaults": {
                "color": {"mode": "palette-classic"},
                "custom": {
                  "drawStyle": "line",
                  "lineInterpolation": "smooth",
                  "lineWidth": 2,
                  "fillOpacity": 10,
                  "pointSize": 3
                },
                "unit": "percentunit",
                "min": 0,
                "max": 1,
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "yellow", "value": 0.3},
                    {"color": "green", "value": 0.7}
                  ]
                }
              }
            }
          },
          {
            "gridPos": {"h": 10, "w": 24, "x": 0, "y": 18},
            "id": 4,
            "type": "state-timeline",
            "title": "Process Anomaly State Timeline (Top $top_n)",
            "datasource": "Prometheus",
            "targets": [
              {
                "expr": "bottomk($top_n, process_cpu_anomaly_score < 0.8)",
                "refId": "A"
              }
            ],
            "options": {
              "legend": {
                "displayMode": "list",
                "placement": "bottom",
                "showLegend": true
              },
              "tooltip": {
                "mode": "single"
              },
              "rowHeight": 0.9
            },
            "fieldConfig": {
              "defaults": {
                "custom": {
                  "lineWidth": 0,
                  "fillOpacity": 70,
                  "spanNulls": false
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "orange", "value": 0.3},
                    {"color": "yellow", "value": 0.5},
                    {"color": "green", "value": 0.7}
                  ]
                },
                "unit": "percentunit",
                "min": 0,
                "max": 1
              }
            }
          },
          {
            "gridPos": {"h": 10, "w": 24, "x": 0, "y": 28},
            "id": 5,
            "type": "table",
            "title": "Anomaly Score Details (Sortable)",
            "datasource": "Prometheus",
            "targets": [
              {
                "expr": "process_cpu_anomaly_score < 0.9",
                "format": "table",
                "instant": true,
                "refId": "A"
              },
              {
                "expr": "process_memory_anomaly_score < 0.9",
                "format": "table",
                "instant": true,
                "refId": "B"
              }
            ],
            "transformations": [
              {
                "id": "merge"
              },
              {
                "id": "organize",
                "options": {
                  "excludeByName": {
                    "Time": true,
                    "__name__": true,
                    "job": true
                  },
                  "renameByName": {
                    "Value #A": "CPU Score",
                    "Value #B": "Memory Score",
                    "groupname": "Process",
                    "instance": "Host"
                  }
                }
              }
            ],
            "options": {
              "showHeader": true,
              "sortBy": [{"desc": false, "displayName": "CPU Score"}]
            },
            "fieldConfig": {
              "defaults": {
                "custom": {
                  "align": "center",
                  "displayMode": "color-background-solid",
                  "filterable": true
                },
                "unit": "percentunit",
                "min": 0,
                "max": 1,
                "color": {"mode": "thresholds"},
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "yellow", "value": 0.3},
                    {"color": "green", "value": 0.7}
                  ]
                }
              }
            }
          }
        ]
      }
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"process-anomaly-improved.json":"{\n  \"uid\": \"process-anomaly-improved\",\n  \"title\": \"ODIN Process Anomaly Detection (Improved)\",\n  \"tags\": [\"anomaly\", \"process\", \"ml\", \"security\", \"odin\", \"improved\"],\n  \"timezone\": \"America/Los_Angeles\",\n  \"schemaVersion\": 38,\n  \"version\": 1,\n  \"refresh\": \"30s\",\n  \"editable\": true,\n  \"time\": {\n    \"from\": \"now-3h\",\n    \"to\": \"now\"\n  },\n  \"templating\": {\n    \"list\": [\n      {\n        \"name\": \"top_n\",\n        \"type\": \"custom\",\n        \"current\": {\n          \"text\": \"30\",\n          \"value\": \"30\"\n        },\n        \"options\": [\n          {\"text\": \"10\", \"value\": \"10\"},\n          {\"text\": \"20\", \"value\": \"20\"},\n          {\"text\": \"30\", \"value\": \"30\"},\n          {\"text\": \"50\", \"value\": \"50\"},\n          {\"text\": \"100\", \"value\": \"100\"}\n        ],\n        \"query\": \"10,20,30,50,100\",\n        \"description\": \"Number of top anomalous processes to show\"\n      }\n    ]\n  },\n  \"panels\": [\n    {\n      \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 0},\n      \"id\": 1,\n      \"type\": \"barchart\",\n      \"title\": \"Top $top_n Most Anomalous Processes\",\n      \"datasource\": \"Prometheus\",\n      \"targets\": [\n        {\n          \"expr\": \"bottomk($top_n, min by (groupname) (process_cpu_anomaly_score \u003c 0.8 or process_memory_anomaly_score \u003c 0.8))\",\n          \"legendFormat\": \"{{groupname}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"orientation\": \"horizontal\",\n        \"displayMode\": \"gradient\",\n        \"showValue\": \"always\",\n        \"legend\": {\n          \"displayMode\": \"hidden\"\n        }\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"continuous-GrYlRd\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"color\": \"red\", \"value\": 0},\n              {\"color\": \"yellow\", \"value\": 0.3},\n              {\"color\": \"green\", \"value\": 0.7}\n            ]\n          },\n          \"unit\": \"percentunit\",\n          \"min\": 0,\n          \"max\": 1\n        }\n      }\n    },\n    {\n      \"gridPos\": {\"h\": 10, \"w\": 12, \"x\": 0, \"y\": 8},\n      \"id\": 2,\n      \"type\": \"timeseries\",\n      \"title\": \"CPU Anomaly Trends (Top $top_n)\",\n      \"datasource\": \"Prometheus\",\n      \"targets\": [\n        {\n          \"expr\": \"bottomk($top_n, process_cpu_anomaly_score \u003c 0.8)\",\n          \"legendFormat\": \"{{groupname}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"tooltip\": {\"mode\": \"multi\"},\n        \"legend\": {\"displayMode\": \"table\", \"placement\": \"right\", \"calcs\": [\"lastNotNull\", \"min\"]}\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"drawStyle\": \"line\",\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 10,\n            \"pointSize\": 3\n          },\n          \"unit\": \"percentunit\",\n          \"min\": 0,\n          \"max\": 1,\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"red\", \"value\": 0},\n              {\"color\": \"yellow\", \"value\": 0.3},\n              {\"color\": \"green\", \"value\": 0.7}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"gridPos\": {\"h\": 10, \"w\": 12, \"x\": 12, \"y\": 8},\n      \"id\": 3,\n      \"type\": \"timeseries\",\n      \"title\": \"Memory Anomaly Trends (Top $top_n)\",\n      \"datasource\": \"Prometheus\",\n      \"targets\": [\n        {\n          \"expr\": \"bottomk($top_n, process_memory_anomaly_score \u003c 0.8)\",\n          \"legendFormat\": \"{{groupname}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"tooltip\": {\"mode\": \"multi\"},\n        \"legend\": {\"displayMode\": \"table\", \"placement\": \"right\", \"calcs\": [\"lastNotNull\", \"min\"]}\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\"mode\": \"palette-classic\"},\n          \"custom\": {\n            \"drawStyle\": \"line\",\n            \"lineInterpolation\": \"smooth\",\n            \"lineWidth\": 2,\n            \"fillOpacity\": 10,\n            \"pointSize\": 3\n          },\n          \"unit\": \"percentunit\",\n          \"min\": 0,\n          \"max\": 1,\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"red\", \"value\": 0},\n              {\"color\": \"yellow\", \"value\": 0.3},\n              {\"color\": \"green\", \"value\": 0.7}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"gridPos\": {\"h\": 10, \"w\": 24, \"x\": 0, \"y\": 18},\n      \"id\": 4,\n      \"type\": \"state-timeline\",\n      \"title\": \"Process Anomaly State Timeline (Top $top_n)\",\n      \"datasource\": \"Prometheus\",\n      \"targets\": [\n        {\n          \"expr\": \"bottomk($top_n, process_cpu_anomaly_score \u003c 0.8)\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"legend\": {\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\",\n          \"showLegend\": true\n        },\n        \"tooltip\": {\n          \"mode\": \"single\"\n        },\n        \"rowHeight\": 0.9\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"custom\": {\n            \"lineWidth\": 0,\n            \"fillOpacity\": 70,\n            \"spanNulls\": false\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\"color\": \"red\", \"value\": 0},\n              {\"color\": \"orange\", \"value\": 0.3},\n              {\"color\": \"yellow\", \"value\": 0.5},\n              {\"color\": \"green\", \"value\": 0.7}\n            ]\n          },\n          \"unit\": \"percentunit\",\n          \"min\": 0,\n          \"max\": 1\n        }\n      }\n    },\n    {\n      \"gridPos\": {\"h\": 10, \"w\": 24, \"x\": 0, \"y\": 28},\n      \"id\": 5,\n      \"type\": \"table\",\n      \"title\": \"Anomaly Score Details (Sortable)\",\n      \"datasource\": \"Prometheus\",\n      \"targets\": [\n        {\n          \"expr\": \"process_cpu_anomaly_score \u003c 0.9\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"process_memory_anomaly_score \u003c 0.9\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"B\"\n        }\n      ],\n      \"transformations\": [\n        {\n          \"id\": \"merge\"\n        },\n        {\n          \"id\": \"organize\",\n          \"options\": {\n            \"excludeByName\": {\n              \"Time\": true,\n              \"__name__\": true,\n              \"job\": true\n            },\n            \"renameByName\": {\n              \"Value #A\": \"CPU Score\",\n              \"Value #B\": \"Memory Score\",\n              \"groupname\": \"Process\",\n              \"instance\": \"Host\"\n            }\n          }\n        }\n      ],\n      \"options\": {\n        \"showHeader\": true,\n        \"sortBy\": [{\"desc\": false, \"displayName\": \"CPU Score\"}]\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"custom\": {\n            \"align\": \"center\",\n            \"displayMode\": \"color-background-solid\",\n            \"filterable\": true\n          },\n          \"unit\": \"percentunit\",\n          \"min\": 0,\n          \"max\": 1,\n          \"color\": {\"mode\": \"thresholds\"},\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"red\", \"value\": 0},\n              {\"color\": \"yellow\", \"value\": 0.3},\n              {\"color\": \"green\", \"value\": 0.7}\n            ]\n          }\n        }\n      }\n    }\n  ]\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"grafana_dashboard":"1"},"name":"process-anomaly-improved-standalone","namespace":"monitoring"}}
    creationTimestamp: "2025-06-07T02:24:19Z"
    labels:
      grafana_dashboard: "1"
    name: process-anomaly-improved-standalone
    namespace: monitoring
    resourceVersion: "4603048"
    uid: ba5b0b93-189e-45c1-91ff-e2c1dc8c4148
- apiVersion: v1
  data:
    process-exporter.yaml: |
      # Monitor all processes
      process_names:
      - name: "{{.Comm}}"
        cmdline:
        - '.+'
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"process-exporter.yaml":"# Monitor all processes\nprocess_names:\n- name: \"{{.Comm}}\"\n  cmdline:\n  - '.+'\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"process-exporter-config","namespace":"monitoring"}}
    creationTimestamp: "2025-05-27T23:23:16Z"
    name: process-exporter-config
    namespace: monitoring
    resourceVersion: "4265"
    uid: d5aa962a-723b-49df-bf72-5e72a377a98c
- apiVersion: v1
  data:
    alert_rules.yml: "groups:\n- name: node_alerts\n  rules:\n  - alert: HighCPUUsage\n
      \   expr: 100 - (avg(rate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)
      > 80\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n
      \     summary: \"High CPU usage detected\"\n      description: \"CPU usage is
      above 80% for more than 5 minutes\"\n  \n  - alert: HighMemoryUsage\n    expr:
      (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 >
      85\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n      summary:
      \"High memory usage detected\"\n      description: \"Memory usage is above 85%
      for more than 5 minutes\"\n  \n  - alert: DiskSpaceLow\n    expr: 100 - ((node_filesystem_avail_bytes
      * 100) / node_filesystem_size_bytes) > 90\n    for: 5m\n    labels:\n      severity:
      critical\n    annotations:\n      summary: \"Disk space is critically low\"\n
      \     description: \"Disk usage is above 90% on {{ $labels.mountpoint }}\"\n\n-
      name: container_alerts\n  rules:\n  - alert: PodRestarting\n    expr: rate(kube_pod_container_status_restarts_total[15m])
      > 0\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n      summary:
      \"Pod is restarting frequently\"\n      description: \"Pod {{ $labels.pod }}
      in namespace {{ $labels.namespace }} is restarting\"\n  \n  - alert: PodNotReady\n
      \   expr: kube_pod_status_ready{condition=\"false\"} == 1\n    for: 10m\n    labels:\n
      \     severity: warning\n    annotations:\n      summary: \"Pod not ready\"\n
      \     description: \"Pod {{ $labels.pod }} in namespace {{ $labels.namespace
      }} has been not ready for more than 10 minutes\"\n  \n  - alert: KubernetesMemoryPressure\n
      \   expr: kube_node_status_condition{condition=\"MemoryPressure\",status=\"true\"}
      == 1\n    for: 2m\n    labels:\n      severity: critical\n    annotations:\n
      \     summary: \"Kubernetes memory pressure\"\n      description: \"Node {{
      $labels.node }} has memory pressure\"\n  \n  - alert: KubernetesDiskPressure\n
      \   expr: kube_node_status_condition{condition=\"DiskPressure\",status=\"true\"}
      == 1\n    for: 2m\n    labels:\n      severity: critical\n    annotations:\n
      \     summary: \"Kubernetes disk pressure\"\n      description: \"Node {{ $labels.node
      }} has disk pressure\"\n\n- name: gpu_alerts\n  rules:\n  - alert: GPUHighTemperature\n
      \   expr: DCGM_FI_DEV_GPU_TEMP > 80\n    for: 2m\n    labels:\n      severity:
      warning\n    annotations:\n      summary: \"GPU temperature high\"\n      description:
      \"GPU {{ $labels.gpu }} temperature is {{ $value }}°C\"\n  \n  - alert: GPUMemoryFull\n
      \   expr: (DCGM_FI_DEV_FB_USED / (DCGM_FI_DEV_FB_USED + DCGM_FI_DEV_FB_FREE))
      * 100 > 95\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n
      \     summary: \"GPU memory almost full\"\n      description: \"GPU {{ $labels.gpu
      }} memory usage is {{ $value }}%\"\n  \n  - alert: GPUPowerHigh\n    expr: DCGM_FI_DEV_POWER_USAGE
      > 350\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n
      \     summary: \"GPU power consumption high\"\n      description: \"GPU {{ $labels.gpu
      }} power usage is {{ $value }}W\"\n  \n  - alert: GPUUtilizationLow\n    expr:
      DCGM_FI_DEV_GPU_UTIL < 5\n    for: 30m\n    labels:\n      severity: info\n
      \   annotations:\n      summary: \"GPU utilization low\"\n      description:
      \"GPU {{ $labels.gpu }} utilization has been below 5% for 30 minutes\"\n\n-
      name: process_alerts\n  rules:\n  - alert: ProcessHighCPU\n    expr: topk(5,
      sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m])) * 100)
      > 80\n    for: 10m\n    labels:\n      severity: warning\n    annotations:\n
      \     summary: \"Process using high CPU\"\n      description: \"Process {{ $labels.groupname
      }} is using {{ $value }}% CPU for 10 minutes\"\n  \n  - alert: ProcessHighMemory\n
      \   expr: topk(5, sum by (groupname) (namedprocess_namegroup_memory_bytes) /
      1024 / 1024 / 1024) > 8\n    for: 10m\n    labels:\n      severity: warning\n
      \   annotations:\n      summary: \"Process using high memory\"\n      description:
      \"Process {{ $labels.groupname }} is using {{ $value }}GB memory\"\n  \n  -
      alert: ZombieProcesses\n    expr: sum(namedprocess_namegroup_states{state=\"Zombie\"})
      > 5\n    for: 5m\n    labels:\n      severity: critical\n    annotations:\n
      \     summary: \"Multiple zombie processes detected\"\n      description: \"{{
      $value }} zombie processes detected on the system\"\n  \n  - alert: TooManyProcesses\n
      \   expr: sum(namedprocess_namegroup_num_procs) > 1000\n    for: 5m\n    labels:\n
      \     severity: warning\n    annotations:\n      summary: \"Too many processes
      running\"\n      description: \"{{ $value }} processes are running on the system\"\n
      \ \n  - alert: ProcessRestartingFrequently\n    expr: changes(namedprocess_namegroup_oldest_start_time_seconds[1h])
      > 5\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n      summary:
      \"Process restarting frequently\"\n      description: \"Process {{ $labels.groupname
      }} has restarted {{ $value }} times in the last hour\"\n\n- name: power_alerts\n
      \ rules:\n  - alert: HighPowerConsumption\n    expr: sum(node_cpu_package_power_watts)
      > 100\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n
      \     summary: \"High CPU power consumption\"\n      description: \"CPU package
      power consumption is {{ $value }}W\"\n  \n  - alert: BatteryLow\n    expr: node_power_supply_capacity
      < 20\n    for: 1m\n    labels:\n      severity: critical\n    annotations:\n
      \     summary: \"Battery level low\"\n      description: \"Battery level is
      {{ $value }}%\"\n  \n  - alert: BatteryHealthDegraded\n    expr: node_battery_health_percent
      < 80\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n
      \     summary: \"Battery health degraded\"\n      description: \"Battery health
      is {{ $value }}% of design capacity\"\n  \n  - alert: ThermalThrottling\n    expr:
      rate(node_cpu_throttles_total[5m]) > 0\n    for: 1m\n    labels:\n      severity:
      critical\n    annotations:\n      summary: \"CPU thermal throttling detected\"\n
      \     description: \"CPU is being thermally throttled\"\n\n- name: monitoring_alerts\n
      \ rules:\n  - alert: PrometheusTargetDown\n    expr: up == 0\n    for: 5m\n
      \   labels:\n      severity: warning\n    annotations:\n      summary: \"Prometheus
      target down\"\n      description: \"Target {{ $labels.job }} on {{ $labels.instance
      }} is down\"\n  \n  - alert: PrometheusConfigReloadFailed\n    expr: prometheus_config_last_reload_successful
      != 1\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n
      \     summary: \"Prometheus configuration reload failed\"\n      description:
      \"Prometheus configuration reload has failed\"\n"
    prometheus.yml: |
      global:
        scrape_interval: 15s
        evaluation_interval: 15s

      # AlertManager configuration
      alerting:
        alertmanagers:
          - static_configs:
              - targets: ['alertmanager:9093']

      rule_files:
        - "/etc/prometheus/rules/gpu/*.yaml"
        - "/etc/prometheus/rules/power-exporter/*.yaml"
        - "/etc/prometheus/rules/claude-code/*.yaml"
        - "/etc/prometheus/rules/k3s/*.yaml"
        - "/etc/prometheus/rules/odin-stack/*.yaml"
        - "/etc/prometheus/rules/anomaly/*.yaml"
        - "/etc/prometheus/rules/process-anomaly/*.yaml"
        - "/etc/prometheus/rules/disk-space/*.yaml"
        - "/etc/prometheus/rules/anomaly-recording/*.yaml"

      scrape_configs:
      - job_name: 'prometheus'
        static_configs:
        - targets: ['localhost:9090']

      - job_name: 'kubernetes-service-discovery'
        kubernetes_sd_configs:
        - role: service
          namespaces:
            names: ['monitoring', 'odin-prime']
        relabel_configs:
        - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
          action: keep
          regex: true
        - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_service_annotation_prometheus_io_port]
          action: replace
          target_label: __address__
          regex: (.+);(.+);(.+)
          replacement: $2.$1.svc.cluster.local:$3

      - job_name: 'node-exporter'
        static_configs:
        - targets: ['192.168.1.154:9100']

      - job_name: 'cadvisor'
        static_configs:
        - targets: ['cadvisor:8080']

      - job_name: 'alertmanager'
        static_configs:
        - targets: ['alertmanager:9093']

      - job_name: 'grafana'
        static_configs:
        - targets: ['grafana:3000']

      - job_name: 'kube-state-metrics'
        static_configs:
        - targets: ['kube-state-metrics:8080']


      - job_name: 'process-exporter'
        static_configs:
        - targets: ['process-exporter:9256']

      - job_name: 'power-exporter'
        static_configs:
        - targets: ['power-exporter:9402']


      - job_name: 'claude-code-exporter'
        static_configs:
        - targets: ['claude-code-exporter:9403']

      - job_name: 'claude-token-collector'
        static_configs:
        - targets: ['claude-token-collector:9404']

      # Network monitoring exporters
      - job_name: 'unifi-exporter'
        static_configs:
        - targets: ['unifi-exporter:9130']

      - job_name: 'unifi-enhanced-exporter'
        static_configs:
        - targets: ['unifi-enhanced-exporter:9135']

      - job_name: 'network-performance-exporter'
        static_configs:
        - targets: ['network-performance-exporter:9131']

      - job_name: 'network-topology-exporter'
        static_configs:
        - targets: ['network-topology-exporter:9132']

      - job_name: 'gpu-anomaly-detector'
        static_configs:
        - targets: ['anomaly-detector-v2:9405']

      - job_name: 'netflow-collector'
        static_configs:
        - targets: ['netflow-collector:9134']

      - job_name: 'process-anomaly-detector'
        static_configs:
        - targets: ['process-anomaly-detector:9407']

      - job_name: 'advanced-process-anomaly-detector'
        static_configs:
        - targets: ['advanced-process-anomaly-detector:9409']

      - job_name: 'k8s-pod-anomaly-detector'
        static_configs:
        - targets: ['k8s-pod-anomaly-detector:9406']

      - job_name: 'disk-anomaly-detector'
        static_configs:
        - targets: ['disk-anomaly-detector:9408']

      - job_name: 'disk-usage-monitor'
        static_configs:
        - targets: ['disk-usage-monitor:9410']
        scrape_interval: 60s

      - job_name: 'nvidia-rtx-exporter'
        static_configs:
        - targets: ['nvidia-rtx-exporter:9410']

      - job_name: 'loki'
        static_configs:
        - targets: ['loki:3100']

      - job_name: 'promtail'
        static_configs:
        - targets: ['promtail:9080']

      - job_name: 'snmp'
        static_configs:
        - targets:
          - 192.168.1.1  # UniFi Dream Machine
        metrics_path: /snmp
        params:
          auth: [public_v2]
        relabel_configs:
        - source_labels: [__address__]
          target_label: __param_target
        - source_labels: [__param_target]
          target_label: instance
        - target_label: __address__
          replacement: snmp-exporter:9116

      # ODIN Prime Services
      - job_name: 'odin-prime-alert-ingestion'
        static_configs:
        - targets: ['alert-ingestion.odin-prime.svc.cluster.local:8080']
          labels:
            service: 'alert-ingestion'
            namespace: 'odin-prime'

      - job_name: 'odin-prime-escalation'
        static_configs:
        - targets: ['escalation-service.odin-prime.svc.cluster.local:8080']
          labels:
            service: 'escalation-service'
            namespace: 'odin-prime'

      - job_name: 'odin-prime-automation'
        static_configs:
        - targets: ['automation-engine.odin-prime.svc.cluster.local:8080']
          labels:
            service: 'automation-engine'
            namespace: 'odin-prime'

      - job_name: 'odin-prime-pattern-matcher'
        static_configs:
        - targets: ['pattern-matcher.odin-prime.svc.cluster.local:9090']
          labels:
            service: 'pattern-matcher'
            namespace: 'odin-prime'

      - job_name: 'odin-prime-tier1'
        static_configs:
        - targets: ['tier1-hybrid.odin-prime.svc.cluster.local:8080']
          labels:
            service: 'tier1-hybrid'
            namespace: 'odin-prime'
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"alert_rules.yml":"groups:\n- name: node_alerts\n  rules:\n  - alert: HighCPUUsage\n    expr: 100 - (avg(rate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100) \u003e 80\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n      summary: \"High CPU usage detected\"\n      description: \"CPU usage is above 80% for more than 5 minutes\"\n  \n  - alert: HighMemoryUsage\n    expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 \u003e 85\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n      summary: \"High memory usage detected\"\n      description: \"Memory usage is above 85% for more than 5 minutes\"\n  \n  - alert: DiskSpaceLow\n    expr: 100 - ((node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes) \u003e 90\n    for: 5m\n    labels:\n      severity: critical\n    annotations:\n      summary: \"Disk space is critically low\"\n      description: \"Disk usage is above 90% on {{ $labels.mountpoint }}\"\n\n- name: container_alerts\n  rules:\n  - alert: PodRestarting\n    expr: rate(kube_pod_container_status_restarts_total[15m]) \u003e 0\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n      summary: \"Pod is restarting frequently\"\n      description: \"Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} is restarting\"\n  \n  - alert: PodNotReady\n    expr: kube_pod_status_ready{condition=\"false\"} == 1\n    for: 10m\n    labels:\n      severity: warning\n    annotations:\n      summary: \"Pod not ready\"\n      description: \"Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} has been not ready for more than 10 minutes\"\n  \n  - alert: KubernetesMemoryPressure\n    expr: kube_node_status_condition{condition=\"MemoryPressure\",status=\"true\"} == 1\n    for: 2m\n    labels:\n      severity: critical\n    annotations:\n      summary: \"Kubernetes memory pressure\"\n      description: \"Node {{ $labels.node }} has memory pressure\"\n  \n  - alert: KubernetesDiskPressure\n    expr: kube_node_status_condition{condition=\"DiskPressure\",status=\"true\"} == 1\n    for: 2m\n    labels:\n      severity: critical\n    annotations:\n      summary: \"Kubernetes disk pressure\"\n      description: \"Node {{ $labels.node }} has disk pressure\"\n\n- name: gpu_alerts\n  rules:\n  - alert: GPUHighTemperature\n    expr: DCGM_FI_DEV_GPU_TEMP \u003e 80\n    for: 2m\n    labels:\n      severity: warning\n    annotations:\n      summary: \"GPU temperature high\"\n      description: \"GPU {{ $labels.gpu }} temperature is {{ $value }}°C\"\n  \n  - alert: GPUMemoryFull\n    expr: (DCGM_FI_DEV_FB_USED / (DCGM_FI_DEV_FB_USED + DCGM_FI_DEV_FB_FREE)) * 100 \u003e 95\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n      summary: \"GPU memory almost full\"\n      description: \"GPU {{ $labels.gpu }} memory usage is {{ $value }}%\"\n  \n  - alert: GPUPowerHigh\n    expr: DCGM_FI_DEV_POWER_USAGE \u003e 350\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n      summary: \"GPU power consumption high\"\n      description: \"GPU {{ $labels.gpu }} power usage is {{ $value }}W\"\n  \n  - alert: GPUUtilizationLow\n    expr: DCGM_FI_DEV_GPU_UTIL \u003c 5\n    for: 30m\n    labels:\n      severity: info\n    annotations:\n      summary: \"GPU utilization low\"\n      description: \"GPU {{ $labels.gpu }} utilization has been below 5% for 30 minutes\"\n\n- name: process_alerts\n  rules:\n  - alert: ProcessHighCPU\n    expr: topk(5, sum by (groupname) (rate(namedprocess_namegroup_cpu_seconds_total[5m])) * 100) \u003e 80\n    for: 10m\n    labels:\n      severity: warning\n    annotations:\n      summary: \"Process using high CPU\"\n      description: \"Process {{ $labels.groupname }} is using {{ $value }}% CPU for 10 minutes\"\n  \n  - alert: ProcessHighMemory\n    expr: topk(5, sum by (groupname) (namedprocess_namegroup_memory_bytes) / 1024 / 1024 / 1024) \u003e 8\n    for: 10m\n    labels:\n      severity: warning\n    annotations:\n      summary: \"Process using high memory\"\n      description: \"Process {{ $labels.groupname }} is using {{ $value }}GB memory\"\n  \n  - alert: ZombieProcesses\n    expr: sum(namedprocess_namegroup_states{state=\"Zombie\"}) \u003e 5\n    for: 5m\n    labels:\n      severity: critical\n    annotations:\n      summary: \"Multiple zombie processes detected\"\n      description: \"{{ $value }} zombie processes detected on the system\"\n  \n  - alert: TooManyProcesses\n    expr: sum(namedprocess_namegroup_num_procs) \u003e 1000\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n      summary: \"Too many processes running\"\n      description: \"{{ $value }} processes are running on the system\"\n  \n  - alert: ProcessRestartingFrequently\n    expr: changes(namedprocess_namegroup_oldest_start_time_seconds[1h]) \u003e 5\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n      summary: \"Process restarting frequently\"\n      description: \"Process {{ $labels.groupname }} has restarted {{ $value }} times in the last hour\"\n\n- name: power_alerts\n  rules:\n  - alert: HighPowerConsumption\n    expr: sum(node_cpu_package_power_watts) \u003e 100\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n      summary: \"High CPU power consumption\"\n      description: \"CPU package power consumption is {{ $value }}W\"\n  \n  - alert: BatteryLow\n    expr: node_power_supply_capacity \u003c 20\n    for: 1m\n    labels:\n      severity: critical\n    annotations:\n      summary: \"Battery level low\"\n      description: \"Battery level is {{ $value }}%\"\n  \n  - alert: BatteryHealthDegraded\n    expr: node_battery_health_percent \u003c 80\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n      summary: \"Battery health degraded\"\n      description: \"Battery health is {{ $value }}% of design capacity\"\n  \n  - alert: ThermalThrottling\n    expr: rate(node_cpu_throttles_total[5m]) \u003e 0\n    for: 1m\n    labels:\n      severity: critical\n    annotations:\n      summary: \"CPU thermal throttling detected\"\n      description: \"CPU is being thermally throttled\"\n\n- name: monitoring_alerts\n  rules:\n  - alert: PrometheusTargetDown\n    expr: up == 0\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n      summary: \"Prometheus target down\"\n      description: \"Target {{ $labels.job }} on {{ $labels.instance }} is down\"\n  \n  - alert: PrometheusConfigReloadFailed\n    expr: prometheus_config_last_reload_successful != 1\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n      summary: \"Prometheus configuration reload failed\"\n      description: \"Prometheus configuration reload has failed\"\n","prometheus.yml":"global:\n  scrape_interval: 15s\n  evaluation_interval: 15s\n\n# AlertManager configuration\nalerting:\n  alertmanagers:\n    - static_configs:\n        - targets: ['alertmanager:9093']\n\nrule_files:\n  - \"/etc/prometheus/rules/gpu/*.yaml\"\n  - \"/etc/prometheus/rules/power-exporter/*.yaml\"\n  - \"/etc/prometheus/rules/claude-code/*.yaml\"\n  - \"/etc/prometheus/rules/k3s/*.yaml\"\n  - \"/etc/prometheus/rules/odin-stack/*.yaml\"\n  - \"/etc/prometheus/rules/anomaly/*.yaml\"\n  - \"/etc/prometheus/rules/process-anomaly/*.yaml\"\n  - \"/etc/prometheus/rules/disk-space/*.yaml\"\n  - \"/etc/prometheus/rules/anomaly-recording/*.yaml\"\n\nscrape_configs:\n- job_name: 'prometheus'\n  static_configs:\n  - targets: ['localhost:9090']\n\n- job_name: 'kubernetes-service-discovery'\n  kubernetes_sd_configs:\n  - role: service\n    namespaces:\n      names: ['monitoring', 'odin-prime']\n  relabel_configs:\n  - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]\n    action: keep\n    regex: true\n  - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_service_annotation_prometheus_io_port]\n    action: replace\n    target_label: __address__\n    regex: (.+);(.+);(.+)\n    replacement: $2.$1.svc.cluster.local:$3\n\n- job_name: 'node-exporter'\n  static_configs:\n  - targets: ['192.168.1.154:9100']\n\n- job_name: 'cadvisor'\n  static_configs:\n  - targets: ['cadvisor:8080']\n\n- job_name: 'alertmanager'\n  static_configs:\n  - targets: ['alertmanager:9093']\n\n- job_name: 'grafana'\n  static_configs:\n  - targets: ['grafana:3000']\n\n- job_name: 'kube-state-metrics'\n  static_configs:\n  - targets: ['kube-state-metrics:8080']\n\n\n- job_name: 'process-exporter'\n  static_configs:\n  - targets: ['process-exporter:9256']\n\n- job_name: 'power-exporter'\n  static_configs:\n  - targets: ['power-exporter:9402']\n\n\n- job_name: 'claude-code-exporter'\n  static_configs:\n  - targets: ['claude-code-exporter:9403']\n\n- job_name: 'claude-token-collector'\n  static_configs:\n  - targets: ['claude-token-collector:9404']\n\n# Network monitoring exporters\n- job_name: 'unifi-exporter'\n  static_configs:\n  - targets: ['unifi-exporter:9130']\n\n- job_name: 'unifi-enhanced-exporter'\n  static_configs:\n  - targets: ['unifi-enhanced-exporter:9135']\n\n- job_name: 'network-performance-exporter'\n  static_configs:\n  - targets: ['network-performance-exporter:9131']\n\n- job_name: 'network-topology-exporter'\n  static_configs:\n  - targets: ['network-topology-exporter:9132']\n\n- job_name: 'gpu-anomaly-detector'\n  static_configs:\n  - targets: ['anomaly-detector-v2:9405']\n\n- job_name: 'netflow-collector'\n  static_configs:\n  - targets: ['netflow-collector:9134']\n\n- job_name: 'process-anomaly-detector'\n  static_configs:\n  - targets: ['process-anomaly-detector:9407']\n\n- job_name: 'advanced-process-anomaly-detector'\n  static_configs:\n  - targets: ['advanced-process-anomaly-detector:9409']\n\n- job_name: 'k8s-pod-anomaly-detector'\n  static_configs:\n  - targets: ['k8s-pod-anomaly-detector:9406']\n\n- job_name: 'disk-anomaly-detector'\n  static_configs:\n  - targets: ['disk-anomaly-detector:9408']\n\n- job_name: 'disk-usage-monitor'\n  static_configs:\n  - targets: ['disk-usage-monitor:9410']\n  scrape_interval: 60s\n\n- job_name: 'nvidia-rtx-exporter'\n  static_configs:\n  - targets: ['nvidia-rtx-exporter:9410']\n\n- job_name: 'loki'\n  static_configs:\n  - targets: ['loki:3100']\n\n- job_name: 'promtail'\n  static_configs:\n  - targets: ['promtail:9080']\n\n- job_name: 'snmp'\n  static_configs:\n  - targets:\n    - 192.168.1.1  # UniFi Dream Machine\n  metrics_path: /snmp\n  params:\n    auth: [public_v2]\n  relabel_configs:\n  - source_labels: [__address__]\n    target_label: __param_target\n  - source_labels: [__param_target]\n    target_label: instance\n  - target_label: __address__\n    replacement: snmp-exporter:9116\n\n# ODIN Prime Services\n- job_name: 'odin-prime-alert-ingestion'\n  static_configs:\n  - targets: ['alert-ingestion.odin-prime.svc.cluster.local:8080']\n    labels:\n      service: 'alert-ingestion'\n      namespace: 'odin-prime'\n\n- job_name: 'odin-prime-escalation'\n  static_configs:\n  - targets: ['escalation-service.odin-prime.svc.cluster.local:8080']\n    labels:\n      service: 'escalation-service'\n      namespace: 'odin-prime'\n\n- job_name: 'odin-prime-automation'\n  static_configs:\n  - targets: ['automation-engine.odin-prime.svc.cluster.local:8080']\n    labels:\n      service: 'automation-engine'\n      namespace: 'odin-prime'\n\n- job_name: 'odin-prime-pattern-matcher'\n  static_configs:\n  - targets: ['pattern-matcher.odin-prime.svc.cluster.local:9090']\n    labels:\n      service: 'pattern-matcher'\n      namespace: 'odin-prime'\n\n- job_name: 'odin-prime-tier1'\n  static_configs:\n  - targets: ['tier1-hybrid.odin-prime.svc.cluster.local:8080']\n    labels:\n      service: 'tier1-hybrid'\n      namespace: 'odin-prime'\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"prometheus-config","namespace":"monitoring"}}
    creationTimestamp: "2025-05-27T22:05:21Z"
    name: prometheus-config
    namespace: monitoring
    resourceVersion: "5646623"
    uid: 824fbcee-222e-4326-a651-ac883fc05227
- apiVersion: v1
  data:
    prometheus-patch.yml: |
      # Add this to the prometheus.yml rule_files section:
      # - "/etc/prometheus/rules/odin-prime/*.yaml"

      # Additional scrape configs for ODIN Prime services
      - job_name: 'odin-prime-services'
        kubernetes_sd_configs:
        - role: endpoints
          namespaces:
            names:
            - odin-prime
        relabel_configs:
        - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
          action: keep
          regex: true
        - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
          action: replace
          target_label: __metrics_path__
          regex: (.+)
        - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
          action: replace
          regex: ([^:]+)(?::\d+)?;(\d+)
          replacement: $1:$2
          target_label: __address__
        - action: labelmap
          regex: __meta_kubernetes_service_label_(.+)
        - source_labels: [__meta_kubernetes_namespace]
          action: replace
          target_label: kubernetes_namespace
        - source_labels: [__meta_kubernetes_service_name]
          action: replace
          target_label: kubernetes_name
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"prometheus-patch.yml":"# Add this to the prometheus.yml rule_files section:\n# - \"/etc/prometheus/rules/odin-prime/*.yaml\"\n\n# Additional scrape configs for ODIN Prime services\n- job_name: 'odin-prime-services'\n  kubernetes_sd_configs:\n  - role: endpoints\n    namespaces:\n      names:\n      - odin-prime\n  relabel_configs:\n  - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]\n    action: keep\n    regex: true\n  - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]\n    action: replace\n    target_label: __metrics_path__\n    regex: (.+)\n  - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]\n    action: replace\n    regex: ([^:]+)(?::\\d+)?;(\\d+)\n    replacement: $1:$2\n    target_label: __address__\n  - action: labelmap\n    regex: __meta_kubernetes_service_label_(.+)\n  - source_labels: [__meta_kubernetes_namespace]\n    action: replace\n    target_label: kubernetes_namespace\n  - source_labels: [__meta_kubernetes_service_name]\n    action: replace\n    target_label: kubernetes_name\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"prometheus-config-patch","namespace":"monitoring"}}
    creationTimestamp: "2025-06-07T16:28:25Z"
    name: prometheus-config-patch
    namespace: monitoring
    resourceVersion: "4973409"
    uid: 162f0b51-a10b-458f-87a8-dc28c9023880
- apiVersion: v1
  data:
    tier1-optimized.yaml: |
      - job_name: 'odin-prime-tier1-optimized'
        static_configs:
        - targets: ['tier1-optimized.odin-prime.svc.cluster.local:9419']
          labels:
            service: 'tier1-optimized'
            namespace: 'odin-prime'
            tier: 'tier1'
            optimized: 'true'
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"tier1-optimized.yaml":"- job_name: 'odin-prime-tier1-optimized'\n  static_configs:\n  - targets: ['tier1-optimized.odin-prime.svc.cluster.local:9419']\n    labels:\n      service: 'tier1-optimized'\n      namespace: 'odin-prime'\n      tier: 'tier1'\n      optimized: 'true'\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"prometheus-tier1-optimized-job","namespace":"monitoring"}}
    creationTimestamp: "2025-06-08T20:24:56Z"
    name: prometheus-tier1-optimized-job
    namespace: monitoring
    resourceVersion: "5716650"
    uid: 4ec0c48d-c82a-47b0-903a-794eccd65f79
- apiVersion: v1
  data:
    promtail.yaml: "server:\n  http_listen_port: 9080\n  grpc_listen_port: 0\n\nclients:\n
      \ - url: http://loki:3100/loki/api/v1/push\n\npositions:\n  filename: /tmp/positions.yaml\n\nscrape_configs:\n
      \ # ODIN monitoring namespace logs\n  - job_name: odin-monitoring\n    kubernetes_sd_configs:\n
      \     - role: pod\n        namespaces:\n          names:\n            - monitoring\n
      \   pipeline_stages:\n      - cri: {}\n      - labeldrop:\n          - filename\n
      \         - kubernetes_config_source\n    relabel_configs:\n      - source_labels:
      [__meta_kubernetes_namespace]\n        target_label: namespace\n      - source_labels:
      [__meta_kubernetes_pod_name]\n        target_label: pod\n      - source_labels:
      [__meta_kubernetes_pod_label_app]\n        target_label: app\n      - action:
      replace\n        replacement: /var/log/pods/*$1/*.log\n        separator: /\n
      \       source_labels: [__meta_kubernetes_pod_uid, __meta_kubernetes_pod_container_name]\n
      \       target_label: __path__\n  \n  # System logs - simplified\n  - job_name:
      system\n    static_configs:\n      - targets:\n          - localhost\n        labels:\n
      \         job: system\n          host: razerblade\n          __path__: /var/log/syslog\n
      \   pipeline_stages:\n      - multiline:\n          firstline: '^\\d{4}-\\d{2}-\\d{2}'\n
      \         max_wait_time: 3s\n      - regex:\n          expression: '^(?P<timestamp>\\S+\\s+\\S+)\\s+(?P<hostname>\\S+)\\s+(?P<program>\\S+?)(\\[(?P<pid>\\d+)\\])?\\s*:\\s*(?P<message>.*)$'\n
      \     - labels:\n          program:\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"promtail.yaml":"server:\n  http_listen_port: 9080\n  grpc_listen_port: 0\n\nclients:\n  - url: http://loki:3100/loki/api/v1/push\n\npositions:\n  filename: /tmp/positions.yaml\n\nscrape_configs:\n  # ODIN monitoring namespace logs\n  - job_name: odin-monitoring\n    kubernetes_sd_configs:\n      - role: pod\n        namespaces:\n          names:\n            - monitoring\n    pipeline_stages:\n      - cri: {}\n      - labeldrop:\n          - filename\n          - kubernetes_config_source\n    relabel_configs:\n      - source_labels: [__meta_kubernetes_namespace]\n        target_label: namespace\n      - source_labels: [__meta_kubernetes_pod_name]\n        target_label: pod\n      - source_labels: [__meta_kubernetes_pod_label_app]\n        target_label: app\n      - action: replace\n        replacement: /var/log/pods/*$1/*.log\n        separator: /\n        source_labels: [__meta_kubernetes_pod_uid, __meta_kubernetes_pod_container_name]\n        target_label: __path__\n  \n  # System logs - simplified\n  - job_name: system\n    static_configs:\n      - targets:\n          - localhost\n        labels:\n          job: system\n          host: razerblade\n          __path__: /var/log/syslog\n    pipeline_stages:\n      - multiline:\n          firstline: '^\\d{4}-\\d{2}-\\d{2}'\n          max_wait_time: 3s\n      - regex:\n          expression: '^(?P\u003ctimestamp\u003e\\S+\\s+\\S+)\\s+(?P\u003chostname\u003e\\S+)\\s+(?P\u003cprogram\u003e\\S+?)(\\[(?P\u003cpid\u003e\\d+)\\])?\\s*:\\s*(?P\u003cmessage\u003e.*)$'\n      - labels:\n          program:\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"promtail-config","namespace":"monitoring"}}
    creationTimestamp: "2025-05-27T22:23:21Z"
    name: promtail-config
    namespace: monitoring
    resourceVersion: "11834"
    uid: 0e7cf683-2e4e-44f6-bceb-9525fa9a5c98
- apiVersion: v1
  data:
    razer-exporter.py: "#!/usr/bin/env python3\nimport os\nimport time\nimport glob\nfrom
      prometheus_client import start_http_server, Gauge\n\n# Define Prometheus metrics\nbattery_level
      = Gauge('razer_battery_level_percent', 'Battery level percentage', ['device'])\nbattery_charging
      = Gauge('razer_battery_charging', 'Battery charging status', ['device'])\nfan_rpm
      = Gauge('razer_fan_rpm', 'Fan RPM', ['device', 'fan'])\nkeyboard_brightness
      = Gauge('razer_keyboard_brightness_percent', 'Keyboard backlight brightness',
      ['device'])\ndpi = Gauge('razer_mouse_dpi', 'Mouse DPI setting', ['device',
      'axis'])\npolling_rate = Gauge('razer_device_polling_rate_hz', 'Device polling
      rate', ['device'])\n\ndef collect_razer_metrics():\n    \"\"\"Collect metrics
      from OpenRazer sysfs interface\"\"\"\n    razer_path = \"/sys/bus/hid/drivers/razerkbd/\"\n
      \   \n    # Find all Razer devices\n    devices = glob.glob(razer_path + \"*/device_type\")\n
      \   \n    for device_path in devices:\n        device_dir = os.path.dirname(device_path)\n
      \       device_name = os.path.basename(device_dir)\n        \n        # Battery
      metrics\n        battery_path = os.path.join(device_dir, \"power_supply\", \"razer_*\",
      \"capacity\")\n        battery_files = glob.glob(battery_path)\n        if battery_files:\n
      \           try:\n                with open(battery_files[0], 'r') as f:\n                    battery_level.labels(device=device_name).set(float(f.read().strip()))\n
      \           except:\n                pass\n        \n        # Keyboard brightness\n
      \       brightness_path = os.path.join(device_dir, \"matrix_brightness\")\n
      \       if os.path.exists(brightness_path):\n            try:\n                with
      open(brightness_path, 'r') as f:\n                    brightness = int(f.read().strip())\n
      \                   keyboard_brightness.labels(device=device_name).set(brightness
      * 100 / 255)\n            except:\n                pass\n        \n        #
      Fan RPM (if available)\n        fan_path = os.path.join(device_dir, \"fan_rpm\")\n
      \       if os.path.exists(fan_path):\n            try:\n                with
      open(fan_path, 'r') as f:\n                    fan_rpm.labels(device=device_name,
      fan=\"main\").set(float(f.read().strip()))\n            except:\n                pass\n\nif
      __name__ == '__main__':\n    # Start Prometheus metrics server\n    start_http_server(9401)\n
      \   \n    # Collect metrics every 10 seconds\n    while True:\n        try:\n
      \           collect_razer_metrics()\n        except Exception as e:\n            print(f\"Error
      collecting metrics: {e}\")\n        time.sleep(10)\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"razer-exporter.py":"#!/usr/bin/env python3\nimport os\nimport time\nimport glob\nfrom prometheus_client import start_http_server, Gauge\n\n# Define Prometheus metrics\nbattery_level = Gauge('razer_battery_level_percent', 'Battery level percentage', ['device'])\nbattery_charging = Gauge('razer_battery_charging', 'Battery charging status', ['device'])\nfan_rpm = Gauge('razer_fan_rpm', 'Fan RPM', ['device', 'fan'])\nkeyboard_brightness = Gauge('razer_keyboard_brightness_percent', 'Keyboard backlight brightness', ['device'])\ndpi = Gauge('razer_mouse_dpi', 'Mouse DPI setting', ['device', 'axis'])\npolling_rate = Gauge('razer_device_polling_rate_hz', 'Device polling rate', ['device'])\n\ndef collect_razer_metrics():\n    \"\"\"Collect metrics from OpenRazer sysfs interface\"\"\"\n    razer_path = \"/sys/bus/hid/drivers/razerkbd/\"\n    \n    # Find all Razer devices\n    devices = glob.glob(razer_path + \"*/device_type\")\n    \n    for device_path in devices:\n        device_dir = os.path.dirname(device_path)\n        device_name = os.path.basename(device_dir)\n        \n        # Battery metrics\n        battery_path = os.path.join(device_dir, \"power_supply\", \"razer_*\", \"capacity\")\n        battery_files = glob.glob(battery_path)\n        if battery_files:\n            try:\n                with open(battery_files[0], 'r') as f:\n                    battery_level.labels(device=device_name).set(float(f.read().strip()))\n            except:\n                pass\n        \n        # Keyboard brightness\n        brightness_path = os.path.join(device_dir, \"matrix_brightness\")\n        if os.path.exists(brightness_path):\n            try:\n                with open(brightness_path, 'r') as f:\n                    brightness = int(f.read().strip())\n                    keyboard_brightness.labels(device=device_name).set(brightness * 100 / 255)\n            except:\n                pass\n        \n        # Fan RPM (if available)\n        fan_path = os.path.join(device_dir, \"fan_rpm\")\n        if os.path.exists(fan_path):\n            try:\n                with open(fan_path, 'r') as f:\n                    fan_rpm.labels(device=device_name, fan=\"main\").set(float(f.read().strip()))\n            except:\n                pass\n\nif __name__ == '__main__':\n    # Start Prometheus metrics server\n    start_http_server(9401)\n    \n    # Collect metrics every 10 seconds\n    while True:\n        try:\n            collect_razer_metrics()\n        except Exception as e:\n            print(f\"Error collecting metrics: {e}\")\n        time.sleep(10)\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"razer-exporter-script","namespace":"monitoring"}}
    creationTimestamp: "2025-05-27T23:34:15Z"
    name: razer-exporter-script
    namespace: monitoring
    resourceVersion: "4921"
    uid: 99443d12-e430-4b43-b3ca-829021c8618d
- apiVersion: v1
  data:
    razerblade-18-system.json: |
      {
        "id": null,
        "title": "Razer Blade 18 - System Overview",
        "description": "Comprehensive system monitoring for Razer Blade 18 running Ubuntu 22.04",
        "tags": ["system", "razerblade", "performance", "showcase"],
        "style": "dark",
        "timezone": "browser",
        "refresh": "5s",
        "schemaVersion": 27,
        "version": 1,
        "time": {
          "from": "now-3h",
          "to": "now"
        },
        "panels": [
          {
            "id": 1,
            "title": "System Information",
            "type": "stat",
            "targets": [
              {
                "expr": "node_uname_info{nodename=\"razerblade-18-rz09-0484\"}",
                "legendFormat": "{{ nodename }}",
                "refId": "A"
              }
            ],
            "options": {
              "textMode": "name"
            },
            "fieldConfig": {
              "defaults": {
                "custom": {
                  "align": "center",
                  "textMode": "value"
                }
              }
            },
            "gridPos": {"h": 3, "w": 6, "x": 0, "y": 0}
          },
          {
            "id": 2,
            "title": "Uptime",
            "type": "stat",
            "targets": [
              {
                "expr": "time() - node_boot_time_seconds",
                "legendFormat": "Uptime",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "s"
              }
            },
            "gridPos": {"h": 3, "w": 6, "x": 6, "y": 0}
          },
          {
            "id": 3,
            "title": "CPU Model",
            "type": "stat",
            "targets": [
              {
                "expr": "count(node_cpu_seconds_total{mode=\"idle\"})",
                "legendFormat": "CPU Cores",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "short",
                "mappings": [
                  {"type": "value", "value": "32", "text": "Intel i9-14900HX (32 cores)"}
                ]
              }
            },
            "gridPos": {"h": 3, "w": 6, "x": 12, "y": 0}
          },
          {
            "id": 4,
            "title": "GPU Status",
            "type": "stat",
            "targets": [
              {
                "expr": "1",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "short",
                "mappings": [
                  {"type": "value", "value": "1", "text": "NVIDIA RTX 4080"}
                ]
              }
            },
            "gridPos": {"h": 3, "w": 6, "x": 18, "y": 0}
          },
          {
            "id": 5,
            "title": "CPU Usage",
            "type": "gauge",
            "targets": [
              {
                "expr": "100 - (avg(rate(node_cpu_seconds_total{mode=\"idle\"}[1m])) * 100)",
                "legendFormat": "CPU Usage",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "percent",
                "min": 0,
                "max": 100,
                "thresholds": {
                  "steps": [
                    {"color": "green", "value": null},
                    {"color": "yellow", "value": 60},
                    {"color": "orange", "value": 80},
                    {"color": "red", "value": 90}
                  ]
                }
              }
            },
            "gridPos": {"h": 8, "w": 6, "x": 0, "y": 3}
          },
          {
            "id": 6,
            "title": "Memory Usage",
            "type": "gauge",
            "targets": [
              {
                "expr": "(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100",
                "legendFormat": "Memory Usage",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "percent",
                "min": 0,
                "max": 100,
                "thresholds": {
                  "steps": [
                    {"color": "green", "value": null},
                    {"color": "yellow", "value": 70},
                    {"color": "orange", "value": 85},
                    {"color": "red", "value": 95}
                  ]
                }
              }
            },
            "gridPos": {"h": 8, "w": 6, "x": 6, "y": 3}
          },
          {
            "id": 7,
            "title": "CPU & Memory Details",
            "type": "stat",
            "targets": [
              {
                "expr": "node_memory_MemTotal_bytes",
                "legendFormat": "Total Memory",
                "refId": "A"
              },
              {
                "expr": "node_memory_MemAvailable_bytes",
                "legendFormat": "Available Memory",
                "refId": "B"
              },
              {
                "expr": "node_load15",
                "legendFormat": "Load Average (15m)",
                "refId": "C"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "bytes"
              },
              "overrides": [
                {
                  "matcher": {"id": "byName", "options": "Load Average (15m)"},
                  "properties": [{"id": "unit", "value": "short"}]
                }
              ]
            },
            "gridPos": {"h": 8, "w": 6, "x": 12, "y": 3}
          },
          {
            "id": 8,
            "title": "System Temperatures",
            "type": "timeseries",
            "targets": [
              {
                "expr": "node_hwmon_temp_celsius",
                "legendFormat": "{{ chip }} - {{ sensor }}",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "celsius",
                "thresholds": {
                  "steps": [
                    {"color": "blue", "value": null},
                    {"color": "green", "value": 40},
                    {"color": "yellow", "value": 60},
                    {"color": "orange", "value": 75},
                    {"color": "red", "value": 85}
                  ]
                }
              }
            },
            "gridPos": {"h": 8, "w": 6, "x": 18, "y": 3}
          },
          {
            "id": 9,
            "title": "CPU Usage by Core",
            "type": "heatmap",
            "targets": [
              {
                "expr": "100 - (rate(node_cpu_seconds_total{mode=\"idle\"}[1m]) * 100)",
                "legendFormat": "CPU {{ cpu }}",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "custom": {
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  },
                  "scaleDistribution": {
                    "type": "linear"
                  }
                }
              }
            },
            "options": {
              "calculate": true,
              "yAxis": {
                "unit": "percent",
                "decimals": 0
              },
              "rowsFrame": {
                "layout": "auto"
              },
              "cellGap": 1,
              "color": {
                "mode": "scheme",
                "scheme": "Turbo",
                "steps": 256
              }
            },
            "gridPos": {"h": 10, "w": 12, "x": 0, "y": 11}
          },
          {
            "id": 10,
            "title": "Memory Breakdown",
            "type": "piechart",
            "targets": [
              {
                "expr": "node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes",
                "legendFormat": "Used",
                "refId": "A"
              },
              {
                "expr": "node_memory_Cached_bytes",
                "legendFormat": "Cached",
                "refId": "B"
              },
              {
                "expr": "node_memory_Buffers_bytes",
                "legendFormat": "Buffers",
                "refId": "C"
              },
              {
                "expr": "node_memory_MemFree_bytes",
                "legendFormat": "Free",
                "refId": "D"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "bytes"
              }
            },
            "options": {
              "pieType": "donut",
              "displayLabels": ["name", "percent"],
              "legendDisplayMode": "table",
              "legendPlacement": "right"
            },
            "gridPos": {"h": 10, "w": 12, "x": 12, "y": 11}
          },
          {
            "id": 11,
            "title": "Disk I/O Performance",
            "type": "timeseries",
            "targets": [
              {
                "expr": "rate(node_disk_read_bytes_total[5m])",
                "legendFormat": "Read - {{ device }}",
                "refId": "A"
              },
              {
                "expr": "rate(node_disk_written_bytes_total[5m])",
                "legendFormat": "Write - {{ device }}",
                "refId": "B"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "Bps"
              }
            },
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 21}
          },
          {
            "id": 12,
            "title": "Network I/O",
            "type": "timeseries",
            "targets": [
              {
                "expr": "rate(node_network_receive_bytes_total{device!~\"lo|docker.*|veth.*\"}[5m])",
                "legendFormat": "RX - {{ device }}",
                "refId": "A"
              },
              {
                "expr": "rate(node_network_transmit_bytes_total{device!~\"lo|docker.*|veth.*\"}[5m])",
                "legendFormat": "TX - {{ device }}",
                "refId": "B"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "Bps"
              }
            },
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 21}
          },
          {
            "id": 13,
            "title": "File System Usage",
            "type": "bargauge",
            "targets": [
              {
                "expr": "100 - ((node_filesystem_avail_bytes{fstype!~\"tmpfs|fuse.lxcfs|squashfs|vfat\"} * 100) / node_filesystem_size_bytes{fstype!~\"tmpfs|fuse.lxcfs|squashfs|vfat\"})",
                "legendFormat": "{{ mountpoint }}",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "percent",
                "min": 0,
                "max": 100,
                "thresholds": {
                  "steps": [
                    {"color": "green", "value": null},
                    {"color": "yellow", "value": 70},
                    {"color": "orange", "value": 85},
                    {"color": "red", "value": 95}
                  ]
                }
              }
            },
            "options": {
              "orientation": "horizontal",
              "displayMode": "gradient"
            },
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 29}
          },
          {
            "id": 14,
            "title": "Power Supply & Battery",
            "type": "stat",
            "targets": [
              {
                "expr": "node_power_supply_capacity",
                "legendFormat": "Battery Level",
                "refId": "A"
              },
              {
                "expr": "node_power_supply_online",
                "legendFormat": "AC Power",
                "refId": "B"
              },
              {
                "expr": "node_power_supply_voltage_min_design / 1000000",
                "legendFormat": "Voltage",
                "refId": "C"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "percent"
              },
              "overrides": [
                {
                  "matcher": {"id": "byName", "options": "AC Power"},
                  "properties": [
                    {"id": "unit", "value": "short"},
                    {"id": "mappings", "value": [
                      {"type": "value", "value": "0", "text": "Unplugged"},
                      {"type": "value", "value": "1", "text": "Plugged In"}
                    ]}
                  ]
                },
                {
                  "matcher": {"id": "byName", "options": "Voltage"},
                  "properties": [{"id": "unit", "value": "volt"}]
                }
              ]
            },
            "gridPos": {"h": 6, "w": 8, "x": 0, "y": 37}
          },
          {
            "id": 15,
            "title": "System Load Trend",
            "type": "timeseries",
            "targets": [
              {
                "expr": "node_load1",
                "legendFormat": "1 min",
                "refId": "A"
              },
              {
                "expr": "node_load5",
                "legendFormat": "5 min",
                "refId": "B"
              },
              {
                "expr": "node_load15",
                "legendFormat": "15 min",
                "refId": "C"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "short"
              }
            },
            "gridPos": {"h": 6, "w": 8, "x": 8, "y": 37}
          },
          {
            "id": 16,
            "title": "Context Switches & Interrupts",
            "type": "timeseries",
            "targets": [
              {
                "expr": "rate(node_context_switches_total[5m])",
                "legendFormat": "Context Switches/sec",
                "refId": "A"
              },
              {
                "expr": "rate(node_intr_total[5m])",
                "legendFormat": "Interrupts/sec",
                "refId": "B"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "ops"
              }
            },
            "gridPos": {"h": 6, "w": 8, "x": 16, "y": 37}
          }
        ]
      }
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"razerblade-18-system.json":"{\n  \"id\": null,\n  \"title\": \"Razer Blade 18 - System Overview\",\n  \"description\": \"Comprehensive system monitoring for Razer Blade 18 running Ubuntu 22.04\",\n  \"tags\": [\"system\", \"razerblade\", \"performance\", \"showcase\"],\n  \"style\": \"dark\",\n  \"timezone\": \"browser\",\n  \"refresh\": \"5s\",\n  \"schemaVersion\": 27,\n  \"version\": 1,\n  \"time\": {\n    \"from\": \"now-3h\",\n    \"to\": \"now\"\n  },\n  \"panels\": [\n    {\n      \"id\": 1,\n      \"title\": \"System Information\",\n      \"type\": \"stat\",\n      \"targets\": [\n        {\n          \"expr\": \"node_uname_info{nodename=\\\"razerblade-18-rz09-0484\\\"}\",\n          \"legendFormat\": \"{{ nodename }}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"options\": {\n        \"textMode\": \"name\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"custom\": {\n            \"align\": \"center\",\n            \"textMode\": \"value\"\n          }\n        }\n      },\n      \"gridPos\": {\"h\": 3, \"w\": 6, \"x\": 0, \"y\": 0}\n    },\n    {\n      \"id\": 2,\n      \"title\": \"Uptime\",\n      \"type\": \"stat\",\n      \"targets\": [\n        {\n          \"expr\": \"time() - node_boot_time_seconds\",\n          \"legendFormat\": \"Uptime\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"s\"\n        }\n      },\n      \"gridPos\": {\"h\": 3, \"w\": 6, \"x\": 6, \"y\": 0}\n    },\n    {\n      \"id\": 3,\n      \"title\": \"CPU Model\",\n      \"type\": \"stat\",\n      \"targets\": [\n        {\n          \"expr\": \"count(node_cpu_seconds_total{mode=\\\"idle\\\"})\",\n          \"legendFormat\": \"CPU Cores\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"mappings\": [\n            {\"type\": \"value\", \"value\": \"32\", \"text\": \"Intel i9-14900HX (32 cores)\"}\n          ]\n        }\n      },\n      \"gridPos\": {\"h\": 3, \"w\": 6, \"x\": 12, \"y\": 0}\n    },\n    {\n      \"id\": 4,\n      \"title\": \"GPU Status\",\n      \"type\": \"stat\",\n      \"targets\": [\n        {\n          \"expr\": \"1\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"mappings\": [\n            {\"type\": \"value\", \"value\": \"1\", \"text\": \"NVIDIA RTX 4080\"}\n          ]\n        }\n      },\n      \"gridPos\": {\"h\": 3, \"w\": 6, \"x\": 18, \"y\": 0}\n    },\n    {\n      \"id\": 5,\n      \"title\": \"CPU Usage\",\n      \"type\": \"gauge\",\n      \"targets\": [\n        {\n          \"expr\": \"100 - (avg(rate(node_cpu_seconds_total{mode=\\\"idle\\\"}[1m])) * 100)\",\n          \"legendFormat\": \"CPU Usage\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"percent\",\n          \"min\": 0,\n          \"max\": 100,\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 60},\n              {\"color\": \"orange\", \"value\": 80},\n              {\"color\": \"red\", \"value\": 90}\n            ]\n          }\n        }\n      },\n      \"gridPos\": {\"h\": 8, \"w\": 6, \"x\": 0, \"y\": 3}\n    },\n    {\n      \"id\": 6,\n      \"title\": \"Memory Usage\",\n      \"type\": \"gauge\",\n      \"targets\": [\n        {\n          \"expr\": \"(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100\",\n          \"legendFormat\": \"Memory Usage\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"percent\",\n          \"min\": 0,\n          \"max\": 100,\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 70},\n              {\"color\": \"orange\", \"value\": 85},\n              {\"color\": \"red\", \"value\": 95}\n            ]\n          }\n        }\n      },\n      \"gridPos\": {\"h\": 8, \"w\": 6, \"x\": 6, \"y\": 3}\n    },\n    {\n      \"id\": 7,\n      \"title\": \"CPU \u0026 Memory Details\",\n      \"type\": \"stat\",\n      \"targets\": [\n        {\n          \"expr\": \"node_memory_MemTotal_bytes\",\n          \"legendFormat\": \"Total Memory\",\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"node_memory_MemAvailable_bytes\",\n          \"legendFormat\": \"Available Memory\",\n          \"refId\": \"B\"\n        },\n        {\n          \"expr\": \"node_load15\",\n          \"legendFormat\": \"Load Average (15m)\",\n          \"refId\": \"C\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"bytes\"\n        },\n        \"overrides\": [\n          {\n            \"matcher\": {\"id\": \"byName\", \"options\": \"Load Average (15m)\"},\n            \"properties\": [{\"id\": \"unit\", \"value\": \"short\"}]\n          }\n        ]\n      },\n      \"gridPos\": {\"h\": 8, \"w\": 6, \"x\": 12, \"y\": 3}\n    },\n    {\n      \"id\": 8,\n      \"title\": \"System Temperatures\",\n      \"type\": \"timeseries\",\n      \"targets\": [\n        {\n          \"expr\": \"node_hwmon_temp_celsius\",\n          \"legendFormat\": \"{{ chip }} - {{ sensor }}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"celsius\",\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"blue\", \"value\": null},\n              {\"color\": \"green\", \"value\": 40},\n              {\"color\": \"yellow\", \"value\": 60},\n              {\"color\": \"orange\", \"value\": 75},\n              {\"color\": \"red\", \"value\": 85}\n            ]\n          }\n        }\n      },\n      \"gridPos\": {\"h\": 8, \"w\": 6, \"x\": 18, \"y\": 3}\n    },\n    {\n      \"id\": 9,\n      \"title\": \"CPU Usage by Core\",\n      \"type\": \"heatmap\",\n      \"targets\": [\n        {\n          \"expr\": \"100 - (rate(node_cpu_seconds_total{mode=\\\"idle\\\"}[1m]) * 100)\",\n          \"legendFormat\": \"CPU {{ cpu }}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"custom\": {\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            },\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            }\n          }\n        }\n      },\n      \"options\": {\n        \"calculate\": true,\n        \"yAxis\": {\n          \"unit\": \"percent\",\n          \"decimals\": 0\n        },\n        \"rowsFrame\": {\n          \"layout\": \"auto\"\n        },\n        \"cellGap\": 1,\n        \"color\": {\n          \"mode\": \"scheme\",\n          \"scheme\": \"Turbo\",\n          \"steps\": 256\n        }\n      },\n      \"gridPos\": {\"h\": 10, \"w\": 12, \"x\": 0, \"y\": 11}\n    },\n    {\n      \"id\": 10,\n      \"title\": \"Memory Breakdown\",\n      \"type\": \"piechart\",\n      \"targets\": [\n        {\n          \"expr\": \"node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes\",\n          \"legendFormat\": \"Used\",\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"node_memory_Cached_bytes\",\n          \"legendFormat\": \"Cached\",\n          \"refId\": \"B\"\n        },\n        {\n          \"expr\": \"node_memory_Buffers_bytes\",\n          \"legendFormat\": \"Buffers\",\n          \"refId\": \"C\"\n        },\n        {\n          \"expr\": \"node_memory_MemFree_bytes\",\n          \"legendFormat\": \"Free\",\n          \"refId\": \"D\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"bytes\"\n        }\n      },\n      \"options\": {\n        \"pieType\": \"donut\",\n        \"displayLabels\": [\"name\", \"percent\"],\n        \"legendDisplayMode\": \"table\",\n        \"legendPlacement\": \"right\"\n      },\n      \"gridPos\": {\"h\": 10, \"w\": 12, \"x\": 12, \"y\": 11}\n    },\n    {\n      \"id\": 11,\n      \"title\": \"Disk I/O Performance\",\n      \"type\": \"timeseries\",\n      \"targets\": [\n        {\n          \"expr\": \"rate(node_disk_read_bytes_total[5m])\",\n          \"legendFormat\": \"Read - {{ device }}\",\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"rate(node_disk_written_bytes_total[5m])\",\n          \"legendFormat\": \"Write - {{ device }}\",\n          \"refId\": \"B\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"Bps\"\n        }\n      },\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 21}\n    },\n    {\n      \"id\": 12,\n      \"title\": \"Network I/O\",\n      \"type\": \"timeseries\",\n      \"targets\": [\n        {\n          \"expr\": \"rate(node_network_receive_bytes_total{device!~\\\"lo|docker.*|veth.*\\\"}[5m])\",\n          \"legendFormat\": \"RX - {{ device }}\",\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"rate(node_network_transmit_bytes_total{device!~\\\"lo|docker.*|veth.*\\\"}[5m])\",\n          \"legendFormat\": \"TX - {{ device }}\",\n          \"refId\": \"B\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"Bps\"\n        }\n      },\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 21}\n    },\n    {\n      \"id\": 13,\n      \"title\": \"File System Usage\",\n      \"type\": \"bargauge\",\n      \"targets\": [\n        {\n          \"expr\": \"100 - ((node_filesystem_avail_bytes{fstype!~\\\"tmpfs|fuse.lxcfs|squashfs|vfat\\\"} * 100) / node_filesystem_size_bytes{fstype!~\\\"tmpfs|fuse.lxcfs|squashfs|vfat\\\"})\",\n          \"legendFormat\": \"{{ mountpoint }}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"percent\",\n          \"min\": 0,\n          \"max\": 100,\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 70},\n              {\"color\": \"orange\", \"value\": 85},\n              {\"color\": \"red\", \"value\": 95}\n            ]\n          }\n        }\n      },\n      \"options\": {\n        \"orientation\": \"horizontal\",\n        \"displayMode\": \"gradient\"\n      },\n      \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 29}\n    },\n    {\n      \"id\": 14,\n      \"title\": \"Power Supply \u0026 Battery\",\n      \"type\": \"stat\",\n      \"targets\": [\n        {\n          \"expr\": \"node_power_supply_capacity\",\n          \"legendFormat\": \"Battery Level\",\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"node_power_supply_online\",\n          \"legendFormat\": \"AC Power\",\n          \"refId\": \"B\"\n        },\n        {\n          \"expr\": \"node_power_supply_voltage_min_design / 1000000\",\n          \"legendFormat\": \"Voltage\",\n          \"refId\": \"C\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"percent\"\n        },\n        \"overrides\": [\n          {\n            \"matcher\": {\"id\": \"byName\", \"options\": \"AC Power\"},\n            \"properties\": [\n              {\"id\": \"unit\", \"value\": \"short\"},\n              {\"id\": \"mappings\", \"value\": [\n                {\"type\": \"value\", \"value\": \"0\", \"text\": \"Unplugged\"},\n                {\"type\": \"value\", \"value\": \"1\", \"text\": \"Plugged In\"}\n              ]}\n            ]\n          },\n          {\n            \"matcher\": {\"id\": \"byName\", \"options\": \"Voltage\"},\n            \"properties\": [{\"id\": \"unit\", \"value\": \"volt\"}]\n          }\n        ]\n      },\n      \"gridPos\": {\"h\": 6, \"w\": 8, \"x\": 0, \"y\": 37}\n    },\n    {\n      \"id\": 15,\n      \"title\": \"System Load Trend\",\n      \"type\": \"timeseries\",\n      \"targets\": [\n        {\n          \"expr\": \"node_load1\",\n          \"legendFormat\": \"1 min\",\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"node_load5\",\n          \"legendFormat\": \"5 min\",\n          \"refId\": \"B\"\n        },\n        {\n          \"expr\": \"node_load15\",\n          \"legendFormat\": \"15 min\",\n          \"refId\": \"C\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\"\n        }\n      },\n      \"gridPos\": {\"h\": 6, \"w\": 8, \"x\": 8, \"y\": 37}\n    },\n    {\n      \"id\": 16,\n      \"title\": \"Context Switches \u0026 Interrupts\",\n      \"type\": \"timeseries\",\n      \"targets\": [\n        {\n          \"expr\": \"rate(node_context_switches_total[5m])\",\n          \"legendFormat\": \"Context Switches/sec\",\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"rate(node_intr_total[5m])\",\n          \"legendFormat\": \"Interrupts/sec\",\n          \"refId\": \"B\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"ops\"\n        }\n      },\n      \"gridPos\": {\"h\": 6, \"w\": 8, \"x\": 16, \"y\": 37}\n    }\n  ]\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"razerblade-system-dashboard","namespace":"monitoring"}}
    creationTimestamp: "2025-05-27T23:16:56Z"
    name: razerblade-system-dashboard
    namespace: monitoring
    resourceVersion: "3993"
    uid: 0a46d081-6320-4b52-a7d5-e41557ec0e6a
- apiVersion: v1
  data:
    service-endpoint-rules.yml: "groups:\n- name: service_endpoint_monitoring\n  rules:\n
      \ - alert: ServiceHasNoEndpoints\n    expr: |\n      kube_service_info{namespace=\"monitoring\"}\n
      \     unless on(service,namespace) \n      kube_endpoint_info{namespace=\"monitoring\"}\n
      \   for: 5m\n    labels:\n      severity: warning\n      component: service-discovery\n
      \   annotations:\n      summary: \"Service {{ $labels.service }} has no active
      endpoints\"\n      description: \"Service {{ $labels.service }} in namespace
      {{ $labels.namespace }} has been without endpoints for more than 5 minutes\"\n
      \     \n  - alert: EndpointNotReady\n    expr: |\n      kube_endpoint_info{namespace=\"monitoring\"}
      \n      unless on(endpoint,namespace) \n      kube_endpoint_ready{namespace=\"monitoring\"}\n
      \   for: 2m\n    labels:\n      severity: warning\n      component: service-discovery\n
      \   annotations:\n      summary: \"Endpoint {{ $labels.endpoint }} is not ready\"\n
      \     description: \"Endpoint {{ $labels.endpoint }} in service {{ $labels.service
      }} is not ready\"\n      \n  - alert: PrometheusTargetMissing\n    expr: |\n
      \     up{job=~\"kubernetes-service-discovery\"} == 0\n    for: 3m\n    labels:\n
      \     severity: warning\n      component: prometheus\n    annotations:\n      summary:
      \"Prometheus target {{ $labels.instance }} is down\"\n      description: \"Prometheus
      target {{ $labels.instance }} from job {{ $labels.job }} has been down for more
      than 3 minutes\"\n      \n  - alert: ServiceDiscoveryErrors\n    expr: |\n      rate(prometheus_sd_kubernetes_events_total{event=\"delete\"}[5m])
      > \n      rate(prometheus_sd_kubernetes_events_total{event=\"add\"}[5m]) * 2\n
      \   for: 10m\n    labels:\n      severity: warning\n      component: service-discovery\n
      \   annotations:\n      summary: \"High service discovery churn detected\"\n
      \     description: \"Kubernetes service discovery is showing high delete rate
      compared to add rate\"\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"service-endpoint-rules.yml":"groups:\n- name: service_endpoint_monitoring\n  rules:\n  - alert: ServiceHasNoEndpoints\n    expr: |\n      kube_service_info{namespace=\"monitoring\"}\n      unless on(service,namespace) \n      kube_endpoint_info{namespace=\"monitoring\"}\n    for: 5m\n    labels:\n      severity: warning\n      component: service-discovery\n    annotations:\n      summary: \"Service {{ $labels.service }} has no active endpoints\"\n      description: \"Service {{ $labels.service }} in namespace {{ $labels.namespace }} has been without endpoints for more than 5 minutes\"\n      \n  - alert: EndpointNotReady\n    expr: |\n      kube_endpoint_info{namespace=\"monitoring\"} \n      unless on(endpoint,namespace) \n      kube_endpoint_ready{namespace=\"monitoring\"}\n    for: 2m\n    labels:\n      severity: warning\n      component: service-discovery\n    annotations:\n      summary: \"Endpoint {{ $labels.endpoint }} is not ready\"\n      description: \"Endpoint {{ $labels.endpoint }} in service {{ $labels.service }} is not ready\"\n      \n  - alert: PrometheusTargetMissing\n    expr: |\n      up{job=~\"kubernetes-service-discovery\"} == 0\n    for: 3m\n    labels:\n      severity: warning\n      component: prometheus\n    annotations:\n      summary: \"Prometheus target {{ $labels.instance }} is down\"\n      description: \"Prometheus target {{ $labels.instance }} from job {{ $labels.job }} has been down for more than 3 minutes\"\n      \n  - alert: ServiceDiscoveryErrors\n    expr: |\n      rate(prometheus_sd_kubernetes_events_total{event=\"delete\"}[5m]) \u003e \n      rate(prometheus_sd_kubernetes_events_total{event=\"add\"}[5m]) * 2\n    for: 10m\n    labels:\n      severity: warning\n      component: service-discovery\n    annotations:\n      summary: \"High service discovery churn detected\"\n      description: \"Kubernetes service discovery is showing high delete rate compared to add rate\"\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"service-endpoint-alerts","namespace":"monitoring"}}
    creationTimestamp: "2025-05-31T14:55:48Z"
    name: service-endpoint-alerts
    namespace: monitoring
    resourceVersion: "533073"
    uid: 189d093f-543e-46cf-871a-1ba5ea6fdf16
- apiVersion: v1
  data:
    simple-logs-dashboard.json: |
      {
        "id": null,
        "uid": "simple-logs",
        "title": "ODIN Simple Logs Dashboard",
        "tags": ["logs", "monitoring", "odin"],
        "timezone": "browser",
        "schemaVersion": 38,
        "version": 2,
        "refresh": "10s",
        "panels": [
          {
            "datasource": {
              "type": "loki",
              "uid": "loki"
            },
            "gridPos": {
              "h": 10,
              "w": 24,
              "x": 0,
              "y": 0
            },
            "id": 1,
            "options": {
              "dedupStrategy": "none",
              "enableLogDetails": true,
              "prettifyLogMessage": false,
              "showCommonLabels": false,
              "showLabels": true,
              "showTime": true,
              "sortOrder": "Descending",
              "wrapLogMessage": false
            },
            "targets": [
              {
                "datasource": {
                  "type": "loki",
                  "uid": "loki"
                },
                "editorMode": "code",
                "expr": "{namespace=\"monitoring\"} |~ \"(?i)error|warn|fail|critical|exception\" !~ \"Failed to update stats for container\" !~ \"binary.Read: invalid type int32\"",
                "legendFormat": "",
                "queryType": "range",
                "refId": "A"
              }
            ],
            "title": "All Monitoring Logs (Filtered)",
            "type": "logs"
          },
          {
            "datasource": {
              "type": "loki",
              "uid": "loki"
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 0,
              "y": 10
            },
            "id": 2,
            "options": {
              "dedupStrategy": "none",
              "enableLogDetails": true,
              "prettifyLogMessage": false,
              "showCommonLabels": false,
              "showLabels": false,
              "showTime": true,
              "sortOrder": "Descending",
              "wrapLogMessage": false
            },
            "targets": [
              {
                "datasource": {
                  "type": "loki",
                  "uid": "loki"
                },
                "editorMode": "code",
                "expr": "{namespace=\"monitoring\",pod=~\"prometheus-.*\"}",
                "queryType": "range",
                "refId": "A"
              }
            ],
            "title": "Prometheus Logs",
            "type": "logs"
          },
          {
            "datasource": {
              "type": "loki",
              "uid": "loki"
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 12,
              "y": 10
            },
            "id": 3,
            "options": {
              "dedupStrategy": "none",
              "enableLogDetails": true,
              "prettifyLogMessage": false,
              "showCommonLabels": false,
              "showLabels": false,
              "showTime": true,
              "sortOrder": "Descending",
              "wrapLogMessage": false
            },
            "targets": [
              {
                "datasource": {
                  "type": "loki",
                  "uid": "loki"
                },
                "editorMode": "code",
                "expr": "{namespace=\"monitoring\",pod=~\"grafana-.*\"}",
                "queryType": "range",
                "refId": "A"
              }
            ],
            "title": "Grafana Logs",
            "type": "logs"
          },
          {
            "datasource": {
              "type": "loki",
              "uid": "loki"
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 0,
              "y": 18
            },
            "id": 4,
            "options": {
              "dedupStrategy": "none",
              "enableLogDetails": true,
              "prettifyLogMessage": false,
              "showCommonLabels": false,
              "showLabels": false,
              "showTime": true,
              "sortOrder": "Descending",
              "wrapLogMessage": false
            },
            "targets": [
              {
                "datasource": {
                  "type": "loki",
                  "uid": "loki"
                },
                "editorMode": "code",
                "expr": "{namespace=\"monitoring\",pod=~\"loki-.*\"}",
                "queryType": "range",
                "refId": "A"
              }
            ],
            "title": "Loki Logs",
            "type": "logs"
          },
          {
            "datasource": {
              "type": "loki",
              "uid": "loki"
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 12,
              "y": 18
            },
            "id": 5,
            "options": {
              "dedupStrategy": "none",
              "enableLogDetails": true,
              "prettifyLogMessage": false,
              "showCommonLabels": false,
              "showLabels": false,
              "showTime": true,
              "sortOrder": "Descending",
              "wrapLogMessage": false
            },
            "targets": [
              {
                "datasource": {
                  "type": "loki",
                  "uid": "loki"
                },
                "editorMode": "code",
                "expr": "{namespace=\"monitoring\",pod=~\"alertmanager-.*\"}",
                "queryType": "range",
                "refId": "A"
              }
            ],
            "title": "AlertManager Logs",
            "type": "logs"
          },
          {
            "datasource": {
              "type": "loki",
              "uid": "loki"
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 0,
              "y": 26
            },
            "id": 6,
            "options": {
              "dedupStrategy": "none",
              "enableLogDetails": true,
              "prettifyLogMessage": false,
              "showCommonLabels": false,
              "showLabels": true,
              "showTime": true,
              "sortOrder": "Descending",
              "wrapLogMessage": false
            },
            "targets": [
              {
                "datasource": {
                  "type": "loki",
                  "uid": "loki"
                },
                "editorMode": "code",
                "expr": "{job=\"systemd-journal\"} |~ \"(?i)error|warn|fail|critical\"",
                "queryType": "range",
                "refId": "A"
              }
            ],
            "title": "System Logs",
            "type": "logs"
          },
          {
            "datasource": {
              "type": "loki",
              "uid": "loki"
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 12,
              "y": 26
            },
            "id": 7,
            "options": {
              "dedupStrategy": "none",
              "enableLogDetails": true,
              "prettifyLogMessage": false,
              "showCommonLabels": false,
              "showLabels": true,
              "showTime": true,
              "sortOrder": "Descending",
              "wrapLogMessage": false
            },
            "targets": [
              {
                "datasource": {
                  "type": "loki",
                  "uid": "loki"
                },
                "editorMode": "code",
                "expr": "{namespace=\"monitoring\"} |~ \"(?i)error|exception|fatal\" !~ \"Failed to update stats for container\" !~ \"binary.Read: invalid type int32\" !~ \"level=info\"",
                "queryType": "range",
                "refId": "A"
              }
            ],
            "title": "Error Logs (Filtered)",
            "type": "logs"
          },
          {
            "datasource": {
              "type": "loki",
              "uid": "loki"
            },
            "gridPos": {
              "h": 8,
              "w": 24,
              "x": 0,
              "y": 34
            },
            "id": 8,
            "options": {
              "dedupStrategy": "none",
              "enableLogDetails": true,
              "prettifyLogMessage": false,
              "showCommonLabels": false,
              "showLabels": true,
              "showTime": true,
              "sortOrder": "Descending",
              "wrapLogMessage": false
            },
            "targets": [
              {
                "datasource": {
                  "type": "loki",
                  "uid": "loki"
                },
                "editorMode": "code",
                "expr": "{namespace=\"monitoring\",pod=~\"cadvisor-.*\"} |~ \"Failed to update stats for container\"",
                "queryType": "range",
                "refId": "A"
              }
            ],
            "title": "cAdvisor Errors (Monitoring Only)",
            "type": "logs",
            "description": "These errors are non-critical and relate to cAdvisor's compatibility with systemd cgroups v2. They can be safely ignored."
          }
        ],
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "timepicker": {
          "refresh_intervals": ["5s", "10s", "30s", "1m", "5m", "15m", "30m", "1h", "2h", "1d"]
        },
        "templating": {
          "list": []
        }
      }
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"simple-logs-dashboard.json":"{\n  \"id\": null,\n  \"uid\": \"simple-logs\",\n  \"title\": \"ODIN Simple Logs Dashboard\",\n  \"tags\": [\"logs\", \"monitoring\", \"odin\"],\n  \"timezone\": \"browser\",\n  \"schemaVersion\": 38,\n  \"version\": 2,\n  \"refresh\": \"10s\",\n  \"panels\": [\n    {\n      \"datasource\": {\n        \"type\": \"loki\",\n        \"uid\": \"loki\"\n      },\n      \"gridPos\": {\n        \"h\": 10,\n        \"w\": 24,\n        \"x\": 0,\n        \"y\": 0\n      },\n      \"id\": 1,\n      \"options\": {\n        \"dedupStrategy\": \"none\",\n        \"enableLogDetails\": true,\n        \"prettifyLogMessage\": false,\n        \"showCommonLabels\": false,\n        \"showLabels\": true,\n        \"showTime\": true,\n        \"sortOrder\": \"Descending\",\n        \"wrapLogMessage\": false\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"loki\",\n            \"uid\": \"loki\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"{namespace=\\\"monitoring\\\"} |~ \\\"(?i)error|warn|fail|critical|exception\\\" !~ \\\"Failed to update stats for container\\\" !~ \\\"binary.Read: invalid type int32\\\"\",\n          \"legendFormat\": \"\",\n          \"queryType\": \"range\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"All Monitoring Logs (Filtered)\",\n      \"type\": \"logs\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"loki\",\n        \"uid\": \"loki\"\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 0,\n        \"y\": 10\n      },\n      \"id\": 2,\n      \"options\": {\n        \"dedupStrategy\": \"none\",\n        \"enableLogDetails\": true,\n        \"prettifyLogMessage\": false,\n        \"showCommonLabels\": false,\n        \"showLabels\": false,\n        \"showTime\": true,\n        \"sortOrder\": \"Descending\",\n        \"wrapLogMessage\": false\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"loki\",\n            \"uid\": \"loki\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"{namespace=\\\"monitoring\\\",pod=~\\\"prometheus-.*\\\"}\",\n          \"queryType\": \"range\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Prometheus Logs\",\n      \"type\": \"logs\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"loki\",\n        \"uid\": \"loki\"\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 10\n      },\n      \"id\": 3,\n      \"options\": {\n        \"dedupStrategy\": \"none\",\n        \"enableLogDetails\": true,\n        \"prettifyLogMessage\": false,\n        \"showCommonLabels\": false,\n        \"showLabels\": false,\n        \"showTime\": true,\n        \"sortOrder\": \"Descending\",\n        \"wrapLogMessage\": false\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"loki\",\n            \"uid\": \"loki\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"{namespace=\\\"monitoring\\\",pod=~\\\"grafana-.*\\\"}\",\n          \"queryType\": \"range\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Grafana Logs\",\n      \"type\": \"logs\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"loki\",\n        \"uid\": \"loki\"\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 0,\n        \"y\": 18\n      },\n      \"id\": 4,\n      \"options\": {\n        \"dedupStrategy\": \"none\",\n        \"enableLogDetails\": true,\n        \"prettifyLogMessage\": false,\n        \"showCommonLabels\": false,\n        \"showLabels\": false,\n        \"showTime\": true,\n        \"sortOrder\": \"Descending\",\n        \"wrapLogMessage\": false\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"loki\",\n            \"uid\": \"loki\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"{namespace=\\\"monitoring\\\",pod=~\\\"loki-.*\\\"}\",\n          \"queryType\": \"range\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Loki Logs\",\n      \"type\": \"logs\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"loki\",\n        \"uid\": \"loki\"\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 18\n      },\n      \"id\": 5,\n      \"options\": {\n        \"dedupStrategy\": \"none\",\n        \"enableLogDetails\": true,\n        \"prettifyLogMessage\": false,\n        \"showCommonLabels\": false,\n        \"showLabels\": false,\n        \"showTime\": true,\n        \"sortOrder\": \"Descending\",\n        \"wrapLogMessage\": false\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"loki\",\n            \"uid\": \"loki\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"{namespace=\\\"monitoring\\\",pod=~\\\"alertmanager-.*\\\"}\",\n          \"queryType\": \"range\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"AlertManager Logs\",\n      \"type\": \"logs\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"loki\",\n        \"uid\": \"loki\"\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 0,\n        \"y\": 26\n      },\n      \"id\": 6,\n      \"options\": {\n        \"dedupStrategy\": \"none\",\n        \"enableLogDetails\": true,\n        \"prettifyLogMessage\": false,\n        \"showCommonLabels\": false,\n        \"showLabels\": true,\n        \"showTime\": true,\n        \"sortOrder\": \"Descending\",\n        \"wrapLogMessage\": false\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"loki\",\n            \"uid\": \"loki\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"{job=\\\"systemd-journal\\\"} |~ \\\"(?i)error|warn|fail|critical\\\"\",\n          \"queryType\": \"range\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"System Logs\",\n      \"type\": \"logs\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"loki\",\n        \"uid\": \"loki\"\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 26\n      },\n      \"id\": 7,\n      \"options\": {\n        \"dedupStrategy\": \"none\",\n        \"enableLogDetails\": true,\n        \"prettifyLogMessage\": false,\n        \"showCommonLabels\": false,\n        \"showLabels\": true,\n        \"showTime\": true,\n        \"sortOrder\": \"Descending\",\n        \"wrapLogMessage\": false\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"loki\",\n            \"uid\": \"loki\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"{namespace=\\\"monitoring\\\"} |~ \\\"(?i)error|exception|fatal\\\" !~ \\\"Failed to update stats for container\\\" !~ \\\"binary.Read: invalid type int32\\\" !~ \\\"level=info\\\"\",\n          \"queryType\": \"range\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Error Logs (Filtered)\",\n      \"type\": \"logs\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"loki\",\n        \"uid\": \"loki\"\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 24,\n        \"x\": 0,\n        \"y\": 34\n      },\n      \"id\": 8,\n      \"options\": {\n        \"dedupStrategy\": \"none\",\n        \"enableLogDetails\": true,\n        \"prettifyLogMessage\": false,\n        \"showCommonLabels\": false,\n        \"showLabels\": true,\n        \"showTime\": true,\n        \"sortOrder\": \"Descending\",\n        \"wrapLogMessage\": false\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"loki\",\n            \"uid\": \"loki\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"{namespace=\\\"monitoring\\\",pod=~\\\"cadvisor-.*\\\"} |~ \\\"Failed to update stats for container\\\"\",\n          \"queryType\": \"range\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"cAdvisor Errors (Monitoring Only)\",\n      \"type\": \"logs\",\n      \"description\": \"These errors are non-critical and relate to cAdvisor's compatibility with systemd cgroups v2. They can be safely ignored.\"\n    }\n  ],\n  \"time\": {\n    \"from\": \"now-1h\",\n    \"to\": \"now\"\n  },\n  \"timepicker\": {\n    \"refresh_intervals\": [\"5s\", \"10s\", \"30s\", \"1m\", \"5m\", \"15m\", \"30m\", \"1h\", \"2h\", \"1d\"]\n  },\n  \"templating\": {\n    \"list\": []\n  }\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"simple-logs-dashboard","namespace":"monitoring"}}
    creationTimestamp: "2025-05-28T03:35:01Z"
    name: simple-logs-dashboard
    namespace: monitoring
    resourceVersion: "562721"
    uid: 318c9947-d8a5-4733-8078-727852f3c3fe
- apiVersion: v1
  data:
    simple-logs-dashboard.json: |
      {
        "id": null,
        "uid": "simple-logs-fixed",
        "title": "ODIN Simple Logs Dashboard (Fixed)",
        "tags": ["logs", "monitoring", "odin"],
        "timezone": "browser",
        "schemaVersion": 38,
        "version": 3,
        "refresh": "10s",
        "panels": [
          {
            "datasource": {
              "type": "loki",
              "uid": "loki"
            },
            "gridPos": {
              "h": 10,
              "w": 24,
              "x": 0,
              "y": 0
            },
            "id": 1,
            "options": {
              "dedupStrategy": "none",
              "enableLogDetails": true,
              "prettifyLogMessage": false,
              "showCommonLabels": false,
              "showLabels": true,
              "showTime": true,
              "sortOrder": "Descending",
              "wrapLogMessage": false
            },
            "targets": [
              {
                "datasource": {
                  "type": "loki",
                  "uid": "loki"
                },
                "editorMode": "code",
                "expr": "{namespace=\"monitoring\"} |~ \"(?i)error|warn|fail|critical|exception\" !~ \"Failed to update stats for container\" !~ \"binary.Read: invalid type int32\"",
                "legendFormat": "",
                "queryType": "range",
                "refId": "A"
              }
            ],
            "title": "All Monitoring Logs (Filtered)",
            "type": "logs"
          },
          {
            "datasource": {
              "type": "loki",
              "uid": "loki"
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 0,
              "y": 10
            },
            "id": 2,
            "options": {
              "dedupStrategy": "none",
              "enableLogDetails": true,
              "prettifyLogMessage": false,
              "showCommonLabels": false,
              "showLabels": false,
              "showTime": true,
              "sortOrder": "Descending",
              "wrapLogMessage": false
            },
            "targets": [
              {
                "datasource": {
                  "type": "loki",
                  "uid": "loki"
                },
                "editorMode": "code",
                "expr": "{namespace=\"monitoring\",pod=~\"prometheus-.*\"}",
                "queryType": "range",
                "refId": "A"
              }
            ],
            "title": "Prometheus Logs",
            "type": "logs"
          },
          {
            "datasource": {
              "type": "loki",
              "uid": "loki"
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 12,
              "y": 10
            },
            "id": 3,
            "options": {
              "dedupStrategy": "none",
              "enableLogDetails": true,
              "prettifyLogMessage": false,
              "showCommonLabels": false,
              "showLabels": false,
              "showTime": true,
              "sortOrder": "Descending",
              "wrapLogMessage": false
            },
            "targets": [
              {
                "datasource": {
                  "type": "loki",
                  "uid": "loki"
                },
                "editorMode": "code",
                "expr": "{namespace=\"monitoring\",pod=~\"grafana-.*\"}",
                "queryType": "range",
                "refId": "A"
              }
            ],
            "title": "Grafana Logs",
            "type": "logs"
          },
          {
            "datasource": {
              "type": "loki",
              "uid": "loki"
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 0,
              "y": 18
            },
            "id": 4,
            "options": {
              "dedupStrategy": "none",
              "enableLogDetails": true,
              "prettifyLogMessage": false,
              "showCommonLabels": false,
              "showLabels": false,
              "showTime": true,
              "sortOrder": "Descending",
              "wrapLogMessage": false
            },
            "targets": [
              {
                "datasource": {
                  "type": "loki",
                  "uid": "loki"
                },
                "editorMode": "code",
                "expr": "{namespace=\"monitoring\",pod=~\"loki-.*\"}",
                "queryType": "range",
                "refId": "A"
              }
            ],
            "title": "Loki Logs",
            "type": "logs"
          },
          {
            "datasource": {
              "type": "loki",
              "uid": "loki"
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 12,
              "y": 18
            },
            "id": 5,
            "options": {
              "dedupStrategy": "none",
              "enableLogDetails": true,
              "prettifyLogMessage": false,
              "showCommonLabels": false,
              "showLabels": false,
              "showTime": true,
              "sortOrder": "Descending",
              "wrapLogMessage": false
            },
            "targets": [
              {
                "datasource": {
                  "type": "loki",
                  "uid": "loki"
                },
                "editorMode": "code",
                "expr": "{namespace=\"monitoring\",pod=~\"alertmanager-.*\"}",
                "queryType": "range",
                "refId": "A"
              }
            ],
            "title": "AlertManager Logs",
            "type": "logs"
          },
          {
            "datasource": {
              "type": "loki",
              "uid": "loki"
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 0,
              "y": 26
            },
            "id": 6,
            "options": {
              "dedupStrategy": "none",
              "enableLogDetails": true,
              "prettifyLogMessage": false,
              "showCommonLabels": false,
              "showLabels": true,
              "showTime": true,
              "sortOrder": "Descending",
              "wrapLogMessage": false
            },
            "targets": [
              {
                "datasource": {
                  "type": "loki",
                  "uid": "loki"
                },
                "editorMode": "code",
                "expr": "{job=\"systemd-journal\"} |~ \"(?i)error|warn|fail|critical\"",
                "queryType": "range",
                "refId": "A"
              }
            ],
            "title": "System Logs",
            "type": "logs"
          },
          {
            "datasource": {
              "type": "loki",
              "uid": "loki"
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 12,
              "y": 26
            },
            "id": 7,
            "options": {
              "dedupStrategy": "none",
              "enableLogDetails": true,
              "prettifyLogMessage": false,
              "showCommonLabels": false,
              "showLabels": true,
              "showTime": true,
              "sortOrder": "Descending",
              "wrapLogMessage": false
            },
            "targets": [
              {
                "datasource": {
                  "type": "loki",
                  "uid": "loki"
                },
                "editorMode": "code",
                "expr": "{namespace=\"monitoring\"} |~ \"(?i)error|exception|fatal\" !~ \"Failed to update stats for container\" !~ \"binary.Read: invalid type int32\" !~ \"level=info\"",
                "queryType": "range",
                "refId": "A"
              }
            ],
            "title": "Error Logs (Filtered)",
            "type": "logs"
          },
          {
            "datasource": {
              "type": "loki",
              "uid": "loki"
            },
            "gridPos": {
              "h": 8,
              "w": 24,
              "x": 0,
              "y": 34
            },
            "id": 8,
            "options": {
              "dedupStrategy": "none",
              "enableLogDetails": true,
              "prettifyLogMessage": false,
              "showCommonLabels": false,
              "showLabels": true,
              "showTime": true,
              "sortOrder": "Descending",
              "wrapLogMessage": false
            },
            "targets": [
              {
                "datasource": {
                  "type": "loki",
                  "uid": "loki"
                },
                "editorMode": "code",
                "expr": "{namespace=\"monitoring\",pod=~\"cadvisor-.*\"} |~ \"Failed to update stats for container\"",
                "queryType": "range",
                "refId": "A"
              }
            ],
            "title": "cAdvisor Errors (Monitoring Only)",
            "type": "logs",
            "description": "These errors are non-critical and relate to cAdvisor's compatibility with systemd cgroups v2. They can be safely ignored."
          },
          {
            "datasource": {
              "type": "loki",
              "uid": "loki"
            },
            "gridPos": {
              "h": 8,
              "w": 24,
              "x": 0,
              "y": 42
            },
            "id": 9,
            "options": {
              "dedupStrategy": "none",
              "enableLogDetails": true,
              "prettifyLogMessage": false,
              "showCommonLabels": false,
              "showLabels": true,
              "showTime": true,
              "sortOrder": "Descending",
              "wrapLogMessage": false
            },
            "targets": [
              {
                "datasource": {
                  "type": "loki",
                  "uid": "loki"
                },
                "editorMode": "code",
                "expr": "{namespace=\"monitoring\"} |= \"level=warn\" !~ \"Failed to update stats for container\"",
                "queryType": "range",
                "refId": "A"
              }
            ],
            "title": "Warning Logs (Clean)",
            "type": "logs",
            "description": "Warning level logs filtered to exclude known non-critical messages"
          }
        ],
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "timepicker": {
          "refresh_intervals": ["5s", "10s", "30s", "1m", "5m", "15m", "30m", "1h", "2h", "1d"]
        },
        "templating": {
          "list": []
        }
      }
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"simple-logs-dashboard.json":"{\n  \"id\": null,\n  \"uid\": \"simple-logs-fixed\",\n  \"title\": \"ODIN Simple Logs Dashboard (Fixed)\",\n  \"tags\": [\"logs\", \"monitoring\", \"odin\"],\n  \"timezone\": \"browser\",\n  \"schemaVersion\": 38,\n  \"version\": 3,\n  \"refresh\": \"10s\",\n  \"panels\": [\n    {\n      \"datasource\": {\n        \"type\": \"loki\",\n        \"uid\": \"loki\"\n      },\n      \"gridPos\": {\n        \"h\": 10,\n        \"w\": 24,\n        \"x\": 0,\n        \"y\": 0\n      },\n      \"id\": 1,\n      \"options\": {\n        \"dedupStrategy\": \"none\",\n        \"enableLogDetails\": true,\n        \"prettifyLogMessage\": false,\n        \"showCommonLabels\": false,\n        \"showLabels\": true,\n        \"showTime\": true,\n        \"sortOrder\": \"Descending\",\n        \"wrapLogMessage\": false\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"loki\",\n            \"uid\": \"loki\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"{namespace=\\\"monitoring\\\"} |~ \\\"(?i)error|warn|fail|critical|exception\\\" !~ \\\"Failed to update stats for container\\\" !~ \\\"binary.Read: invalid type int32\\\"\",\n          \"legendFormat\": \"\",\n          \"queryType\": \"range\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"All Monitoring Logs (Filtered)\",\n      \"type\": \"logs\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"loki\",\n        \"uid\": \"loki\"\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 0,\n        \"y\": 10\n      },\n      \"id\": 2,\n      \"options\": {\n        \"dedupStrategy\": \"none\",\n        \"enableLogDetails\": true,\n        \"prettifyLogMessage\": false,\n        \"showCommonLabels\": false,\n        \"showLabels\": false,\n        \"showTime\": true,\n        \"sortOrder\": \"Descending\",\n        \"wrapLogMessage\": false\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"loki\",\n            \"uid\": \"loki\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"{namespace=\\\"monitoring\\\",pod=~\\\"prometheus-.*\\\"}\",\n          \"queryType\": \"range\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Prometheus Logs\",\n      \"type\": \"logs\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"loki\",\n        \"uid\": \"loki\"\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 10\n      },\n      \"id\": 3,\n      \"options\": {\n        \"dedupStrategy\": \"none\",\n        \"enableLogDetails\": true,\n        \"prettifyLogMessage\": false,\n        \"showCommonLabels\": false,\n        \"showLabels\": false,\n        \"showTime\": true,\n        \"sortOrder\": \"Descending\",\n        \"wrapLogMessage\": false\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"loki\",\n            \"uid\": \"loki\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"{namespace=\\\"monitoring\\\",pod=~\\\"grafana-.*\\\"}\",\n          \"queryType\": \"range\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Grafana Logs\",\n      \"type\": \"logs\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"loki\",\n        \"uid\": \"loki\"\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 0,\n        \"y\": 18\n      },\n      \"id\": 4,\n      \"options\": {\n        \"dedupStrategy\": \"none\",\n        \"enableLogDetails\": true,\n        \"prettifyLogMessage\": false,\n        \"showCommonLabels\": false,\n        \"showLabels\": false,\n        \"showTime\": true,\n        \"sortOrder\": \"Descending\",\n        \"wrapLogMessage\": false\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"loki\",\n            \"uid\": \"loki\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"{namespace=\\\"monitoring\\\",pod=~\\\"loki-.*\\\"}\",\n          \"queryType\": \"range\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Loki Logs\",\n      \"type\": \"logs\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"loki\",\n        \"uid\": \"loki\"\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 18\n      },\n      \"id\": 5,\n      \"options\": {\n        \"dedupStrategy\": \"none\",\n        \"enableLogDetails\": true,\n        \"prettifyLogMessage\": false,\n        \"showCommonLabels\": false,\n        \"showLabels\": false,\n        \"showTime\": true,\n        \"sortOrder\": \"Descending\",\n        \"wrapLogMessage\": false\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"loki\",\n            \"uid\": \"loki\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"{namespace=\\\"monitoring\\\",pod=~\\\"alertmanager-.*\\\"}\",\n          \"queryType\": \"range\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"AlertManager Logs\",\n      \"type\": \"logs\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"loki\",\n        \"uid\": \"loki\"\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 0,\n        \"y\": 26\n      },\n      \"id\": 6,\n      \"options\": {\n        \"dedupStrategy\": \"none\",\n        \"enableLogDetails\": true,\n        \"prettifyLogMessage\": false,\n        \"showCommonLabels\": false,\n        \"showLabels\": true,\n        \"showTime\": true,\n        \"sortOrder\": \"Descending\",\n        \"wrapLogMessage\": false\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"loki\",\n            \"uid\": \"loki\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"{job=\\\"systemd-journal\\\"} |~ \\\"(?i)error|warn|fail|critical\\\"\",\n          \"queryType\": \"range\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"System Logs\",\n      \"type\": \"logs\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"loki\",\n        \"uid\": \"loki\"\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 26\n      },\n      \"id\": 7,\n      \"options\": {\n        \"dedupStrategy\": \"none\",\n        \"enableLogDetails\": true,\n        \"prettifyLogMessage\": false,\n        \"showCommonLabels\": false,\n        \"showLabels\": true,\n        \"showTime\": true,\n        \"sortOrder\": \"Descending\",\n        \"wrapLogMessage\": false\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"loki\",\n            \"uid\": \"loki\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"{namespace=\\\"monitoring\\\"} |~ \\\"(?i)error|exception|fatal\\\" !~ \\\"Failed to update stats for container\\\" !~ \\\"binary.Read: invalid type int32\\\" !~ \\\"level=info\\\"\",\n          \"queryType\": \"range\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Error Logs (Filtered)\",\n      \"type\": \"logs\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"loki\",\n        \"uid\": \"loki\"\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 24,\n        \"x\": 0,\n        \"y\": 34\n      },\n      \"id\": 8,\n      \"options\": {\n        \"dedupStrategy\": \"none\",\n        \"enableLogDetails\": true,\n        \"prettifyLogMessage\": false,\n        \"showCommonLabels\": false,\n        \"showLabels\": true,\n        \"showTime\": true,\n        \"sortOrder\": \"Descending\",\n        \"wrapLogMessage\": false\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"loki\",\n            \"uid\": \"loki\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"{namespace=\\\"monitoring\\\",pod=~\\\"cadvisor-.*\\\"} |~ \\\"Failed to update stats for container\\\"\",\n          \"queryType\": \"range\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"cAdvisor Errors (Monitoring Only)\",\n      \"type\": \"logs\",\n      \"description\": \"These errors are non-critical and relate to cAdvisor's compatibility with systemd cgroups v2. They can be safely ignored.\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"loki\",\n        \"uid\": \"loki\"\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 24,\n        \"x\": 0,\n        \"y\": 42\n      },\n      \"id\": 9,\n      \"options\": {\n        \"dedupStrategy\": \"none\",\n        \"enableLogDetails\": true,\n        \"prettifyLogMessage\": false,\n        \"showCommonLabels\": false,\n        \"showLabels\": true,\n        \"showTime\": true,\n        \"sortOrder\": \"Descending\",\n        \"wrapLogMessage\": false\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"loki\",\n            \"uid\": \"loki\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"{namespace=\\\"monitoring\\\"} |= \\\"level=warn\\\" !~ \\\"Failed to update stats for container\\\"\",\n          \"queryType\": \"range\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Warning Logs (Clean)\",\n      \"type\": \"logs\",\n      \"description\": \"Warning level logs filtered to exclude known non-critical messages\"\n    }\n  ],\n  \"time\": {\n    \"from\": \"now-1h\",\n    \"to\": \"now\"\n  },\n  \"timepicker\": {\n    \"refresh_intervals\": [\"5s\", \"10s\", \"30s\", \"1m\", \"5m\", \"15m\", \"30m\", \"1h\", \"2h\", \"1d\"]\n  },\n  \"templating\": {\n    \"list\": []\n  }\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"simple-logs-dashboard-fixed","namespace":"monitoring"}}
    creationTimestamp: "2025-05-31T16:03:21Z"
    name: simple-logs-dashboard-fixed
    namespace: monitoring
    resourceVersion: "562424"
    uid: 86a94810-25e6-425d-b942-5b7fe5a530b7
- apiVersion: v1
  data:
    sli-slo-rules.yml: "groups:\n- name: odin_sli_recording_rules\n  interval: 30s\n
      \ rules:\n  # ODIN Stack Availability SLI\n  - record: odin:sli:availability\n
      \   expr: |\n      avg_over_time(up{job=~\"prometheus|grafana|alertmanager|loki\"}[5m])\n
      \   labels:\n      sli_type: availability\n      service: odin-core\n      \n
      \ # ODIN Stack Error Rate SLI  \n  - record: odin:sli:error_rate\n    expr:
      |\n      (\n        rate(prometheus_http_requests_total{code=~\"5..\"}[5m])
      +\n        rate(grafana_http_request_duration_seconds_count{status_code=~\"5..\"}[5m])\n
      \     ) / (\n        rate(prometheus_http_requests_total[5m]) +\n        rate(grafana_http_request_duration_seconds_count[5m])\n
      \     )\n    labels:\n      sli_type: error_rate\n      service: odin-core\n
      \     \n  # ODIN Stack Response Time SLI (95th percentile)\n  - record: odin:sli:latency_p95\n
      \   expr: |\n      histogram_quantile(0.95,\n        rate(prometheus_http_request_duration_seconds_bucket[5m])
      +\n        rate(grafana_http_request_duration_seconds_bucket[5m])\n      )\n
      \   labels:\n      sli_type: latency\n      service: odin-core\n      \n  #
      GPU Monitoring Availability SLI\n  - record: odin:sli:gpu_monitoring_availability\n
      \   expr: |\n      avg_over_time(up{job=~\"razer-exporter|power-exporter\"}[5m])\n
      \   labels:\n      sli_type: availability\n      service: gpu-monitoring\n      \n
      \ # Log Ingestion SLI\n  - record: odin:sli:log_ingestion_success_rate\n    expr:
      |\n      rate(loki_ingester_streams_created_total[5m]) / \n      (rate(loki_ingester_streams_created_total[5m])
      + rate(loki_ingester_streams_failed_total[5m]))\n    labels:\n      sli_type:
      success_rate\n      service: log-ingestion\n      \n  # Service Discovery Health
      SLI\n  - record: odin:sli:service_discovery_health\n    expr: |\n      (\n        sum(up{job=\"kubernetes-service-discovery\"})
      /\n        count(up{job=\"kubernetes-service-discovery\"})\n      )\n    labels:\n
      \     sli_type: availability\n      service: service-discovery\n      \n- name:
      odin_slo_alerting_rules\n  rules:\n  # SLO: 99.5% availability for core ODIN
      services\n  - alert: OdinCoreSLOBreach\n    expr: |\n      (\n        odin:sli:availability{service=\"odin-core\"}
      < 0.995\n      ) and (\n        odin:sli:availability{service=\"odin-core\"}
      offset 5m < 0.995\n      )\n    for: 2m\n    labels:\n      severity: critical\n
      \     slo: \"99.5%\"\n      service: odin-core\n      component: sli-slo\n    annotations:\n
      \     summary: \"ODIN Core SLO breach - Availability below 99.5%\"\n      description:
      \"ODIN core services availability is {{ $value | humanizePercentage }} (below
      99.5% SLO)\"\n      runbook_url: \"https://github.com/your-org/odin/wiki/runbooks/slo-breach\"\n
      \     \n  # SLO: Error rate below 1% \n  - alert: OdinCoreErrorRateSLOBreach\n
      \   expr: |\n      odin:sli:error_rate{service=\"odin-core\"} > 0.01\n    for:
      5m\n    labels:\n      severity: warning\n      slo: \"1%\"\n      service:
      odin-core\n      component: sli-slo\n    annotations:\n      summary: \"ODIN
      Core error rate SLO breach\"\n      description: \"ODIN core services error
      rate is {{ $value | humanizePercentage }} (above 1% SLO)\"\n      \n  # SLO:
      95th percentile response time below 2 seconds\n  - alert: OdinCoreLatencySLOBreach\n
      \   expr: |\n      odin:sli:latency_p95{service=\"odin-core\"} > 2\n    for:
      10m\n    labels:\n      severity: warning\n      slo: \"2s\"\n      service:
      odin-core\n      component: sli-slo\n    annotations:\n      summary: \"ODIN
      Core latency SLO breach\"\n      description: \"ODIN core services 95th percentile
      latency is {{ $value }}s (above 2s SLO)\"\n      \n  # SLO: GPU monitoring 98%
      availability\n  - alert: OdinGPUMonitoringSLOBreach\n    expr: |\n      odin:sli:gpu_monitoring_availability{service=\"gpu-monitoring\"}
      < 0.98\n    for: 15m\n    labels:\n      severity: warning\n      slo: \"98%\"\n
      \     service: gpu-monitoring\n      component: sli-slo\n    annotations:\n
      \     summary: \"GPU monitoring SLO breach\"\n      description: \"GPU monitoring
      availability is {{ $value | humanizePercentage }} (below 98% SLO)\"\n      \n
      \ # SLO: Log ingestion 99% success rate\n  - alert: OdinLogIngestionSLOBreach\n
      \   expr: |\n      odin:sli:log_ingestion_success_rate{service=\"log-ingestion\"}
      < 0.99\n    for: 10m\n    labels:\n      severity: warning\n      slo: \"99%\"\n
      \     service: log-ingestion\n      component: sli-slo\n    annotations:\n      summary:
      \"Log ingestion SLO breach\"\n      description: \"Log ingestion success rate
      is {{ $value | humanizePercentage }} (below 99% SLO)\"\n      \n  # Service
      Discovery Health SLO\n  - alert: OdinServiceDiscoverySLOBreach\n    expr: |\n
      \     odin:sli:service_discovery_health{service=\"service-discovery\"} < 0.95\n
      \   for: 5m\n    labels:\n      severity: warning\n      slo: \"95%\"\n      service:
      service-discovery\n      component: sli-slo\n    annotations:\n      summary:
      \"Service discovery SLO breach\"\n      description: \"Service discovery health
      is {{ $value | humanizePercentage }} (below 95% SLO)\"\n      \n- name: odin_burn_rate_alerts\n
      \ rules:\n  # Fast burn rate alert (1% budget in 1 hour = 2% budget in 5m)\n
      \ - alert: OdinSLOFastBurn\n    expr: |\n      (\n        odin:sli:availability{service=\"odin-core\"}
      < (1 - 14.4 * 0.005)  # 2.8% error budget burn in 5m\n      )\n    for: 2m\n
      \   labels:\n      severity: critical\n      burn_rate: fast\n      service:
      odin-core\n      component: sli-slo\n    annotations:\n      summary: \"ODIN
      SLO fast burn rate detected\"\n      description: \"ODIN availability {{ $value
      | humanizePercentage }} indicates fast error budget burn\"\n      \n  # Slow
      burn rate alert (5% budget in 6 hours = 0.83% in 1h)  \n  - alert: OdinSLOSlowBurn\n
      \   expr: |\n      (\n        odin:sli:availability{service=\"odin-core\"} <
      (1 - 6 * 0.005)  # 3% error budget burn in 1h\n      )\n    for: 15m\n    labels:\n
      \     severity: warning\n      burn_rate: slow\n      service: odin-core\n      component:
      sli-slo\n    annotations:\n      summary: \"ODIN SLO slow burn rate detected\"\n
      \     description: \"ODIN availability {{ $value | humanizePercentage }} indicates
      slow error budget burn\"\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"sli-slo-rules.yml":"groups:\n- name: odin_sli_recording_rules\n  interval: 30s\n  rules:\n  # ODIN Stack Availability SLI\n  - record: odin:sli:availability\n    expr: |\n      avg_over_time(up{job=~\"prometheus|grafana|alertmanager|loki\"}[5m])\n    labels:\n      sli_type: availability\n      service: odin-core\n      \n  # ODIN Stack Error Rate SLI  \n  - record: odin:sli:error_rate\n    expr: |\n      (\n        rate(prometheus_http_requests_total{code=~\"5..\"}[5m]) +\n        rate(grafana_http_request_duration_seconds_count{status_code=~\"5..\"}[5m])\n      ) / (\n        rate(prometheus_http_requests_total[5m]) +\n        rate(grafana_http_request_duration_seconds_count[5m])\n      )\n    labels:\n      sli_type: error_rate\n      service: odin-core\n      \n  # ODIN Stack Response Time SLI (95th percentile)\n  - record: odin:sli:latency_p95\n    expr: |\n      histogram_quantile(0.95,\n        rate(prometheus_http_request_duration_seconds_bucket[5m]) +\n        rate(grafana_http_request_duration_seconds_bucket[5m])\n      )\n    labels:\n      sli_type: latency\n      service: odin-core\n      \n  # GPU Monitoring Availability SLI\n  - record: odin:sli:gpu_monitoring_availability\n    expr: |\n      avg_over_time(up{job=~\"razer-exporter|power-exporter\"}[5m])\n    labels:\n      sli_type: availability\n      service: gpu-monitoring\n      \n  # Log Ingestion SLI\n  - record: odin:sli:log_ingestion_success_rate\n    expr: |\n      rate(loki_ingester_streams_created_total[5m]) / \n      (rate(loki_ingester_streams_created_total[5m]) + rate(loki_ingester_streams_failed_total[5m]))\n    labels:\n      sli_type: success_rate\n      service: log-ingestion\n      \n  # Service Discovery Health SLI\n  - record: odin:sli:service_discovery_health\n    expr: |\n      (\n        sum(up{job=\"kubernetes-service-discovery\"}) /\n        count(up{job=\"kubernetes-service-discovery\"})\n      )\n    labels:\n      sli_type: availability\n      service: service-discovery\n      \n- name: odin_slo_alerting_rules\n  rules:\n  # SLO: 99.5% availability for core ODIN services\n  - alert: OdinCoreSLOBreach\n    expr: |\n      (\n        odin:sli:availability{service=\"odin-core\"} \u003c 0.995\n      ) and (\n        odin:sli:availability{service=\"odin-core\"} offset 5m \u003c 0.995\n      )\n    for: 2m\n    labels:\n      severity: critical\n      slo: \"99.5%\"\n      service: odin-core\n      component: sli-slo\n    annotations:\n      summary: \"ODIN Core SLO breach - Availability below 99.5%\"\n      description: \"ODIN core services availability is {{ $value | humanizePercentage }} (below 99.5% SLO)\"\n      runbook_url: \"https://github.com/your-org/odin/wiki/runbooks/slo-breach\"\n      \n  # SLO: Error rate below 1% \n  - alert: OdinCoreErrorRateSLOBreach\n    expr: |\n      odin:sli:error_rate{service=\"odin-core\"} \u003e 0.01\n    for: 5m\n    labels:\n      severity: warning\n      slo: \"1%\"\n      service: odin-core\n      component: sli-slo\n    annotations:\n      summary: \"ODIN Core error rate SLO breach\"\n      description: \"ODIN core services error rate is {{ $value | humanizePercentage }} (above 1% SLO)\"\n      \n  # SLO: 95th percentile response time below 2 seconds\n  - alert: OdinCoreLatencySLOBreach\n    expr: |\n      odin:sli:latency_p95{service=\"odin-core\"} \u003e 2\n    for: 10m\n    labels:\n      severity: warning\n      slo: \"2s\"\n      service: odin-core\n      component: sli-slo\n    annotations:\n      summary: \"ODIN Core latency SLO breach\"\n      description: \"ODIN core services 95th percentile latency is {{ $value }}s (above 2s SLO)\"\n      \n  # SLO: GPU monitoring 98% availability\n  - alert: OdinGPUMonitoringSLOBreach\n    expr: |\n      odin:sli:gpu_monitoring_availability{service=\"gpu-monitoring\"} \u003c 0.98\n    for: 15m\n    labels:\n      severity: warning\n      slo: \"98%\"\n      service: gpu-monitoring\n      component: sli-slo\n    annotations:\n      summary: \"GPU monitoring SLO breach\"\n      description: \"GPU monitoring availability is {{ $value | humanizePercentage }} (below 98% SLO)\"\n      \n  # SLO: Log ingestion 99% success rate\n  - alert: OdinLogIngestionSLOBreach\n    expr: |\n      odin:sli:log_ingestion_success_rate{service=\"log-ingestion\"} \u003c 0.99\n    for: 10m\n    labels:\n      severity: warning\n      slo: \"99%\"\n      service: log-ingestion\n      component: sli-slo\n    annotations:\n      summary: \"Log ingestion SLO breach\"\n      description: \"Log ingestion success rate is {{ $value | humanizePercentage }} (below 99% SLO)\"\n      \n  # Service Discovery Health SLO\n  - alert: OdinServiceDiscoverySLOBreach\n    expr: |\n      odin:sli:service_discovery_health{service=\"service-discovery\"} \u003c 0.95\n    for: 5m\n    labels:\n      severity: warning\n      slo: \"95%\"\n      service: service-discovery\n      component: sli-slo\n    annotations:\n      summary: \"Service discovery SLO breach\"\n      description: \"Service discovery health is {{ $value | humanizePercentage }} (below 95% SLO)\"\n      \n- name: odin_burn_rate_alerts\n  rules:\n  # Fast burn rate alert (1% budget in 1 hour = 2% budget in 5m)\n  - alert: OdinSLOFastBurn\n    expr: |\n      (\n        odin:sli:availability{service=\"odin-core\"} \u003c (1 - 14.4 * 0.005)  # 2.8% error budget burn in 5m\n      )\n    for: 2m\n    labels:\n      severity: critical\n      burn_rate: fast\n      service: odin-core\n      component: sli-slo\n    annotations:\n      summary: \"ODIN SLO fast burn rate detected\"\n      description: \"ODIN availability {{ $value | humanizePercentage }} indicates fast error budget burn\"\n      \n  # Slow burn rate alert (5% budget in 6 hours = 0.83% in 1h)  \n  - alert: OdinSLOSlowBurn\n    expr: |\n      (\n        odin:sli:availability{service=\"odin-core\"} \u003c (1 - 6 * 0.005)  # 3% error budget burn in 1h\n      )\n    for: 15m\n    labels:\n      severity: warning\n      burn_rate: slow\n      service: odin-core\n      component: sli-slo\n    annotations:\n      summary: \"ODIN SLO slow burn rate detected\"\n      description: \"ODIN availability {{ $value | humanizePercentage }} indicates slow error budget burn\"\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"sli-slo-rules","namespace":"monitoring"}}
    creationTimestamp: "2025-05-31T15:04:17Z"
    name: sli-slo-rules
    namespace: monitoring
    resourceVersion: "536803"
    uid: 718214e9-903b-4a5f-9e6d-32596be328bf
- apiVersion: v1
  data:
    snmp.yml: |
      auths:
        public_v2:
          community: odin-monitoring
          security_level: noAuthNoPriv
          auth_protocol: ""
          priv_protocol: ""
          version: 2
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"snmp.yml":"auths:\n  public_v2:\n    community: odin-monitoring\n    security_level: noAuthNoPriv\n    auth_protocol: \"\"\n    priv_protocol: \"\"\n    version: 2\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"snmp-exporter-config","namespace":"monitoring"}}
    creationTimestamp: "2025-06-03T17:22:36Z"
    name: snmp-exporter-config
    namespace: monitoring
    resourceVersion: "2463171"
    uid: db280278-401b-4da3-a324-b43d21d724c2
- apiVersion: v1
  data:
    fluent-bit.conf: |
      [SERVICE]
          Flush         1
          Log_Level     info
          Daemon        off
          Parsers_File  parsers.conf
          HTTP_Server   On
          HTTP_Listen   0.0.0.0
          HTTP_Port     2020
          storage.path  /tmp/flb-storage/
          storage.sync  normal
          storage.checksum off
          storage.backlog.mem_limit 5M

      [INPUT]
          Name              syslog
          Mode              udp
          Listen            0.0.0.0
          Port              514
          Tag               unifi.router.syslog
          Parser            simple_syslog
          Buffer_Chunk_Size 32k
          Buffer_Max_Size   64k

      [INPUT]
          Name              syslog
          Mode              tcp
          Listen            0.0.0.0
          Port              515
          Tag               unifi.router.syslog
          Parser            simple_syslog
          Buffer_Chunk_Size 32k
          Buffer_Max_Size   64k

      [FILTER]
          Name    modify
          Match   *
          Add     job unifi-router
          Add     source_type syslog
          Add     router_ip 192.168.1.1

      [OUTPUT]
          Name            loki
          Match           *
          Host            loki.monitoring.svc.cluster.local
          Port            3100
          Labels          job=unifi-router,source_type=syslog,router_ip=192.168.1.1
          Remove_keys     message
          Line_format     json
    parsers.conf: |
      [PARSER]
          Name        simple_syslog
          Format      regex
          Regex       ^(?<message>.*)$
          Time_Keep   Off
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"fluent-bit.conf":"[SERVICE]\n    Flush         1\n    Log_Level     info\n    Daemon        off\n    Parsers_File  parsers.conf\n    HTTP_Server   On\n    HTTP_Listen   0.0.0.0\n    HTTP_Port     2020\n    storage.path  /tmp/flb-storage/\n    storage.sync  normal\n    storage.checksum off\n    storage.backlog.mem_limit 5M\n\n[INPUT]\n    Name              syslog\n    Mode              udp\n    Listen            0.0.0.0\n    Port              514\n    Tag               unifi.router.syslog\n    Parser            simple_syslog\n    Buffer_Chunk_Size 32k\n    Buffer_Max_Size   64k\n\n[INPUT]\n    Name              syslog\n    Mode              tcp\n    Listen            0.0.0.0\n    Port              515\n    Tag               unifi.router.syslog\n    Parser            simple_syslog\n    Buffer_Chunk_Size 32k\n    Buffer_Max_Size   64k\n\n[FILTER]\n    Name    modify\n    Match   *\n    Add     job unifi-router\n    Add     source_type syslog\n    Add     router_ip 192.168.1.1\n\n[OUTPUT]\n    Name            loki\n    Match           *\n    Host            loki.monitoring.svc.cluster.local\n    Port            3100\n    Labels          job=unifi-router,source_type=syslog,router_ip=192.168.1.1\n    Remove_keys     message\n    Line_format     json\n","parsers.conf":"[PARSER]\n    Name        simple_syslog\n    Format      regex\n    Regex       ^(?\u003cmessage\u003e.*)$\n    Time_Keep   Off\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"syslog-bridge-config","namespace":"monitoring"}}
    creationTimestamp: "2025-06-02T02:22:20Z"
    name: syslog-bridge-config
    namespace: monitoring
    resourceVersion: "1822504"
    uid: e1407873-2424-4eca-b2ce-4ea6082926bc
- apiVersion: v1
  data:
    system-alerts.yaml: |
      groups:
      - name: system
        rules:
        - alert: NodeDown
          expr: up == 0
          for: 1m
          labels:
            severity: critical
          annotations:
            summary: "Node {{ $labels.instance }} is down"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"system-alerts.yaml":"groups:\n- name: system\n  rules:\n  - alert: NodeDown\n    expr: up == 0\n    for: 1m\n    labels:\n      severity: critical\n    annotations:\n      summary: \"Node {{ $labels.instance }} is down\"\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"system-alert-rules","namespace":"monitoring"}}
    creationTimestamp: "2025-06-04T14:47:34Z"
    name: system-alert-rules
    namespace: monitoring
    resourceVersion: "3018029"
    uid: 07adb483-9c89-4085-8278-49a738cd43df
- apiVersion: v1
  data:
    odin-rollup-dashboard.json: "{\n  \"annotations\": {\n    \"list\": [\n      {\n
      \       \"builtIn\": 1,\n        \"datasource\": {\n          \"type\": \"grafana\",\n
      \         \"uid\": \"-- Grafana --\"\n        },\n        \"enable\": true,\n
      \       \"hide\": true,\n        \"iconColor\": \"rgba(0, 211, 255, 1)\",\n
      \       \"name\": \"Annotations & Alerts\",\n        \"type\": \"dashboard\"\n
      \     }\n    ]\n  },\n  \"editable\": true,\n  \"fiscalYearStartMonth\": 0,\n
      \ \"graphTooltip\": 1,\n  \"id\": null,\n  \"links\": [],\n  \"liveNow\": false,\n
      \ \"panels\": [\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n
      \       \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\":
      {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n
      \         \"mappings\": [\n            {\n              \"options\": {\n                \"0\":
      {\n                  \"color\": \"red\",\n                  \"index\": 1,\n
      \                 \"text\": \"DOWN\"\n                },\n                \"1\":
      {\n                  \"color\": \"green\",\n                  \"index\": 0,\n
      \                 \"text\": \"UP\"\n                }\n              },\n              \"type\":
      \"value\"\n            }\n          ],\n          \"thresholds\": {\n            \"mode\":
      \"absolute\",\n            \"steps\": [\n              {\n                \"color\":
      \"red\",\n                \"value\": null\n              },\n              {\n
      \               \"color\": \"green\",\n                \"value\": 1\n              }\n
      \           ]\n          },\n          \"unit\": \"short\"\n        },\n        \"overrides\":
      []\n      },\n      \"gridPos\": {\n        \"h\": 4,\n        \"w\": 24,\n
      \       \"x\": 0,\n        \"y\": 0\n      },\n      \"id\": 1,\n      \"options\":
      {\n        \"colorMode\": \"background\",\n        \"graphMode\": \"none\",\n
      \       \"justifyMode\": \"center\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\":
      {\n          \"calcs\": [\"lastNotNull\"],\n          \"fields\": \"\",\n          \"values\":
      false\n        },\n        \"text\": {},\n        \"textMode\": \"auto\"\n      },\n
      \     \"pluginVersion\": \"10.0.0\",\n      \"targets\": [\n        {\n          \"expr\":
      \"up{job=\\\"prometheus\\\"}\",\n          \"legendFormat\": \"Prometheus\",\n
      \         \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"up{job=\\\"grafana\\\"}\",\n
      \         \"legendFormat\": \"Grafana\",\n          \"refId\": \"B\"\n        },\n
      \       {\n          \"expr\": \"up{job=\\\"loki\\\"}\",\n          \"legendFormat\":
      \"Loki\",\n          \"refId\": \"C\"\n        },\n        {\n          \"expr\":
      \"up{job=\\\"alertmanager\\\"}\",\n          \"legendFormat\": \"AlertManager\",\n
      \         \"refId\": \"D\"\n        },\n        {\n          \"expr\": \"up{job=\\\"node-exporter\\\"}\",\n
      \         \"legendFormat\": \"Node Exporter\",\n          \"refId\": \"E\"\n
      \       },\n        {\n          \"expr\": \"up{job=\\\"power-exporter\\\"}\",\n
      \         \"legendFormat\": \"GPU Power\",\n          \"refId\": \"F\"\n        },\n
      \       {\n          \"expr\": \"up{job=\\\"cadvisor\\\"}\",\n          \"legendFormat\":
      \"cAdvisor\",\n          \"refId\": \"G\"\n        },\n        {\n          \"expr\":
      \"up{job=\\\"kube-state-metrics\\\"}\",\n          \"legendFormat\": \"K8s Metrics\",\n
      \         \"refId\": \"H\"\n        },\n        {\n          \"expr\": \"up{job=\\\"promtail\\\"}\",\n
      \         \"legendFormat\": \"Promtail\",\n          \"refId\": \"I\"\n        },\n
      \       {\n          \"expr\": \"up{job=\\\"claude-code-exporter\\\"}\",\n          \"legendFormat\":
      \"Claude Code\",\n          \"refId\": \"J\"\n        }\n      ],\n      \"title\":
      \"\U0001F6E1️ ODIN Stack Health Matrix\",\n      \"type\": \"stat\"\n    },\n
      \   {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\":
      \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n
      \         \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n
      \         \"custom\": {\n            \"axisCenteredZero\": false,\n            \"axisColorMode\":
      \"text\",\n            \"axisLabel\": \"\",\n            \"axisPlacement\":
      \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n
      \           \"fillOpacity\": 10,\n            \"gradientMode\": \"none\",\n
      \           \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\":
      false,\n              \"legend\": false\n            },\n            \"insertNulls\":
      false,\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\":
      1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\":
      \"linear\"\n            },\n            \"showPoints\": \"never\",\n            \"spanNulls\":
      false,\n            \"stacking\": {\n              \"group\": \"A\",\n              \"mode\":
      \"none\"\n            },\n            \"thresholdsStyle\": {\n              \"mode\":
      \"off\"\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\":
      {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n
      \               \"color\": \"green\",\n                \"value\": null\n              }\n
      \           ]\n          },\n          \"unit\": \"percent\"\n        },\n        \"overrides\":
      []\n      },\n      \"gridPos\": {\n        \"h\": 6,\n        \"w\": 12,\n
      \       \"x\": 0,\n        \"y\": 4\n      },\n      \"id\": 6,\n      \"options\":
      {\n        \"legend\": {\n          \"calcs\": [\"mean\", \"max\"],\n          \"displayMode\":
      \"table\",\n          \"placement\": \"bottom\",\n          \"showLegend\":
      true\n        },\n        \"tooltip\": {\n          \"mode\": \"multi\",\n          \"sort\":
      \"desc\"\n        }\n      },\n      \"pluginVersion\": \"10.0.0\",\n      \"targets\":
      [\n        {\n          \"expr\": \"100 - (avg by (instance) (rate(node_cpu_seconds_total{mode=\\\"idle\\\"}[5m]))
      * 100)\",\n          \"legendFormat\": \"CPU\",\n          \"refId\": \"A\"\n
      \       },\n        {\n          \"expr\": \"(1 - (node_memory_MemAvailable_bytes
      / node_memory_MemTotal_bytes)) * 100\",\n          \"legendFormat\": \"Memory\",\n
      \         \"refId\": \"B\"\n        },\n        {\n          \"expr\": \"nvidia_gpu_utilization_percent\",\n
      \         \"legendFormat\": \"GPU Util\",\n          \"refId\": \"C\"\n        }\n
      \     ],\n      \"title\": \"\U0001F4CA System Resource Utilization\",\n      \"type\":
      \"timeseries\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n
      \       \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\":
      {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n
      \         \"custom\": {\n            \"axisCenteredZero\": false,\n            \"axisColorMode\":
      \"text\",\n            \"axisLabel\": \"\",\n            \"axisPlacement\":
      \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n
      \           \"fillOpacity\": 10,\n            \"gradientMode\": \"none\",\n
      \           \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\":
      false,\n              \"legend\": false\n            },\n            \"insertNulls\":
      false,\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\":
      1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\":
      \"linear\"\n            },\n            \"showPoints\": \"never\",\n            \"spanNulls\":
      false,\n            \"stacking\": {\n              \"group\": \"A\",\n              \"mode\":
      \"none\"\n            },\n            \"thresholdsStyle\": {\n              \"mode\":
      \"off\"\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\":
      {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n
      \               \"color\": \"green\",\n                \"value\": null\n              }\n
      \           ]\n          },\n          \"unit\": \"celsius\"\n        },\n        \"overrides\":
      [\n          {\n            \"matcher\": {\n              \"id\": \"byName\",\n
      \             \"options\": \"GPU Power\"\n            },\n            \"properties\":
      [\n              {\n                \"id\": \"unit\",\n                \"value\":
      \"watt\"\n              },\n              {\n                \"id\": \"custom.axisPlacement\",\n
      \               \"value\": \"right\"\n              }\n            ]\n          }\n
      \       ]\n      },\n      \"gridPos\": {\n        \"h\": 6,\n        \"w\":
      12,\n        \"x\": 12,\n        \"y\": 4\n      },\n      \"id\": 7,\n      \"options\":
      {\n        \"legend\": {\n          \"calcs\": [\"mean\", \"max\"],\n          \"displayMode\":
      \"table\",\n          \"placement\": \"bottom\",\n          \"showLegend\":
      true\n        },\n        \"tooltip\": {\n          \"mode\": \"multi\",\n          \"sort\":
      \"desc\"\n        }\n      },\n      \"pluginVersion\": \"10.0.0\",\n      \"targets\":
      [\n        {\n          \"expr\": \"nvidia_gpu_temperature_celsius\",\n          \"legendFormat\":
      \"GPU Temp\",\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\":
      \"node_hwmon_temp_celsius{chip=~\\\".*coretemp.*\\\",sensor=~\\\".*Package.*\\\"}\",\n
      \         \"legendFormat\": \"CPU Temp\",\n          \"refId\": \"B\"\n        },\n
      \       {\n          \"expr\": \"nvidia_gpu_power_draw_watts\",\n          \"legendFormat\":
      \"GPU Power\",\n          \"refId\": \"C\"\n        }\n      ],\n      \"title\":
      \"\U0001F321️ Thermal & Power Status\",\n      \"type\": \"timeseries\"\n    }\n
      \ ],\n  \"refresh\": \"30s\",\n  \"schemaVersion\": 38,\n  \"style\": \"dark\",\n
      \ \"tags\": [\"odin\", \"rollup\", \"monitoring\"],\n  \"templating\": {\n    \"list\":
      []\n  },\n  \"time\": {\n    \"from\": \"now-1h\",\n    \"to\": \"now\"\n  },\n
      \ \"timepicker\": {\n    \"refresh_intervals\": [\"10s\", \"30s\", \"1m\", \"5m\",
      \"15m\", \"30m\", \"1h\", \"2h\", \"1d\"]\n  },\n  \"timezone\": \"\",\n  \"title\":
      \"ODIN Rollup Dashboard\",\n  \"uid\": \"odin-rollup\",\n  \"version\": 1,\n
      \ \"weekStart\": \"\"\n}\n"
    system-overview-dashboard.json: "{\n  \"id\": null,\n  \"uid\": \"system-overview\",
      \n  \"title\": \"ODIN System Overview\",\n    \"tags\": [\"odin\", \"overview\",
      \"system\"],\n    \"style\": \"dark\",\n    \"timezone\": \"browser\",\n    \"refresh\":
      \"30s\",\n    \"schemaVersion\": 27,\n    \"version\": 1,\n    \"time\": {\n
      \     \"from\": \"now-1h\",\n      \"to\": \"now\"\n    },\n    \"panels\":
      [\n      {\n        \"id\": 1,\n        \"title\": \"System Status\",\n        \"type\":
      \"stat\",\n        \"targets\": [\n          {\n            \"expr\": \"up{job=\\\"prometheus\\\"}\",\n
      \           \"legendFormat\": \"Prometheus\",\n            \"refId\": \"A\"\n
      \         },\n          {\n            \"expr\": \"up{job=\\\"alertmanager\\\"}\",\n
      \           \"legendFormat\": \"AlertManager\",\n            \"refId\": \"B\"\n
      \         },\n          {\n            \"expr\": \"up{job=\\\"node-exporter\\\"}\",\n
      \           \"legendFormat\": \"Node Exporter\",\n            \"refId\": \"C\"\n
      \         },\n          {\n            \"expr\": \"up{job=\\\"kube-state-metrics\\\"}\",\n
      \           \"legendFormat\": \"Kube State Metrics\",\n            \"refId\":
      \"D\"\n          },\n          {\n            \"expr\": \"up{job=\\\"power-exporter\\\"}\",\n
      \           \"legendFormat\": \"Power Exporter\",\n            \"refId\": \"E\"\n
      \         },\n          {\n            \"expr\": \"up{job=\\\"process-exporter\\\"}\",\n
      \           \"legendFormat\": \"Process Exporter\",\n            \"refId\":
      \"F\"\n          },\n          {\n            \"expr\": \"up{job=\\\"claude-code-exporter\\\"}\",\n
      \           \"legendFormat\": \"Claude Code Exporter\",\n            \"refId\":
      \"G\"\n          },\n          {\n            \"expr\": \"up{job=\\\"razer-exporter\\\"}\",\n
      \           \"legendFormat\": \"Razer Exporter\",\n            \"refId\": \"H\"\n
      \         }\n        ],\n        \"fieldConfig\": {\n          \"defaults\":
      {\n            \"color\": {\"mode\": \"thresholds\"},\n            \"thresholds\":
      {\n              \"steps\": [\n                {\"color\": \"red\", \"value\":
      null},\n                {\"color\": \"green\", \"value\": 1}\n              ]\n
      \           },\n            \"mappings\": [\n              {\"options\": {\"0\":
      {\"text\": \"DOWN\", \"color\": \"red\"}}, \"type\": \"value\"},\n              {\"options\":
      {\"1\": {\"text\": \"UP\", \"color\": \"green\"}}, \"type\": \"value\"}\n            ],\n
      \           \"unit\": \"short\"\n          }\n        },\n        \"gridPos\":
      {\"h\": 4, \"w\": 12, \"x\": 0, \"y\": 0}\n      },\n      {\n        \"id\":
      2,\n        \"title\": \"Cluster Resources\",\n        \"type\": \"stat\",\n
      \       \"targets\": [\n          {\n            \"expr\": \"(1 - avg(rate(node_cpu_seconds_total{mode=\\\"idle\\\"}[5m])))
      * 100\",\n            \"legendFormat\": \"CPU Usage %\",\n            \"refId\":
      \"A\"\n          },\n          {\n            \"expr\": \"(1 - (node_memory_MemAvailable_bytes
      / node_memory_MemTotal_bytes)) * 100\",\n            \"legendFormat\": \"Memory
      Usage %\",\n            \"refId\": \"B\"\n          },\n          {\n            \"expr\":
      \"(1 - (node_filesystem_avail_bytes{mountpoint=\\\"/\\\"} / node_filesystem_size_bytes{mountpoint=\\\"/\\\"}))
      * 100\",\n            \"legendFormat\": \"Disk Usage %\",\n            \"refId\":
      \"C\"\n          }\n        ],\n        \"fieldConfig\": {\n          \"defaults\":
      {\n            \"color\": {\"mode\": \"thresholds\"},\n            \"thresholds\":
      {\n              \"steps\": [\n                {\"color\": \"green\", \"value\":
      null},\n                {\"color\": \"yellow\", \"value\": 70},\n                {\"color\":
      \"red\", \"value\": 90}\n              ]\n            },\n            \"unit\":
      \"percent\",\n            \"decimals\": 1\n          }\n        },\n        \"gridPos\":
      {\"h\": 4, \"w\": 6, \"x\": 12, \"y\": 0}\n      },\n      {\n        \"id\":
      3,\n        \"title\": \"GPU Status\",\n        \"type\": \"stat\",\n        \"targets\":
      [\n          {\n            \"expr\": \"nvidia_gpu_temperature_celsius\",\n
      \           \"legendFormat\": \"GPU Temp °C\",\n            \"refId\": \"A\"\n
      \         },\n          {\n            \"expr\": \"nvidia_gpu_power_draw_watts\",\n
      \           \"legendFormat\": \"Power Draw W\",\n            \"refId\": \"B\"\n
      \         },\n          {\n            \"expr\": \"nvidia_gpu_utilization_percent\",\n
      \           \"legendFormat\": \"GPU Usage %\",\n            \"refId\": \"C\"\n
      \         }\n        ],\n        \"fieldConfig\": {\n          \"defaults\":
      {\n            \"color\": {\"mode\": \"thresholds\"},\n            \"thresholds\":
      {\n              \"steps\": [\n                {\"color\": \"green\", \"value\":
      null},\n                {\"color\": \"yellow\", \"value\": 70},\n                {\"color\":
      \"red\", \"value\": 85}\n              ]\n            },\n            \"decimals\":
      0\n          },\n          \"overrides\": [\n            {\n              \"matcher\":
      {\"id\": \"byName\", \"options\": \"GPU Temp °C\"},\n              \"properties\":
      [{\"id\": \"unit\", \"value\": \"celsius\"}]\n            },\n            {\n
      \             \"matcher\": {\"id\": \"byName\", \"options\": \"Power Draw W\"},\n
      \             \"properties\": [{\"id\": \"unit\", \"value\": \"watt\"}]\n            },\n
      \           {\n              \"matcher\": {\"id\": \"byName\", \"options\":
      \"GPU Usage %\"},\n              \"properties\": [{\"id\": \"unit\", \"value\":
      \"percent\"}]\n            }\n          ]\n        },\n        \"gridPos\":
      {\"h\": 4, \"w\": 6, \"x\": 18, \"y\": 0}\n      },\n      {\n        \"id\":
      4,\n        \"title\": \"CPU Usage\",\n        \"type\": \"timeseries\",\n        \"targets\":
      [\n          {\n            \"expr\": \"(1 - avg(rate(node_cpu_seconds_total{mode=\\\"idle\\\"}[5m]))
      by (instance)) * 100\",\n            \"legendFormat\": \"CPU Usage\",\n            \"refId\":
      \"A\"\n          }\n        ],\n        \"fieldConfig\": {\n          \"defaults\":
      {\n            \"color\": {\"mode\": \"palette-classic\"},\n            \"custom\":
      {\n              \"drawStyle\": \"line\",\n              \"lineInterpolation\":
      \"linear\",\n              \"lineWidth\": 2,\n              \"fillOpacity\":
      10\n            },\n            \"unit\": \"percent\"\n          }\n        },\n
      \       \"gridPos\": {\"h\": 8, \"w\": 8, \"x\": 0, \"y\": 4}\n      },\n      {\n
      \       \"id\": 5,\n        \"title\": \"Memory Usage\",\n        \"type\":
      \"timeseries\",\n        \"targets\": [\n          {\n            \"expr\":
      \"(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100\",\n
      \           \"legendFormat\": \"Memory Usage\",\n            \"refId\": \"A\"\n
      \         }\n        ],\n        \"fieldConfig\": {\n          \"defaults\":
      {\n            \"color\": {\"mode\": \"palette-classic\"},\n            \"custom\":
      {\n              \"drawStyle\": \"line\",\n              \"lineInterpolation\":
      \"linear\",\n              \"lineWidth\": 2,\n              \"fillOpacity\":
      10\n            },\n            \"unit\": \"percent\"\n          }\n        },\n
      \       \"gridPos\": {\"h\": 8, \"w\": 8, \"x\": 8, \"y\": 4}\n      },\n      {\n
      \       \"id\": 6,\n        \"title\": \"GPU Metrics\",\n        \"type\": \"timeseries\",\n
      \       \"targets\": [\n          {\n            \"expr\": \"nvidia_gpu_temperature_celsius\",\n
      \           \"legendFormat\": \"Temperature °C\",\n            \"refId\": \"A\"\n
      \         },\n          {\n            \"expr\": \"nvidia_gpu_utilization_percent\",\n
      \           \"legendFormat\": \"Utilization %\",\n            \"refId\": \"B\"\n
      \         }\n        ],\n        \"fieldConfig\": {\n          \"defaults\":
      {\n            \"color\": {\"mode\": \"palette-classic\"},\n            \"custom\":
      {\n              \"drawStyle\": \"line\",\n              \"lineInterpolation\":
      \"linear\",\n              \"lineWidth\": 2,\n              \"fillOpacity\":
      10\n            }\n          },\n          \"overrides\": [\n            {\n
      \             \"matcher\": {\"id\": \"byName\", \"options\": \"Temperature °C\"},\n
      \             \"properties\": [{\"id\": \"unit\", \"value\": \"celsius\"}]\n
      \           },\n            {\n              \"matcher\": {\"id\": \"byName\",
      \"options\": \"Utilization %\"},\n              \"properties\": [{\"id\": \"unit\",
      \"value\": \"percent\"}]\n            }\n          ]\n        },\n        \"gridPos\":
      {\"h\": 8, \"w\": 8, \"x\": 16, \"y\": 4}\n      }\n    ]\n}\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: "{\"apiVersion\":\"v1\",\"data\":{\"odin-rollup-dashboard.json\":\"{\\n
        \ \\\"annotations\\\": {\\n    \\\"list\\\": [\\n      {\\n        \\\"builtIn\\\":
        1,\\n        \\\"datasource\\\": {\\n          \\\"type\\\": \\\"grafana\\\",\\n
        \         \\\"uid\\\": \\\"-- Grafana --\\\"\\n        },\\n        \\\"enable\\\":
        true,\\n        \\\"hide\\\": true,\\n        \\\"iconColor\\\": \\\"rgba(0,
        211, 255, 1)\\\",\\n        \\\"name\\\": \\\"Annotations \\u0026 Alerts\\\",\\n
        \       \\\"type\\\": \\\"dashboard\\\"\\n      }\\n    ]\\n  },\\n  \\\"editable\\\":
        true,\\n  \\\"fiscalYearStartMonth\\\": 0,\\n  \\\"graphTooltip\\\": 1,\\n
        \ \\\"id\\\": null,\\n  \\\"links\\\": [],\\n  \\\"liveNow\\\": false,\\n
        \ \\\"panels\\\": [\\n    {\\n      \\\"datasource\\\": {\\n        \\\"type\\\":
        \\\"prometheus\\\",\\n        \\\"uid\\\": \\\"prometheus\\\"\\n      },\\n
        \     \\\"fieldConfig\\\": {\\n        \\\"defaults\\\": {\\n          \\\"color\\\":
        {\\n            \\\"mode\\\": \\\"thresholds\\\"\\n          },\\n          \\\"mappings\\\":
        [\\n            {\\n              \\\"options\\\": {\\n                \\\"0\\\":
        {\\n                  \\\"color\\\": \\\"red\\\",\\n                  \\\"index\\\":
        1,\\n                  \\\"text\\\": \\\"DOWN\\\"\\n                },\\n
        \               \\\"1\\\": {\\n                  \\\"color\\\": \\\"green\\\",\\n
        \                 \\\"index\\\": 0,\\n                  \\\"text\\\": \\\"UP\\\"\\n
        \               }\\n              },\\n              \\\"type\\\": \\\"value\\\"\\n
        \           }\\n          ],\\n          \\\"thresholds\\\": {\\n            \\\"mode\\\":
        \\\"absolute\\\",\\n            \\\"steps\\\": [\\n              {\\n                \\\"color\\\":
        \\\"red\\\",\\n                \\\"value\\\": null\\n              },\\n              {\\n
        \               \\\"color\\\": \\\"green\\\",\\n                \\\"value\\\":
        1\\n              }\\n            ]\\n          },\\n          \\\"unit\\\":
        \\\"short\\\"\\n        },\\n        \\\"overrides\\\": []\\n      },\\n      \\\"gridPos\\\":
        {\\n        \\\"h\\\": 4,\\n        \\\"w\\\": 24,\\n        \\\"x\\\": 0,\\n
        \       \\\"y\\\": 0\\n      },\\n      \\\"id\\\": 1,\\n      \\\"options\\\":
        {\\n        \\\"colorMode\\\": \\\"background\\\",\\n        \\\"graphMode\\\":
        \\\"none\\\",\\n        \\\"justifyMode\\\": \\\"center\\\",\\n        \\\"orientation\\\":
        \\\"auto\\\",\\n        \\\"reduceOptions\\\": {\\n          \\\"calcs\\\":
        [\\\"lastNotNull\\\"],\\n          \\\"fields\\\": \\\"\\\",\\n          \\\"values\\\":
        false\\n        },\\n        \\\"text\\\": {},\\n        \\\"textMode\\\":
        \\\"auto\\\"\\n      },\\n      \\\"pluginVersion\\\": \\\"10.0.0\\\",\\n
        \     \\\"targets\\\": [\\n        {\\n          \\\"expr\\\": \\\"up{job=\\\\\\\"prometheus\\\\\\\"}\\\",\\n
        \         \\\"legendFormat\\\": \\\"Prometheus\\\",\\n          \\\"refId\\\":
        \\\"A\\\"\\n        },\\n        {\\n          \\\"expr\\\": \\\"up{job=\\\\\\\"grafana\\\\\\\"}\\\",\\n
        \         \\\"legendFormat\\\": \\\"Grafana\\\",\\n          \\\"refId\\\":
        \\\"B\\\"\\n        },\\n        {\\n          \\\"expr\\\": \\\"up{job=\\\\\\\"loki\\\\\\\"}\\\",\\n
        \         \\\"legendFormat\\\": \\\"Loki\\\",\\n          \\\"refId\\\": \\\"C\\\"\\n
        \       },\\n        {\\n          \\\"expr\\\": \\\"up{job=\\\\\\\"alertmanager\\\\\\\"}\\\",\\n
        \         \\\"legendFormat\\\": \\\"AlertManager\\\",\\n          \\\"refId\\\":
        \\\"D\\\"\\n        },\\n        {\\n          \\\"expr\\\": \\\"up{job=\\\\\\\"node-exporter\\\\\\\"}\\\",\\n
        \         \\\"legendFormat\\\": \\\"Node Exporter\\\",\\n          \\\"refId\\\":
        \\\"E\\\"\\n        },\\n        {\\n          \\\"expr\\\": \\\"up{job=\\\\\\\"power-exporter\\\\\\\"}\\\",\\n
        \         \\\"legendFormat\\\": \\\"GPU Power\\\",\\n          \\\"refId\\\":
        \\\"F\\\"\\n        },\\n        {\\n          \\\"expr\\\": \\\"up{job=\\\\\\\"cadvisor\\\\\\\"}\\\",\\n
        \         \\\"legendFormat\\\": \\\"cAdvisor\\\",\\n          \\\"refId\\\":
        \\\"G\\\"\\n        },\\n        {\\n          \\\"expr\\\": \\\"up{job=\\\\\\\"kube-state-metrics\\\\\\\"}\\\",\\n
        \         \\\"legendFormat\\\": \\\"K8s Metrics\\\",\\n          \\\"refId\\\":
        \\\"H\\\"\\n        },\\n        {\\n          \\\"expr\\\": \\\"up{job=\\\\\\\"promtail\\\\\\\"}\\\",\\n
        \         \\\"legendFormat\\\": \\\"Promtail\\\",\\n          \\\"refId\\\":
        \\\"I\\\"\\n        },\\n        {\\n          \\\"expr\\\": \\\"up{job=\\\\\\\"claude-code-exporter\\\\\\\"}\\\",\\n
        \         \\\"legendFormat\\\": \\\"Claude Code\\\",\\n          \\\"refId\\\":
        \\\"J\\\"\\n        }\\n      ],\\n      \\\"title\\\": \\\"\U0001F6E1️ ODIN
        Stack Health Matrix\\\",\\n      \\\"type\\\": \\\"stat\\\"\\n    },\\n    {\\n
        \     \\\"datasource\\\": {\\n        \\\"type\\\": \\\"prometheus\\\",\\n
        \       \\\"uid\\\": \\\"prometheus\\\"\\n      },\\n      \\\"fieldConfig\\\":
        {\\n        \\\"defaults\\\": {\\n          \\\"color\\\": {\\n            \\\"mode\\\":
        \\\"palette-classic\\\"\\n          },\\n          \\\"custom\\\": {\\n            \\\"axisCenteredZero\\\":
        false,\\n            \\\"axisColorMode\\\": \\\"text\\\",\\n            \\\"axisLabel\\\":
        \\\"\\\",\\n            \\\"axisPlacement\\\": \\\"auto\\\",\\n            \\\"barAlignment\\\":
        0,\\n            \\\"drawStyle\\\": \\\"line\\\",\\n            \\\"fillOpacity\\\":
        10,\\n            \\\"gradientMode\\\": \\\"none\\\",\\n            \\\"hideFrom\\\":
        {\\n              \\\"tooltip\\\": false,\\n              \\\"viz\\\": false,\\n
        \             \\\"legend\\\": false\\n            },\\n            \\\"insertNulls\\\":
        false,\\n            \\\"lineInterpolation\\\": \\\"linear\\\",\\n            \\\"lineWidth\\\":
        1,\\n            \\\"pointSize\\\": 5,\\n            \\\"scaleDistribution\\\":
        {\\n              \\\"type\\\": \\\"linear\\\"\\n            },\\n            \\\"showPoints\\\":
        \\\"never\\\",\\n            \\\"spanNulls\\\": false,\\n            \\\"stacking\\\":
        {\\n              \\\"group\\\": \\\"A\\\",\\n              \\\"mode\\\":
        \\\"none\\\"\\n            },\\n            \\\"thresholdsStyle\\\": {\\n
        \             \\\"mode\\\": \\\"off\\\"\\n            }\\n          },\\n
        \         \\\"mappings\\\": [],\\n          \\\"thresholds\\\": {\\n            \\\"mode\\\":
        \\\"absolute\\\",\\n            \\\"steps\\\": [\\n              {\\n                \\\"color\\\":
        \\\"green\\\",\\n                \\\"value\\\": null\\n              }\\n
        \           ]\\n          },\\n          \\\"unit\\\": \\\"percent\\\"\\n
        \       },\\n        \\\"overrides\\\": []\\n      },\\n      \\\"gridPos\\\":
        {\\n        \\\"h\\\": 6,\\n        \\\"w\\\": 12,\\n        \\\"x\\\": 0,\\n
        \       \\\"y\\\": 4\\n      },\\n      \\\"id\\\": 6,\\n      \\\"options\\\":
        {\\n        \\\"legend\\\": {\\n          \\\"calcs\\\": [\\\"mean\\\", \\\"max\\\"],\\n
        \         \\\"displayMode\\\": \\\"table\\\",\\n          \\\"placement\\\":
        \\\"bottom\\\",\\n          \\\"showLegend\\\": true\\n        },\\n        \\\"tooltip\\\":
        {\\n          \\\"mode\\\": \\\"multi\\\",\\n          \\\"sort\\\": \\\"desc\\\"\\n
        \       }\\n      },\\n      \\\"pluginVersion\\\": \\\"10.0.0\\\",\\n      \\\"targets\\\":
        [\\n        {\\n          \\\"expr\\\": \\\"100 - (avg by (instance) (rate(node_cpu_seconds_total{mode=\\\\\\\"idle\\\\\\\"}[5m]))
        * 100)\\\",\\n          \\\"legendFormat\\\": \\\"CPU\\\",\\n          \\\"refId\\\":
        \\\"A\\\"\\n        },\\n        {\\n          \\\"expr\\\": \\\"(1 - (node_memory_MemAvailable_bytes
        / node_memory_MemTotal_bytes)) * 100\\\",\\n          \\\"legendFormat\\\":
        \\\"Memory\\\",\\n          \\\"refId\\\": \\\"B\\\"\\n        },\\n        {\\n
        \         \\\"expr\\\": \\\"nvidia_gpu_utilization_percent\\\",\\n          \\\"legendFormat\\\":
        \\\"GPU Util\\\",\\n          \\\"refId\\\": \\\"C\\\"\\n        }\\n      ],\\n
        \     \\\"title\\\": \\\"\U0001F4CA System Resource Utilization\\\",\\n      \\\"type\\\":
        \\\"timeseries\\\"\\n    },\\n    {\\n      \\\"datasource\\\": {\\n        \\\"type\\\":
        \\\"prometheus\\\",\\n        \\\"uid\\\": \\\"prometheus\\\"\\n      },\\n
        \     \\\"fieldConfig\\\": {\\n        \\\"defaults\\\": {\\n          \\\"color\\\":
        {\\n            \\\"mode\\\": \\\"palette-classic\\\"\\n          },\\n          \\\"custom\\\":
        {\\n            \\\"axisCenteredZero\\\": false,\\n            \\\"axisColorMode\\\":
        \\\"text\\\",\\n            \\\"axisLabel\\\": \\\"\\\",\\n            \\\"axisPlacement\\\":
        \\\"auto\\\",\\n            \\\"barAlignment\\\": 0,\\n            \\\"drawStyle\\\":
        \\\"line\\\",\\n            \\\"fillOpacity\\\": 10,\\n            \\\"gradientMode\\\":
        \\\"none\\\",\\n            \\\"hideFrom\\\": {\\n              \\\"tooltip\\\":
        false,\\n              \\\"viz\\\": false,\\n              \\\"legend\\\":
        false\\n            },\\n            \\\"insertNulls\\\": false,\\n            \\\"lineInterpolation\\\":
        \\\"linear\\\",\\n            \\\"lineWidth\\\": 1,\\n            \\\"pointSize\\\":
        5,\\n            \\\"scaleDistribution\\\": {\\n              \\\"type\\\":
        \\\"linear\\\"\\n            },\\n            \\\"showPoints\\\": \\\"never\\\",\\n
        \           \\\"spanNulls\\\": false,\\n            \\\"stacking\\\": {\\n
        \             \\\"group\\\": \\\"A\\\",\\n              \\\"mode\\\": \\\"none\\\"\\n
        \           },\\n            \\\"thresholdsStyle\\\": {\\n              \\\"mode\\\":
        \\\"off\\\"\\n            }\\n          },\\n          \\\"mappings\\\": [],\\n
        \         \\\"thresholds\\\": {\\n            \\\"mode\\\": \\\"absolute\\\",\\n
        \           \\\"steps\\\": [\\n              {\\n                \\\"color\\\":
        \\\"green\\\",\\n                \\\"value\\\": null\\n              }\\n
        \           ]\\n          },\\n          \\\"unit\\\": \\\"celsius\\\"\\n
        \       },\\n        \\\"overrides\\\": [\\n          {\\n            \\\"matcher\\\":
        {\\n              \\\"id\\\": \\\"byName\\\",\\n              \\\"options\\\":
        \\\"GPU Power\\\"\\n            },\\n            \\\"properties\\\": [\\n
        \             {\\n                \\\"id\\\": \\\"unit\\\",\\n                \\\"value\\\":
        \\\"watt\\\"\\n              },\\n              {\\n                \\\"id\\\":
        \\\"custom.axisPlacement\\\",\\n                \\\"value\\\": \\\"right\\\"\\n
        \             }\\n            ]\\n          }\\n        ]\\n      },\\n      \\\"gridPos\\\":
        {\\n        \\\"h\\\": 6,\\n        \\\"w\\\": 12,\\n        \\\"x\\\": 12,\\n
        \       \\\"y\\\": 4\\n      },\\n      \\\"id\\\": 7,\\n      \\\"options\\\":
        {\\n        \\\"legend\\\": {\\n          \\\"calcs\\\": [\\\"mean\\\", \\\"max\\\"],\\n
        \         \\\"displayMode\\\": \\\"table\\\",\\n          \\\"placement\\\":
        \\\"bottom\\\",\\n          \\\"showLegend\\\": true\\n        },\\n        \\\"tooltip\\\":
        {\\n          \\\"mode\\\": \\\"multi\\\",\\n          \\\"sort\\\": \\\"desc\\\"\\n
        \       }\\n      },\\n      \\\"pluginVersion\\\": \\\"10.0.0\\\",\\n      \\\"targets\\\":
        [\\n        {\\n          \\\"expr\\\": \\\"nvidia_gpu_temperature_celsius\\\",\\n
        \         \\\"legendFormat\\\": \\\"GPU Temp\\\",\\n          \\\"refId\\\":
        \\\"A\\\"\\n        },\\n        {\\n          \\\"expr\\\": \\\"node_hwmon_temp_celsius{chip=~\\\\\\\".*coretemp.*\\\\\\\",sensor=~\\\\\\\".*Package.*\\\\\\\"}\\\",\\n
        \         \\\"legendFormat\\\": \\\"CPU Temp\\\",\\n          \\\"refId\\\":
        \\\"B\\\"\\n        },\\n        {\\n          \\\"expr\\\": \\\"nvidia_gpu_power_draw_watts\\\",\\n
        \         \\\"legendFormat\\\": \\\"GPU Power\\\",\\n          \\\"refId\\\":
        \\\"C\\\"\\n        }\\n      ],\\n      \\\"title\\\": \\\"\U0001F321️ Thermal
        \\u0026 Power Status\\\",\\n      \\\"type\\\": \\\"timeseries\\\"\\n    }\\n
        \ ],\\n  \\\"refresh\\\": \\\"30s\\\",\\n  \\\"schemaVersion\\\": 38,\\n  \\\"style\\\":
        \\\"dark\\\",\\n  \\\"tags\\\": [\\\"odin\\\", \\\"rollup\\\", \\\"monitoring\\\"],\\n
        \ \\\"templating\\\": {\\n    \\\"list\\\": []\\n  },\\n  \\\"time\\\": {\\n
        \   \\\"from\\\": \\\"now-1h\\\",\\n    \\\"to\\\": \\\"now\\\"\\n  },\\n
        \ \\\"timepicker\\\": {\\n    \\\"refresh_intervals\\\": [\\\"10s\\\", \\\"30s\\\",
        \\\"1m\\\", \\\"5m\\\", \\\"15m\\\", \\\"30m\\\", \\\"1h\\\", \\\"2h\\\",
        \\\"1d\\\"]\\n  },\\n  \\\"timezone\\\": \\\"\\\",\\n  \\\"title\\\": \\\"ODIN
        Rollup Dashboard\\\",\\n  \\\"uid\\\": \\\"odin-rollup\\\",\\n  \\\"version\\\":
        1,\\n  \\\"weekStart\\\": \\\"\\\"\\n}\\n\",\"system-overview-dashboard.json\":\"{\\n
        \ \\\"id\\\": null,\\n  \\\"uid\\\": \\\"system-overview\\\", \\n  \\\"title\\\":
        \\\"ODIN System Overview\\\",\\n    \\\"tags\\\": [\\\"odin\\\", \\\"overview\\\",
        \\\"system\\\"],\\n    \\\"style\\\": \\\"dark\\\",\\n    \\\"timezone\\\":
        \\\"browser\\\",\\n    \\\"refresh\\\": \\\"30s\\\",\\n    \\\"schemaVersion\\\":
        27,\\n    \\\"version\\\": 1,\\n    \\\"time\\\": {\\n      \\\"from\\\":
        \\\"now-1h\\\",\\n      \\\"to\\\": \\\"now\\\"\\n    },\\n    \\\"panels\\\":
        [\\n      {\\n        \\\"id\\\": 1,\\n        \\\"title\\\": \\\"System Status\\\",\\n
        \       \\\"type\\\": \\\"stat\\\",\\n        \\\"targets\\\": [\\n          {\\n
        \           \\\"expr\\\": \\\"up{job=\\\\\\\"prometheus\\\\\\\"}\\\",\\n            \\\"legendFormat\\\":
        \\\"Prometheus\\\",\\n            \\\"refId\\\": \\\"A\\\"\\n          },\\n
        \         {\\n            \\\"expr\\\": \\\"up{job=\\\\\\\"alertmanager\\\\\\\"}\\\",\\n
        \           \\\"legendFormat\\\": \\\"AlertManager\\\",\\n            \\\"refId\\\":
        \\\"B\\\"\\n          },\\n          {\\n            \\\"expr\\\": \\\"up{job=\\\\\\\"node-exporter\\\\\\\"}\\\",\\n
        \           \\\"legendFormat\\\": \\\"Node Exporter\\\",\\n            \\\"refId\\\":
        \\\"C\\\"\\n          },\\n          {\\n            \\\"expr\\\": \\\"up{job=\\\\\\\"kube-state-metrics\\\\\\\"}\\\",\\n
        \           \\\"legendFormat\\\": \\\"Kube State Metrics\\\",\\n            \\\"refId\\\":
        \\\"D\\\"\\n          },\\n          {\\n            \\\"expr\\\": \\\"up{job=\\\\\\\"power-exporter\\\\\\\"}\\\",\\n
        \           \\\"legendFormat\\\": \\\"Power Exporter\\\",\\n            \\\"refId\\\":
        \\\"E\\\"\\n          },\\n          {\\n            \\\"expr\\\": \\\"up{job=\\\\\\\"process-exporter\\\\\\\"}\\\",\\n
        \           \\\"legendFormat\\\": \\\"Process Exporter\\\",\\n            \\\"refId\\\":
        \\\"F\\\"\\n          },\\n          {\\n            \\\"expr\\\": \\\"up{job=\\\\\\\"claude-code-exporter\\\\\\\"}\\\",\\n
        \           \\\"legendFormat\\\": \\\"Claude Code Exporter\\\",\\n            \\\"refId\\\":
        \\\"G\\\"\\n          },\\n          {\\n            \\\"expr\\\": \\\"up{job=\\\\\\\"razer-exporter\\\\\\\"}\\\",\\n
        \           \\\"legendFormat\\\": \\\"Razer Exporter\\\",\\n            \\\"refId\\\":
        \\\"H\\\"\\n          }\\n        ],\\n        \\\"fieldConfig\\\": {\\n          \\\"defaults\\\":
        {\\n            \\\"color\\\": {\\\"mode\\\": \\\"thresholds\\\"},\\n            \\\"thresholds\\\":
        {\\n              \\\"steps\\\": [\\n                {\\\"color\\\": \\\"red\\\",
        \\\"value\\\": null},\\n                {\\\"color\\\": \\\"green\\\", \\\"value\\\":
        1}\\n              ]\\n            },\\n            \\\"mappings\\\": [\\n
        \             {\\\"options\\\": {\\\"0\\\": {\\\"text\\\": \\\"DOWN\\\", \\\"color\\\":
        \\\"red\\\"}}, \\\"type\\\": \\\"value\\\"},\\n              {\\\"options\\\":
        {\\\"1\\\": {\\\"text\\\": \\\"UP\\\", \\\"color\\\": \\\"green\\\"}}, \\\"type\\\":
        \\\"value\\\"}\\n            ],\\n            \\\"unit\\\": \\\"short\\\"\\n
        \         }\\n        },\\n        \\\"gridPos\\\": {\\\"h\\\": 4, \\\"w\\\":
        12, \\\"x\\\": 0, \\\"y\\\": 0}\\n      },\\n      {\\n        \\\"id\\\":
        2,\\n        \\\"title\\\": \\\"Cluster Resources\\\",\\n        \\\"type\\\":
        \\\"stat\\\",\\n        \\\"targets\\\": [\\n          {\\n            \\\"expr\\\":
        \\\"(1 - avg(rate(node_cpu_seconds_total{mode=\\\\\\\"idle\\\\\\\"}[5m])))
        * 100\\\",\\n            \\\"legendFormat\\\": \\\"CPU Usage %\\\",\\n            \\\"refId\\\":
        \\\"A\\\"\\n          },\\n          {\\n            \\\"expr\\\": \\\"(1
        - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100\\\",\\n
        \           \\\"legendFormat\\\": \\\"Memory Usage %\\\",\\n            \\\"refId\\\":
        \\\"B\\\"\\n          },\\n          {\\n            \\\"expr\\\": \\\"(1
        - (node_filesystem_avail_bytes{mountpoint=\\\\\\\"/\\\\\\\"} / node_filesystem_size_bytes{mountpoint=\\\\\\\"/\\\\\\\"}))
        * 100\\\",\\n            \\\"legendFormat\\\": \\\"Disk Usage %\\\",\\n            \\\"refId\\\":
        \\\"C\\\"\\n          }\\n        ],\\n        \\\"fieldConfig\\\": {\\n          \\\"defaults\\\":
        {\\n            \\\"color\\\": {\\\"mode\\\": \\\"thresholds\\\"},\\n            \\\"thresholds\\\":
        {\\n              \\\"steps\\\": [\\n                {\\\"color\\\": \\\"green\\\",
        \\\"value\\\": null},\\n                {\\\"color\\\": \\\"yellow\\\", \\\"value\\\":
        70},\\n                {\\\"color\\\": \\\"red\\\", \\\"value\\\": 90}\\n
        \             ]\\n            },\\n            \\\"unit\\\": \\\"percent\\\",\\n
        \           \\\"decimals\\\": 1\\n          }\\n        },\\n        \\\"gridPos\\\":
        {\\\"h\\\": 4, \\\"w\\\": 6, \\\"x\\\": 12, \\\"y\\\": 0}\\n      },\\n      {\\n
        \       \\\"id\\\": 3,\\n        \\\"title\\\": \\\"GPU Status\\\",\\n        \\\"type\\\":
        \\\"stat\\\",\\n        \\\"targets\\\": [\\n          {\\n            \\\"expr\\\":
        \\\"nvidia_gpu_temperature_celsius\\\",\\n            \\\"legendFormat\\\":
        \\\"GPU Temp °C\\\",\\n            \\\"refId\\\": \\\"A\\\"\\n          },\\n
        \         {\\n            \\\"expr\\\": \\\"nvidia_gpu_power_draw_watts\\\",\\n
        \           \\\"legendFormat\\\": \\\"Power Draw W\\\",\\n            \\\"refId\\\":
        \\\"B\\\"\\n          },\\n          {\\n            \\\"expr\\\": \\\"nvidia_gpu_utilization_percent\\\",\\n
        \           \\\"legendFormat\\\": \\\"GPU Usage %\\\",\\n            \\\"refId\\\":
        \\\"C\\\"\\n          }\\n        ],\\n        \\\"fieldConfig\\\": {\\n          \\\"defaults\\\":
        {\\n            \\\"color\\\": {\\\"mode\\\": \\\"thresholds\\\"},\\n            \\\"thresholds\\\":
        {\\n              \\\"steps\\\": [\\n                {\\\"color\\\": \\\"green\\\",
        \\\"value\\\": null},\\n                {\\\"color\\\": \\\"yellow\\\", \\\"value\\\":
        70},\\n                {\\\"color\\\": \\\"red\\\", \\\"value\\\": 85}\\n
        \             ]\\n            },\\n            \\\"decimals\\\": 0\\n          },\\n
        \         \\\"overrides\\\": [\\n            {\\n              \\\"matcher\\\":
        {\\\"id\\\": \\\"byName\\\", \\\"options\\\": \\\"GPU Temp °C\\\"},\\n              \\\"properties\\\":
        [{\\\"id\\\": \\\"unit\\\", \\\"value\\\": \\\"celsius\\\"}]\\n            },\\n
        \           {\\n              \\\"matcher\\\": {\\\"id\\\": \\\"byName\\\",
        \\\"options\\\": \\\"Power Draw W\\\"},\\n              \\\"properties\\\":
        [{\\\"id\\\": \\\"unit\\\", \\\"value\\\": \\\"watt\\\"}]\\n            },\\n
        \           {\\n              \\\"matcher\\\": {\\\"id\\\": \\\"byName\\\",
        \\\"options\\\": \\\"GPU Usage %\\\"},\\n              \\\"properties\\\":
        [{\\\"id\\\": \\\"unit\\\", \\\"value\\\": \\\"percent\\\"}]\\n            }\\n
        \         ]\\n        },\\n        \\\"gridPos\\\": {\\\"h\\\": 4, \\\"w\\\":
        6, \\\"x\\\": 18, \\\"y\\\": 0}\\n      },\\n      {\\n        \\\"id\\\":
        4,\\n        \\\"title\\\": \\\"CPU Usage\\\",\\n        \\\"type\\\": \\\"timeseries\\\",\\n
        \       \\\"targets\\\": [\\n          {\\n            \\\"expr\\\": \\\"(1
        - avg(rate(node_cpu_seconds_total{mode=\\\\\\\"idle\\\\\\\"}[5m])) by (instance))
        * 100\\\",\\n            \\\"legendFormat\\\": \\\"CPU Usage\\\",\\n            \\\"refId\\\":
        \\\"A\\\"\\n          }\\n        ],\\n        \\\"fieldConfig\\\": {\\n          \\\"defaults\\\":
        {\\n            \\\"color\\\": {\\\"mode\\\": \\\"palette-classic\\\"},\\n
        \           \\\"custom\\\": {\\n              \\\"drawStyle\\\": \\\"line\\\",\\n
        \             \\\"lineInterpolation\\\": \\\"linear\\\",\\n              \\\"lineWidth\\\":
        2,\\n              \\\"fillOpacity\\\": 10\\n            },\\n            \\\"unit\\\":
        \\\"percent\\\"\\n          }\\n        },\\n        \\\"gridPos\\\": {\\\"h\\\":
        8, \\\"w\\\": 8, \\\"x\\\": 0, \\\"y\\\": 4}\\n      },\\n      {\\n        \\\"id\\\":
        5,\\n        \\\"title\\\": \\\"Memory Usage\\\",\\n        \\\"type\\\":
        \\\"timeseries\\\",\\n        \\\"targets\\\": [\\n          {\\n            \\\"expr\\\":
        \\\"(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) *
        100\\\",\\n            \\\"legendFormat\\\": \\\"Memory Usage\\\",\\n            \\\"refId\\\":
        \\\"A\\\"\\n          }\\n        ],\\n        \\\"fieldConfig\\\": {\\n          \\\"defaults\\\":
        {\\n            \\\"color\\\": {\\\"mode\\\": \\\"palette-classic\\\"},\\n
        \           \\\"custom\\\": {\\n              \\\"drawStyle\\\": \\\"line\\\",\\n
        \             \\\"lineInterpolation\\\": \\\"linear\\\",\\n              \\\"lineWidth\\\":
        2,\\n              \\\"fillOpacity\\\": 10\\n            },\\n            \\\"unit\\\":
        \\\"percent\\\"\\n          }\\n        },\\n        \\\"gridPos\\\": {\\\"h\\\":
        8, \\\"w\\\": 8, \\\"x\\\": 8, \\\"y\\\": 4}\\n      },\\n      {\\n        \\\"id\\\":
        6,\\n        \\\"title\\\": \\\"GPU Metrics\\\",\\n        \\\"type\\\": \\\"timeseries\\\",\\n
        \       \\\"targets\\\": [\\n          {\\n            \\\"expr\\\": \\\"nvidia_gpu_temperature_celsius\\\",\\n
        \           \\\"legendFormat\\\": \\\"Temperature °C\\\",\\n            \\\"refId\\\":
        \\\"A\\\"\\n          },\\n          {\\n            \\\"expr\\\": \\\"nvidia_gpu_utilization_percent\\\",\\n
        \           \\\"legendFormat\\\": \\\"Utilization %\\\",\\n            \\\"refId\\\":
        \\\"B\\\"\\n          }\\n        ],\\n        \\\"fieldConfig\\\": {\\n          \\\"defaults\\\":
        {\\n            \\\"color\\\": {\\\"mode\\\": \\\"palette-classic\\\"},\\n
        \           \\\"custom\\\": {\\n              \\\"drawStyle\\\": \\\"line\\\",\\n
        \             \\\"lineInterpolation\\\": \\\"linear\\\",\\n              \\\"lineWidth\\\":
        2,\\n              \\\"fillOpacity\\\": 10\\n            }\\n          },\\n
        \         \\\"overrides\\\": [\\n            {\\n              \\\"matcher\\\":
        {\\\"id\\\": \\\"byName\\\", \\\"options\\\": \\\"Temperature °C\\\"},\\n
        \             \\\"properties\\\": [{\\\"id\\\": \\\"unit\\\", \\\"value\\\":
        \\\"celsius\\\"}]\\n            },\\n            {\\n              \\\"matcher\\\":
        {\\\"id\\\": \\\"byName\\\", \\\"options\\\": \\\"Utilization %\\\"},\\n              \\\"properties\\\":
        [{\\\"id\\\": \\\"unit\\\", \\\"value\\\": \\\"percent\\\"}]\\n            }\\n
        \         ]\\n        },\\n        \\\"gridPos\\\": {\\\"h\\\": 8, \\\"w\\\":
        8, \\\"x\\\": 16, \\\"y\\\": 4}\\n      }\\n    ]\\n}\\n\"},\"kind\":\"ConfigMap\",\"metadata\":{\"annotations\":{},\"labels\":{\"grafana_dashboard\":\"1\"},\"name\":\"system-overview-dashboard\",\"namespace\":\"monitoring\"}}\n"
    creationTimestamp: "2025-05-31T18:56:05Z"
    labels:
      grafana_dashboard: "1"
    name: system-overview-dashboard
    namespace: monitoring
    resourceVersion: "646685"
    uid: a40b5848-e2a0-47fa-a01d-297a0ca3560f
- apiVersion: v1
  data:
    tcp-alerts.yaml: "groups:\n- name: tcp_connection_alerts\n  interval: 30s\n  rules:\n
      \ \n  # TCP Reset Alerts\n  - alert: HighTCPResetRate\n    expr: rate(node_netstat_Tcp_OutRsts[5m])
      > 2\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n      summary:
      \"High TCP reset rate detected\"\n      description: \"TCP reset rate is {{
      $value  < /dev/null |  humanize }} resets/sec on {{ $labels.instance }}, indicating
      potential connection issues\"\n      \n  - alert: ExcessiveTCPResetRate\n    expr:
      rate(node_netstat_Tcp_OutRsts[5m]) > 5\n    for: 2m\n    labels:\n      severity:
      critical\n    annotations:\n      summary: \"Excessive TCP reset rate\"\n      description:
      \"TCP reset rate is {{ $value | humanize }} resets/sec on {{ $labels.instance
      }}, indicating severe connection problems\"\n      \n  - alert: HighTCPResetPercentage\n
      \   expr: |\n      (rate(node_netstat_Tcp_OutRsts[5m]) / rate(node_netstat_Tcp_ActiveOpens[5m]))
      * 100 > 20\n      and rate(node_netstat_Tcp_ActiveOpens[5m]) > 1\n    for: 5m\n
      \   labels:\n      severity: warning\n    annotations:\n      summary: \"High
      percentage of TCP connections being reset\"\n      description: \"{{ $value
      | humanize }}% of TCP connections are being reset on {{ $labels.instance }}\"\n
      \     \n  # TCP Retransmission Alerts\n  - alert: HighTCPRetransmissionRate\n
      \   expr: |\n      (rate(node_netstat_Tcp_RetransSegs[5m]) / rate(node_netstat_Tcp_OutSegs[5m]))
      * 100 > 1\n      and rate(node_netstat_Tcp_OutSegs[5m]) > 10\n    for: 5m\n
      \   labels:\n      severity: warning\n    annotations:\n      summary: \"High
      TCP retransmission rate\"\n      description: \"{{ $value | humanize }}% of
      TCP segments are being retransmitted on {{ $labels.instance }}, indicating network
      quality issues\"\n      \n  # TCP Connection Failures\n  - alert: HighTCPConnectionFailures\n
      \   expr: |\n      rate(node_netstat_Tcp_AttemptFails[5m]) > 0.5\n    for: 5m\n
      \   labels:\n      severity: warning\n    annotations:\n      summary: \"High
      TCP connection failure rate\"\n      description: \"TCP connection failures
      at {{ $value | humanize }} failures/sec on {{ $labels.instance }}\"\n      \n
      \ # TCP Listen Overflows (dropped connections due to full queue)\n  - alert:
      TCPListenOverflows\n    expr: rate(node_netstat_Tcp_ListenOverflows[5m]) > 0\n
      \   for: 1m\n    labels:\n      severity: critical\n    annotations:\n      summary:
      \"TCP listen queue overflowing\"\n      description: \"TCP listen queue is overflowing
      at {{ $value | humanize }} drops/sec on {{ $labels.instance }}. Application
      may be overwhelmed.\"\n      \n  # TCP Congestion Detection - FIXED\n  - alert:
      TCPCongestionDetected\n    expr: |\n      (rate(node_netstat_Tcp_OutRsts[5m])
      > 1) \n      and (rate(node_netstat_Tcp_RetransSegs[5m]) / rate(node_netstat_Tcp_OutSegs[5m])
      * 100 > 0.5)\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n
      \     summary: \"TCP congestion detected\"\n      description: \"High reset
      rate combined with retransmissions indicates network congestion on {{ $labels.instance
      }}\"\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"tcp-alerts.yaml":"groups:\n- name: tcp_connection_alerts\n  interval: 30s\n  rules:\n  \n  # TCP Reset Alerts\n  - alert: HighTCPResetRate\n    expr: rate(node_netstat_Tcp_OutRsts[5m]) \u003e 2\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n      summary: \"High TCP reset rate detected\"\n      description: \"TCP reset rate is {{ $value | humanize }} resets/sec on {{ $labels.instance }}, indicating potential connection issues\"\n      \n  - alert: ExcessiveTCPResetRate\n    expr: rate(node_netstat_Tcp_OutRsts[5m]) \u003e 5\n    for: 2m\n    labels:\n      severity: critical\n    annotations:\n      summary: \"Excessive TCP reset rate\"\n      description: \"TCP reset rate is {{ $value | humanize }} resets/sec on {{ $labels.instance }}, indicating severe connection problems\"\n      \n  - alert: HighTCPResetPercentage\n    expr: |\n      (rate(node_netstat_Tcp_OutRsts[5m]) / rate(node_netstat_Tcp_ActiveOpens[5m])) * 100 \u003e 20\n      and rate(node_netstat_Tcp_ActiveOpens[5m]) \u003e 1\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n      summary: \"High percentage of TCP connections being reset\"\n      description: \"{{ $value | humanize }}% of TCP connections are being reset on {{ $labels.instance }}\"\n      \n  # TCP Retransmission Alerts\n  - alert: HighTCPRetransmissionRate\n    expr: |\n      (rate(node_netstat_Tcp_RetransSegs[5m]) / rate(node_netstat_Tcp_OutSegs[5m])) * 100 \u003e 1\n      and rate(node_netstat_Tcp_OutSegs[5m]) \u003e 10\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n      summary: \"High TCP retransmission rate\"\n      description: \"{{ $value | humanize }}% of TCP segments are being retransmitted on {{ $labels.instance }}, indicating network quality issues\"\n      \n  # TCP Connection Failures\n  - alert: HighTCPConnectionFailures\n    expr: |\n      rate(node_netstat_Tcp_AttemptFails[5m]) \u003e 0.5\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n      summary: \"High TCP connection failure rate\"\n      description: \"TCP connection failures at {{ $value | humanize }} failures/sec on {{ $labels.instance }}\"\n      \n  # TCP Listen Overflows (dropped connections due to full queue)\n  - alert: TCPListenOverflows\n    expr: rate(node_netstat_Tcp_ListenOverflows[5m]) \u003e 0\n    for: 1m\n    labels:\n      severity: critical\n    annotations:\n      summary: \"TCP listen queue overflowing\"\n      description: \"TCP listen queue is overflowing at {{ $value | humanize }} drops/sec on {{ $labels.instance }}. Application may be overwhelmed.\"\n      \n  # TCP Congestion Detection\n  - alert: TCPCongestionDetected\n    expr: |\n      (rate(node_netstat_Tcp_OutRsts[5m]) \u003e 1) \n      and (rate(node_netstat_Tcp_RetransSegs[5m]) / rate(node_netstat_Tcp_OutSegs[5m]) * 100 \u003e 0.5)\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n      summary: \"TCP congestion detected\"\n      description: \"High reset rate ({{ $values.A | humanize }}/sec) combined with retransmissions indicates network congestion on {{ $labels.instance }}\"\n"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"prometheus":"kube-prometheus"},"name":"tcp-network-alerts","namespace":"monitoring"}}
    creationTimestamp: "2025-05-30T21:02:54Z"
    labels:
      prometheus: kube-prometheus
    name: tcp-network-alerts
    namespace: monitoring
    resourceVersion: "553298"
    uid: 8b551501-e85f-4cfd-b98d-ad4f7ca6f694
- apiVersion: v1
  data:
    test-alerts.yml: |
      groups:
      - name: test-alerts
        rules:
        - alert: TestNotificationAlert
          expr: up{job="prometheus"} == 1
          for: 0m
          labels:
            severity: info
            component: test
          annotations:
            summary: "Test alert for notification verification"
            description: "This is a test alert to verify webhook notification delivery is working. Prometheus is UP."
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"test-alerts.yml":"groups:\n- name: test-alerts\n  rules:\n  - alert: TestNotificationAlert\n    expr: up{job=\"prometheus\"} == 1\n    for: 0m\n    labels:\n      severity: info\n      component: test\n    annotations:\n      summary: \"Test alert for notification verification\"\n      description: \"This is a test alert to verify webhook notification delivery is working. Prometheus is UP.\"\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"test-alert-rules","namespace":"monitoring"}}
    creationTimestamp: "2025-06-01T13:25:02Z"
    name: test-alert-rules
    namespace: monitoring
    resourceVersion: "1107877"
    uid: 3e370988-ead5-4ede-b3b4-632365108fd7
- apiVersion: v1
  data:
    ubiquiti-dashboard.json: |
      {
        "annotations": {
          "list": [
            {
              "builtIn": 1,
              "datasource": {
                "type": "grafana",
                "uid": "-- Grafana --"
              },
              "enable": true,
              "hide": true,
              "iconColor": "rgba(0, 211, 255, 1)",
              "name": "Annotations & Alerts",
              "type": "dashboard"
            }
          ]
        },
        "editable": true,
        "fiscalYearStartMonth": 0,
        "graphTooltip": 0,
        "id": null,
        "links": [],
        "liveNow": false,
        "panels": [
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "description": "Current operational status of UniFi devices",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "custom": {
                  "align": "auto",
                  "cellOptions": {
                    "type": "auto"
                  },
                  "inspect": false
                },
                "mappings": [
                  {
                    "options": {
                      "0": {
                        "color": "red",
                        "index": 0,
                        "text": "Offline"
                      },
                      "1": {
                        "color": "green",
                        "index": 1,
                        "text": "Online"
                      }
                    },
                    "type": "value"
                  }
                ],
                "thresholds": {
                  "steps": [
                    {
                      "color": "red",
                      "value": null
                    },
                    {
                      "color": "green",
                      "value": 1
                    }
                  ]
                }
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 0,
              "y": 0
            },
            "id": 1,
            "options": {
              "cellHeight": "sm",
              "footer": {
                "countRows": false,
                "fields": "",
                "reducer": [
                  "sum"
                ],
                "show": false
              },
              "showHeader": true
            },
            "pluginVersion": "10.2.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "up{job=~\".*unifi.*\"}",
                "format": "table",
                "instant": true,
                "legendFormat": "__auto",
                "range": false,
                "refId": "A"
              }
            ],
            "title": "UniFi Device Status",
            "type": "table"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "description": "Device uptime in days",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisCenteredZero": false,
                  "axisColorMode": "text",
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 0,
                  "gradientMode": "none",
                  "hideFrom": {
                    "legend": false,
                    "tooltip": false,
                    "vis": false
                  },
                  "insertNulls": false,
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "auto",
                  "spanNulls": false,
                  "stacking": {
                    "group": "A",
                    "mode": "none"
                  },
                  "thresholdsStyle": {
                    "mode": "off"
                  }
                },
                "mappings": [],
                "thresholds": {
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "red",
                      "value": 80
                    }
                  ]
                },
                "unit": "s"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 12,
              "y": 0
            },
            "id": 2,
            "options": {
              "legend": {
                "calcs": [],
                "displayMode": "list",
                "placement": "bottom",
                "showLegend": true
              },
              "tooltip": {
                "mode": "single",
                "sort": "none"
              }
            },
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "unifi_device_uptime_seconds",
                "instant": false,
                "legendFormat": "{{device_name}}",
                "range": true,
                "refId": "A"
              }
            ],
            "title": "Device Uptime",
            "type": "timeseries"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "description": "Current CPU usage percentage",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "max": 100,
                "min": 0,
                "thresholds": {
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "yellow",
                      "value": 60
                    },
                    {
                      "color": "red",
                      "value": 80
                    }
                  ]
                },
                "unit": "percent"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 6,
              "x": 0,
              "y": 8
            },
            "id": 3,
            "options": {
              "orientation": "auto",
              "reduceOptions": {
                "calcs": [
                  "lastNotNull"
                ],
                "fields": "",
                "values": false
              },
              "showThresholdLabels": false,
              "showThresholdMarkers": true,
              "text": {}
            },
            "pluginVersion": "10.2.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "unifi_device_cpu_usage_percent",
                "instant": false,
                "legendFormat": "{{device_name}}",
                "range": true,
                "refId": "A"
              }
            ],
            "title": "CPU Usage",
            "type": "gauge"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "description": "Current memory usage percentage",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "max": 100,
                "min": 0,
                "thresholds": {
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "yellow",
                      "value": 70
                    },
                    {
                      "color": "red",
                      "value": 85
                    }
                  ]
                },
                "unit": "percent"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 6,
              "x": 6,
              "y": 8
            },
            "id": 4,
            "options": {
              "orientation": "auto",
              "reduceOptions": {
                "calcs": [
                  "lastNotNull"
                ],
                "fields": "",
                "values": false
              },
              "showThresholdLabels": false,
              "showThresholdMarkers": true,
              "text": {}
            },
            "pluginVersion": "10.2.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "unifi_device_memory_usage_percent",
                "instant": false,
                "legendFormat": "{{device_name}}",
                "range": true,
                "refId": "A"
              }
            ],
            "title": "Memory Usage",
            "type": "gauge"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "description": "Device temperature in Celsius",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "max": 100,
                "min": 0,
                "thresholds": {
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "yellow",
                      "value": 60
                    },
                    {
                      "color": "red",
                      "value": 75
                    }
                  ]
                },
                "unit": "celsius"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 6,
              "x": 12,
              "y": 8
            },
            "id": 5,
            "options": {
              "orientation": "auto",
              "reduceOptions": {
                "calcs": [
                  "lastNotNull"
                ],
                "fields": "",
                "values": false
              },
              "showThresholdLabels": false,
              "showThresholdMarkers": true,
              "text": {}
            },
            "pluginVersion": "10.2.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "unifi_device_temperature_celsius",
                "instant": false,
                "legendFormat": "{{device_name}} - {{sensor}}",
                "range": true,
                "refId": "A"
              }
            ],
            "title": "Device Temperature",
            "type": "gauge"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "description": "Current number of connected clients",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "hideFrom": {
                    "legend": false,
                    "tooltip": false,
                    "vis": false
                  }
                },
                "mappings": [],
                "unit": "short"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 6,
              "x": 18,
              "y": 8
            },
            "id": 6,
            "options": {
              "displayLabels": [
                "name",
                "value"
              ],
              "legend": {
                "displayMode": "visible",
                "placement": "right",
                "showLegend": true,
                "values": []
              },
              "pieType": "pie",
              "reduceOptions": {
                "calcs": [
                  "lastNotNull"
                ],
                "fields": "",
                "values": false
              },
              "tooltip": {
                "mode": "single",
                "sort": "none"
              }
            },
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "unifi_clients_total",
                "instant": false,
                "legendFormat": "{{device_name}} - {{type}}",
                "range": true,
                "refId": "A"
              }
            ],
            "title": "Connected Clients",
            "type": "piechart"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "description": "Network interface traffic rates",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisCenteredZero": false,
                  "axisColorMode": "text",
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 10,
                  "gradientMode": "none",
                  "hideFrom": {
                    "legend": false,
                    "tooltip": false,
                    "vis": false
                  },
                  "insertNulls": false,
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "never",
                  "spanNulls": false,
                  "stacking": {
                    "group": "A",
                    "mode": "none"
                  },
                  "thresholdsStyle": {
                    "mode": "off"
                  }
                },
                "mappings": [],
                "thresholds": {
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "red",
                      "value": 80
                    }
                  ]
                },
                "unit": "bps"
              },
              "overrides": [
                {
                  "matcher": {
                    "id": "byRegexp",
                    "options": "/.*TX.*/"
                  },
                  "properties": [
                    {
                      "id": "custom.transform",
                      "value": "negative-Y"
                    }
                  ]
                }
              ]
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 0,
              "y": 16
            },
            "id": 7,
            "options": {
              "legend": {
                "calcs": [],
                "displayMode": "list",
                "placement": "bottom",
                "showLegend": true
              },
              "tooltip": {
                "mode": "multi",
                "sort": "none"
              }
            },
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "rate(unifi_interface_rx_bytes_total[5m]) * 8",
                "instant": false,
                "legendFormat": "{{device_name}}-{{interface}} RX",
                "range": true,
                "refId": "A"
              },
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "rate(unifi_interface_tx_bytes_total[5m]) * 8",
                "instant": false,
                "legendFormat": "{{device_name}}-{{interface}} TX",
                "range": true,
                "refId": "B"
              }
            ],
            "title": "Interface Traffic",
            "type": "timeseries"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "description": "Interface operational status",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "custom": {
                  "align": "auto",
                  "cellOptions": {
                    "type": "auto"
                  },
                  "inspect": false
                },
                "mappings": [
                  {
                    "options": {
                      "0": {
                        "color": "red",
                        "index": 0,
                        "text": "Down"
                      },
                      "1": {
                        "color": "green",
                        "index": 1,
                        "text": "Up"
                      }
                    },
                    "type": "value"
                  }
                ],
                "thresholds": {
                  "steps": [
                    {
                      "color": "red",
                      "value": null
                    },
                    {
                      "color": "green",
                      "value": 1
                    }
                  ]
                }
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 12,
              "y": 16
            },
            "id": 8,
            "options": {
              "cellHeight": "sm",
              "footer": {
                "countRows": false,
                "fields": "",
                "reducer": [
                  "sum"
                ],
                "show": false
              },
              "showHeader": true
            },
            "pluginVersion": "10.2.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "unifi_interface_up",
                "format": "table",
                "instant": true,
                "legendFormat": "__auto",
                "range": false,
                "refId": "A"
              }
            ],
            "title": "Interface Status",
            "type": "table"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "description": "WiFi client signal strength distribution",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisCenteredZero": false,
                  "axisColorMode": "text",
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 0,
                  "gradientMode": "none",
                  "hideFrom": {
                    "legend": false,
                    "tooltip": false,
                    "vis": false
                  },
                  "insertNulls": false,
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "auto",
                  "spanNulls": false,
                  "stacking": {
                    "group": "A",
                    "mode": "none"
                  },
                  "thresholdsStyle": {
                    "mode": "off"
                  }
                },
                "mappings": [],
                "thresholds": {
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "red",
                      "value": 80
                    }
                  ]
                },
                "unit": "dBm"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 0,
              "y": 24
            },
            "id": 9,
            "options": {
              "legend": {
                "calcs": [],
                "displayMode": "list",
                "placement": "bottom",
                "showLegend": true
              },
              "tooltip": {
                "mode": "single",
                "sort": "none"
              }
            },
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "unifi_client_signal_strength_dbm",
                "instant": false,
                "legendFormat": "{{device_name}} - Client {{client_mac}}",
                "range": true,
                "refId": "A"
              }
            ],
            "title": "WiFi Signal Strength",
            "type": "timeseries"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "description": "NetFlow traffic patterns",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisCenteredZero": false,
                  "axisColorMode": "text",
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 10,
                  "gradientMode": "none",
                  "hideFrom": {
                    "legend": false,
                    "tooltip": false,
                    "vis": false
                  },
                  "insertNulls": false,
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "never",
                  "spanNulls": false,
                  "stacking": {
                    "group": "A",
                    "mode": "none"
                  },
                  "thresholdsStyle": {
                    "mode": "off"
                  }
                },
                "mappings": [],
                "thresholds": {
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "red",
                      "value": 80
                    }
                  ]
                },
                "unit": "bps"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 12,
              "y": 24
            },
            "id": 10,
            "options": {
              "legend": {
                "calcs": [],
                "displayMode": "list",
                "placement": "bottom",
                "showLegend": true
              },
              "tooltip": {
                "mode": "multi",
                "sort": "none"
              }
            },
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "rate(netflow_bytes_total[5m]) * 8",
                "instant": false,
                "legendFormat": "{{src_net}} -> {{dst_net}} ({{protocol}})",
                "range": true,
                "refId": "A"
              }
            ],
            "title": "NetFlow Traffic Analysis",
            "type": "timeseries"
          },
          {
            "datasource": {
              "type": "loki",
              "uid": "loki"
            },
            "description": "Recent UniFi device logs",
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 0,
              "y": 32
            },
            "id": 11,
            "options": {
              "dedupStrategy": "none",
              "enableLogDetails": true,
              "prettifyLogMessage": false,
              "showCommonLabels": false,
              "showLabels": false,
              "showTime": false,
              "sortOrder": "Descending",
              "wrapLogMessage": false
            },
            "targets": [
              {
                "datasource": {
                  "type": "loki",
                  "uid": "loki"
                },
                "editorMode": "code",
                "expr": "{job=\"unifi-router\"}",
                "queryType": "",
                "refId": "A"
              }
            ],
            "title": "UniFi Device Logs",
            "type": "logs"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "description": "Top protocols by flow count",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "hideFrom": {
                    "legend": false,
                    "tooltip": false,
                    "vis": false
                  }
                },
                "mappings": [],
                "unit": "short"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 12,
              "y": 32
            },
            "id": 12,
            "options": {
              "displayLabels": [
                "name",
                "percent"
              ],
              "legend": {
                "displayMode": "visible",
                "placement": "right",
                "showLegend": true,
                "values": []
              },
              "pieType": "pie",
              "reduceOptions": {
                "calcs": [
                  "lastNotNull"
                ],
                "fields": "",
                "values": false
              },
              "tooltip": {
                "mode": "single",
                "sort": "none"
              }
            },
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "topk(10, sum by (protocol) (rate(netflow_flows_total[5m])))",
                "instant": false,
                "legendFormat": "{{protocol}}",
                "range": true,
                "refId": "A"
              }
            ],
            "title": "Top Network Protocols",
            "type": "piechart"
          }
        ],
        "refresh": "30s",
        "schemaVersion": 38,
        "style": "dark",
        "tags": [
          "ubiquiti",
          "unifi",
          "network",
          "odin"
        ],
        "templating": {
          "list": []
        },
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "timepicker": {},
        "timezone": "",
        "title": "ODIN UniFi Network Dashboard",
        "uid": "ubiquiti-dashboard",
        "version": 1,
        "weekStart": ""
      }
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"ubiquiti-dashboard.json":"{\n  \"annotations\": {\n    \"list\": [\n      {\n        \"builtIn\": 1,\n        \"datasource\": {\n          \"type\": \"grafana\",\n          \"uid\": \"-- Grafana --\"\n        },\n        \"enable\": true,\n        \"hide\": true,\n        \"iconColor\": \"rgba(0, 211, 255, 1)\",\n        \"name\": \"Annotations \u0026 Alerts\",\n        \"type\": \"dashboard\"\n      }\n    ]\n  },\n  \"editable\": true,\n  \"fiscalYearStartMonth\": 0,\n  \"graphTooltip\": 0,\n  \"id\": null,\n  \"links\": [],\n  \"liveNow\": false,\n  \"panels\": [\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"description\": \"Current operational status of UniFi devices\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"custom\": {\n            \"align\": \"auto\",\n            \"cellOptions\": {\n              \"type\": \"auto\"\n            },\n            \"inspect\": false\n          },\n          \"mappings\": [\n            {\n              \"options\": {\n                \"0\": {\n                  \"color\": \"red\",\n                  \"index\": 0,\n                  \"text\": \"Offline\"\n                },\n                \"1\": {\n                  \"color\": \"green\",\n                  \"index\": 1,\n                  \"text\": \"Online\"\n                }\n              },\n              \"type\": \"value\"\n            }\n          ],\n          \"thresholds\": {\n            \"steps\": [\n              {\n                \"color\": \"red\",\n                \"value\": null\n              },\n              {\n                \"color\": \"green\",\n                \"value\": 1\n              }\n            ]\n          }\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 0,\n        \"y\": 0\n      },\n      \"id\": 1,\n      \"options\": {\n        \"cellHeight\": \"sm\",\n        \"footer\": {\n          \"countRows\": false,\n          \"fields\": \"\",\n          \"reducer\": [\n            \"sum\"\n          ],\n          \"show\": false\n        },\n        \"showHeader\": true\n      },\n      \"pluginVersion\": \"10.2.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"up{job=~\\\".*unifi.*\\\"}\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"legendFormat\": \"__auto\",\n          \"range\": false,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"UniFi Device Status\",\n      \"type\": \"table\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"description\": \"Device uptime in days\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisCenteredZero\": false,\n            \"axisColorMode\": \"text\",\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 0,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"legend\": false,\n              \"tooltip\": false,\n              \"vis\": false\n            },\n            \"insertNulls\": false,\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"auto\",\n            \"spanNulls\": false,\n            \"stacking\": {\n              \"group\": \"A\",\n              \"mode\": \"none\"\n            },\n            \"thresholdsStyle\": {\n              \"mode\": \"off\"\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 80\n              }\n            ]\n          },\n          \"unit\": \"s\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 0\n      },\n      \"id\": 2,\n      \"options\": {\n        \"legend\": {\n          \"calcs\": [],\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\",\n          \"showLegend\": true\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        }\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"unifi_device_uptime_seconds\",\n          \"instant\": false,\n          \"legendFormat\": \"{{device_name}}\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Device Uptime\",\n      \"type\": \"timeseries\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"description\": \"Current CPU usage percentage\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"max\": 100,\n          \"min\": 0,\n          \"thresholds\": {\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"yellow\",\n                \"value\": 60\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 80\n              }\n            ]\n          },\n          \"unit\": \"percent\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 6,\n        \"x\": 0,\n        \"y\": 8\n      },\n      \"id\": 3,\n      \"options\": {\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"calcs\": [\n            \"lastNotNull\"\n          ],\n          \"fields\": \"\",\n          \"values\": false\n        },\n        \"showThresholdLabels\": false,\n        \"showThresholdMarkers\": true,\n        \"text\": {}\n      },\n      \"pluginVersion\": \"10.2.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"unifi_device_cpu_usage_percent\",\n          \"instant\": false,\n          \"legendFormat\": \"{{device_name}}\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"CPU Usage\",\n      \"type\": \"gauge\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"description\": \"Current memory usage percentage\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"max\": 100,\n          \"min\": 0,\n          \"thresholds\": {\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"yellow\",\n                \"value\": 70\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 85\n              }\n            ]\n          },\n          \"unit\": \"percent\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 6,\n        \"x\": 6,\n        \"y\": 8\n      },\n      \"id\": 4,\n      \"options\": {\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"calcs\": [\n            \"lastNotNull\"\n          ],\n          \"fields\": \"\",\n          \"values\": false\n        },\n        \"showThresholdLabels\": false,\n        \"showThresholdMarkers\": true,\n        \"text\": {}\n      },\n      \"pluginVersion\": \"10.2.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"unifi_device_memory_usage_percent\",\n          \"instant\": false,\n          \"legendFormat\": \"{{device_name}}\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Memory Usage\",\n      \"type\": \"gauge\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"description\": \"Device temperature in Celsius\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"max\": 100,\n          \"min\": 0,\n          \"thresholds\": {\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"yellow\",\n                \"value\": 60\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 75\n              }\n            ]\n          },\n          \"unit\": \"celsius\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 6,\n        \"x\": 12,\n        \"y\": 8\n      },\n      \"id\": 5,\n      \"options\": {\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"calcs\": [\n            \"lastNotNull\"\n          ],\n          \"fields\": \"\",\n          \"values\": false\n        },\n        \"showThresholdLabels\": false,\n        \"showThresholdMarkers\": true,\n        \"text\": {}\n      },\n      \"pluginVersion\": \"10.2.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"unifi_device_temperature_celsius\",\n          \"instant\": false,\n          \"legendFormat\": \"{{device_name}} - {{sensor}}\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Device Temperature\",\n      \"type\": \"gauge\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"description\": \"Current number of connected clients\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"hideFrom\": {\n              \"legend\": false,\n              \"tooltip\": false,\n              \"vis\": false\n            }\n          },\n          \"mappings\": [],\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 6,\n        \"x\": 18,\n        \"y\": 8\n      },\n      \"id\": 6,\n      \"options\": {\n        \"displayLabels\": [\n          \"name\",\n          \"value\"\n        ],\n        \"legend\": {\n          \"displayMode\": \"visible\",\n          \"placement\": \"right\",\n          \"showLegend\": true,\n          \"values\": []\n        },\n        \"pieType\": \"pie\",\n        \"reduceOptions\": {\n          \"calcs\": [\n            \"lastNotNull\"\n          ],\n          \"fields\": \"\",\n          \"values\": false\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        }\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"unifi_clients_total\",\n          \"instant\": false,\n          \"legendFormat\": \"{{device_name}} - {{type}}\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Connected Clients\",\n      \"type\": \"piechart\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"description\": \"Network interface traffic rates\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisCenteredZero\": false,\n            \"axisColorMode\": \"text\",\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 10,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"legend\": false,\n              \"tooltip\": false,\n              \"vis\": false\n            },\n            \"insertNulls\": false,\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"never\",\n            \"spanNulls\": false,\n            \"stacking\": {\n              \"group\": \"A\",\n              \"mode\": \"none\"\n            },\n            \"thresholdsStyle\": {\n              \"mode\": \"off\"\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 80\n              }\n            ]\n          },\n          \"unit\": \"bps\"\n        },\n        \"overrides\": [\n          {\n            \"matcher\": {\n              \"id\": \"byRegexp\",\n              \"options\": \"/.*TX.*/\"\n            },\n            \"properties\": [\n              {\n                \"id\": \"custom.transform\",\n                \"value\": \"negative-Y\"\n              }\n            ]\n          }\n        ]\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 0,\n        \"y\": 16\n      },\n      \"id\": 7,\n      \"options\": {\n        \"legend\": {\n          \"calcs\": [],\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\",\n          \"showLegend\": true\n        },\n        \"tooltip\": {\n          \"mode\": \"multi\",\n          \"sort\": \"none\"\n        }\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"rate(unifi_interface_rx_bytes_total[5m]) * 8\",\n          \"instant\": false,\n          \"legendFormat\": \"{{device_name}}-{{interface}} RX\",\n          \"range\": true,\n          \"refId\": \"A\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"rate(unifi_interface_tx_bytes_total[5m]) * 8\",\n          \"instant\": false,\n          \"legendFormat\": \"{{device_name}}-{{interface}} TX\",\n          \"range\": true,\n          \"refId\": \"B\"\n        }\n      ],\n      \"title\": \"Interface Traffic\",\n      \"type\": \"timeseries\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"description\": \"Interface operational status\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"custom\": {\n            \"align\": \"auto\",\n            \"cellOptions\": {\n              \"type\": \"auto\"\n            },\n            \"inspect\": false\n          },\n          \"mappings\": [\n            {\n              \"options\": {\n                \"0\": {\n                  \"color\": \"red\",\n                  \"index\": 0,\n                  \"text\": \"Down\"\n                },\n                \"1\": {\n                  \"color\": \"green\",\n                  \"index\": 1,\n                  \"text\": \"Up\"\n                }\n              },\n              \"type\": \"value\"\n            }\n          ],\n          \"thresholds\": {\n            \"steps\": [\n              {\n                \"color\": \"red\",\n                \"value\": null\n              },\n              {\n                \"color\": \"green\",\n                \"value\": 1\n              }\n            ]\n          }\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 16\n      },\n      \"id\": 8,\n      \"options\": {\n        \"cellHeight\": \"sm\",\n        \"footer\": {\n          \"countRows\": false,\n          \"fields\": \"\",\n          \"reducer\": [\n            \"sum\"\n          ],\n          \"show\": false\n        },\n        \"showHeader\": true\n      },\n      \"pluginVersion\": \"10.2.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"unifi_interface_up\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"legendFormat\": \"__auto\",\n          \"range\": false,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Interface Status\",\n      \"type\": \"table\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"description\": \"WiFi client signal strength distribution\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisCenteredZero\": false,\n            \"axisColorMode\": \"text\",\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 0,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"legend\": false,\n              \"tooltip\": false,\n              \"vis\": false\n            },\n            \"insertNulls\": false,\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"auto\",\n            \"spanNulls\": false,\n            \"stacking\": {\n              \"group\": \"A\",\n              \"mode\": \"none\"\n            },\n            \"thresholdsStyle\": {\n              \"mode\": \"off\"\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 80\n              }\n            ]\n          },\n          \"unit\": \"dBm\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 0,\n        \"y\": 24\n      },\n      \"id\": 9,\n      \"options\": {\n        \"legend\": {\n          \"calcs\": [],\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\",\n          \"showLegend\": true\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        }\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"unifi_client_signal_strength_dbm\",\n          \"instant\": false,\n          \"legendFormat\": \"{{device_name}} - Client {{client_mac}}\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"WiFi Signal Strength\",\n      \"type\": \"timeseries\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"description\": \"NetFlow traffic patterns\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisCenteredZero\": false,\n            \"axisColorMode\": \"text\",\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 10,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"legend\": false,\n              \"tooltip\": false,\n              \"vis\": false\n            },\n            \"insertNulls\": false,\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"never\",\n            \"spanNulls\": false,\n            \"stacking\": {\n              \"group\": \"A\",\n              \"mode\": \"none\"\n            },\n            \"thresholdsStyle\": {\n              \"mode\": \"off\"\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 80\n              }\n            ]\n          },\n          \"unit\": \"bps\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 24\n      },\n      \"id\": 10,\n      \"options\": {\n        \"legend\": {\n          \"calcs\": [],\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\",\n          \"showLegend\": true\n        },\n        \"tooltip\": {\n          \"mode\": \"multi\",\n          \"sort\": \"none\"\n        }\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"rate(netflow_bytes_total[5m]) * 8\",\n          \"instant\": false,\n          \"legendFormat\": \"{{src_net}} -\u003e {{dst_net}} ({{protocol}})\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"NetFlow Traffic Analysis\",\n      \"type\": \"timeseries\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"loki\",\n        \"uid\": \"loki\"\n      },\n      \"description\": \"Recent UniFi device logs\",\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 0,\n        \"y\": 32\n      },\n      \"id\": 11,\n      \"options\": {\n        \"dedupStrategy\": \"none\",\n        \"enableLogDetails\": true,\n        \"prettifyLogMessage\": false,\n        \"showCommonLabels\": false,\n        \"showLabels\": false,\n        \"showTime\": false,\n        \"sortOrder\": \"Descending\",\n        \"wrapLogMessage\": false\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"loki\",\n            \"uid\": \"loki\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"{job=\\\"unifi-router\\\"}\",\n          \"queryType\": \"\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"UniFi Device Logs\",\n      \"type\": \"logs\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"description\": \"Top protocols by flow count\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"hideFrom\": {\n              \"legend\": false,\n              \"tooltip\": false,\n              \"vis\": false\n            }\n          },\n          \"mappings\": [],\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 32\n      },\n      \"id\": 12,\n      \"options\": {\n        \"displayLabels\": [\n          \"name\",\n          \"percent\"\n        ],\n        \"legend\": {\n          \"displayMode\": \"visible\",\n          \"placement\": \"right\",\n          \"showLegend\": true,\n          \"values\": []\n        },\n        \"pieType\": \"pie\",\n        \"reduceOptions\": {\n          \"calcs\": [\n            \"lastNotNull\"\n          ],\n          \"fields\": \"\",\n          \"values\": false\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        }\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"topk(10, sum by (protocol) (rate(netflow_flows_total[5m])))\",\n          \"instant\": false,\n          \"legendFormat\": \"{{protocol}}\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Top Network Protocols\",\n      \"type\": \"piechart\"\n    }\n  ],\n  \"refresh\": \"30s\",\n  \"schemaVersion\": 38,\n  \"style\": \"dark\",\n  \"tags\": [\n    \"ubiquiti\",\n    \"unifi\",\n    \"network\",\n    \"odin\"\n  ],\n  \"templating\": {\n    \"list\": []\n  },\n  \"time\": {\n    \"from\": \"now-1h\",\n    \"to\": \"now\"\n  },\n  \"timepicker\": {},\n  \"timezone\": \"\",\n  \"title\": \"ODIN UniFi Network Dashboard\",\n  \"uid\": \"ubiquiti-dashboard\",\n  \"version\": 1,\n  \"weekStart\": \"\"\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"grafana_dashboard":"1"},"name":"ubiquiti-dashboard","namespace":"monitoring"}}
    creationTimestamp: "2025-06-02T14:47:48Z"
    labels:
      grafana_dashboard: "1"
    name: ubiquiti-dashboard
    namespace: monitoring
    resourceVersion: "1773277"
    uid: 4307f82f-4b20-493c-994a-150040d5053d
- apiVersion: v1
  data:
    udm-fixed-logs-dashboard.json: |
      {
        "id": null,
        "uid": "udm-fixed-logs",
        "title": "UDM Pro System Logs (Fixed)",
        "tags": ["network", "odin", "udm-pro", "logs", "fixed"],
        "style": "dark",
        "timezone": "browser",
        "refresh": "30s",
        "schemaVersion": 27,
        "version": 1,
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "panels": [
          {
            "id": 1,
            "title": "System Log Rate",
            "type": "stat",
            "gridPos": {"h": 4, "w": 6, "x": 0, "y": 0},
            "targets": [
              {
                "expr": "rate(loki_distributor_lines_received_total[5m])",
                "legendFormat": "Logs/sec",
                "refId": "A",
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                }
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "logs/sec",
                "color": {"mode": "thresholds"},
                "thresholds": {
                  "steps": [
                    {"color": "green", "value": null},
                    {"color": "yellow", "value": 10},
                    {"color": "red", "value": 100}
                  ]
                }
              }
            }
          },
          {
            "id": 2,
            "title": "Recent System Logs",
            "type": "logs",
            "gridPos": {"h": 16, "w": 18, "x": 6, "y": 0},
            "targets": [
              {
                "expr": "{job=\"system\"}",
                "refId": "A",
                "datasource": {
                  "type": "loki",
                  "uid": "loki"
                }
              }
            ],
            "options": {
              "showTime": true,
              "showLabels": true,
              "wrapLogMessage": true,
              "sortOrder": "Descending",
              "enableLogDetails": true
            }
          },
          {
            "id": 3,
            "title": "Log Sources Count",
            "type": "stat",
            "gridPos": {"h": 4, "w": 6, "x": 0, "y": 4},
            "targets": [
              {
                "expr": "count by (filename) (count by (filename) ({job=\"system\"}))",
                "legendFormat": "{{filename}}",
                "refId": "A",
                "datasource": {
                  "type": "loki",
                  "uid": "loki"
                }
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "short",
                "color": {"mode": "palette-classic"}
              }
            }
          },
          {
            "id": 4,
            "title": "Error and Warning Logs",
            "type": "logs",
            "gridPos": {"h": 8, "w": 6, "x": 0, "y": 8},
            "targets": [
              {
                "expr": "{job=\"system\"} |~ \"(?i)(error|fail|warn|critical|alert)\"",
                "refId": "A",
                "datasource": {
                  "type": "loki",
                  "uid": "loki"
                }
              }
            ],
            "options": {
              "showTime": true,
              "showLabels": false,
              "wrapLogMessage": true,
              "sortOrder": "Descending"
            }
          },
          {
            "id": 5,
            "title": "Network-Related Logs",
            "type": "logs",
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 16},
            "targets": [
              {
                "expr": "{job=\"system\"} |~ \"(?i)(network|wifi|ethernet|connection|ip|dns|dhcp)\"",
                "refId": "A",
                "datasource": {
                  "type": "loki",
                  "uid": "loki"
                }
              }
            ],
            "options": {
              "showTime": true,
              "showLabels": true,
              "wrapLogMessage": true,
              "sortOrder": "Descending"
            }
          }
        ]
      }
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"udm-fixed-logs-dashboard.json":"{\n  \"id\": null,\n  \"uid\": \"udm-fixed-logs\",\n  \"title\": \"UDM Pro System Logs (Fixed)\",\n  \"tags\": [\"network\", \"odin\", \"udm-pro\", \"logs\", \"fixed\"],\n  \"style\": \"dark\",\n  \"timezone\": \"browser\",\n  \"refresh\": \"30s\",\n  \"schemaVersion\": 27,\n  \"version\": 1,\n  \"time\": {\n    \"from\": \"now-1h\",\n    \"to\": \"now\"\n  },\n  \"panels\": [\n    {\n      \"id\": 1,\n      \"title\": \"System Log Rate\",\n      \"type\": \"stat\",\n      \"gridPos\": {\"h\": 4, \"w\": 6, \"x\": 0, \"y\": 0},\n      \"targets\": [\n        {\n          \"expr\": \"rate(loki_distributor_lines_received_total[5m])\",\n          \"legendFormat\": \"Logs/sec\",\n          \"refId\": \"A\",\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          }\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"logs/sec\",\n          \"color\": {\"mode\": \"thresholds\"},\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 10},\n              {\"color\": \"red\", \"value\": 100}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"id\": 2,\n      \"title\": \"Recent System Logs\",\n      \"type\": \"logs\",\n      \"gridPos\": {\"h\": 16, \"w\": 18, \"x\": 6, \"y\": 0},\n      \"targets\": [\n        {\n          \"expr\": \"{job=\\\"system\\\"}\",\n          \"refId\": \"A\",\n          \"datasource\": {\n            \"type\": \"loki\",\n            \"uid\": \"loki\"\n          }\n        }\n      ],\n      \"options\": {\n        \"showTime\": true,\n        \"showLabels\": true,\n        \"wrapLogMessage\": true,\n        \"sortOrder\": \"Descending\",\n        \"enableLogDetails\": true\n      }\n    },\n    {\n      \"id\": 3,\n      \"title\": \"Log Sources Count\",\n      \"type\": \"stat\",\n      \"gridPos\": {\"h\": 4, \"w\": 6, \"x\": 0, \"y\": 4},\n      \"targets\": [\n        {\n          \"expr\": \"count by (filename) (count by (filename) ({job=\\\"system\\\"}))\",\n          \"legendFormat\": \"{{filename}}\",\n          \"refId\": \"A\",\n          \"datasource\": {\n            \"type\": \"loki\",\n            \"uid\": \"loki\"\n          }\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"color\": {\"mode\": \"palette-classic\"}\n        }\n      }\n    },\n    {\n      \"id\": 4,\n      \"title\": \"Error and Warning Logs\",\n      \"type\": \"logs\",\n      \"gridPos\": {\"h\": 8, \"w\": 6, \"x\": 0, \"y\": 8},\n      \"targets\": [\n        {\n          \"expr\": \"{job=\\\"system\\\"} |~ \\\"(?i)(error|fail|warn|critical|alert)\\\"\",\n          \"refId\": \"A\",\n          \"datasource\": {\n            \"type\": \"loki\",\n            \"uid\": \"loki\"\n          }\n        }\n      ],\n      \"options\": {\n        \"showTime\": true,\n        \"showLabels\": false,\n        \"wrapLogMessage\": true,\n        \"sortOrder\": \"Descending\"\n      }\n    },\n    {\n      \"id\": 5,\n      \"title\": \"Network-Related Logs\",\n      \"type\": \"logs\",\n      \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 16},\n      \"targets\": [\n        {\n          \"expr\": \"{job=\\\"system\\\"} |~ \\\"(?i)(network|wifi|ethernet|connection|ip|dns|dhcp)\\\"\",\n          \"refId\": \"A\",\n          \"datasource\": {\n            \"type\": \"loki\",\n            \"uid\": \"loki\"\n          }\n        }\n      ],\n      \"options\": {\n        \"showTime\": true,\n        \"showLabels\": true,\n        \"wrapLogMessage\": true,\n        \"sortOrder\": \"Descending\"\n      }\n    }\n  ]\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"grafana_dashboard":"1"},"name":"udm-fixed-logs-dashboard","namespace":"monitoring"}}
    creationTimestamp: "2025-06-02T15:41:19Z"
    labels:
      grafana_dashboard: "1"
    name: udm-fixed-logs-dashboard
    namespace: monitoring
    resourceVersion: "1796967"
    uid: 64ba8d56-e12e-46d4-a186-1eeb1d78f77a
- apiVersion: v1
  data:
    udm-fixed-netflow-dashboard.json: |
      {
        "id": null,
        "uid": "udm-fixed-netflow",
        "title": "UDM Pro NetFlow Analysis (Fixed)",
        "tags": ["network", "odin", "udm-pro", "netflow", "fixed"],
        "style": "dark",
        "timezone": "browser",
        "refresh": "30s",
        "schemaVersion": 27,
        "version": 1,
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "panels": [
          {
            "id": 1,
            "title": "NetFlow Collector Status",
            "type": "gauge",
            "gridPos": {"h": 4, "w": 6, "x": 0, "y": 0},
            "targets": [
              {
                "expr": "up{job=\"netflow-collector\"}",
                "legendFormat": "Collector Up",
                "refId": "A",
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                }
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "short",
                "min": 0,
                "max": 1,
                "color": {"mode": "thresholds"},
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": null},
                    {"color": "green", "value": 1}
                  ]
                }
              }
            }
          },
          {
            "id": 2,
            "title": "Active Network Flows",
            "type": "stat",
            "gridPos": {"h": 4, "w": 6, "x": 6, "y": 0},
            "targets": [
              {
                "expr": "netflow_active_flows",
                "legendFormat": "Active Flows",
                "refId": "A",
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                }
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "short",
                "color": {"mode": "thresholds"},
                "thresholds": {
                  "steps": [
                    {"color": "blue", "value": null},
                    {"color": "green", "value": 1},
                    {"color": "yellow", "value": 100},
                    {"color": "red", "value": 1000}
                  ]
                }
              }
            }
          },
          {
            "id": 3,
            "title": "NetFlow Data Awaiting Collection",
            "type": "stat",
            "gridPos": {"h": 4, "w": 12, "x": 12, "y": 0},
            "targets": [
              {
                "expr": "0",
                "legendFormat": "Waiting for Data",
                "refId": "A",
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                }
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "short",
                "color": {"mode": "fixed", "fixedColor": "blue"}
              }
            },
            "options": {
              "text": {
                "valueSize": 18
              }
            }
          },
          {
            "id": 4,
            "title": "NetFlow Flows Over Time",
            "type": "timeseries",
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 4},
            "targets": [
              {
                "expr": "rate(netflow_flows_total[5m])",
                "legendFormat": "Flows/sec - {{src_net}} to {{dst_net}}",
                "refId": "A",
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                }
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "ops",
                "color": {"mode": "palette-classic"}
              }
            }
          },
          {
            "id": 5,
            "title": "NetFlow Traffic Volume",
            "type": "timeseries",
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 4},
            "targets": [
              {
                "expr": "rate(netflow_bytes_total[5m]) * 8 / 1000000",
                "legendFormat": "{{src_net}} → {{dst_net}} ({{protocol}})",
                "refId": "A",
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                }
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "Mbps",
                "color": {"mode": "palette-classic"}
              }
            }
          },
          {
            "id": 6,
            "title": "Configuration Instructions",
            "type": "text",
            "gridPos": {"h": 6, "w": 24, "x": 0, "y": 12},
            "options": {
              "content": "## NetFlow Configuration Status\n\n**✅ NetFlow Collector**: Running and healthy at `192.168.1.154:30514`\n\n**⚠️ Waiting for Data**: Your Ubiquiti device needs to send NetFlow data to start seeing metrics.\n\n**Next Steps**:\n1. Verify Ubiquiti NetFlow is configured to send to `192.168.1.154:30514`\n2. Check Ubiquiti device network connectivity to this IP\n3. Once data flows, the panels above will populate automatically\n\n**Current Status**: Ready to receive data - `netflow_active_flows = 0` (no incoming flows yet)",
              "mode": "markdown"
            }
          }
        ]
      }
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"udm-fixed-netflow-dashboard.json":"{\n  \"id\": null,\n  \"uid\": \"udm-fixed-netflow\",\n  \"title\": \"UDM Pro NetFlow Analysis (Fixed)\",\n  \"tags\": [\"network\", \"odin\", \"udm-pro\", \"netflow\", \"fixed\"],\n  \"style\": \"dark\",\n  \"timezone\": \"browser\",\n  \"refresh\": \"30s\",\n  \"schemaVersion\": 27,\n  \"version\": 1,\n  \"time\": {\n    \"from\": \"now-1h\",\n    \"to\": \"now\"\n  },\n  \"panels\": [\n    {\n      \"id\": 1,\n      \"title\": \"NetFlow Collector Status\",\n      \"type\": \"gauge\",\n      \"gridPos\": {\"h\": 4, \"w\": 6, \"x\": 0, \"y\": 0},\n      \"targets\": [\n        {\n          \"expr\": \"up{job=\\\"netflow-collector\\\"}\",\n          \"legendFormat\": \"Collector Up\",\n          \"refId\": \"A\",\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          }\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"min\": 0,\n          \"max\": 1,\n          \"color\": {\"mode\": \"thresholds\"},\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"red\", \"value\": null},\n              {\"color\": \"green\", \"value\": 1}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"id\": 2,\n      \"title\": \"Active Network Flows\",\n      \"type\": \"stat\",\n      \"gridPos\": {\"h\": 4, \"w\": 6, \"x\": 6, \"y\": 0},\n      \"targets\": [\n        {\n          \"expr\": \"netflow_active_flows\",\n          \"legendFormat\": \"Active Flows\",\n          \"refId\": \"A\",\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          }\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"color\": {\"mode\": \"thresholds\"},\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"blue\", \"value\": null},\n              {\"color\": \"green\", \"value\": 1},\n              {\"color\": \"yellow\", \"value\": 100},\n              {\"color\": \"red\", \"value\": 1000}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"id\": 3,\n      \"title\": \"NetFlow Data Awaiting Collection\",\n      \"type\": \"stat\",\n      \"gridPos\": {\"h\": 4, \"w\": 12, \"x\": 12, \"y\": 0},\n      \"targets\": [\n        {\n          \"expr\": \"0\",\n          \"legendFormat\": \"Waiting for Data\",\n          \"refId\": \"A\",\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          }\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"color\": {\"mode\": \"fixed\", \"fixedColor\": \"blue\"}\n        }\n      },\n      \"options\": {\n        \"text\": {\n          \"valueSize\": 18\n        }\n      }\n    },\n    {\n      \"id\": 4,\n      \"title\": \"NetFlow Flows Over Time\",\n      \"type\": \"timeseries\",\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 4},\n      \"targets\": [\n        {\n          \"expr\": \"rate(netflow_flows_total[5m])\",\n          \"legendFormat\": \"Flows/sec - {{src_net}} to {{dst_net}}\",\n          \"refId\": \"A\",\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          }\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"ops\",\n          \"color\": {\"mode\": \"palette-classic\"}\n        }\n      }\n    },\n    {\n      \"id\": 5,\n      \"title\": \"NetFlow Traffic Volume\",\n      \"type\": \"timeseries\",\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 4},\n      \"targets\": [\n        {\n          \"expr\": \"rate(netflow_bytes_total[5m]) * 8 / 1000000\",\n          \"legendFormat\": \"{{src_net}} → {{dst_net}} ({{protocol}})\",\n          \"refId\": \"A\",\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          }\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"Mbps\",\n          \"color\": {\"mode\": \"palette-classic\"}\n        }\n      }\n    },\n    {\n      \"id\": 6,\n      \"title\": \"Configuration Instructions\",\n      \"type\": \"text\",\n      \"gridPos\": {\"h\": 6, \"w\": 24, \"x\": 0, \"y\": 12},\n      \"options\": {\n        \"content\": \"## NetFlow Configuration Status\\n\\n**✅ NetFlow Collector**: Running and healthy at `192.168.1.154:30514`\\n\\n**⚠️ Waiting for Data**: Your Ubiquiti device needs to send NetFlow data to start seeing metrics.\\n\\n**Next Steps**:\\n1. Verify Ubiquiti NetFlow is configured to send to `192.168.1.154:30514`\\n2. Check Ubiquiti device network connectivity to this IP\\n3. Once data flows, the panels above will populate automatically\\n\\n**Current Status**: Ready to receive data - `netflow_active_flows = 0` (no incoming flows yet)\",\n        \"mode\": \"markdown\"\n      }\n    }\n  ]\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"grafana_dashboard":"1"},"name":"udm-fixed-netflow-dashboard","namespace":"monitoring"}}
    creationTimestamp: "2025-06-02T15:41:19Z"
    labels:
      grafana_dashboard: "1"
    name: udm-fixed-netflow-dashboard
    namespace: monitoring
    resourceVersion: "1796968"
    uid: 3a78dc41-12a0-4ebc-adb9-36a89f08e468
- apiVersion: v1
  data:
    udm-pro-logs-dashboard.json: |
      {
        "id": null,
        "uid": "udm-pro-logs",
        "title": "UDM Pro Activity Logs",
        "tags": ["network", "odin", "udm-pro", "logs"],
        "style": "dark",
        "timezone": "browser",
        "refresh": "30s",
        "schemaVersion": 27,
        "version": 1,
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "panels": [
          {
            "id": 1,
            "title": "Log Rate",
            "type": "stat",
            "gridPos": {"h": 4, "w": 6, "x": 0, "y": 0},
            "targets": [
              {
                "expr": "sum(rate(loki_distributor_lines_received_total{job=\"asus-router\"}[5m]))",
                "legendFormat": "Logs/sec",
                "refId": "A",
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                }
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "logs/sec",
                "color": {"mode": "thresholds"},
                "thresholds": {
                  "steps": [
                    {"color": "green", "value": null},
                    {"color": "yellow", "value": 10},
                    {"color": "red", "value": 100}
                  ]
                }
              }
            }
          },
          {
            "id": 2,
            "title": "Recent UDM Pro Logs",
            "type": "logs",
            "gridPos": {"h": 16, "w": 18, "x": 6, "y": 0},
            "targets": [
              {
                "expr": "{job=\"asus-router\"}",
                "refId": "A",
                "datasource": {
                  "type": "loki",
                  "uid": "loki"
                }
              }
            ],
            "options": {
              "showTime": true,
              "showLabels": true,
              "wrapLogMessage": true,
              "sortOrder": "Descending",
              "enableLogDetails": true
            }
          },
          {
            "id": 3,
            "title": "Log Sources",
            "type": "stat",
            "gridPos": {"h": 4, "w": 6, "x": 0, "y": 4},
            "targets": [
              {
                "expr": "count by (router_ip) (count by (router_ip) ({job=\"asus-router\"}))",
                "legendFormat": "{{router_ip}}",
                "refId": "A",
                "datasource": {
                  "type": "loki",
                  "uid": "loki"
                }
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "short",
                "color": {"mode": "palette-classic"}
              }
            }
          },
          {
            "id": 4,
            "title": "Error and Warning Logs",
            "type": "logs",
            "gridPos": {"h": 8, "w": 6, "x": 0, "y": 8},
            "targets": [
              {
                "expr": "{job=\"asus-router\"} |~ \"(?i)(error|fail|warn|critical|alert)\"",
                "refId": "A",
                "datasource": {
                  "type": "loki",
                  "uid": "loki"
                }
              }
            ],
            "options": {
              "showTime": true,
              "showLabels": false,
              "wrapLogMessage": true,
              "sortOrder": "Descending"
            }
          },
          {
            "id": 5,
            "title": "Security Events",
            "type": "logs",
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 16},
            "targets": [
              {
                "expr": "{job=\"asus-router\"} |~ \"(?i)(security|auth|login|fail|block|deny|intrusion|attack)\"",
                "refId": "A",
                "datasource": {
                  "type": "loki",
                  "uid": "loki"
                }
              }
            ],
            "options": {
              "showTime": true,
              "showLabels": true,
              "wrapLogMessage": true,
              "sortOrder": "Descending"
            }
          },
          {
            "id": 6,
            "title": "WiFi Events",
            "type": "logs",
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 24},
            "targets": [
              {
                "expr": "{job=\"asus-router\"} |~ \"(?i)(wifi|wireless|connect|disconnect|association|client)\"",
                "refId": "A",
                "datasource": {
                  "type": "loki",
                  "uid": "loki"
                }
              }
            ],
            "options": {
              "showTime": true,
              "showLabels": true,
              "wrapLogMessage": true,
              "sortOrder": "Descending"
            }
          }
        ]
      }
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"udm-pro-logs-dashboard.json":"{\n  \"id\": null,\n  \"uid\": \"udm-pro-logs\",\n  \"title\": \"UDM Pro Activity Logs\",\n  \"tags\": [\"network\", \"odin\", \"udm-pro\", \"logs\"],\n  \"style\": \"dark\",\n  \"timezone\": \"browser\",\n  \"refresh\": \"30s\",\n  \"schemaVersion\": 27,\n  \"version\": 1,\n  \"time\": {\n    \"from\": \"now-1h\",\n    \"to\": \"now\"\n  },\n  \"panels\": [\n    {\n      \"id\": 1,\n      \"title\": \"Log Rate\",\n      \"type\": \"stat\",\n      \"gridPos\": {\"h\": 4, \"w\": 6, \"x\": 0, \"y\": 0},\n      \"targets\": [\n        {\n          \"expr\": \"sum(rate(loki_distributor_lines_received_total{job=\\\"asus-router\\\"}[5m]))\",\n          \"legendFormat\": \"Logs/sec\",\n          \"refId\": \"A\",\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          }\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"logs/sec\",\n          \"color\": {\"mode\": \"thresholds\"},\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 10},\n              {\"color\": \"red\", \"value\": 100}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"id\": 2,\n      \"title\": \"Recent UDM Pro Logs\",\n      \"type\": \"logs\",\n      \"gridPos\": {\"h\": 16, \"w\": 18, \"x\": 6, \"y\": 0},\n      \"targets\": [\n        {\n          \"expr\": \"{job=\\\"asus-router\\\"}\",\n          \"refId\": \"A\",\n          \"datasource\": {\n            \"type\": \"loki\",\n            \"uid\": \"loki\"\n          }\n        }\n      ],\n      \"options\": {\n        \"showTime\": true,\n        \"showLabels\": true,\n        \"wrapLogMessage\": true,\n        \"sortOrder\": \"Descending\",\n        \"enableLogDetails\": true\n      }\n    },\n    {\n      \"id\": 3,\n      \"title\": \"Log Sources\",\n      \"type\": \"stat\",\n      \"gridPos\": {\"h\": 4, \"w\": 6, \"x\": 0, \"y\": 4},\n      \"targets\": [\n        {\n          \"expr\": \"count by (router_ip) (count by (router_ip) ({job=\\\"asus-router\\\"}))\",\n          \"legendFormat\": \"{{router_ip}}\",\n          \"refId\": \"A\",\n          \"datasource\": {\n            \"type\": \"loki\",\n            \"uid\": \"loki\"\n          }\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"color\": {\"mode\": \"palette-classic\"}\n        }\n      }\n    },\n    {\n      \"id\": 4,\n      \"title\": \"Error and Warning Logs\",\n      \"type\": \"logs\",\n      \"gridPos\": {\"h\": 8, \"w\": 6, \"x\": 0, \"y\": 8},\n      \"targets\": [\n        {\n          \"expr\": \"{job=\\\"asus-router\\\"} |~ \\\"(?i)(error|fail|warn|critical|alert)\\\"\",\n          \"refId\": \"A\",\n          \"datasource\": {\n            \"type\": \"loki\",\n            \"uid\": \"loki\"\n          }\n        }\n      ],\n      \"options\": {\n        \"showTime\": true,\n        \"showLabels\": false,\n        \"wrapLogMessage\": true,\n        \"sortOrder\": \"Descending\"\n      }\n    },\n    {\n      \"id\": 5,\n      \"title\": \"Security Events\",\n      \"type\": \"logs\",\n      \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 16},\n      \"targets\": [\n        {\n          \"expr\": \"{job=\\\"asus-router\\\"} |~ \\\"(?i)(security|auth|login|fail|block|deny|intrusion|attack)\\\"\",\n          \"refId\": \"A\",\n          \"datasource\": {\n            \"type\": \"loki\",\n            \"uid\": \"loki\"\n          }\n        }\n      ],\n      \"options\": {\n        \"showTime\": true,\n        \"showLabels\": true,\n        \"wrapLogMessage\": true,\n        \"sortOrder\": \"Descending\"\n      }\n    },\n    {\n      \"id\": 6,\n      \"title\": \"WiFi Events\",\n      \"type\": \"logs\",\n      \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 24},\n      \"targets\": [\n        {\n          \"expr\": \"{job=\\\"asus-router\\\"} |~ \\\"(?i)(wifi|wireless|connect|disconnect|association|client)\\\"\",\n          \"refId\": \"A\",\n          \"datasource\": {\n            \"type\": \"loki\",\n            \"uid\": \"loki\"\n          }\n        }\n      ],\n      \"options\": {\n        \"showTime\": true,\n        \"showLabels\": true,\n        \"wrapLogMessage\": true,\n        \"sortOrder\": \"Descending\"\n      }\n    }\n  ]\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"grafana_dashboard":"1"},"name":"udm-pro-logs-dashboard","namespace":"monitoring"}}
    creationTimestamp: "2025-06-02T03:19:26Z"
    labels:
      grafana_dashboard: "1"
    name: udm-pro-logs-dashboard
    namespace: monitoring
    resourceVersion: "1473529"
    uid: 3008e45d-42ec-473f-8b9d-77b2810de0f6
- apiVersion: v1
  data:
    udm-pro-netflow-dashboard.json: |
      {
        "id": null,
        "uid": "udm-pro-netflow",
        "title": "UDM Pro NetFlow Analysis",
        "tags": ["network", "odin", "udm-pro", "netflow"],
        "style": "dark",
        "timezone": "browser",
        "refresh": "30s",
        "schemaVersion": 27,
        "version": 1,
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "panels": [
          {
            "id": 1,
            "title": "Total Network Flows",
            "type": "stat",
            "gridPos": {"h": 4, "w": 6, "x": 0, "y": 0},
            "targets": [
              {
                "expr": "sum(rate(netflow_flows_total[5m]))",
                "legendFormat": "Flows/sec",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "ops",
                "color": {"mode": "thresholds"},
                "thresholds": {
                  "steps": [
                    {"color": "green", "value": null},
                    {"color": "yellow", "value": 100},
                    {"color": "red", "value": 1000}
                  ]
                }
              }
            }
          },
          {
            "id": 2,
            "title": "Network Throughput",
            "type": "stat",
            "gridPos": {"h": 4, "w": 6, "x": 6, "y": 0},
            "targets": [
              {
                "expr": "sum(rate(netflow_bytes_total[5m])) * 8 / 1000000",
                "legendFormat": "Mbps",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "Mbps",
                "color": {"mode": "thresholds"},
                "thresholds": {
                  "steps": [
                    {"color": "green", "value": null},
                    {"color": "yellow", "value": 100},
                    {"color": "red", "value": 500}
                  ]
                }
              }
            }
          },
          {
            "id": 3,
            "title": "Active Flows",
            "type": "stat",
            "gridPos": {"h": 4, "w": 6, "x": 12, "y": 0},
            "targets": [
              {
                "expr": "netflow_active_flows",
                "legendFormat": "Active",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "short",
                "color": {"mode": "thresholds"},
                "thresholds": {
                  "steps": [
                    {"color": "green", "value": null},
                    {"color": "yellow", "value": 1000},
                    {"color": "red", "value": 5000}
                  ]
                }
              }
            }
          },
          {
            "id": 4,
            "title": "Total Packets",
            "type": "stat",
            "gridPos": {"h": 4, "w": 6, "x": 18, "y": 0},
            "targets": [
              {
                "expr": "sum(rate(netflow_packets_total[5m]))",
                "legendFormat": "Packets/sec",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "pps",
                "color": {"mode": "thresholds"},
                "thresholds": {
                  "steps": [
                    {"color": "green", "value": null},
                    {"color": "yellow", "value": 1000},
                    {"color": "red", "value": 10000}
                  ]
                }
              }
            }
          },
          {
            "id": 5,
            "title": "Network Traffic by Direction",
            "type": "timeseries",
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 4},
            "targets": [
              {
                "expr": "sum by (src_net, dst_net) (rate(netflow_bytes_total[5m])) * 8 / 1000000",
                "legendFormat": "{{src_net}} → {{dst_net}}",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "Mbps",
                "color": {"mode": "palette-classic"}
              }
            }
          },
          {
            "id": 6,
            "title": "Top Protocols by Traffic",
            "type": "piechart",
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 4},
            "targets": [
              {
                "expr": "topk(10, sum by (protocol) (rate(netflow_bytes_total[5m])))",
                "legendFormat": "{{protocol}}",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "bytes",
                "color": {"mode": "palette-classic"}
              }
            }
          },
          {
            "id": 7,
            "title": "LAN to WAN Traffic",
            "type": "timeseries",
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 12},
            "targets": [
              {
                "expr": "sum(rate(netflow_bytes_total{src_net=~\"lan_.*\", dst_net=\"wan\"}[5m])) * 8 / 1000000",
                "legendFormat": "LAN → WAN (Upload)",
                "refId": "A"
              },
              {
                "expr": "sum(rate(netflow_bytes_total{src_net=\"wan\", dst_net=~\"lan_.*\"}[5m])) * 8 / 1000000",
                "legendFormat": "WAN → LAN (Download)",
                "refId": "B"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "Mbps",
                "color": {"mode": "palette-classic"}
              }
            }
          },
          {
            "id": 8,
            "title": "Internal Network Traffic",
            "type": "timeseries",
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 12},
            "targets": [
              {
                "expr": "sum by (src_net, dst_net) (rate(netflow_bytes_total{src_net=~\"lan_.*\", dst_net=~\"lan_.*\"}[5m])) * 8 / 1000000",
                "legendFormat": "{{src_net}} → {{dst_net}}",
                "refId": "A"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "Mbps",
                "color": {"mode": "palette-classic"}
              }
            }
          },
          {
            "id": 9,
            "title": "Top Talkers by Bytes",
            "type": "table",
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 20},
            "targets": [
              {
                "expr": "topk(10, sum by (src_ip, dst_ip) (rate(netflow_top_talkers_bytes[5m])))",
                "format": "table",
                "instant": true,
                "refId": "A"
              }
            ],
            "transformations": [
              {
                "id": "organize",
                "options": {
                  "excludeByName": {
                    "Time": true,
                    "__name__": true,
                    "job": true,
                    "instance": true
                  },
                  "renameByName": {
                    "src_ip": "Source IP",
                    "dst_ip": "Destination IP",
                    "Value": "Bytes/sec"
                  }
                }
              }
            ]
          },
          {
            "id": 10,
            "title": "Protocol Distribution",
            "type": "table",
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 20},
            "targets": [
              {
                "expr": "topk(15, sum by (protocol) (rate(netflow_flows_total[5m])))",
                "format": "table",
                "instant": true,
                "refId": "A"
              }
            ],
            "transformations": [
              {
                "id": "organize",
                "options": {
                  "excludeByName": {
                    "Time": true,
                    "__name__": true,
                    "job": true,
                    "instance": true
                  },
                  "renameByName": {
                    "protocol": "Protocol",
                    "Value": "Flows/sec"
                  }
                }
              }
            ]
          }
        ]
      }
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"udm-pro-netflow-dashboard.json":"{\n  \"id\": null,\n  \"uid\": \"udm-pro-netflow\",\n  \"title\": \"UDM Pro NetFlow Analysis\",\n  \"tags\": [\"network\", \"odin\", \"udm-pro\", \"netflow\"],\n  \"style\": \"dark\",\n  \"timezone\": \"browser\",\n  \"refresh\": \"30s\",\n  \"schemaVersion\": 27,\n  \"version\": 1,\n  \"time\": {\n    \"from\": \"now-1h\",\n    \"to\": \"now\"\n  },\n  \"panels\": [\n    {\n      \"id\": 1,\n      \"title\": \"Total Network Flows\",\n      \"type\": \"stat\",\n      \"gridPos\": {\"h\": 4, \"w\": 6, \"x\": 0, \"y\": 0},\n      \"targets\": [\n        {\n          \"expr\": \"sum(rate(netflow_flows_total[5m]))\",\n          \"legendFormat\": \"Flows/sec\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"ops\",\n          \"color\": {\"mode\": \"thresholds\"},\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 100},\n              {\"color\": \"red\", \"value\": 1000}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"id\": 2,\n      \"title\": \"Network Throughput\",\n      \"type\": \"stat\",\n      \"gridPos\": {\"h\": 4, \"w\": 6, \"x\": 6, \"y\": 0},\n      \"targets\": [\n        {\n          \"expr\": \"sum(rate(netflow_bytes_total[5m])) * 8 / 1000000\",\n          \"legendFormat\": \"Mbps\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"Mbps\",\n          \"color\": {\"mode\": \"thresholds\"},\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 100},\n              {\"color\": \"red\", \"value\": 500}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"id\": 3,\n      \"title\": \"Active Flows\",\n      \"type\": \"stat\",\n      \"gridPos\": {\"h\": 4, \"w\": 6, \"x\": 12, \"y\": 0},\n      \"targets\": [\n        {\n          \"expr\": \"netflow_active_flows\",\n          \"legendFormat\": \"Active\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"short\",\n          \"color\": {\"mode\": \"thresholds\"},\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 1000},\n              {\"color\": \"red\", \"value\": 5000}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"id\": 4,\n      \"title\": \"Total Packets\",\n      \"type\": \"stat\",\n      \"gridPos\": {\"h\": 4, \"w\": 6, \"x\": 18, \"y\": 0},\n      \"targets\": [\n        {\n          \"expr\": \"sum(rate(netflow_packets_total[5m]))\",\n          \"legendFormat\": \"Packets/sec\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"pps\",\n          \"color\": {\"mode\": \"thresholds\"},\n          \"thresholds\": {\n            \"steps\": [\n              {\"color\": \"green\", \"value\": null},\n              {\"color\": \"yellow\", \"value\": 1000},\n              {\"color\": \"red\", \"value\": 10000}\n            ]\n          }\n        }\n      }\n    },\n    {\n      \"id\": 5,\n      \"title\": \"Network Traffic by Direction\",\n      \"type\": \"timeseries\",\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 4},\n      \"targets\": [\n        {\n          \"expr\": \"sum by (src_net, dst_net) (rate(netflow_bytes_total[5m])) * 8 / 1000000\",\n          \"legendFormat\": \"{{src_net}} → {{dst_net}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"Mbps\",\n          \"color\": {\"mode\": \"palette-classic\"}\n        }\n      }\n    },\n    {\n      \"id\": 6,\n      \"title\": \"Top Protocols by Traffic\",\n      \"type\": \"piechart\",\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 4},\n      \"targets\": [\n        {\n          \"expr\": \"topk(10, sum by (protocol) (rate(netflow_bytes_total[5m])))\",\n          \"legendFormat\": \"{{protocol}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"bytes\",\n          \"color\": {\"mode\": \"palette-classic\"}\n        }\n      }\n    },\n    {\n      \"id\": 7,\n      \"title\": \"LAN to WAN Traffic\",\n      \"type\": \"timeseries\",\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 12},\n      \"targets\": [\n        {\n          \"expr\": \"sum(rate(netflow_bytes_total{src_net=~\\\"lan_.*\\\", dst_net=\\\"wan\\\"}[5m])) * 8 / 1000000\",\n          \"legendFormat\": \"LAN → WAN (Upload)\",\n          \"refId\": \"A\"\n        },\n        {\n          \"expr\": \"sum(rate(netflow_bytes_total{src_net=\\\"wan\\\", dst_net=~\\\"lan_.*\\\"}[5m])) * 8 / 1000000\",\n          \"legendFormat\": \"WAN → LAN (Download)\",\n          \"refId\": \"B\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"Mbps\",\n          \"color\": {\"mode\": \"palette-classic\"}\n        }\n      }\n    },\n    {\n      \"id\": 8,\n      \"title\": \"Internal Network Traffic\",\n      \"type\": \"timeseries\",\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 12},\n      \"targets\": [\n        {\n          \"expr\": \"sum by (src_net, dst_net) (rate(netflow_bytes_total{src_net=~\\\"lan_.*\\\", dst_net=~\\\"lan_.*\\\"}[5m])) * 8 / 1000000\",\n          \"legendFormat\": \"{{src_net}} → {{dst_net}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"unit\": \"Mbps\",\n          \"color\": {\"mode\": \"palette-classic\"}\n        }\n      }\n    },\n    {\n      \"id\": 9,\n      \"title\": \"Top Talkers by Bytes\",\n      \"type\": \"table\",\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 20},\n      \"targets\": [\n        {\n          \"expr\": \"topk(10, sum by (src_ip, dst_ip) (rate(netflow_top_talkers_bytes[5m])))\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"transformations\": [\n        {\n          \"id\": \"organize\",\n          \"options\": {\n            \"excludeByName\": {\n              \"Time\": true,\n              \"__name__\": true,\n              \"job\": true,\n              \"instance\": true\n            },\n            \"renameByName\": {\n              \"src_ip\": \"Source IP\",\n              \"dst_ip\": \"Destination IP\",\n              \"Value\": \"Bytes/sec\"\n            }\n          }\n        }\n      ]\n    },\n    {\n      \"id\": 10,\n      \"title\": \"Protocol Distribution\",\n      \"type\": \"table\",\n      \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 20},\n      \"targets\": [\n        {\n          \"expr\": \"topk(15, sum by (protocol) (rate(netflow_flows_total[5m])))\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"transformations\": [\n        {\n          \"id\": \"organize\",\n          \"options\": {\n            \"excludeByName\": {\n              \"Time\": true,\n              \"__name__\": true,\n              \"job\": true,\n              \"instance\": true\n            },\n            \"renameByName\": {\n              \"protocol\": \"Protocol\",\n              \"Value\": \"Flows/sec\"\n            }\n          }\n        }\n      ]\n    }\n  ]\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"grafana_dashboard":"1"},"name":"udm-pro-netflow-dashboard","namespace":"monitoring"}}
    creationTimestamp: "2025-06-02T03:19:26Z"
    labels:
      grafana_dashboard: "1"
    name: udm-pro-netflow-dashboard
    namespace: monitoring
    resourceVersion: "1473528"
    uid: c5e97745-1526-4ad8-b10a-857488842dd9
- apiVersion: v1
  data:
    udm-test-dashboard.json: |
      {
        "annotations": {
          "list": []
        },
        "editable": true,
        "fiscalYearStartMonth": 0,
        "graphTooltip": 0,
        "id": null,
        "links": [],
        "liveNow": false,
        "panels": [
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "description": "Available NetFlow metrics",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisCenteredZero": false,
                  "axisColorMode": "text",
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 0,
                  "gradientMode": "none",
                  "hideFrom": {
                    "legend": false,
                    "tooltip": false,
                    "vis": false
                  },
                  "insertNulls": false,
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "auto",
                  "spanNulls": false,
                  "stacking": {
                    "group": "A",
                    "mode": "none"
                  },
                  "thresholdsStyle": {
                    "mode": "off"
                  }
                },
                "mappings": [],
                "thresholds": {
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "red",
                      "value": 80
                    }
                  ]
                }
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 0,
              "y": 0
            },
            "id": 1,
            "options": {
              "legend": {
                "calcs": [],
                "displayMode": "list",
                "placement": "bottom",
                "showLegend": true
              },
              "tooltip": {
                "mode": "single",
                "sort": "none"
              }
            },
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "netflow_active_flows",
                "instant": false,
                "legendFormat": "Active Flows",
                "range": true,
                "refId": "A"
              }
            ],
            "title": "NetFlow Active Flows",
            "type": "timeseries"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "description": "Check if NetFlow collector is collecting data",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "thresholds": {
                  "steps": [
                    {
                      "color": "red",
                      "value": null
                    },
                    {
                      "color": "green",
                      "value": 1
                    }
                  ]
                },
                "unit": "short"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 12,
              "y": 0
            },
            "id": 2,
            "options": {
              "orientation": "auto",
              "reduceOptions": {
                "calcs": [
                  "lastNotNull"
                ],
                "fields": "",
                "values": false
              },
              "showThresholdLabels": false,
              "showThresholdMarkers": true
            },
            "pluginVersion": "10.2.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "up{job=\"netflow-collector\"}",
                "instant": false,
                "legendFormat": "NetFlow Collector Status",
                "range": true,
                "refId": "A"
              }
            ],
            "title": "NetFlow Collector Status",
            "type": "gauge"
          },
          {
            "datasource": {
              "type": "loki",
              "uid": "loki"
            },
            "description": "All available logs",
            "gridPos": {
              "h": 8,
              "w": 24,
              "x": 0,
              "y": 8
            },
            "id": 3,
            "options": {
              "dedupStrategy": "none",
              "enableLogDetails": true,
              "prettifyLogMessage": false,
              "showCommonLabels": false,
              "showLabels": false,
              "showTime": false,
              "sortOrder": "Descending",
              "wrapLogMessage": false
            },
            "targets": [
              {
                "datasource": {
                  "type": "loki",
                  "uid": "loki"
                },
                "editorMode": "code",
                "expr": "{job=\"system\"}",
                "queryType": "",
                "refId": "A"
              }
            ],
            "title": "System Logs (All Available)",
            "type": "logs"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "description": "Show what jobs are available",
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "custom": {
                  "align": "auto",
                  "cellOptions": {
                    "type": "auto"
                  },
                  "inspect": false
                },
                "mappings": [],
                "thresholds": {
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "red",
                      "value": 80
                    }
                  ]
                }
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 24,
              "x": 0,
              "y": 16
            },
            "id": 4,
            "options": {
              "cellHeight": "sm",
              "footer": {
                "countRows": false,
                "fields": "",
                "reducer": [
                  "sum"
                ],
                "show": false
              },
              "showHeader": true
            },
            "pluginVersion": "10.2.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "editorMode": "code",
                "expr": "up",
                "format": "table",
                "instant": true,
                "legendFormat": "__auto",
                "range": false,
                "refId": "A"
              }
            ],
            "title": "All Available Prometheus Targets",
            "type": "table"
          }
        ],
        "refresh": "30s",
        "schemaVersion": 38,
        "style": "dark",
        "tags": [
          "test",
          "udm",
          "debug"
        ],
        "templating": {
          "list": []
        },
        "time": {
          "from": "now-5m",
          "to": "now"
        },
        "timepicker": {},
        "timezone": "",
        "title": "UDM Data Source Test",
        "uid": "udm-test",
        "version": 1,
        "weekStart": ""
      }
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"udm-test-dashboard.json":"{\n  \"annotations\": {\n    \"list\": []\n  },\n  \"editable\": true,\n  \"fiscalYearStartMonth\": 0,\n  \"graphTooltip\": 0,\n  \"id\": null,\n  \"links\": [],\n  \"liveNow\": false,\n  \"panels\": [\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"description\": \"Available NetFlow metrics\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisCenteredZero\": false,\n            \"axisColorMode\": \"text\",\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 0,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"legend\": false,\n              \"tooltip\": false,\n              \"vis\": false\n            },\n            \"insertNulls\": false,\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"auto\",\n            \"spanNulls\": false,\n            \"stacking\": {\n              \"group\": \"A\",\n              \"mode\": \"none\"\n            },\n            \"thresholdsStyle\": {\n              \"mode\": \"off\"\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 80\n              }\n            ]\n          }\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 0,\n        \"y\": 0\n      },\n      \"id\": 1,\n      \"options\": {\n        \"legend\": {\n          \"calcs\": [],\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\",\n          \"showLegend\": true\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        }\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"netflow_active_flows\",\n          \"instant\": false,\n          \"legendFormat\": \"Active Flows\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"NetFlow Active Flows\",\n      \"type\": \"timeseries\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"description\": \"Check if NetFlow collector is collecting data\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"steps\": [\n              {\n                \"color\": \"red\",\n                \"value\": null\n              },\n              {\n                \"color\": \"green\",\n                \"value\": 1\n              }\n            ]\n          },\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 0\n      },\n      \"id\": 2,\n      \"options\": {\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"calcs\": [\n            \"lastNotNull\"\n          ],\n          \"fields\": \"\",\n          \"values\": false\n        },\n        \"showThresholdLabels\": false,\n        \"showThresholdMarkers\": true\n      },\n      \"pluginVersion\": \"10.2.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"up{job=\\\"netflow-collector\\\"}\",\n          \"instant\": false,\n          \"legendFormat\": \"NetFlow Collector Status\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"NetFlow Collector Status\",\n      \"type\": \"gauge\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"loki\",\n        \"uid\": \"loki\"\n      },\n      \"description\": \"All available logs\",\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 24,\n        \"x\": 0,\n        \"y\": 8\n      },\n      \"id\": 3,\n      \"options\": {\n        \"dedupStrategy\": \"none\",\n        \"enableLogDetails\": true,\n        \"prettifyLogMessage\": false,\n        \"showCommonLabels\": false,\n        \"showLabels\": false,\n        \"showTime\": false,\n        \"sortOrder\": \"Descending\",\n        \"wrapLogMessage\": false\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"loki\",\n            \"uid\": \"loki\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"{job=\\\"system\\\"}\",\n          \"queryType\": \"\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"System Logs (All Available)\",\n      \"type\": \"logs\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"description\": \"Show what jobs are available\",\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"custom\": {\n            \"align\": \"auto\",\n            \"cellOptions\": {\n              \"type\": \"auto\"\n            },\n            \"inspect\": false\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 80\n              }\n            ]\n          }\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 24,\n        \"x\": 0,\n        \"y\": 16\n      },\n      \"id\": 4,\n      \"options\": {\n        \"cellHeight\": \"sm\",\n        \"footer\": {\n          \"countRows\": false,\n          \"fields\": \"\",\n          \"reducer\": [\n            \"sum\"\n          ],\n          \"show\": false\n        },\n        \"showHeader\": true\n      },\n      \"pluginVersion\": \"10.2.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"up\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"legendFormat\": \"__auto\",\n          \"range\": false,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"All Available Prometheus Targets\",\n      \"type\": \"table\"\n    }\n  ],\n  \"refresh\": \"30s\",\n  \"schemaVersion\": 38,\n  \"style\": \"dark\",\n  \"tags\": [\n    \"test\",\n    \"udm\",\n    \"debug\"\n  ],\n  \"templating\": {\n    \"list\": []\n  },\n  \"time\": {\n    \"from\": \"now-5m\",\n    \"to\": \"now\"\n  },\n  \"timepicker\": {},\n  \"timezone\": \"\",\n  \"title\": \"UDM Data Source Test\",\n  \"uid\": \"udm-test\",\n  \"version\": 1,\n  \"weekStart\": \"\"\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"grafana_dashboard":"1"},"name":"udm-test-dashboard","namespace":"monitoring"}}
    creationTimestamp: "2025-06-02T15:32:47Z"
    labels:
      grafana_dashboard: "1"
    name: udm-test-dashboard
    namespace: monitoring
    resourceVersion: "1793077"
    uid: 58ca9696-b327-4f49-9a41-0bcb75358e26
- apiVersion: v1
  data:
    unifi-api-network-dashboard.json: |
      {
        "annotations": {
          "list": [
            {
              "builtIn": 1,
              "datasource": {
                "type": "grafana",
                "uid": "-- Grafana --"
              },
              "enable": true,
              "hide": true,
              "iconColor": "rgba(0, 211, 255, 1)",
              "name": "Annotations & Alerts",
              "type": "dashboard"
            }
          ]
        },
        "editable": true,
        "fiscalYearStartMonth": 0,
        "graphTooltip": 0,
        "id": null,
        "links": [],
        "liveNow": false,
        "panels": [
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisCenteredZero": false,
                  "axisColorMode": "text",
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 10,
                  "gradientMode": "none",
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  },
                  "insertNulls": false,
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "never",
                  "spanNulls": false,
                  "stacking": {
                    "group": "A",
                    "mode": "none"
                  },
                  "thresholdsStyle": {
                    "mode": "off"
                  }
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    }
                  ]
                },
                "unit": "bps"
              },
              "overrides": [
                {
                  "matcher": {
                    "id": "byRegexp",
                    "options": ".*RX.*"
                  },
                  "properties": [
                    {
                      "id": "custom.transform",
                      "value": "negative-Y"
                    }
                  ]
                }
              ]
            },
            "gridPos": {
              "h": 8,
              "w": 24,
              "x": 0,
              "y": 0
            },
            "id": 1,
            "options": {
              "legend": {
                "calcs": ["mean", "last"],
                "displayMode": "table",
                "placement": "right",
                "showLegend": true
              },
              "tooltip": {
                "mode": "single",
                "sort": "none"
              }
            },
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "expr": "rate(unifi_interface_rx_bytes_total[5m]) * 8",
                "legendFormat": "{{device_name}} - {{interface}} RX",
                "refId": "A"
              },
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "expr": "rate(unifi_interface_tx_bytes_total[5m]) * 8",
                "legendFormat": "{{device_name}} - {{interface}} TX",
                "refId": "B"
              }
            ],
            "title": "Network Interface Traffic",
            "type": "timeseries"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "yellow",
                      "value": 70
                    },
                    {
                      "color": "red",
                      "value": 85
                    }
                  ]
                },
                "unit": "celsius"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 4,
              "w": 6,
              "x": 0,
              "y": 8
            },
            "id": 2,
            "options": {
              "orientation": "auto",
              "reduceOptions": {
                "calcs": [
                  "lastNotNull"
                ],
                "fields": "",
                "values": false
              },
              "showThresholdLabels": false,
              "showThresholdMarkers": true
            },
            "pluginVersion": "10.0.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "expr": "unifi_device_temperature_celsius",
                "refId": "A"
              }
            ],
            "title": "Device Temperature",
            "type": "gauge"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "yellow",
                      "value": 70
                    },
                    {
                      "color": "red",
                      "value": 85
                    }
                  ]
                },
                "unit": "percent"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 4,
              "w": 6,
              "x": 6,
              "y": 8
            },
            "id": 3,
            "options": {
              "orientation": "auto",
              "reduceOptions": {
                "calcs": [
                  "lastNotNull"
                ],
                "fields": "",
                "values": false
              },
              "showThresholdLabels": false,
              "showThresholdMarkers": true
            },
            "pluginVersion": "10.0.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "expr": "unifi_device_cpu_usage_percent",
                "refId": "A"
              }
            ],
            "title": "CPU Usage",
            "type": "gauge"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "yellow",
                      "value": 70
                    },
                    {
                      "color": "red",
                      "value": 85
                    }
                  ]
                },
                "unit": "percent"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 4,
              "w": 6,
              "x": 12,
              "y": 8
            },
            "id": 4,
            "options": {
              "orientation": "auto",
              "reduceOptions": {
                "calcs": [
                  "lastNotNull"
                ],
                "fields": "",
                "values": false
              },
              "showThresholdLabels": false,
              "showThresholdMarkers": true
            },
            "pluginVersion": "10.0.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "expr": "unifi_device_memory_usage_percent",
                "refId": "A"
              }
            ],
            "title": "Memory Usage",
            "type": "gauge"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    }
                  ]
                },
                "unit": "dtdurations"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 4,
              "w": 6,
              "x": 18,
              "y": 8
            },
            "id": 5,
            "options": {
              "colorMode": "value",
              "graphMode": "area",
              "justifyMode": "auto",
              "orientation": "auto",
              "reduceOptions": {
                "calcs": [
                  "lastNotNull"
                ],
                "fields": "",
                "values": false
              },
              "textMode": "auto"
            },
            "pluginVersion": "10.0.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "expr": "unifi_device_uptime_seconds",
                "refId": "A"
              }
            ],
            "title": "Device Uptime",
            "type": "stat"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisCenteredZero": false,
                  "axisColorMode": "text",
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 10,
                  "gradientMode": "none",
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  },
                  "insertNulls": false,
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "never",
                  "spanNulls": false,
                  "stacking": {
                    "group": "A",
                    "mode": "none"
                  },
                  "thresholdsStyle": {
                    "mode": "off"
                  }
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    }
                  ]
                },
                "unit": "short"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 0,
              "y": 12
            },
            "id": 6,
            "options": {
              "legend": {
                "calcs": [],
                "displayMode": "list",
                "placement": "bottom",
                "showLegend": true
              },
              "tooltip": {
                "mode": "single",
                "sort": "none"
              }
            },
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "expr": "rate(unifi_interface_rx_errors_total[5m])",
                "legendFormat": "{{device_name}} - {{interface}} RX Errors",
                "refId": "A"
              },
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "expr": "rate(unifi_interface_tx_errors_total[5m])",
                "legendFormat": "{{device_name}} - {{interface}} TX Errors",
                "refId": "B"
              }
            ],
            "title": "Interface Errors",
            "type": "timeseries"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "palette-classic"
                },
                "custom": {
                  "axisCenteredZero": false,
                  "axisColorMode": "text",
                  "axisLabel": "",
                  "axisPlacement": "auto",
                  "barAlignment": 0,
                  "drawStyle": "line",
                  "fillOpacity": 10,
                  "gradientMode": "none",
                  "hideFrom": {
                    "tooltip": false,
                    "viz": false,
                    "legend": false
                  },
                  "insertNulls": false,
                  "lineInterpolation": "linear",
                  "lineWidth": 1,
                  "pointSize": 5,
                  "scaleDistribution": {
                    "type": "linear"
                  },
                  "showPoints": "never",
                  "spanNulls": false,
                  "stacking": {
                    "group": "A",
                    "mode": "none"
                  },
                  "thresholdsStyle": {
                    "mode": "off"
                  }
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    }
                  ]
                },
                "unit": "pps"
              },
              "overrides": []
            },
            "gridPos": {
              "h": 8,
              "w": 12,
              "x": 12,
              "y": 12
            },
            "id": 7,
            "options": {
              "legend": {
                "calcs": [],
                "displayMode": "list",
                "placement": "bottom",
                "showLegend": true
              },
              "tooltip": {
                "mode": "single",
                "sort": "none"
              }
            },
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "expr": "rate(unifi_interface_rx_packets_total[5m])",
                "legendFormat": "{{device_name}} - {{interface}} RX",
                "refId": "A"
              },
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "expr": "rate(unifi_interface_tx_packets_total[5m])",
                "legendFormat": "{{device_name}} - {{interface}} TX",
                "refId": "B"
              }
            ],
            "title": "Packet Rate",
            "type": "timeseries"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    }
                  ]
                }
              },
              "overrides": []
            },
            "gridPos": {
              "h": 4,
              "w": 6,
              "x": 0,
              "y": 20
            },
            "id": 8,
            "options": {
              "colorMode": "value",
              "graphMode": "area",
              "justifyMode": "auto",
              "orientation": "auto",
              "reduceOptions": {
                "calcs": [
                  "lastNotNull"
                ],
                "fields": "",
                "values": false
              },
              "textMode": "auto"
            },
            "pluginVersion": "10.0.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "expr": "unifi_clients_total",
                "refId": "A"
              }
            ],
            "title": "Connected Clients",
            "type": "stat"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    }
                  ]
                }
              },
              "overrides": []
            },
            "gridPos": {
              "h": 4,
              "w": 6,
              "x": 6,
              "y": 20
            },
            "id": 9,
            "options": {
              "colorMode": "value",
              "graphMode": "area",
              "justifyMode": "auto",
              "orientation": "auto",
              "reduceOptions": {
                "calcs": [
                  "lastNotNull"
                ],
                "fields": "",
                "values": false
              },
              "textMode": "auto"
            },
            "pluginVersion": "10.0.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "expr": "unifi_device_load_average",
                "refId": "A"
              }
            ],
            "title": "Load Average",
            "type": "stat"
          },
          {
            "datasource": {
              "type": "prometheus",
              "uid": "prometheus"
            },
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [
                  {
                    "options": {
                      "0": {
                        "color": "red",
                        "index": 0,
                        "text": "Down"
                      },
                      "1": {
                        "color": "green",
                        "index": 1,
                        "text": "Up"
                      }
                    },
                    "type": "value"
                  }
                ],
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    }
                  ]
                }
              },
              "overrides": []
            },
            "gridPos": {
              "h": 4,
              "w": 12,
              "x": 12,
              "y": 20
            },
            "id": 10,
            "options": {
              "colorMode": "background",
              "graphMode": "area",
              "justifyMode": "auto",
              "orientation": "auto",
              "reduceOptions": {
                "calcs": [
                  "lastNotNull"
                ],
                "fields": "",
                "values": false
              },
              "textMode": "auto"
            },
            "pluginVersion": "10.0.0",
            "targets": [
              {
                "datasource": {
                  "type": "prometheus",
                  "uid": "prometheus"
                },
                "expr": "up{job=\"unifi-exporter\"}",
                "refId": "A"
              }
            ],
            "title": "UniFi API Status",
            "type": "stat"
          }
        ],
        "refresh": "30s",
        "schemaVersion": 38,
        "style": "dark",
        "tags": ["network", "unifi", "api"],
        "templating": {
          "list": []
        },
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "timepicker": {},
        "timezone": "",
        "title": "UniFi Network Monitoring (API)",
        "uid": "unifi-api-network",
        "version": 1,
        "weekStart": ""
      }
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"unifi-api-network-dashboard.json":"{\n  \"annotations\": {\n    \"list\": [\n      {\n        \"builtIn\": 1,\n        \"datasource\": {\n          \"type\": \"grafana\",\n          \"uid\": \"-- Grafana --\"\n        },\n        \"enable\": true,\n        \"hide\": true,\n        \"iconColor\": \"rgba(0, 211, 255, 1)\",\n        \"name\": \"Annotations \u0026 Alerts\",\n        \"type\": \"dashboard\"\n      }\n    ]\n  },\n  \"editable\": true,\n  \"fiscalYearStartMonth\": 0,\n  \"graphTooltip\": 0,\n  \"id\": null,\n  \"links\": [],\n  \"liveNow\": false,\n  \"panels\": [\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisCenteredZero\": false,\n            \"axisColorMode\": \"text\",\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 10,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            },\n            \"insertNulls\": false,\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"never\",\n            \"spanNulls\": false,\n            \"stacking\": {\n              \"group\": \"A\",\n              \"mode\": \"none\"\n            },\n            \"thresholdsStyle\": {\n              \"mode\": \"off\"\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          },\n          \"unit\": \"bps\"\n        },\n        \"overrides\": [\n          {\n            \"matcher\": {\n              \"id\": \"byRegexp\",\n              \"options\": \".*RX.*\"\n            },\n            \"properties\": [\n              {\n                \"id\": \"custom.transform\",\n                \"value\": \"negative-Y\"\n              }\n            ]\n          }\n        ]\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 24,\n        \"x\": 0,\n        \"y\": 0\n      },\n      \"id\": 1,\n      \"options\": {\n        \"legend\": {\n          \"calcs\": [\"mean\", \"last\"],\n          \"displayMode\": \"table\",\n          \"placement\": \"right\",\n          \"showLegend\": true\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        }\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"expr\": \"rate(unifi_interface_rx_bytes_total[5m]) * 8\",\n          \"legendFormat\": \"{{device_name}} - {{interface}} RX\",\n          \"refId\": \"A\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"expr\": \"rate(unifi_interface_tx_bytes_total[5m]) * 8\",\n          \"legendFormat\": \"{{device_name}} - {{interface}} TX\",\n          \"refId\": \"B\"\n        }\n      ],\n      \"title\": \"Network Interface Traffic\",\n      \"type\": \"timeseries\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"yellow\",\n                \"value\": 70\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 85\n              }\n            ]\n          },\n          \"unit\": \"celsius\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 4,\n        \"w\": 6,\n        \"x\": 0,\n        \"y\": 8\n      },\n      \"id\": 2,\n      \"options\": {\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"calcs\": [\n            \"lastNotNull\"\n          ],\n          \"fields\": \"\",\n          \"values\": false\n        },\n        \"showThresholdLabels\": false,\n        \"showThresholdMarkers\": true\n      },\n      \"pluginVersion\": \"10.0.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"expr\": \"unifi_device_temperature_celsius\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Device Temperature\",\n      \"type\": \"gauge\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"yellow\",\n                \"value\": 70\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 85\n              }\n            ]\n          },\n          \"unit\": \"percent\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 4,\n        \"w\": 6,\n        \"x\": 6,\n        \"y\": 8\n      },\n      \"id\": 3,\n      \"options\": {\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"calcs\": [\n            \"lastNotNull\"\n          ],\n          \"fields\": \"\",\n          \"values\": false\n        },\n        \"showThresholdLabels\": false,\n        \"showThresholdMarkers\": true\n      },\n      \"pluginVersion\": \"10.0.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"expr\": \"unifi_device_cpu_usage_percent\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"CPU Usage\",\n      \"type\": \"gauge\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"yellow\",\n                \"value\": 70\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 85\n              }\n            ]\n          },\n          \"unit\": \"percent\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 4,\n        \"w\": 6,\n        \"x\": 12,\n        \"y\": 8\n      },\n      \"id\": 4,\n      \"options\": {\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"calcs\": [\n            \"lastNotNull\"\n          ],\n          \"fields\": \"\",\n          \"values\": false\n        },\n        \"showThresholdLabels\": false,\n        \"showThresholdMarkers\": true\n      },\n      \"pluginVersion\": \"10.0.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"expr\": \"unifi_device_memory_usage_percent\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Memory Usage\",\n      \"type\": \"gauge\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          },\n          \"unit\": \"dtdurations\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 4,\n        \"w\": 6,\n        \"x\": 18,\n        \"y\": 8\n      },\n      \"id\": 5,\n      \"options\": {\n        \"colorMode\": \"value\",\n        \"graphMode\": \"area\",\n        \"justifyMode\": \"auto\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"calcs\": [\n            \"lastNotNull\"\n          ],\n          \"fields\": \"\",\n          \"values\": false\n        },\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"10.0.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"expr\": \"unifi_device_uptime_seconds\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Device Uptime\",\n      \"type\": \"stat\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisCenteredZero\": false,\n            \"axisColorMode\": \"text\",\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 10,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            },\n            \"insertNulls\": false,\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"never\",\n            \"spanNulls\": false,\n            \"stacking\": {\n              \"group\": \"A\",\n              \"mode\": \"none\"\n            },\n            \"thresholdsStyle\": {\n              \"mode\": \"off\"\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          },\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 0,\n        \"y\": 12\n      },\n      \"id\": 6,\n      \"options\": {\n        \"legend\": {\n          \"calcs\": [],\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\",\n          \"showLegend\": true\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        }\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"expr\": \"rate(unifi_interface_rx_errors_total[5m])\",\n          \"legendFormat\": \"{{device_name}} - {{interface}} RX Errors\",\n          \"refId\": \"A\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"expr\": \"rate(unifi_interface_tx_errors_total[5m])\",\n          \"legendFormat\": \"{{device_name}} - {{interface}} TX Errors\",\n          \"refId\": \"B\"\n        }\n      ],\n      \"title\": \"Interface Errors\",\n      \"type\": \"timeseries\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisCenteredZero\": false,\n            \"axisColorMode\": \"text\",\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 10,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            },\n            \"insertNulls\": false,\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"never\",\n            \"spanNulls\": false,\n            \"stacking\": {\n              \"group\": \"A\",\n              \"mode\": \"none\"\n            },\n            \"thresholdsStyle\": {\n              \"mode\": \"off\"\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          },\n          \"unit\": \"pps\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 12\n      },\n      \"id\": 7,\n      \"options\": {\n        \"legend\": {\n          \"calcs\": [],\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\",\n          \"showLegend\": true\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        }\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"expr\": \"rate(unifi_interface_rx_packets_total[5m])\",\n          \"legendFormat\": \"{{device_name}} - {{interface}} RX\",\n          \"refId\": \"A\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"expr\": \"rate(unifi_interface_tx_packets_total[5m])\",\n          \"legendFormat\": \"{{device_name}} - {{interface}} TX\",\n          \"refId\": \"B\"\n        }\n      ],\n      \"title\": \"Packet Rate\",\n      \"type\": \"timeseries\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          }\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 4,\n        \"w\": 6,\n        \"x\": 0,\n        \"y\": 20\n      },\n      \"id\": 8,\n      \"options\": {\n        \"colorMode\": \"value\",\n        \"graphMode\": \"area\",\n        \"justifyMode\": \"auto\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"calcs\": [\n            \"lastNotNull\"\n          ],\n          \"fields\": \"\",\n          \"values\": false\n        },\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"10.0.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"expr\": \"unifi_clients_total\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Connected Clients\",\n      \"type\": \"stat\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          }\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 4,\n        \"w\": 6,\n        \"x\": 6,\n        \"y\": 20\n      },\n      \"id\": 9,\n      \"options\": {\n        \"colorMode\": \"value\",\n        \"graphMode\": \"area\",\n        \"justifyMode\": \"auto\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"calcs\": [\n            \"lastNotNull\"\n          ],\n          \"fields\": \"\",\n          \"values\": false\n        },\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"10.0.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"expr\": \"unifi_device_load_average\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Load Average\",\n      \"type\": \"stat\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"prometheus\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [\n            {\n              \"options\": {\n                \"0\": {\n                  \"color\": \"red\",\n                  \"index\": 0,\n                  \"text\": \"Down\"\n                },\n                \"1\": {\n                  \"color\": \"green\",\n                  \"index\": 1,\n                  \"text\": \"Up\"\n                }\n              },\n              \"type\": \"value\"\n            }\n          ],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          }\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 4,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 20\n      },\n      \"id\": 10,\n      \"options\": {\n        \"colorMode\": \"background\",\n        \"graphMode\": \"area\",\n        \"justifyMode\": \"auto\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"calcs\": [\n            \"lastNotNull\"\n          ],\n          \"fields\": \"\",\n          \"values\": false\n        },\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"10.0.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"prometheus\"\n          },\n          \"expr\": \"up{job=\\\"unifi-exporter\\\"}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"UniFi API Status\",\n      \"type\": \"stat\"\n    }\n  ],\n  \"refresh\": \"30s\",\n  \"schemaVersion\": 38,\n  \"style\": \"dark\",\n  \"tags\": [\"network\", \"unifi\", \"api\"],\n  \"templating\": {\n    \"list\": []\n  },\n  \"time\": {\n    \"from\": \"now-1h\",\n    \"to\": \"now\"\n  },\n  \"timepicker\": {},\n  \"timezone\": \"\",\n  \"title\": \"UniFi Network Monitoring (API)\",\n  \"uid\": \"unifi-api-network\",\n  \"version\": 1,\n  \"weekStart\": \"\"\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"unifi-api-network-dashboard","namespace":"monitoring"}}
    creationTimestamp: "2025-06-03T17:44:50Z"
    name: unifi-api-network-dashboard
    namespace: monitoring
    resourceVersion: "2472958"
    uid: ae5e4983-fc35-4e97-a158-f1bcde0e8b1b
- apiVersion: v1
  data:
    unifi_enhanced_exporter.py: "#!/usr/bin/env python3\nimport requests\nimport json\nimport
      time\nimport logging\nimport os\nfrom datetime import datetime\nfrom prometheus_client
      import start_http_server, Gauge, Info, Counter\nfrom urllib3.exceptions import
      InsecureRequestWarning\n\n# Disable SSL warnings for self-signed certs\nrequests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n\n#
      Configure logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s
      - %(levelname)s - %(message)s')\nlogger = logging.getLogger('unifi-enhanced-exporter')\n\n#
      Configuration from environment\nUNIFI_HOST = os.getenv('UNIFI_HOST', '192.168.1.1')\nUNIFI_PORT
      = os.getenv('UNIFI_PORT', '8443')\nUNIFI_API_KEY = os.getenv('UNIFI_API_KEY',
      '')\nUNIFI_USERNAME = os.getenv('UNIFI_USERNAME', 'admin')\nUNIFI_PASSWORD =
      os.getenv('UNIFI_PASSWORD', 'password')\nUNIFI_SITE = os.getenv('UNIFI_SITE',
      'default')\nEXPORTER_PORT = int(os.getenv('EXPORTER_PORT', '9130'))\n\n# Prometheus
      metrics\ndevice_info = Info('unifi_device_info', 'UniFi device information')\ndevice_uptime
      = Gauge('unifi_device_uptime_seconds', 'Device uptime in seconds', ['device_name',
      'mac'])\ndevice_temperature = Gauge('unifi_device_temperature_celsius', 'Device
      temperature in Celsius', ['device_name', 'mac', 'sensor'])\ndevice_cpu_usage
      = Gauge('unifi_device_cpu_usage_percent', 'Device CPU usage percentage', ['device_name',
      'mac'])\ndevice_memory_usage = Gauge('unifi_device_memory_usage_percent', 'Device
      memory usage percentage', ['device_name', 'mac'])\n\n# Interface metrics\ninterface_rx_bytes
      = Counter('unifi_interface_rx_bytes_total', 'Interface received bytes', ['device_name',
      'interface'])\ninterface_tx_bytes = Counter('unifi_interface_tx_bytes_total',
      'Interface transmitted bytes', ['device_name', 'interface'])\n\n# Client metrics\nclients_total
      = Gauge('unifi_clients_total', 'Total number of connected clients')\n\nclass
      UniFiEnhancedExporter:\n    def __init__(self):\n        self.session = requests.Session()\n
      \       self.session.verify = False\n        self.base_url = f\"https://{UNIFI_HOST}:{UNIFI_PORT}\"\n
      \       self.logged_in = False\n        self.api_version_detected = None\n        \n
      \   def detect_api_version(self):\n        \"\"\"Detect UniFi Controller API
      version and capabilities\"\"\"\n        test_endpoints = [\n            # Dream
      Machine Pro web interface endpoints\n            ('udm-pro-web', '/proxy/network/api/s/default/stat/device'),\n
      \           ('udm-pro-direct', '/api/s/default/stat/device'),\n            ('udm-pro-v2',
      '/api/unifi/stat/device'),\n            ('udm-pro-dashboard', '/v2/api/site/default/device'),\n
      \           # Standard UniFi Controller\n            ('controller', '/api/s/default/stat/device'),\n
      \           # Legacy endpoints\n            ('legacy', '/api/stat/device')\n
      \       ]\n        \n        for version, endpoint in test_endpoints:\n            try:\n
      \               logger.info(f\"Testing API version: {version} with endpoint:
      {endpoint}\")\n                response = self.session.get(f\"{self.base_url}{endpoint}\",
      timeout=10)\n                logger.info(f\"API test response: {response.status_code}\")\n
      \               \n                if response.status_code in [200, 401, 403]:
      \ # Valid responses (even if unauthorized)\n                    self.api_version_detected
      = version\n                    logger.info(f\"Detected API version: {version}\")\n
      \                   return version\n                    \n            except
      Exception as e:\n                logger.debug(f\"API version {version} test
      failed: {e}\")\n                continue\n                \n        logger.warning(\"Could
      not detect API version, defaulting to controller\")\n        self.api_version_detected
      = 'controller'\n        return 'controller'\n        \n    def login(self):\n
      \       \"\"\"Login to UniFi Controller\"\"\"\n        try:\n            if
      UNIFI_API_KEY:\n                logger.info(\"Using API key authentication\")\n
      \               self.session.headers.update({\n                    'Authorization':
      f'Bearer {UNIFI_API_KEY}',\n                    'Content-Type': 'application/json',\n
      \                   'Accept': 'application/json'\n                })\n                self.logged_in
      = True\n                return True\n            else:\n                logger.info(\"Using
      username/password authentication\")\n                # Try different login endpoints
      based on detected version\n                login_endpoints = {\n                    'udm-pro-web':
      '/api/auth/login',\n                    'udm-pro-direct': '/api/login',\n                    'udm-pro-v2':
      '/api/auth/login',\n                    'udm-pro-dashboard': '/api/auth/login',\n
      \                   'controller': '/api/login',\n                    'legacy':
      '/login'\n                }\n                \n                login_endpoint
      = login_endpoints.get(self.api_version_detected, '/api/login')\n                \n
      \               login_data = {\n                    'username': UNIFI_USERNAME,\n
      \                   'password': UNIFI_PASSWORD\n                }\n                \n
      \               response = self.session.post(\n                    f\"{self.base_url}{login_endpoint}\",\n
      \                   json=login_data,\n                    timeout=10\n                )\n
      \               \n                if response.status_code == 200:\n                    self.logged_in
      = True\n                    logger.info(\"Successfully logged in\")\n                    return
      True\n                else:\n                    logger.error(f\"Login failed:
      {response.status_code} - {response.text}\")\n                    return False\n
      \                   \n        except Exception as e:\n            logger.error(f\"Login
      error: {e}\")\n            return False\n            \n    def api_request(self,
      endpoint):\n        \"\"\"Make API request with multiple endpoint variations\"\"\"\n
      \       if not self.logged_in:\n            logger.warning(\"Not logged in,
      attempting login...\")\n            if not self.login():\n                return
      None\n                \n        # Define endpoint patterns based on detected
      API version\n        endpoint_patterns = {\n            'udm-pro-web': [\n                f'/proxy/network/api/s/{UNIFI_SITE}/{endpoint}',\n
      \               f'/api/s/{UNIFI_SITE}/{endpoint}',\n                f'/{endpoint}'\n
      \           ],\n            'udm-pro-direct': [\n                f'/api/s/{UNIFI_SITE}/{endpoint}',\n
      \               f'/proxy/network/api/s/{UNIFI_SITE}/{endpoint}',\n                f'/{endpoint}'\n
      \           ],\n            'udm-pro-v2': [\n                f'/api/unifi/{endpoint}',\n
      \               f'/api/s/{UNIFI_SITE}/{endpoint}',\n                f'/{endpoint}'\n
      \           ],\n            'udm-pro-dashboard': [\n                f'/v2/api/site/{UNIFI_SITE}/{endpoint}',\n
      \               f'/api/v2/site/{UNIFI_SITE}/{endpoint}',\n                f'/{endpoint}'\n
      \           ],\n            'controller': [\n                f'/api/s/{UNIFI_SITE}/{endpoint}',\n
      \               f'/api/{endpoint}',\n                f'/{endpoint}'\n            ],\n
      \           'legacy': [\n                f'/api/{endpoint}',\n                f'/{endpoint}'\n
      \           ]\n        }\n        \n        patterns = endpoint_patterns.get(self.api_version_detected,
      endpoint_patterns['controller'])\n        \n        for pattern in patterns:\n
      \           try:\n                url = f\"{self.base_url}{pattern}\"\n                logger.debug(f\"Trying
      URL: {url}\")\n                \n                response = self.session.get(url,
      timeout=10)\n                logger.debug(f\"Response: {response.status_code}\")\n
      \               \n                if response.status_code == 200:\n                    data
      = response.json()\n                    if data.get('meta', {}).get('rc') ==
      'ok':\n                        logger.info(f\"Successful API call to {pattern}\")\n
      \                       return data.get('data', [])\n                    else:\n
      \                       logger.warning(f\"API returned error: {data}\")\n                elif
      response.status_code == 404:\n                    logger.debug(f\"404 for {pattern},
      trying next...\")\n                    continue\n                else:\n                    logger.warning(f\"API
      request failed: {response.status_code}\")\n                    \n            except
      Exception as e:\n                logger.debug(f\"Request failed for {pattern}:
      {e}\")\n                continue\n                \n        logger.error(f\"All
      endpoint patterns failed for: {endpoint}\")\n        return None\n        \n
      \   def get_devices(self):\n        \"\"\"Get device information\"\"\"\n        return
      self.api_request('stat/device')\n        \n    def get_clients(self):\n        \"\"\"Get
      client information\"\"\"\n        return self.api_request('stat/sta')\n        \n
      \   def collect_device_metrics(self):\n        \"\"\"Collect device metrics\"\"\"\n
      \       try:\n            devices = self.get_devices()\n            if not devices:\n
      \               logger.warning(\"No device data received\")\n                return\n
      \               \n            logger.info(f\"Retrieved {len(devices)} devices\")\n
      \           \n            for device in devices:\n                device_name
      = device.get('name', device.get('model', 'unknown'))\n                device_mac
      = device.get('mac', 'unknown')\n                device_model = device.get('model',
      'unknown')\n                device_version = device.get('version', 'unknown')\n
      \               \n                # Set device info\n                device_info.info({\n
      \                   'device_name': device_name,\n                    'model':
      device_model,\n                    'version': device_version,\n                    'mac':
      device_mac,\n                    'type': device.get('type', 'unknown'),\n                    'state':
      str(device.get('state', 0))\n                })\n                \n                #
      Uptime\n                if 'uptime' in device:\n                    device_uptime.labels(device_name=device_name,
      mac=device_mac).set(device['uptime'])\n                    \n                #
      Temperature\n                if 'general_temperature' in device:\n                    device_temperature.labels(\n
      \                       device_name=device_name,\n                        mac=device_mac,\n
      \                       sensor='general'\n                    ).set(device['general_temperature'])\n
      \                   \n                # System stats\n                if 'sys_stats'
      in device:\n                    sys_stats = device['sys_stats']\n                    if
      'cpu' in sys_stats:\n                        device_cpu_usage.labels(device_name=device_name,
      mac=device_mac).set(sys_stats['cpu'])\n                    if 'mem' in sys_stats:\n
      \                       device_memory_usage.labels(device_name=device_name,
      mac=device_mac).set(sys_stats['mem'])\n                        \n            logger.info(\"Device
      metrics collected successfully\")\n            \n        except Exception as
      e:\n            logger.error(f\"Error collecting device metrics: {e}\")\n            \n
      \   def collect_client_metrics(self):\n        \"\"\"Collect client metrics\"\"\"\n
      \       try:\n            clients = self.get_clients()\n            if clients:\n
      \               clients_total.set(len(clients))\n                logger.info(f\"Retrieved
      {len(clients)} clients\")\n            else:\n                logger.warning(\"No
      client data received\")\n                \n        except Exception as e:\n
      \           logger.error(f\"Error collecting client metrics: {e}\")\n            \n
      \   def collect_all_metrics(self):\n        \"\"\"Collect all metrics\"\"\"\n
      \       logger.info(\"Collecting UniFi metrics...\")\n        \n        try:\n
      \           self.collect_device_metrics()\n            self.collect_client_metrics()\n
      \           logger.info(\"Metrics collection completed successfully\")\n            \n
      \       except Exception as e:\n            logger.error(f\"Error during metrics
      collection: {e}\")\n\ndef main():\n    logger.info(f\"Starting UniFi Enhanced
      Exporter on port {EXPORTER_PORT}\")\n    logger.info(f\"Connecting to UniFi
      Controller at {UNIFI_HOST}:{UNIFI_PORT}\")\n    \n    exporter = UniFiEnhancedExporter()\n
      \   \n    # Detect API version\n    api_version = exporter.detect_api_version()\n
      \   logger.info(f\"Using API version: {api_version}\")\n    \n    # Start Prometheus
      metrics server\n    start_http_server(EXPORTER_PORT)\n    logger.info(f\"Metrics
      server started on port {EXPORTER_PORT}\")\n    \n    # Main collection loop\n
      \   while True:\n        try:\n            exporter.collect_all_metrics()\n
      \           time.sleep(30)\n            \n        except KeyboardInterrupt:\n
      \           logger.info(\"Shutting down...\")\n            break\n        except
      Exception as e:\n            logger.error(f\"Unexpected error: {e}\")\n            time.sleep(60)\n\nif
      __name__ == '__main__':\n    main()\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"unifi_enhanced_exporter.py":"#!/usr/bin/env python3\nimport requests\nimport json\nimport time\nimport logging\nimport os\nfrom datetime import datetime\nfrom prometheus_client import start_http_server, Gauge, Info, Counter\nfrom urllib3.exceptions import InsecureRequestWarning\n\n# Disable SSL warnings for self-signed certs\nrequests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger('unifi-enhanced-exporter')\n\n# Configuration from environment\nUNIFI_HOST = os.getenv('UNIFI_HOST', '192.168.1.1')\nUNIFI_PORT = os.getenv('UNIFI_PORT', '8443')\nUNIFI_API_KEY = os.getenv('UNIFI_API_KEY', '')\nUNIFI_USERNAME = os.getenv('UNIFI_USERNAME', 'admin')\nUNIFI_PASSWORD = os.getenv('UNIFI_PASSWORD', 'password')\nUNIFI_SITE = os.getenv('UNIFI_SITE', 'default')\nEXPORTER_PORT = int(os.getenv('EXPORTER_PORT', '9130'))\n\n# Prometheus metrics\ndevice_info = Info('unifi_device_info', 'UniFi device information')\ndevice_uptime = Gauge('unifi_device_uptime_seconds', 'Device uptime in seconds', ['device_name', 'mac'])\ndevice_temperature = Gauge('unifi_device_temperature_celsius', 'Device temperature in Celsius', ['device_name', 'mac', 'sensor'])\ndevice_cpu_usage = Gauge('unifi_device_cpu_usage_percent', 'Device CPU usage percentage', ['device_name', 'mac'])\ndevice_memory_usage = Gauge('unifi_device_memory_usage_percent', 'Device memory usage percentage', ['device_name', 'mac'])\n\n# Interface metrics\ninterface_rx_bytes = Counter('unifi_interface_rx_bytes_total', 'Interface received bytes', ['device_name', 'interface'])\ninterface_tx_bytes = Counter('unifi_interface_tx_bytes_total', 'Interface transmitted bytes', ['device_name', 'interface'])\n\n# Client metrics\nclients_total = Gauge('unifi_clients_total', 'Total number of connected clients')\n\nclass UniFiEnhancedExporter:\n    def __init__(self):\n        self.session = requests.Session()\n        self.session.verify = False\n        self.base_url = f\"https://{UNIFI_HOST}:{UNIFI_PORT}\"\n        self.logged_in = False\n        self.api_version_detected = None\n        \n    def detect_api_version(self):\n        \"\"\"Detect UniFi Controller API version and capabilities\"\"\"\n        test_endpoints = [\n            # Dream Machine Pro web interface endpoints\n            ('udm-pro-web', '/proxy/network/api/s/default/stat/device'),\n            ('udm-pro-direct', '/api/s/default/stat/device'),\n            ('udm-pro-v2', '/api/unifi/stat/device'),\n            ('udm-pro-dashboard', '/v2/api/site/default/device'),\n            # Standard UniFi Controller\n            ('controller', '/api/s/default/stat/device'),\n            # Legacy endpoints\n            ('legacy', '/api/stat/device')\n        ]\n        \n        for version, endpoint in test_endpoints:\n            try:\n                logger.info(f\"Testing API version: {version} with endpoint: {endpoint}\")\n                response = self.session.get(f\"{self.base_url}{endpoint}\", timeout=10)\n                logger.info(f\"API test response: {response.status_code}\")\n                \n                if response.status_code in [200, 401, 403]:  # Valid responses (even if unauthorized)\n                    self.api_version_detected = version\n                    logger.info(f\"Detected API version: {version}\")\n                    return version\n                    \n            except Exception as e:\n                logger.debug(f\"API version {version} test failed: {e}\")\n                continue\n                \n        logger.warning(\"Could not detect API version, defaulting to controller\")\n        self.api_version_detected = 'controller'\n        return 'controller'\n        \n    def login(self):\n        \"\"\"Login to UniFi Controller\"\"\"\n        try:\n            if UNIFI_API_KEY:\n                logger.info(\"Using API key authentication\")\n                self.session.headers.update({\n                    'Authorization': f'Bearer {UNIFI_API_KEY}',\n                    'Content-Type': 'application/json',\n                    'Accept': 'application/json'\n                })\n                self.logged_in = True\n                return True\n            else:\n                logger.info(\"Using username/password authentication\")\n                # Try different login endpoints based on detected version\n                login_endpoints = {\n                    'udm-pro-web': '/api/auth/login',\n                    'udm-pro-direct': '/api/login',\n                    'udm-pro-v2': '/api/auth/login',\n                    'udm-pro-dashboard': '/api/auth/login',\n                    'controller': '/api/login',\n                    'legacy': '/login'\n                }\n                \n                login_endpoint = login_endpoints.get(self.api_version_detected, '/api/login')\n                \n                login_data = {\n                    'username': UNIFI_USERNAME,\n                    'password': UNIFI_PASSWORD\n                }\n                \n                response = self.session.post(\n                    f\"{self.base_url}{login_endpoint}\",\n                    json=login_data,\n                    timeout=10\n                )\n                \n                if response.status_code == 200:\n                    self.logged_in = True\n                    logger.info(\"Successfully logged in\")\n                    return True\n                else:\n                    logger.error(f\"Login failed: {response.status_code} - {response.text}\")\n                    return False\n                    \n        except Exception as e:\n            logger.error(f\"Login error: {e}\")\n            return False\n            \n    def api_request(self, endpoint):\n        \"\"\"Make API request with multiple endpoint variations\"\"\"\n        if not self.logged_in:\n            logger.warning(\"Not logged in, attempting login...\")\n            if not self.login():\n                return None\n                \n        # Define endpoint patterns based on detected API version\n        endpoint_patterns = {\n            'udm-pro-web': [\n                f'/proxy/network/api/s/{UNIFI_SITE}/{endpoint}',\n                f'/api/s/{UNIFI_SITE}/{endpoint}',\n                f'/{endpoint}'\n            ],\n            'udm-pro-direct': [\n                f'/api/s/{UNIFI_SITE}/{endpoint}',\n                f'/proxy/network/api/s/{UNIFI_SITE}/{endpoint}',\n                f'/{endpoint}'\n            ],\n            'udm-pro-v2': [\n                f'/api/unifi/{endpoint}',\n                f'/api/s/{UNIFI_SITE}/{endpoint}',\n                f'/{endpoint}'\n            ],\n            'udm-pro-dashboard': [\n                f'/v2/api/site/{UNIFI_SITE}/{endpoint}',\n                f'/api/v2/site/{UNIFI_SITE}/{endpoint}',\n                f'/{endpoint}'\n            ],\n            'controller': [\n                f'/api/s/{UNIFI_SITE}/{endpoint}',\n                f'/api/{endpoint}',\n                f'/{endpoint}'\n            ],\n            'legacy': [\n                f'/api/{endpoint}',\n                f'/{endpoint}'\n            ]\n        }\n        \n        patterns = endpoint_patterns.get(self.api_version_detected, endpoint_patterns['controller'])\n        \n        for pattern in patterns:\n            try:\n                url = f\"{self.base_url}{pattern}\"\n                logger.debug(f\"Trying URL: {url}\")\n                \n                response = self.session.get(url, timeout=10)\n                logger.debug(f\"Response: {response.status_code}\")\n                \n                if response.status_code == 200:\n                    data = response.json()\n                    if data.get('meta', {}).get('rc') == 'ok':\n                        logger.info(f\"Successful API call to {pattern}\")\n                        return data.get('data', [])\n                    else:\n                        logger.warning(f\"API returned error: {data}\")\n                elif response.status_code == 404:\n                    logger.debug(f\"404 for {pattern}, trying next...\")\n                    continue\n                else:\n                    logger.warning(f\"API request failed: {response.status_code}\")\n                    \n            except Exception as e:\n                logger.debug(f\"Request failed for {pattern}: {e}\")\n                continue\n                \n        logger.error(f\"All endpoint patterns failed for: {endpoint}\")\n        return None\n        \n    def get_devices(self):\n        \"\"\"Get device information\"\"\"\n        return self.api_request('stat/device')\n        \n    def get_clients(self):\n        \"\"\"Get client information\"\"\"\n        return self.api_request('stat/sta')\n        \n    def collect_device_metrics(self):\n        \"\"\"Collect device metrics\"\"\"\n        try:\n            devices = self.get_devices()\n            if not devices:\n                logger.warning(\"No device data received\")\n                return\n                \n            logger.info(f\"Retrieved {len(devices)} devices\")\n            \n            for device in devices:\n                device_name = device.get('name', device.get('model', 'unknown'))\n                device_mac = device.get('mac', 'unknown')\n                device_model = device.get('model', 'unknown')\n                device_version = device.get('version', 'unknown')\n                \n                # Set device info\n                device_info.info({\n                    'device_name': device_name,\n                    'model': device_model,\n                    'version': device_version,\n                    'mac': device_mac,\n                    'type': device.get('type', 'unknown'),\n                    'state': str(device.get('state', 0))\n                })\n                \n                # Uptime\n                if 'uptime' in device:\n                    device_uptime.labels(device_name=device_name, mac=device_mac).set(device['uptime'])\n                    \n                # Temperature\n                if 'general_temperature' in device:\n                    device_temperature.labels(\n                        device_name=device_name,\n                        mac=device_mac,\n                        sensor='general'\n                    ).set(device['general_temperature'])\n                    \n                # System stats\n                if 'sys_stats' in device:\n                    sys_stats = device['sys_stats']\n                    if 'cpu' in sys_stats:\n                        device_cpu_usage.labels(device_name=device_name, mac=device_mac).set(sys_stats['cpu'])\n                    if 'mem' in sys_stats:\n                        device_memory_usage.labels(device_name=device_name, mac=device_mac).set(sys_stats['mem'])\n                        \n            logger.info(\"Device metrics collected successfully\")\n            \n        except Exception as e:\n            logger.error(f\"Error collecting device metrics: {e}\")\n            \n    def collect_client_metrics(self):\n        \"\"\"Collect client metrics\"\"\"\n        try:\n            clients = self.get_clients()\n            if clients:\n                clients_total.set(len(clients))\n                logger.info(f\"Retrieved {len(clients)} clients\")\n            else:\n                logger.warning(\"No client data received\")\n                \n        except Exception as e:\n            logger.error(f\"Error collecting client metrics: {e}\")\n            \n    def collect_all_metrics(self):\n        \"\"\"Collect all metrics\"\"\"\n        logger.info(\"Collecting UniFi metrics...\")\n        \n        try:\n            self.collect_device_metrics()\n            self.collect_client_metrics()\n            logger.info(\"Metrics collection completed successfully\")\n            \n        except Exception as e:\n            logger.error(f\"Error during metrics collection: {e}\")\n\ndef main():\n    logger.info(f\"Starting UniFi Enhanced Exporter on port {EXPORTER_PORT}\")\n    logger.info(f\"Connecting to UniFi Controller at {UNIFI_HOST}:{UNIFI_PORT}\")\n    \n    exporter = UniFiEnhancedExporter()\n    \n    # Detect API version\n    api_version = exporter.detect_api_version()\n    logger.info(f\"Using API version: {api_version}\")\n    \n    # Start Prometheus metrics server\n    start_http_server(EXPORTER_PORT)\n    logger.info(f\"Metrics server started on port {EXPORTER_PORT}\")\n    \n    # Main collection loop\n    while True:\n        try:\n            exporter.collect_all_metrics()\n            time.sleep(30)\n            \n        except KeyboardInterrupt:\n            logger.info(\"Shutting down...\")\n            break\n        except Exception as e:\n            logger.error(f\"Unexpected error: {e}\")\n            time.sleep(60)\n\nif __name__ == '__main__':\n    main()\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"unifi-enhanced-script","namespace":"monitoring"}}
    creationTimestamp: "2025-06-02T03:23:44Z"
    name: unifi-enhanced-script
    namespace: monitoring
    resourceVersion: "1476167"
    uid: 10b5d5ae-a7d9-4275-9330-0843ca8bbd8c
- apiVersion: v1
  data:
    unifi_exporter.py: "#!/usr/bin/env python3\nimport requests\nimport json\nimport
      time\nimport logging\nimport os\nfrom datetime import datetime\nfrom prometheus_client
      import start_http_server, Gauge, Info, Counter\nfrom urllib3.exceptions import
      InsecureRequestWarning\n\n# Disable SSL warnings for self-signed certs\nrequests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n\n#
      Configure logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s
      - %(levelname)s - %(message)s')\nlogger = logging.getLogger('unifi-exporter')\n\n#
      Configuration from environment\nUNIFI_HOST = os.getenv('UNIFI_HOST', 'unifi-controller.local')\nUNIFI_PORT
      = os.getenv('UNIFI_PORT', '8443')\nUNIFI_API_KEY = os.getenv('UNIFI_API_KEY',
      '')\nUNIFI_USERNAME = os.getenv('UNIFI_USERNAME', 'admin')  # Fallback for non-API
      key auth\nUNIFI_PASSWORD = os.getenv('UNIFI_PASSWORD', 'password')  # Fallback
      for non-API key auth\nUNIFI_SITE = os.getenv('UNIFI_SITE', 'default')\nEXPORTER_PORT
      = int(os.getenv('EXPORTER_PORT', '9130'))\n\n# Prometheus metrics\ndevice_info
      = Info('unifi_device_info', 'UniFi device information', ['device_name', 'model',
      'version', 'mac'])\ndevice_uptime = Gauge('unifi_device_uptime_seconds', 'Device
      uptime in seconds', ['device_name', 'mac'])\ndevice_temperature = Gauge('unifi_device_temperature_celsius',
      'Device temperature in Celsius', ['device_name', 'mac', 'sensor'])\ndevice_cpu_usage
      = Gauge('unifi_device_cpu_usage_percent', 'Device CPU usage percentage', ['device_name',
      'mac'])\ndevice_memory_usage = Gauge('unifi_device_memory_usage_percent', 'Device
      memory usage percentage', ['device_name', 'mac'])\ndevice_load_average = Gauge('unifi_device_load_average',
      'Device load average', ['device_name', 'mac', 'period'])\n\n# Interface metrics\ninterface_rx_bytes
      = Counter('unifi_interface_rx_bytes_total', 'Interface received bytes', ['device_name',
      'interface', 'mac'])\ninterface_tx_bytes = Counter('unifi_interface_tx_bytes_total',
      'Interface transmitted bytes', ['device_name', 'interface', 'mac'])\ninterface_rx_packets
      = Counter('unifi_interface_rx_packets_total', 'Interface received packets',
      ['device_name', 'interface', 'mac'])\ninterface_tx_packets = Counter('unifi_interface_tx_packets_total',
      'Interface transmitted packets', ['device_name', 'interface', 'mac'])\ninterface_rx_errors
      = Counter('unifi_interface_rx_errors_total', 'Interface receive errors', ['device_name',
      'interface', 'mac'])\ninterface_tx_errors = Counter('unifi_interface_tx_errors_total',
      'Interface transmit errors', ['device_name', 'interface', 'mac'])\ninterface_speed
      = Gauge('unifi_interface_speed_mbps', 'Interface speed in Mbps', ['device_name',
      'interface', 'mac'])\ninterface_up = Gauge('unifi_interface_up', 'Interface
      operational status', ['device_name', 'interface', 'mac'])\n\n# Network performance
      metrics\nspeedtest_download = Gauge('unifi_speedtest_download_mbps', 'Internet
      download speed in Mbps')\nspeedtest_upload = Gauge('unifi_speedtest_upload_mbps',
      'Internet upload speed in Mbps')\nspeedtest_ping = Gauge('unifi_speedtest_ping_ms',
      'Internet ping latency in milliseconds')\nspeedtest_jitter = Gauge('unifi_speedtest_jitter_ms',
      'Internet jitter in milliseconds')\n\n# Client metrics\nclients_total = Gauge('unifi_clients_total',
      'Total number of connected clients', ['device_name', 'type'])\nclient_signal_strength
      = Gauge('unifi_client_signal_strength_dbm', 'Client signal strength in dBm',
      ['client_mac', 'device_name'])\n\nclass UniFiExporter:\n    def __init__(self):\n
      \       self.session = requests.Session()\n        self.session.verify = False
      \ # For self-signed certificates\n        self.base_url = f\"https://{UNIFI_HOST}:{UNIFI_PORT}\"\n
      \       self.logged_in = False\n        self.site_id = None\n        \n    def
      login(self):\n        \"\"\"Login to UniFi Controller using API key or username/password\"\"\"\n
      \       try:\n            # Check if API key is provided\n            if UNIFI_API_KEY:\n
      \               logger.info(\"Using API key authentication\")\n                #
      Set API key in headers for all requests\n                self.session.headers.update({\n
      \                   'X-API-KEY': UNIFI_API_KEY,\n                    'Accept':
      'application/json',\n                    'Content-Type': 'application/json'\n
      \               })\n                \n                # Get site ID dynamically\n
      \               sites_response = self.session.get(f\"{self.base_url}/proxy/network/integration/v1/sites\",
      timeout=10)\n                if sites_response.status_code == 200:\n                    sites_data
      = sites_response.json()\n                    if sites_data.get('data') and len(sites_data['data'])
      > 0:\n                        self.site_id = sites_data['data'][0]['id']  #
      Use first site\n                        logger.info(f\"Found site ID: {self.site_id}\")\n
      \                       self.logged_in = True\n                        return
      True\n                logger.error(\"Failed to get site information\")\n                return
      False\n            else:\n                # Fallback to username/password authentication\n
      \               logger.info(\"Using username/password authentication\")\n                login_data
      = {\n                    'username': UNIFI_USERNAME,\n                    'password':
      UNIFI_PASSWORD,\n                    'remember': False,\n                    'strict':
      True\n                }\n                \n                response = self.session.post(\n
      \                   f\"{self.base_url}/api/login\",\n                    json=login_data,\n
      \                   timeout=10\n                )\n                \n                if
      response.status_code == 200:\n                    self.logged_in = True\n                    logger.info(\"Successfully
      logged in to UniFi Controller\")\n                    return True\n                else:\n
      \                   logger.error(f\"Login failed: {response.status_code} - {response.text}\")\n
      \                   return False\n                    \n        except Exception
      as e:\n            logger.error(f\"Login error: {e}\")\n            return False\n
      \           \n    def logout(self):\n        \"\"\"Logout from UniFi Controller\"\"\"\n
      \       try:\n            self.session.post(f\"{self.base_url}/api/logout\")\n
      \           self.logged_in = False\n            logger.info(\"Logged out from
      UniFi Controller\")\n        except Exception as e:\n            logger.error(f\"Logout
      error: {e}\")\n            \n    def api_request(self, endpoint):\n        \"\"\"Make
      API request to UniFi Controller\"\"\"\n        if not self.logged_in:\n            if
      not self.login():\n                return None\n                \n        try:\n
      \           # Use Network API format for API key auth, legacy format for username/password\n
      \           if UNIFI_API_KEY:\n                api_url = f\"{self.base_url}/proxy/network/integration/v1/{endpoint}\"\n
      \           else:\n                api_url = f\"{self.base_url}/api/s/{UNIFI_SITE}/{endpoint}\"\n
      \               \n            response = self.session.get(api_url, timeout=10)\n
      \           \n            if response.status_code == 200:\n                return
      response.json()\n            else:\n                logger.error(f\"API request
      failed: {response.status_code}\")\n                return None\n                \n
      \       except Exception as e:\n            logger.error(f\"API request error:
      {e}\")\n            return None\n            \n    def collect_device_metrics(self):\n
      \       \"\"\"Collect device health and performance metrics\"\"\"\n        #
      Use appropriate endpoint based on auth method\n        if UNIFI_API_KEY and
      self.site_id:\n            devices_data = self.api_request(f\"sites/{self.site_id}/devices\")\n
      \       else:\n            devices_data = self.api_request(\"stat/device\")\n
      \       if not devices_data or 'data' not in devices_data:\n            logger.warning(\"No
      device data received\")\n            return\n            \n        for device
      in devices_data['data']:\n            device_name = device.get('name', device.get('model',
      'unknown'))\n            device_mac = device.get('mac', 'unknown')\n            device_model
      = device.get('model', 'unknown')\n            device_version = device.get('version',
      'unknown')\n            \n            # Device information\n            device_info.labels(\n
      \               device_name=device_name,\n                model=device_model,\n
      \               version=device_version,\n                mac=device_mac\n            ).info({\n
      \               'type': device.get('type', 'unknown'),\n                'state':
      str(device.get('state', 0)),\n                'adopted': str(device.get('adopted',
      False))\n            })\n            \n            # Device health metrics\n
      \           if 'uptime' in device:\n                device_uptime.labels(device_name=device_name,
      mac=device_mac).set(device['uptime'])\n                \n            # Temperature
      sensors\n            if 'temperatures' in device:\n                for temp_data
      in device['temperatures']:\n                    temp_name = temp_data.get('name',
      'general')\n                    temp_value = temp_data.get('value', 0)\n                    device_temperature.labels(\n
      \                       device_name=device_name,\n                        mac=device_mac,\n
      \                       sensor=temp_name\n                    ).set(temp_value)\n
      \           elif 'general_temperature' in device:\n                device_temperature.labels(\n
      \                   device_name=device_name,\n                    mac=device_mac,\n
      \                   sensor='general'\n                ).set(device['general_temperature'])\n
      \               \n            # CPU and Memory\n            if 'sys_stats' in
      device:\n                sys_stats = device['sys_stats']\n                if
      'cpu' in sys_stats:\n                    device_cpu_usage.labels(device_name=device_name,
      mac=device_mac).set(sys_stats['cpu'])\n                if 'mem' in sys_stats:\n
      \                   device_memory_usage.labels(device_name=device_name, mac=device_mac).set(sys_stats['mem'])\n
      \               if 'loadavg_1' in sys_stats:\n                    device_load_average.labels(device_name=device_name,
      mac=device_mac, period='1m').set(sys_stats['loadavg_1'])\n                if
      'loadavg_5' in sys_stats:\n                    device_load_average.labels(device_name=device_name,
      mac=device_mac, period='5m').set(sys_stats['loadavg_5'])\n                if
      'loadavg_15' in sys_stats:\n                    device_load_average.labels(device_name=device_name,
      mac=device_mac, period='15m').set(sys_stats['loadavg_15'])\n                    \n
      \           # Interface statistics\n            if 'port_table' in device:\n
      \               for port in device['port_table']:\n                    port_name
      = port.get('name', f\"port_{port.get('port_idx', 'unknown')}\")\n                    \n
      \                   # Interface status\n                    interface_up.labels(\n
      \                       device_name=device_name,\n                        interface=port_name,\n
      \                       mac=device_mac\n                    ).set(1 if port.get('up',
      False) else 0)\n                    \n                    # Interface speed\n
      \                   if 'speed' in port:\n                        interface_speed.labels(\n
      \                           device_name=device_name,\n                            interface=port_name,\n
      \                           mac=device_mac\n                        ).set(port['speed'])\n
      \                       \n                    # Traffic statistics\n                    if
      'rx_bytes' in port:\n                        interface_rx_bytes.labels(\n                            device_name=device_name,\n
      \                           interface=port_name,\n                            mac=device_mac\n
      \                       )._value._value = port['rx_bytes']\n                        \n
      \                   if 'tx_bytes' in port:\n                        interface_tx_bytes.labels(\n
      \                           device_name=device_name,\n                            interface=port_name,\n
      \                           mac=device_mac\n                        )._value._value
      = port['tx_bytes']\n                        \n                    if 'rx_packets'
      in port:\n                        interface_rx_packets.labels(\n                            device_name=device_name,\n
      \                           interface=port_name,\n                            mac=device_mac\n
      \                       )._value._value = port['rx_packets']\n                        \n
      \                   if 'tx_packets' in port:\n                        interface_tx_packets.labels(\n
      \                           device_name=device_name,\n                            interface=port_name,\n
      \                           mac=device_mac\n                        )._value._value
      = port['tx_packets']\n                        \n    def collect_client_metrics(self):\n
      \       \"\"\"Collect connected client metrics\"\"\"\n        # Use appropriate
      endpoint based on auth method\n        if UNIFI_API_KEY and self.site_id:\n
      \           clients_data = self.api_request(f\"sites/{self.site_id}/clients\")\n
      \       else:\n            clients_data = self.api_request(\"stat/sta\")\n        if
      not clients_data or 'data' not in clients_data:\n            logger.warning(\"No
      client data received\")\n            return\n            \n        # Count clients
      by type and device\n        client_counts = {}\n        \n        for client
      in clients_data['data']:\n            device_mac = client.get('ap_mac', 'unknown')\n
      \           client_mac = client.get('mac', 'unknown')\n            device_name
      = client.get('ap_name', 'unknown')\n            client_type = 'wireless' if
      client.get('is_wired', False) == False else 'wired'\n            \n            #
      Count clients\n            key = (device_name, client_type)\n            client_counts[key]
      = client_counts.get(key, 0) + 1\n            \n            # Signal strength
      for wireless clients\n            if not client.get('is_wired', False) and 'signal'
      in client:\n                client_signal_strength.labels(\n                    client_mac=client_mac,\n
      \                   device_name=device_name\n                ).set(client['signal'])\n
      \               \n        # Set client count metrics\n        for (device_name,
      client_type), count in client_counts.items():\n            clients_total.labels(device_name=device_name,
      type=client_type).set(count)\n            \n    def run_speedtest(self):\n        \"\"\"Run
      internet speed test (placeholder - would need speedtest-cli)\"\"\"\n        #
      This would integrate with speedtest-cli or similar\n        # For now, we'll
      simulate or skip\n        logger.info(\"Speedtest functionality would be implemented
      here\")\n        \n    def collect_all_metrics(self):\n        \"\"\"Collect
      all metrics from UniFi Controller\"\"\"\n        logger.info(\"Collecting UniFi
      metrics...\")\n        \n        try:\n            self.collect_device_metrics()\n
      \           self.collect_client_metrics()\n            logger.info(\"Metrics
      collection completed successfully\")\n            \n        except Exception
      as e:\n            logger.error(f\"Error collecting metrics: {e}\")\n            \n
      \   def health_check(self):\n        \"\"\"Health check endpoint\"\"\"\n        return
      self.logged_in\n        \ndef main():\n    logger.info(f\"Starting UniFi Network
      Exporter on port {EXPORTER_PORT}\")\n    logger.info(f\"Connecting to UniFi
      Controller at {UNIFI_HOST}:{UNIFI_PORT}\")\n    \n    exporter = UniFiExporter()\n
      \   \n    # Start Prometheus metrics server\n    start_http_server(EXPORTER_PORT)\n
      \   logger.info(f\"Metrics server started on port {EXPORTER_PORT}\")\n    \n
      \   # Main collection loop\n    while True:\n        try:\n            exporter.collect_all_metrics()\n
      \           time.sleep(30)  # Collect metrics every 30 seconds\n            \n
      \       except KeyboardInterrupt:\n            logger.info(\"Received interrupt
      signal, shutting down...\")\n            exporter.logout()\n            break\n
      \       except Exception as e:\n            logger.error(f\"Unexpected error:
      {e}\")\n            time.sleep(60)  # Wait before retrying\n            \nif
      __name__ == '__main__':\n    main()\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"unifi_exporter.py":"#!/usr/bin/env python3\nimport requests\nimport json\nimport time\nimport logging\nimport os\nfrom datetime import datetime\nfrom prometheus_client import start_http_server, Gauge, Info, Counter\nfrom urllib3.exceptions import InsecureRequestWarning\n\n# Disable SSL warnings for self-signed certs\nrequests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger('unifi-exporter')\n\n# Configuration from environment\nUNIFI_HOST = os.getenv('UNIFI_HOST', 'unifi-controller.local')\nUNIFI_PORT = os.getenv('UNIFI_PORT', '8443')\nUNIFI_API_KEY = os.getenv('UNIFI_API_KEY', '')\nUNIFI_USERNAME = os.getenv('UNIFI_USERNAME', 'admin')  # Fallback for non-API key auth\nUNIFI_PASSWORD = os.getenv('UNIFI_PASSWORD', 'password')  # Fallback for non-API key auth\nUNIFI_SITE = os.getenv('UNIFI_SITE', 'default')\nEXPORTER_PORT = int(os.getenv('EXPORTER_PORT', '9130'))\n\n# Prometheus metrics\ndevice_info = Info('unifi_device_info', 'UniFi device information', ['device_name', 'model', 'version', 'mac'])\ndevice_uptime = Gauge('unifi_device_uptime_seconds', 'Device uptime in seconds', ['device_name', 'mac'])\ndevice_temperature = Gauge('unifi_device_temperature_celsius', 'Device temperature in Celsius', ['device_name', 'mac', 'sensor'])\ndevice_cpu_usage = Gauge('unifi_device_cpu_usage_percent', 'Device CPU usage percentage', ['device_name', 'mac'])\ndevice_memory_usage = Gauge('unifi_device_memory_usage_percent', 'Device memory usage percentage', ['device_name', 'mac'])\ndevice_load_average = Gauge('unifi_device_load_average', 'Device load average', ['device_name', 'mac', 'period'])\n\n# Interface metrics\ninterface_rx_bytes = Counter('unifi_interface_rx_bytes_total', 'Interface received bytes', ['device_name', 'interface', 'mac'])\ninterface_tx_bytes = Counter('unifi_interface_tx_bytes_total', 'Interface transmitted bytes', ['device_name', 'interface', 'mac'])\ninterface_rx_packets = Counter('unifi_interface_rx_packets_total', 'Interface received packets', ['device_name', 'interface', 'mac'])\ninterface_tx_packets = Counter('unifi_interface_tx_packets_total', 'Interface transmitted packets', ['device_name', 'interface', 'mac'])\ninterface_rx_errors = Counter('unifi_interface_rx_errors_total', 'Interface receive errors', ['device_name', 'interface', 'mac'])\ninterface_tx_errors = Counter('unifi_interface_tx_errors_total', 'Interface transmit errors', ['device_name', 'interface', 'mac'])\ninterface_speed = Gauge('unifi_interface_speed_mbps', 'Interface speed in Mbps', ['device_name', 'interface', 'mac'])\ninterface_up = Gauge('unifi_interface_up', 'Interface operational status', ['device_name', 'interface', 'mac'])\n\n# Network performance metrics\nspeedtest_download = Gauge('unifi_speedtest_download_mbps', 'Internet download speed in Mbps')\nspeedtest_upload = Gauge('unifi_speedtest_upload_mbps', 'Internet upload speed in Mbps')\nspeedtest_ping = Gauge('unifi_speedtest_ping_ms', 'Internet ping latency in milliseconds')\nspeedtest_jitter = Gauge('unifi_speedtest_jitter_ms', 'Internet jitter in milliseconds')\n\n# Client metrics\nclients_total = Gauge('unifi_clients_total', 'Total number of connected clients', ['device_name', 'type'])\nclient_signal_strength = Gauge('unifi_client_signal_strength_dbm', 'Client signal strength in dBm', ['client_mac', 'device_name'])\n\nclass UniFiExporter:\n    def __init__(self):\n        self.session = requests.Session()\n        self.session.verify = False  # For self-signed certificates\n        self.base_url = f\"https://{UNIFI_HOST}:{UNIFI_PORT}\"\n        self.logged_in = False\n        self.site_id = None\n        \n    def login(self):\n        \"\"\"Login to UniFi Controller using API key or username/password\"\"\"\n        try:\n            # Check if API key is provided\n            if UNIFI_API_KEY:\n                logger.info(\"Using API key authentication\")\n                # Set API key in headers for all requests\n                self.session.headers.update({\n                    'X-API-KEY': UNIFI_API_KEY,\n                    'Accept': 'application/json',\n                    'Content-Type': 'application/json'\n                })\n                \n                # Get site ID dynamically\n                sites_response = self.session.get(f\"{self.base_url}/proxy/network/integration/v1/sites\", timeout=10)\n                if sites_response.status_code == 200:\n                    sites_data = sites_response.json()\n                    if sites_data.get('data') and len(sites_data['data']) \u003e 0:\n                        self.site_id = sites_data['data'][0]['id']  # Use first site\n                        logger.info(f\"Found site ID: {self.site_id}\")\n                        self.logged_in = True\n                        return True\n                logger.error(\"Failed to get site information\")\n                return False\n            else:\n                # Fallback to username/password authentication\n                logger.info(\"Using username/password authentication\")\n                login_data = {\n                    'username': UNIFI_USERNAME,\n                    'password': UNIFI_PASSWORD,\n                    'remember': False,\n                    'strict': True\n                }\n                \n                response = self.session.post(\n                    f\"{self.base_url}/api/login\",\n                    json=login_data,\n                    timeout=10\n                )\n                \n                if response.status_code == 200:\n                    self.logged_in = True\n                    logger.info(\"Successfully logged in to UniFi Controller\")\n                    return True\n                else:\n                    logger.error(f\"Login failed: {response.status_code} - {response.text}\")\n                    return False\n                    \n        except Exception as e:\n            logger.error(f\"Login error: {e}\")\n            return False\n            \n    def logout(self):\n        \"\"\"Logout from UniFi Controller\"\"\"\n        try:\n            self.session.post(f\"{self.base_url}/api/logout\")\n            self.logged_in = False\n            logger.info(\"Logged out from UniFi Controller\")\n        except Exception as e:\n            logger.error(f\"Logout error: {e}\")\n            \n    def api_request(self, endpoint):\n        \"\"\"Make API request to UniFi Controller\"\"\"\n        if not self.logged_in:\n            if not self.login():\n                return None\n                \n        try:\n            # Use Network API format for API key auth, legacy format for username/password\n            if UNIFI_API_KEY:\n                api_url = f\"{self.base_url}/proxy/network/integration/v1/{endpoint}\"\n            else:\n                api_url = f\"{self.base_url}/api/s/{UNIFI_SITE}/{endpoint}\"\n                \n            response = self.session.get(api_url, timeout=10)\n            \n            if response.status_code == 200:\n                return response.json()\n            else:\n                logger.error(f\"API request failed: {response.status_code}\")\n                return None\n                \n        except Exception as e:\n            logger.error(f\"API request error: {e}\")\n            return None\n            \n    def collect_device_metrics(self):\n        \"\"\"Collect device health and performance metrics\"\"\"\n        # Use appropriate endpoint based on auth method\n        if UNIFI_API_KEY and self.site_id:\n            devices_data = self.api_request(f\"sites/{self.site_id}/devices\")\n        else:\n            devices_data = self.api_request(\"stat/device\")\n        if not devices_data or 'data' not in devices_data:\n            logger.warning(\"No device data received\")\n            return\n            \n        for device in devices_data['data']:\n            device_name = device.get('name', device.get('model', 'unknown'))\n            device_mac = device.get('mac', 'unknown')\n            device_model = device.get('model', 'unknown')\n            device_version = device.get('version', 'unknown')\n            \n            # Device information\n            device_info.labels(\n                device_name=device_name,\n                model=device_model,\n                version=device_version,\n                mac=device_mac\n            ).info({\n                'type': device.get('type', 'unknown'),\n                'state': str(device.get('state', 0)),\n                'adopted': str(device.get('adopted', False))\n            })\n            \n            # Device health metrics\n            if 'uptime' in device:\n                device_uptime.labels(device_name=device_name, mac=device_mac).set(device['uptime'])\n                \n            # Temperature sensors\n            if 'temperatures' in device:\n                for temp_data in device['temperatures']:\n                    temp_name = temp_data.get('name', 'general')\n                    temp_value = temp_data.get('value', 0)\n                    device_temperature.labels(\n                        device_name=device_name,\n                        mac=device_mac,\n                        sensor=temp_name\n                    ).set(temp_value)\n            elif 'general_temperature' in device:\n                device_temperature.labels(\n                    device_name=device_name,\n                    mac=device_mac,\n                    sensor='general'\n                ).set(device['general_temperature'])\n                \n            # CPU and Memory\n            if 'sys_stats' in device:\n                sys_stats = device['sys_stats']\n                if 'cpu' in sys_stats:\n                    device_cpu_usage.labels(device_name=device_name, mac=device_mac).set(sys_stats['cpu'])\n                if 'mem' in sys_stats:\n                    device_memory_usage.labels(device_name=device_name, mac=device_mac).set(sys_stats['mem'])\n                if 'loadavg_1' in sys_stats:\n                    device_load_average.labels(device_name=device_name, mac=device_mac, period='1m').set(sys_stats['loadavg_1'])\n                if 'loadavg_5' in sys_stats:\n                    device_load_average.labels(device_name=device_name, mac=device_mac, period='5m').set(sys_stats['loadavg_5'])\n                if 'loadavg_15' in sys_stats:\n                    device_load_average.labels(device_name=device_name, mac=device_mac, period='15m').set(sys_stats['loadavg_15'])\n                    \n            # Interface statistics\n            if 'port_table' in device:\n                for port in device['port_table']:\n                    port_name = port.get('name', f\"port_{port.get('port_idx', 'unknown')}\")\n                    \n                    # Interface status\n                    interface_up.labels(\n                        device_name=device_name,\n                        interface=port_name,\n                        mac=device_mac\n                    ).set(1 if port.get('up', False) else 0)\n                    \n                    # Interface speed\n                    if 'speed' in port:\n                        interface_speed.labels(\n                            device_name=device_name,\n                            interface=port_name,\n                            mac=device_mac\n                        ).set(port['speed'])\n                        \n                    # Traffic statistics\n                    if 'rx_bytes' in port:\n                        interface_rx_bytes.labels(\n                            device_name=device_name,\n                            interface=port_name,\n                            mac=device_mac\n                        )._value._value = port['rx_bytes']\n                        \n                    if 'tx_bytes' in port:\n                        interface_tx_bytes.labels(\n                            device_name=device_name,\n                            interface=port_name,\n                            mac=device_mac\n                        )._value._value = port['tx_bytes']\n                        \n                    if 'rx_packets' in port:\n                        interface_rx_packets.labels(\n                            device_name=device_name,\n                            interface=port_name,\n                            mac=device_mac\n                        )._value._value = port['rx_packets']\n                        \n                    if 'tx_packets' in port:\n                        interface_tx_packets.labels(\n                            device_name=device_name,\n                            interface=port_name,\n                            mac=device_mac\n                        )._value._value = port['tx_packets']\n                        \n    def collect_client_metrics(self):\n        \"\"\"Collect connected client metrics\"\"\"\n        # Use appropriate endpoint based on auth method\n        if UNIFI_API_KEY and self.site_id:\n            clients_data = self.api_request(f\"sites/{self.site_id}/clients\")\n        else:\n            clients_data = self.api_request(\"stat/sta\")\n        if not clients_data or 'data' not in clients_data:\n            logger.warning(\"No client data received\")\n            return\n            \n        # Count clients by type and device\n        client_counts = {}\n        \n        for client in clients_data['data']:\n            device_mac = client.get('ap_mac', 'unknown')\n            client_mac = client.get('mac', 'unknown')\n            device_name = client.get('ap_name', 'unknown')\n            client_type = 'wireless' if client.get('is_wired', False) == False else 'wired'\n            \n            # Count clients\n            key = (device_name, client_type)\n            client_counts[key] = client_counts.get(key, 0) + 1\n            \n            # Signal strength for wireless clients\n            if not client.get('is_wired', False) and 'signal' in client:\n                client_signal_strength.labels(\n                    client_mac=client_mac,\n                    device_name=device_name\n                ).set(client['signal'])\n                \n        # Set client count metrics\n        for (device_name, client_type), count in client_counts.items():\n            clients_total.labels(device_name=device_name, type=client_type).set(count)\n            \n    def run_speedtest(self):\n        \"\"\"Run internet speed test (placeholder - would need speedtest-cli)\"\"\"\n        # This would integrate with speedtest-cli or similar\n        # For now, we'll simulate or skip\n        logger.info(\"Speedtest functionality would be implemented here\")\n        \n    def collect_all_metrics(self):\n        \"\"\"Collect all metrics from UniFi Controller\"\"\"\n        logger.info(\"Collecting UniFi metrics...\")\n        \n        try:\n            self.collect_device_metrics()\n            self.collect_client_metrics()\n            logger.info(\"Metrics collection completed successfully\")\n            \n        except Exception as e:\n            logger.error(f\"Error collecting metrics: {e}\")\n            \n    def health_check(self):\n        \"\"\"Health check endpoint\"\"\"\n        return self.logged_in\n        \ndef main():\n    logger.info(f\"Starting UniFi Network Exporter on port {EXPORTER_PORT}\")\n    logger.info(f\"Connecting to UniFi Controller at {UNIFI_HOST}:{UNIFI_PORT}\")\n    \n    exporter = UniFiExporter()\n    \n    # Start Prometheus metrics server\n    start_http_server(EXPORTER_PORT)\n    logger.info(f\"Metrics server started on port {EXPORTER_PORT}\")\n    \n    # Main collection loop\n    while True:\n        try:\n            exporter.collect_all_metrics()\n            time.sleep(30)  # Collect metrics every 30 seconds\n            \n        except KeyboardInterrupt:\n            logger.info(\"Received interrupt signal, shutting down...\")\n            exporter.logout()\n            break\n        except Exception as e:\n            logger.error(f\"Unexpected error: {e}\")\n            time.sleep(60)  # Wait before retrying\n            \nif __name__ == '__main__':\n    main()\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"unifi-exporter-script","namespace":"monitoring"}}
    creationTimestamp: "2025-06-01T22:34:09Z"
    name: unifi-exporter-script
    namespace: monitoring
    resourceVersion: "1859483"
    uid: 59c40a0e-8c72-49d7-aeab-8222b0e4a48d
- apiVersion: v1
  data:
    webhook-logger.py: "#!/usr/bin/env python3\nimport json\nimport logging\nfrom
      datetime import datetime\nfrom http.server import HTTPServer, BaseHTTPRequestHandler\nimport
      base64\nimport os\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n
      \   format='%(asctime)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler('/var/log/webhook-alerts.log'),\n
      \       logging.StreamHandler()\n    ]\n)\n\nlogger = logging.getLogger(__name__)\n\nclass
      WebhookHandler(BaseHTTPRequestHandler):\n    def do_POST(self):\n        try:\n
      \           # Basic auth check\n            auth_header = self.headers.get('Authorization',
      '')\n            if auth_header.startswith('Basic '):\n                encoded_creds
      = auth_header.split(' ')[1]\n                decoded_creds = base64.b64decode(encoded_creds).decode('utf-8')\n
      \               username, password = decoded_creds.split(':', 1)\n                if
      username != 'odin' or password != 'monitoring':\n                    self.send_response(401)\n
      \                   self.end_headers()\n                    return\n            else:\n
      \               self.send_response(401)\n                self.end_headers()\n
      \               return\n\n            # Read the request body\n            content_length
      = int(self.headers['Content-Length'])\n            post_data = self.rfile.read(content_length)\n
      \           \n            # Parse JSON\n            alert_data = json.loads(post_data.decode('utf-8'))\n
      \           \n            # Log the alert\n            timestamp = datetime.now().isoformat()\n
      \           endpoint = self.path\n            \n            logger.info(f\"===
      ALERT RECEIVED [{timestamp}] ===\")\n            logger.info(f\"Endpoint: {endpoint}\")\n
      \           logger.info(f\"Status: {alert_data.get('status', 'unknown')}\")\n
      \           \n            # Log each alert\n            for alert in alert_data.get('alerts',
      []):\n                alert_name = alert.get('labels', {}).get('alertname',
      'Unknown')\n                severity = alert.get('labels', {}).get('severity',
      'unknown')\n                summary = alert.get('annotations', {}).get('summary',
      'No summary')\n                description = alert.get('annotations', {}).get('description',
      'No description')\n                \n                logger.info(f\"  Alert:
      {alert_name}\")\n                logger.info(f\"  Severity: {severity}\")\n
      \               logger.info(f\"  Summary: {summary}\")\n                logger.info(f\"
      \ Description: {description}\")\n                logger.info(f\"  Labels: {json.dumps(alert.get('labels',
      {}))}\")\n            \n            logger.info(\"=== END ALERT ===\")\n            \n
      \           # Send response\n            self.send_response(200)\n            self.send_header('Content-type',
      'application/json')\n            self.end_headers()\n            response =
      {'status': 'success', 'message': 'Alert received'}\n            self.wfile.write(json.dumps(response).encode('utf-8'))\n
      \           \n        except Exception as e:\n            logger.error(f\"Error
      processing webhook: {e}\")\n            self.send_response(500)\n            self.end_headers()\n\n
      \   def do_GET(self):\n        # Health check endpoint\n        if self.path
      == '/health':\n            self.send_response(200)\n            self.send_header('Content-type',
      'application/json')\n            self.end_headers()\n            response =
      {'status': 'healthy', 'service': 'webhook-logger'}\n            self.wfile.write(json.dumps(response).encode('utf-8'))\n
      \       else:\n            self.send_response(404)\n            self.end_headers()\n\n
      \   def log_message(self, format, *args):\n        # Suppress default HTTP server
      logs\n        pass\n\nif __name__ == '__main__':\n    port = int(os.environ.get('PORT',
      8080))\n    server = HTTPServer(('0.0.0.0', port), WebhookHandler)\n    logger.info(f\"Webhook
      logger started on port {port}\")\n    try:\n        server.serve_forever()\n
      \   except KeyboardInterrupt:\n        logger.info(\"Webhook logger stopped\")\n
      \       server.shutdown()\n"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"webhook-logger.py":"#!/usr/bin/env python3\nimport json\nimport logging\nfrom datetime import datetime\nfrom http.server import HTTPServer, BaseHTTPRequestHandler\nimport base64\nimport os\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler('/var/log/webhook-alerts.log'),\n        logging.StreamHandler()\n    ]\n)\n\nlogger = logging.getLogger(__name__)\n\nclass WebhookHandler(BaseHTTPRequestHandler):\n    def do_POST(self):\n        try:\n            # Basic auth check\n            auth_header = self.headers.get('Authorization', '')\n            if auth_header.startswith('Basic '):\n                encoded_creds = auth_header.split(' ')[1]\n                decoded_creds = base64.b64decode(encoded_creds).decode('utf-8')\n                username, password = decoded_creds.split(':', 1)\n                if username != 'odin' or password != 'monitoring':\n                    self.send_response(401)\n                    self.end_headers()\n                    return\n            else:\n                self.send_response(401)\n                self.end_headers()\n                return\n\n            # Read the request body\n            content_length = int(self.headers['Content-Length'])\n            post_data = self.rfile.read(content_length)\n            \n            # Parse JSON\n            alert_data = json.loads(post_data.decode('utf-8'))\n            \n            # Log the alert\n            timestamp = datetime.now().isoformat()\n            endpoint = self.path\n            \n            logger.info(f\"=== ALERT RECEIVED [{timestamp}] ===\")\n            logger.info(f\"Endpoint: {endpoint}\")\n            logger.info(f\"Status: {alert_data.get('status', 'unknown')}\")\n            \n            # Log each alert\n            for alert in alert_data.get('alerts', []):\n                alert_name = alert.get('labels', {}).get('alertname', 'Unknown')\n                severity = alert.get('labels', {}).get('severity', 'unknown')\n                summary = alert.get('annotations', {}).get('summary', 'No summary')\n                description = alert.get('annotations', {}).get('description', 'No description')\n                \n                logger.info(f\"  Alert: {alert_name}\")\n                logger.info(f\"  Severity: {severity}\")\n                logger.info(f\"  Summary: {summary}\")\n                logger.info(f\"  Description: {description}\")\n                logger.info(f\"  Labels: {json.dumps(alert.get('labels', {}))}\")\n            \n            logger.info(\"=== END ALERT ===\")\n            \n            # Send response\n            self.send_response(200)\n            self.send_header('Content-type', 'application/json')\n            self.end_headers()\n            response = {'status': 'success', 'message': 'Alert received'}\n            self.wfile.write(json.dumps(response).encode('utf-8'))\n            \n        except Exception as e:\n            logger.error(f\"Error processing webhook: {e}\")\n            self.send_response(500)\n            self.end_headers()\n\n    def do_GET(self):\n        # Health check endpoint\n        if self.path == '/health':\n            self.send_response(200)\n            self.send_header('Content-type', 'application/json')\n            self.end_headers()\n            response = {'status': 'healthy', 'service': 'webhook-logger'}\n            self.wfile.write(json.dumps(response).encode('utf-8'))\n        else:\n            self.send_response(404)\n            self.end_headers()\n\n    def log_message(self, format, *args):\n        # Suppress default HTTP server logs\n        pass\n\nif __name__ == '__main__':\n    port = int(os.environ.get('PORT', 8080))\n    server = HTTPServer(('0.0.0.0', port), WebhookHandler)\n    logger.info(f\"Webhook logger started on port {port}\")\n    try:\n        server.serve_forever()\n    except KeyboardInterrupt:\n        logger.info(\"Webhook logger stopped\")\n        server.shutdown()\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"webhook-logger-script","namespace":"monitoring"}}
    creationTimestamp: "2025-05-28T17:28:42Z"
    name: webhook-logger-script
    namespace: monitoring
    resourceVersion: "37040"
    uid: 8cb26114-4941-4652-9964-ab6417a23d86
kind: List
metadata:
  resourceVersion: ""
